title,comment,vote,views,bookmarks,created,modified,languages
linux command to get size of files and directories present in a particular folder? [closed],"
                    
            
        
            
                
                    
                        Closed. This question does not meet Stack Overflow guidelines. It is not currently accepting answers.
                        
                    
                
            
        
            
        
                
                    
                
            
                
                    Want to improve this question? Update the question so it's on-topic for Stack Overflow.
                
                    Closed 1 year ago.

            
        
            
                    
                        Improve this question
                    
            

    

How can I see the size of files and directories in Linux? If use df -m, then it shows the size of all the directory at the top level, but, for the directories and files inside the directory, how do I check the size?
    Use ls command for files and du command for directories.

Checking File Sizes

ls -l filename   #Displays Size of the specified file
ls -l *          #Displays Size of All the files in the current directory
ls -al *         #Displays Size of All the files including hidden files in the current directory
ls -al dir/      #Displays Size of All the files including hidden files in the 'dir' directory


ls command will not list the actual size of directories(why?). Therefore, we use du for this purpose.

Checking Directory sizes

du -sh directory_name    #Gives you the summarized(-s) size of the directory in human readable(-h) format
du -bsh *                #Gives you the apparent(-b) summarized(-s) size of all the files and directories in the current directory in human readable(-h) format


Including -h option in any of the above commands (for Ex: ls -lh * or du -sh) will give you size in human readable format (kb, mb,gb, ...)

For more information see man ls and man du
    Use ls -s to list file size, or if you prefer ls -sh for human readable sizes.

For directories use du, and again, du -h for human readable sizes.
    There is du command.
Size of a directory and/or file, in a human-friendly way:
$ du -sh .bashrc /tmp

I memorised it as a non-existent English word dush.

--apparent-size command line switch makes it measure apparent sizes (what ls shows) rather than actual disk usage.
    There is also a great ncdu utility - it can show directory size with detailed info about subfolders and files.

Installation

Ubuntu:

$ sudo apt-get install ncdu


Usage

Just type ncdu [path] in the command line. After a few seconds for analyzing the path, you will see something like this:

$ ncdu 1.11 ~ Use the arrow keys to navigate, press ? for help
--- / ---------------------------------------------------------
.  96,1 GiB [##########] /home
.  17,7 GiB [#         ] /usr
.   4,5 GiB [          ] /var
    1,1 GiB [          ] /lib
  732,1 MiB [          ] /opt
. 275,6 MiB [          ] /boot
  198,0 MiB [          ] /storage
. 153,5 MiB [          ] /run
.  16,6 MiB [          ] /etc
   13,5 MiB [          ] /bin
   11,3 MiB [          ] /sbin
.   8,8 MiB [          ] /tmp
.   2,2 MiB [          ] /dev
!  16,0 KiB [          ] /lost+found
    8,0 KiB [          ] /media
    8,0 KiB [          ] /snap
    4,0 KiB [          ] /lib64
e   4,0 KiB [          ] /srv
!   4,0 KiB [          ] /root
e   4,0 KiB [          ] /mnt
e   4,0 KiB [          ] /cdrom
.   0,0   B [          ] /proc
.   0,0   B [          ] /sys
@   0,0   B [          ]  initrd.img.old
@   0,0   B [          ]  initrd.img
@   0,0   B [          ]  vmlinuz.old
@   0,0   B [          ]  vmlinuz


Delete the currently highlighted element with d, exit with CTRL + c
    You can use:

ls -lh

Using this command you'll see the apparent space of the directory and true space of the files and in details the names of the files displayed, besides the size and creation date of each.
    You can use ncdu disk usage analyzer here. It displays the size of the files and directories in an ncurses interface. You can navigate to each directory and see the files sizes from the same interface.

To install

$ sudo apt-get install ncdu


To analyze

$ ncdu <directory>



    Go to the chosen directory and execute:

$ du -d 1 -h


where:

-d 1 is the depth of the directories

-h is the human-readable option


You'll see like that:

0   ./proc
8.5M    ./run
0   ./sys
56M ./etc
12G ./root
33G ./var
23M ./tmp
3.2G    ./usr
154M    ./boot
26G ./home
0   ./media
0   ./mnt
421M    ./opt
0   ./srv
2.6G    ./backups
80G .

    File Size in MB

ls -l --b=M  filename | cut -d "" "" -f5


File Size in GB

ls -l --b=G  filename | cut -d "" "" -f5

    All you need is -l and --block-size flags

Size of all files and directories under working directory (in MBs)

ls -l --block-size=M




Size of all files and directories under working directory (in GBs)

ls -l --block-size=G




Size of a specific file or directory

ls -l --block-size=M my_file.txt
ls -l --block-size=M my_dir/





ls --help

  
  -l                         use a long listing format
  
  --block-size=SIZE:       scale sizes by SIZE before printing them; e.g.,
                                 '--block-size=M' prints sizes in units of
                                 1,048,576 bytes; see SIZE format below
  
  SIZE is an integer and optional unit (example: 10M is 10*1024*1024). 
  Units are K, M, G, T, P, E, Z, Y (powers of 1024) or KB, MB, ...
  (powers of 1000).



    ls -sh video.mp4 | sed s/video.mp4//g

output,
5.6M
    
  du -sh [file_name]


works perfectly to get size of a particular file.
    If you are using it in a script, use stat.

$ date | tee /tmp/foo
Wed Mar 13 05:36:31 UTC 2019

$ stat -c %s /tmp/foo
29

$ ls -l /tmp/foo
-rw-r--r--  1 bruno  wheel  29 Mar 13 05:36 /tmp/foo


That will give you size in bytes.  See man stat for more output format options.

The OSX/BSD equivalent is:

$ date | tee /tmp/foo
Wed Mar 13 00:54:16 EDT 2019

$ stat -f %z /tmp/foo
29

$ ls -l /tmp/foo
-rw-r--r--  1 bruno  wheel  29 Mar 13 00:54 /tmp/foo

    I prefer this command ll -sha.
    ls -l --block-size=M will give you a long format listing (needed to actually see the file size) and round file sizes up to the nearest MiB.

If you want MB (10^6 bytes) rather than MiB (2^20 bytes) units, use --block-size=MB instead.

If you don't want the M suffix attached to the file size, you can use something like --block-size=1M. Thanks Stéphane Chazelas for suggesting this.

This is described in the man page for ls; man ls and search for SIZE. It allows for units other than MB/MiB as well, and from the looks of it (I didn't try that) arbitrary block sizes as well (so you could see the file size as number of 412-byte blocks, if you want to).

Note that the --block-size parameter is a GNU extension on top of the Open Group's ls, so this may not work if you don't have a GNU userland (which most Linux installations do). The ls from GNU coreutils 8.5 does support --block-size as described above. 
    You can use below command to get list of files in easily human readable format.


  ls -lrtsh

    Use ls command with -h argument: [root@hots19 etc]#  ls -lh
h : for human readable.

Exemple: 
    [root@CIEYY1Z3 etc]# ls -lh
    total 1.4M
    -rw-r--r--.  1 root   root      44M Sep 15  2015 adjtime
    -rw-r--r--.  1 root   root     1.5K Jun  7  2013 aliases
    -rw-r--r--   1 root   root      12K Nov 25  2015 aliases.db
    drwxr-xr-x.  2 root   root     4.0K Jan 11  2018 alternatives
    -rw-------.  1 root   root      541 Jul  8  2014 anacrontab
    -rw-r--r--.  1 root   root      55M Sep 16  2014 asound.conf
    -rw-r--r--.  1 root   root       1G Oct  6  2014 at.deny

    I'm a Ubuntu 16.04 user myself and I find that the ll command is by far the easiest way to see a directory's contents. I've noticed that not all Linux distributions support this command, but there's probably a workaround/install for each distro out there.

Example:

user@user-XPS-15-9560:/$ ll
total 188
drwxr-xr-x  27 root root  4096 Jan 26 09:13 ./
drwxr-xr-x  27 root root  4096 Jan 26 09:13 ../
drwxr-xr-x   2 root root  4096 Jan 22 15:13 bin/
drwxr-xr-x   4 root root 12288 Jan 29 11:35 boot/
drwxr-xr-x   2 root root  4096 Sep  3 18:14 cdrom/
drwxr-xr-x  20 root root  4440 Feb  5 08:43 dev/
drwxr-xr-x 153 root root 12288 Feb  2 15:17 etc/
drwxr-xr-x   4 root root  4096 Sep  3 18:15 home/
...


The biggest advantage for me is that it's quick and really intuitive to use. 

UPDATE: what I didn't know was that on Ubuntu it's a pre-configured alias. You can easily set it yourself by executing alias ll=""ls -la"" on the command line, or by adding this entry in your .bashrc config file:

sudo nano ~/.bashrc
...add line described above and save file by pressing Ctrl+X and Y...
source ~/.bashrc

    To get the total size of directory or the total size of file use,

du -csh <directory or filename*> | grep total

    I do the following all the time:

$ du -sh backup-lr-May-02-2017-1493723588.tar.gz


NB: 

-s, --summarize
            display only a total for each argument
-h, --human-readable
            print sizes in human readable format (e.g., 1K 234M 2G)

    You have to differenciate between file size and disk usage. The main difference between the two comes from the fact that files are ""cut into pieces"" and stored in blocks.

Modern block size is 4KiB, so files will use disk space multiple of 4KiB, regardless of how small they are.

If you use the command stat you can see both figures side by side. 

stat file.c


If you want a more compact view for a directory, you can use ls -ls, which will give you usage in 1KiB units.

ls -ls dir


Also du will give you real disk usage, in 1KiB units, or dutree with the -u flag.

Example: usage of a 1 byte file

$ echo """" > file.c

$ ls -l file.c
-rw-r--r-- 1 nacho nacho 1 Apr 30 20:42 file.c

$ ls -ls file.c
4 -rw-r--r-- 1 nacho nacho 1 Apr 30 20:42 file.c

$ du file.c
4 file.c

$ dutree file.c
[ file.c 1 B ]

$ dutree -u file.c
[ file.c 4.00 KiB ]

$ stat file.c
 File: file.c
 Size: 1 Blocks: 8 IO Block: 4096 regular file
Device: 2fh/47d Inode: 2185244 Links: 1
Access: (0644/-rw-r--r--) Uid: ( 1000/ nacho) Gid: ( 1000/ nacho)
Access: 2018-04-30 20:41:58.002124411 +0200
Modify: 2018-04-30 20:42:24.835458383 +0200
Change: 2018-04-30 20:42:24.835458383 +0200
 Birth: -


In addition, in modern filesystems we can have snapshots, sparse files (files with holes in them) that further complicate the situation.

You can see more details in this article: understanding file size in Linux
    you can use ls -sh in linux you can do sort also
you need  to go to dir where you want to check the size of files
    go to specific directory then run below command 

# du -sh * 

4.0K    1
4.0K    anadb.sh --> Shell file
4.0K    db.sh/    --> shell file
24K     backup4/  --> Directory
8.0K    backup6/  --> Directory 
1.9G    backup.sql.gz  --> sql file

    ","[495, 740, 139, 195, 45, 53, 6, 27, 32, 14, 3, 6, 11, 2, 19, 10, 6, 4, 5, 7, 2, 1, 1]",1416877,121,2012-07-30T10:57:06,2021-11-24 01:51:00Z,
How to set environment variables from within package.json?,"
                
How to set some environment variables from within package.json to be used with npm start like commands?

Here's what I currently have in my package.json:

{
  ...
  ""scripts"": {
    ""help"": ""tagove help"",
    ""start"": ""tagove start""
  }
  ...
}


I want to set environment variables (like NODE_ENV) in the start script while still being able to start the app with just one command, npm start.
    Set the environment variable in the script command:
...
""scripts"": {
  ""start"": ""node app.js"",
  ""test"": ""NODE_ENV=test mocha --reporter spec""
},
...

Then use process.env.NODE_ENV in your app.
Note: This is for Mac & Linux only. For Windows refer to the comments.
    Just use NPM package cross-env. Super easy. Works on Windows, Linux, and all environments. Notice that you don't use && to move to the next task. You just set the env and then start the next task. Credit to @mikekidder for the suggestion in one of the comments here. 

From documentation:

{
  ""scripts"": {
    ""build"": ""cross-env NODE_ENV=production OTHERFLAG=myValue webpack --config build/webpack.config.js""
  }
}


Notice that if you want to set multiple global vars, you just state them in succession, followed by your command to be executed.

Ultimately, the command that is executed (using spawn) is:

webpack --config build/webpack.config.js


The NODE_ENV environment variable will be set by cross-env
    I just wanted to add my two cents here for future Node-explorers. On my Ubuntu 14.04 the NODE_ENV=test didn't work, I had to use export NODE_ENV=test after which NODE_ENV=test started working too, weird.
On Windows as have been said you have to use set NODE_ENV=test but for a cross-platform solution the cross-env library didn't seem to do the trick and do you really need a library to do this:
export NODE_ENV=test || set NODE_ENV=test&& yadda yadda

The vertical bars are needed as otherwise Windows would crash on the unrecognized export NODE_ENV command. I don't know about the trailing space, but just to be sure I removed them too.
    Because I often find myself working with multiple environment variables, I find it useful to keep them in a separate .env file (make sure to ignore this from your source control). Then (in Linux) prepend export $(cat .env | xargs) &&  in your script command before starting your app.
Example .env file:
VAR_A=Hello World
VAR_B=format the .env file like this with new vars separated by a line break

Example index.js:
console.log('Test', process.env.VAR_A, process.env.VAR_B);

Example package.json:
{
  ...
  ""scripts"": {
    ""start"": ""node index.js"",

    ""env-linux"": ""export $(cat .env | xargs) && env"",
    ""start-linux"": ""export $(cat .env | xargs) && npm start"",

    ""env-windows"": ""(for /F \""tokens=*\"" %i in (.env) do set %i)"",
    ""start-windows"": ""(for /F \""tokens=*\"" %i in (.env) do set %i) && npm start"",

  }
  ...
}

Unfortunately I can't seem to set the environment variables by calling a script from a script -- like ""start-windows"": ""npm run env-windows && npm start"" -- so there is some redundancy in the scripts.
For a test you can see the env variables by running npm run env-linux or npm run env-windows, and test that they make it into your app by running npm run start-linux or npm run start-windows.
    Most elegant and portable solution:
package.json:
""scripts"": {
    ""serve"": ""export NODE_PRESERVE_SYMLINKS_MAIN=1 && vue-cli-service serve""
    },

Under windows create export.cmd and put it somewhere to your %PATH%:
@echo off

set %*

    For a larger set of environment variables or when you want to reuse them you can use env-cmd.

./.env file:

# This is a comment
ENV1=THANKS
ENV2=FOR ALL
ENV3=THE FISH


./package.json:

{
  ""scripts"": {
    ""test"": ""env-cmd mocha -R spec""
  }
}

    When the NODE_ENV environment variable is set to 'production' all devDependencies in your package.json file will be completely ignored when running npm install. You can also enforce this with a --production flag:
npm install --production

For setting NODE_ENV you can use any of these methods
method 1: set NODE_ENV for all node apps
Windows :
set NODE_ENV=production

Linux, macOS or other unix based system :
export NODE_ENV=production

This sets NODE_ENV for current bash session thus any apps started after this statement will have NODE_ENV set to production.
method 2: set NODE_ENV for current app
NODE_ENV=production node app.js

This will set NODE_ENV for the current app only. This helps when we want to test our apps on different environments.
method 3: create .env file and use it
This uses the idea explained here. Refer this post for more detailed explanation.
Basically, you create a .env file and run some bash scripts to set them on the environment.
To avoid writing a bash script, the env-cmd package can be used to load the environment variables defined in the .env file.
env-cmd .env node app.js

method 4: Use cross-env package
This package allows environment variables to be set in one way for every platform.
After installing it with npm, you can just add it to your deployment script in package.json as follows:
""build:deploy"": ""cross-env NODE_ENV=production webpack""

    Try this on Windows by replacing YOURENV: 

  {
    ...
     ""scripts"": {
       ""help"": ""set NODE_ENV=YOURENV && tagove help"",
       ""start"": ""set NODE_ENV=YOURENV && tagove start""
     }
    ...
  }

    @luke's answer was almost the one I needed! Thanks.
As the selected answer is very straightforward (and correct), but old, I would like to offer an alternative for importing variables from a .env separate file when running your scripts and fixing some limitations to Luke's answer.
Try this:
::: .env file :::
# This way, you CAN use comments in your .env files
NODE_PATH=""src/""

# You can also have extra/empty lines in it
SASS_PATH=""node_modules:src/styles""


Then, in your package json, you will create a script that will set the variables and run it before the scripts you need them:
::: package.json :::
scripts: {
  ""set-env"": ""export $(cat .env | grep \""^[^#;]\"" |xargs)"",
  ""storybook"": ""npm run set-env && start-storybook -s public""
}

Some observations:

The regular expression in the grep'ed cat command will clear the comments and empty lines.

The && don't need to be ""glued"" to npm run set-env, as it would be required if you were setting the variables in the same command.

If you are using yarn, you may see a warning, you can either change it to yarn set-env or use npm run set-env --scripts-prepend-node-path && instead.


Different environments
Another advantage when using it is that you can have different environment variables.
scripts: {
  ""set-env:production"": ""export $(cat .production.env | grep \""^[^#;]\"" |xargs)"",
  ""set-env:development"": ""export $(cat .env | grep \""^[^#;]\"" |xargs)"",
}


Please, remember not to add .env files to your git repository when you have keys, passwords or sensitive/personal data in them!

    UPDATE: This solution may break in npm v7 due to npm RFC 21

npm (and yarn) passes a lot of data from package.json into scripts as environment variables.  Use npm run env to see them all.  This is documented in https://docs.npmjs.com/misc/scripts#environment and is not only for ""lifecycle"" scripts like prepublish but also any script executed by npm run.
You can access these inside code (e.g. process.env.npm_package_config_port in JS) but they're already available to the shell running the scripts so you can also access them as $npm_... expansions in the ""scripts"" (unix syntax, might not work on windows?).
The ""config"" section seems intended for this use:
  ""name"": ""myproject"",
  ...
  ""config"": {
    ""port"": ""8010""
  },
  ""scripts"": {
    ""start"": ""node server.js $npm_package_config_port"",
    ""test"": ""wait-on http://localhost:$npm_package_config_port/ && node test.js http://localhost:$npm_package_config_port/""
  } 

An important quality of these ""config"" fields is that users can override them without modifying package.json!
$ npm run start

> myproject@0.0.0 start /home/cben/mydir
> node server.js $npm_package_config_port

Serving on localhost:8010

$ npm config set myproject:port 8020
$ git diff package.json  # no change!
$ cat ~/.npmrc
myproject:port=8020

$ npm run start

> myproject@0.0.0 start /home/cben/mydir
> node server.js $npm_package_config_port

Serving on localhost:8020

See npm config and yarn config docs.
It appears that yarn reads ~/.npmrc so npm config set affects both, but yarn config set writes to ~/.yarnrc, so only yarn will see it :-(
    For single environment variable
 ""scripts"": {
    ""start"": ""set NODE_ENV=production&& node server.js""
 }

For multiple environment variables
 ""scripts"": {
    ""start"": ""set NODE_ENV=production&& set PORT=8000&& node server.js""
 }

    This will work in Windows console:
""scripts"": {
  ""setAndStart"": ""set TMP=test&& node index.js"",
  ""otherScriptCmd"": ""echo %TMP%""
}

npm run aaa
output:
test
See this answer for details.
    use git bash in windows. Git Bash processes commands differently than cmd.

Most Windows command prompts will choke when you set environment variables with NODE_ENV=production like that. (The exception is Bash on Windows, which uses native Bash.) Similarly, there's a difference in how windows and POSIX commands utilize environment variables. With POSIX, you use: $ENV_VAR and on windows you use %ENV_VAR%. - cross-env doc

{
  ...
  ""scripts"": {
    ""help"": ""tagove help"",
    ""start"": ""env NODE_ENV=production tagove start""
  }
  ...
}


use dotenv package to declare the env variables
    suddenly i found that actionhero is using following code, that solved my problem by just passing --NODE_ENV=production in start script command option.

if(argv['NODE_ENV'] != null){
  api.env = argv['NODE_ENV'];
} else if(process.env.NODE_ENV != null){
  api.env = process.env.NODE_ENV;
}


i would really appreciate to accept answer of someone else who know more better way to set environment variables in package.json or init script or something like, where app bootstrapped by someone else.
    {
  ...
  ""scripts"": {
    ""start"": ""ENV NODE_ENV=production someapp --options""
  }
  ...
}

    You should not set ENV variables in package.json. actionhero uses NODE_ENV to allow you to change configuration options which are loaded from the files in ./config.  Check out the redis config file, and see how NODE_ENV is uses to change database options in NODE_ENV=test

If you want to use other ENV variables to set things (perhaps the HTTP port), you still don't need to change anything in package.json.  For example, if you set PORT=1234 in ENV and want to use that as the HTTP port in NODE_ENV=production, just reference that in the relevant config file, IE: 

# in config/servers/web.js
exports.production = { 
  servers: {
    web: function(api){
      return {
       port: process.env.PORT
      }
    }
  }
}

    Although not directly answering the question I´d like to share an idea on top of the other answers. From what I got each of these would offer some level of complexity to achieve cross platform independency.

On my scenario all I wanted, originally, to set a variable to control whether or not to secure the server with JWT authentication (for development purposes)

After reading the answers I decided simply to create 2 different files, with authentication turned on and off respectively.

  ""scripts"": {
    ""dev"": ""nodemon --debug  index_auth.js"",
    ""devna"": ""nodemon --debug  index_no_auth.js"",
  }


The files are simply wrappers that call the original index.js file (which I renamed to appbootstrapper.js):

//index_no_auth.js authentication turned off
const bootstrapper = require('./appbootstrapper');
bootstrapper(false);

//index_auth.js authentication turned on
const bootstrapper = require('./appbootstrapper');
bootstrapper(true);

class AppBootStrapper {

    init(useauth) {
        //real initialization
    }
}


Perhaps this can help someone else
    Note : In order to set multiple environment variable, script should goes like this
  ""scripts"": {
    ""start"": ""set NODE_ENV=production&& set MONGO_USER=your_DB_USER_NAME&& set MONGO_PASSWORD=DB_PASSWORD&& set MONGO_DEFAULT_DATABASE=DB_NAME&& node app.js"",
  },

    ","[495, 640, 326, 72, 64, 3, 12, 4, 30, 13, 12, 6, 12, 9, 10, 5, 1, 2, 0]",697176,109,2014-08-04T05:55:27,2021-11-13 21:39:30Z,
How to update Xcode from command line,"
                
I am trying to update Xcode from the command line.  Initially I tried running:

 xcode-select --install


which resulted in this message:

xcode-select: error: command line tools are already installed, use ""Software Update"" to install updates


So the question remains, is there a way to update Xcode from the command line? 
    What you are actually using is the command to install the Xcode command line tools - xcode-select --install. Hence the error message you got - the tools are already installed.

The command you need to update Xcode is softwareupdate command [args ...]. You can use softwareupdate --list to see what's available and then softwareupdate --install -a to install all updates or softwareupdate --install <product name> to install just the Xcode update (if available). You can get the name from the list command.

As it was mentioned in the comments here is the man page for the softwareupdate tool.

2019 Update

A lot of users are experiencing problems where softwareupdate --install -a will in fact not update to the newest version of Xcode. The cause for this is more than likely a pending macOS update (as @brianlmerritt pointed out below). In most cases updating macOS first will solve the problem and allow Xcode to be updated as well.

Updating the Xcode Command Line Tools

A large portion of users are landing on this answer in an attempt to update the Xcode Command Line Tools. The easiest way to achieve this is by removing the old version of the tools, and installing the new one.

sudo rm -rf /Library/Developer/CommandLineTools
xcode-select --install


A popup will appear and guide you through the rest of the process.
    I had the same issue and I solved by doing the following:


removing the old tools ($ sudo rm -rf /Library/Developer/CommandLineTools)
install xcode command line tools again ($ xcode-select --install).


After these steps you will see a pop to install the new version of the tools.
    I encountered the same issue when I uninstalled the complete version of Xcode to reinstall the CLI version. My fix was:

sudo xcode-select -s /Library/Developer/CommandLineTools
    After installing Command Line Tools (with xcode-select --install), type:

sudo xcode-select --switch /Library/Developer/CommandLineTools/


You should be able to run git now:

10:29 $ git --version
git version 2.17.2 (Apple Git-113)

    I was facing the same problem, resolved it by using the following command.
sudo xcode-select -s /Library/Developer/CommandLineTools
After running the above command then xcode-select -p  command showed the following.
/Library/Developer/CommandLineTools
    I was able to update via CLI using:
softwareupdate --list --verbose

and then
softwareupdate -i Command\ Line\ Tools\ for\ Xcode-13.2

    I am not sure why this was so tricky for me.
sudo xcode-select --install

Did nothing for me.
softwareupdate --all --install --force

Did nothing for me.
I had to do things in the following order
sudo rm -rf /Library/Developer/CommandLineTools
sudo xcode-select --install

This installed a newer xcode, but not latest.
Then I did
softwareupdate --all --install --force

and they updated completely.
    I got this error after deleting Xcode. I fixed it by resetting the command line tools path with sudo xcode-select -r. 

Before:

navin@Radiant ~$ /usr/bin/clang
xcrun: error: active developer path (""/Applications/Xcode.app/Contents/Developer"") does not exist
Use `sudo xcode-select --switch path/to/Xcode.app` to specify the Xcode that you wish to use for command line developer tools, or use `xcode-select --install` to install the standalone command line developer tools.
See `man xcode-select` for more details.

navin@Radiant ~$ xcode-select --install
xcode-select: error: command line tools are already installed, use ""Software Update"" to install updates


After:

navin@Radiant ~$ /usr/bin/clang
clang: error: no input files

    I am now running OS Big Sur. xcode-select --install, and sudo xcode-select --reset did not resolve my issue, neither did the recommended subsequent softwareupdate --install -a command. For good measure, I tried the recommended download from Apple Downloads, but the Command Line Tools downloads available there are not compatible with my OS.
I upvoted the fix that resolved for me, sudo xcode-select --switch /Library/Developer/CommandLineTools/ and added this post for environment context.
    Just type the commands
cd  /Library/Developer/CommandLineTools/Packages/;
open macOS_SDK_headers_for_macOS_10.14.pkg


Reference: https://forums.developer.apple.com/thread/104296
    $ sudo rm -rf /Library/Developer/CommandLineTools
$ xcode-select --install

    I arrived here trying to install Appium. Adding my answer in case other folks land here for the same issue.

appium-doctor --ios

... bunch of stuff...
WARN AppiumDoctor  ✖ Error running xcrun simctl
... bunch of stuff...
info AppiumDoctor ### Manual Fixes Needed ###
info AppiumDoctor The configuration cannot be automatically fixed, please do the
following first:
WARN AppiumDoctor  ➜ Manually install Xcode, and make sure 'xcode-select -p' command shows proper path like '/Applications/Xcode.app/Contents/Developer'
In my case

xcode-select -p

/Library/Developer/CommandLineTools
which appeared wrong...but I knew I had recently updated Xcode and the command line tools
so...

sudo xcode-select -r (sudo required)

then...

xcode-select -p
/Applications/Xcode.app/Contents/Developer

After this, no warning. Appium-doctor returned clean.
    @Vel Genov's answer is correct, except when the version of Xcode can't be updated because it is the latest version for your current version of Mac OS.  If you know there is a newer Xcode (for example, it won't load an app onto a device with a recent version of iOS) then it's necessary to first upgrade Mac OS.

Further note for those like me with old Mac Pro 5.1.  Upgrading to Mojave required installing the metal gpu (Sapphire AMD Radeon RX 560 in my case) but make sure only HDMI monitor is installed (not 4K!  1080 only).  Only then did install Mojave say firmware update required and shut computer down.  Long 2 minute power button hold and it all upgraded fine after that!

Catalina update - softwareupdate --install -a won't upgrade xcode from command line if there is a pending update (say you selected update xcode overnight)
    I was trying to use the React-Native Expo app with create-react-native-app but for some reason it would launch my simulator and just hang without loading the app. The above answer by ipinak above reset the Xcode CLI tools because attempting to update to most recent Xcode CLI was not working. the two commands are:

rm -rf /Library/Developer/CommandLineTools
xcode-select --install


This process take time because of the download.
I am leaving this here for any other would be searches for this specific React-Native Expo fix.
    To those having this issue after update to Catalina, just execute this command on your terminal

sudo rm -rf /Library/Developer/CommandLineTools; xcode-select --install;

    Xcode::Install is a simple cli software that allow you to install/select a specific Xcode version.

You can install it using gem install xcode-install
Then you will be able to install a specific version with xcversion install 9.4.1
And if you have more than one version installed, you can switch version with xcversion select 9.4

You can find more information at https://github.com/KrauseFx/xcode-install
    Hello I solved it like this:

Install Application> Xcode.app> Contents> Resources> Packages> XcodeSystemResources.pkg.
    xCode version 11.2.1 is necessary for building app in iPad 13.2.3, When I directly try to upgrade from xcode 11.1 to 11.2.1 through App Store it get struck, So after some research , I found a solution to upgrade by removing the existing xcode from the system

So here I am adding the steps to upgrade after uninstalling existing xcode.


  
  Go to Applications and identify Xcode and drag it to trash.
  Empty trash to permenently delete Xcode.
  Now go to ~/Library/Developer/ folder and remove the contents completely    Use sudo rm -rf  ~/Library/Developer/ to avoid any
  permission issue while deleting
  Lastly remove any cache directory associated with xcode in the path ~/Library/Caches/com.apple.dt.Xcode    sudo rm -rf
  ~/Library/Caches/com.apple.dt.Xcode/*
  After completing the above steps you can easly install xcode from App Store, which will install the current latest version of xcode
  


Note: Please take a backup of your existing projects before making the above changes
    Update with this one-liner.
softwareupdate --install -a

    ","[495, 709, 276, 71, 28, 11, 1, 1, 25, 5, 21, 13, 1, 9, 4, -1, 8, 1, 0, 0]",541173,136,2016-01-05T17:14:19,2022-02-20 12:48:41Z,
Removing Conda environment,"
                
I want to remove a certain environment created with conda. How can I achieve that? Let's say I have an active testenv environment. I tried, by following documentation, with:

$ conda env remove

CondaEnvironmentError: cannot remove current environment. deactivate and run conda remove again


I then deactivate it:

$ source deactivate


I try running again the command to remove it and I still get the same error. What is going wrong here?
    You probably didn't fully deactivate the Conda environment - remember, the command you need to use with Conda is conda deactivate (for older versions, use source deactivate). So it may be wise to start a new shell and activate the environment in that before you try. Then deactivate it.

You can use the command

conda env remove -n ENV_NAME


to remove the environment with that name. (--name is equivalent to -n)

Note that you can also place environments anywhere you want using -p /path/to/env instead of -n ENV_NAME when both creating and deleting environments, if you choose. They don't have to live in your conda installation.

UPDATE, 30 Jan 2019: From Conda 4.6 onwards the conda activate command becomes the new official way to activate an environment across all platforms. The changes are described in this Anaconda blog post
    After making sure your environment is not active, type:

$ conda env remove --name ENVIRONMENT

    If you are in base:
(base) HP-Compaq-Elite-8300-CMT:~$ 

remove env_name by:
conda env remove -n env_name


if you are already in env_name environment :
(env_name) HP-Compaq-Elite-8300-CMT:~$ 

deactivate then remove by :
conda deactivate
conda env remove -n env_name

    Official documentation way worked for me:

conda remove --name myenv --all


Or just conda env remove --name myenv.

To verify that the environment was removed, in your terminal window or an Anaconda Prompt, run:

conda info --envs


The environments list that displays should not show the removed environment.

You anaconda3 enviroments folder might list an empty folder of deleted environment in your anaconda3 installation folder, like:

/opt/anaconda3/envs

    In my windows 10 Enterprise edition os this code works fine:
(suppose for environment namely testenv)
conda env remove --name testenv

    Environments created with the --prefix or -p flag must be removed with the -p flag (not -n). 

For example: 
conda remove -p </filepath/myenvironment> --all, in which </filepath/myenvironment> is substituted with a complete or relative path to the environment.
    To remove complete conda environment :
conda remove --name YOUR_CONDA_ENV_NAME --all
    There're 3 ways to achieve this in total. Assuming you have a environment named myenv,


conda env remove --name myenv, -n is shortcut for --name.
conda remove --name myenv --all.
Delete the env folder directly. (Not recommended)

# list environments and their locations
conda env list
# or
# conda info --envs

# delete the folder listed
rm -rf /Users/username/.local/share/conda/envs/myenv





If you wanna delete the environment without a prompt to let you check again. Use -y, shortcut for --yes. (For global use check silent prompt in conda)

conda env remove -n myenv -y
conda remove -n myenv --all -y


References


conda env --help
conda remove --help

    You may try the following: Open anaconda command prompt and type

conda remove --name myenv --all


This will remove the entire environment.

Further reading: docs.conda.io > Manage Environments
    if you are unfamiliar with the command line , you can remove it using the anaconda dashboard

    View the environments in Anaconda or miniconda:
conda env list

If you have created an environment using name then use:
conda remove -n envname --all


if you have created an environment using prefix then use:
conda remove -p [path] --all

Change the envname with your environment name and in case of prefix provide the complete path of the environment eg: C:/Users/techv/Desktop/project/env. 
--all will remove all the dependencies of the target environment.
I hope this answer will be helpful.
    My environment name is: test

conda remove -n test --all

    First you have to deactivate your environment before removing it. You can remove conda environment by using the following command

Suppose your environment name is ""sample_env"" , you can remove this environment by using

source deactivate    
conda remove -n sample_env --all


'--all' will be used to remove all the dependencies
    Use source deactivate to deactivate the environment before removing it,  replace ENV_NAME with the environment you wish to remove:

source deactivate
conda env remove -n ENV_NAME

    on terminal it's showing
(base) [root@localhost ~]#
simply hit command :  conda deactivate
and you are out of conda env , now your prompt will look like
[root@localhost ~]#
    This worked for me:

conda env remove --name tensorflow

    First deactivate the environment and come back to the base environment. From the base, you should be able to run the command conda env remove -n <envname>. This will give you the message 

Remove all packages in environment 
C:\Users\<username>\AppData\Local\Continuum\anaconda3\envs\{envname}:
    Because you can only deactivate the active environment, so conda deactivate does not need nor accept arguments. The error message is very explicit here.

Just call conda deactivate
https://github.com/conda/conda/issues/7296#issuecomment-389504269
    ","[495, 674, 154, 52, 66, 46, 38, 16, 35, 18, 1, 0, 14, 14, 9, -3, 5, 6, -1]",922035,102,2018-03-06T09:49:50,2022-03-12 08:32:39Z,python 
TypeScript and React - children type?,"
                
I have a very simple functional component as follows:

import * as React from 'react';

export interface AuxProps  { 
    children: React.ReactNode
 }


const aux = (props: AuxProps) => props.children;

export default aux;


And another component:

import * as React from ""react"";

export interface LayoutProps  { 
   children: React.ReactNode
}

const layout = (props: LayoutProps) => (
    <Aux>
        <div>Toolbar, SideDrawer, Backdrop</div>
        <main>
            {props.children}
        </main>
    <Aux/>
);

export default layout;


I keep on getting the following error:


  [ts]
  JSX element type 'ReactNode' is not a constructor function for JSX elements.
    Type 'undefined' is not assignable to type 'ElementClass'. [2605]


How do I type this correctly?
    Just children: React.ReactNode.
    You can also use React.PropsWithChildren<P>.
type ComponentWithChildProps = React.PropsWithChildren<{example?: string}>;

    You can use ReactChildren and ReactChild:
import React, { ReactChildren, ReactChild } from 'react';
 
interface AuxProps {
  children: ReactChild | ReactChildren;
}

const Aux = ({ children }: AuxProps) => (<div>{children}</div>);

export default Aux;

If you need to pass flat arrays of elements:
interface AuxProps {
  children: ReactChild | ReactChild[] | ReactChildren | ReactChildren[];
}

    In order to use <Aux> in your JSX, it needs to be a function that returns ReactElement<any> | null. That's the definition of a function component.

However, it's currently defined as a function that returns React.ReactNode, which is a much wider type. As React typings say:

type ReactNode = ReactChild | ReactFragment | ReactPortal | boolean | null | undefined;


Make sure the unwanted types are neutralized by wrapping the returned value into React Fragment (<></>):

const aux: React.FC<AuxProps> = props =>
  <>{props.children}</>;

    This is what worked for me:

interface Props {
  children: JSX.Element[] | JSX.Element
}


Edit I would recommend using children: React.ReactNode instead now.
    import { ReactNode, FC } from 'react'

type Props = { children: ReactNode }

const App: FC<Props> = ({children}) => (<div>{children}</div>)

    I'm using the following
type Props = { children: React.ReactNode };

const MyComponent: React.FC<Props> = ({children}) => {
  return (
    <div>
      { children }
    </div>
  );

export default MyComponent;

    As a type that contains children, I'm using:

type ChildrenContainer = Pick<JSX.IntrinsicElements[""div""], ""children"">


This children container type is generic enough to support all the different cases and also aligned with the ReactJS API.

So, for your example it would be something like:

const layout = ({ children }: ChildrenContainer) => (
    <Aux>
        <div>Toolbar, SideDrawer, Backdrop</div>
        <main>
            {children}
        </main>
    <Aux/>
)

    For me @Sibren's answer was not clear enough but I found this SO anwer and made it all inline (that's maybe not the shortest way but the one I find the easiest to grasp).
function MyComponentWithChildren({
    customProp,
    children, /*notice the children are implicit*/
}: React.PropsWithChildren<{ customProp: any }>) {
    return <div>{children}</div>;
}

    These answers appear to be outdated - React now has a built in type PropsWithChildren<{}>. It is defined similarly to some of the correct answers on this page:

type PropsWithChildren<P> = P & { children?: ReactNode };
    A React Node is one of the following types:

Boolean (which is ignored)
null or undefined (which is ignored)
Number
String
A React element (result of JSX)
An array of any of the above, possibly a nested one

    You can also use JSX.ElementChildrenAttribute
export default function Layout({children}: JSX.ElementChildrenAttribute) {
    return <div>
        {children}
    </div>
}

    The function component return type is limited to JSXElement | null in TypeScript. This is a current type limitation, pure React allows more return types.
Minimal demonstration snippet
You can either use a type assertion or Fragments as workaround:
const Aux = (props: AuxProps) => <>props.children</>; 
const Aux2 = (props: AuxProps) => props.children as ReactElement; 


ReactNode
children: React.ReactNode might be suboptimal, if the goal is to have strong types for Aux.
Almost anything can be assigned to current ReactNode type, which is equivalent to {} | undefined | null. A safer type for your case could be:
interface AuxProps {
  children: ReactElement | ReactElement[]
}

Example:
Given Aux needs React elements as children, we accidently added a string to it. Then above solution would error in contrast to ReactNode - take a look at the linked playgrounds.
Typed children are also useful for non-JSX props, like a Render Prop callback.
    The general way to find any type is by example. The beauty of typescript is that you have access to all types, so long as you have the correct @types/ files.

To answer this myself I just thought of a component react uses that has the children prop. The first thing that came to mind? How about a <div />?

All you need to do is open vscode and create a new .tsx file in a react project with @types/react.

import React from 'react';

export default () => (
  <div children={'test'} />
);



Hovering over the children prop shows you the type. And what do you know -- Its type is ReactNode (no need for ReactNode[]).



Then if you click into the type definition it brings you straight to the definition of children coming from DOMAttributes interface.

// node_modules/@types/react/index.d.ts
interface DOMAttributes<T> {
  children?: ReactNode;
  ...
}



  Note: This process should be used to find any unknown type! All of them are there just waiting for you to find them :)

    
you should know that any react component should return null or React.Element, but the type of props.children is React.ReactNode, so you need to use the props.children inside an Element to make the babel configure the constructor of the Element.

the second rule of any react component is that the first letter of the naming should be a capital letter to let the react recognize that the component isn't a html tag.


so the code should be like this.
const Aux = (props: AuxProps) => <>props.children</>;


another hint if you still using typescript, the functional component should be type of React.FC like this
type Props = {
   title: string;
}

const Aux:React.FC<Props> = (props) =>
(
    <div>
        <h3>{props.title}</h3>
        { props.children }
        {/* children is exist by default in type React.FC */}
    </div>
)

    From the TypeScript site: https://github.com/Microsoft/TypeScript/issues/6471 


  The recommended practice is to write the props type as {children?:
  any}


That worked for me. The child node can be many different things, so explicit typing can miss cases. 

There's a longer discussion on the followup issue here: https://github.com/Microsoft/TypeScript/issues/13618, but the any approach still works. 
    This has always worked for me:
type Props = {
  children: JSX.Element;
};

    you can declare your component like this:

const MyComponent: React.FunctionComponent = (props) => {
    return props.children;
}

    React components should have a single wrapper node or return an array of nodes.

Your <Aux>...</Aux> component has two nodes div and main.

Try to wrap your children in a div in Aux component.

import * as React from 'react';

export interface AuxProps  { 
  children: React.ReactNode
}

const aux = (props: AuxProps) => (<div>{props.children}</div>);

export default aux;

    this solution works perfectly fine for me
interface Props {
    children: Array<ReactElement<ChildProps, JSXElementConstructor<ChildType>>>;
}

    You can create a simple component that outputs just children prop without type or interface with FC (functional component). You have to wrap with empty jsx tags <>, as children can be undefined or null:
import { FC } from ""react"";

export const Layout: FC = (props) => {
  return <>{props.children}</>;
};

-- or --
import { FC } from ""react"";

export const Layout: FC = ({ children }) => <>{children}</>;

    ","[495, 598, 60, 81, 98, 73, 10, 13, 3, 1, 7, 18, 7, 13, 11, 1, 9, 5, 15, -4, 0, 0]",351858,53,2018-12-09T02:38:33,2022-04-21 17:09:03Z,typescript 
How do I find the time difference between two datetime objects in python?,"
                
How do I tell the time difference in minutes between two datetime objects?
    Using datetime example
>>> from datetime import datetime
>>> then = datetime(2012, 3, 5, 23, 8, 15)        # Random date in the past
>>> now  = datetime.now()                         # Now
>>> duration = now - then                         # For build-in functions
>>> duration_in_s = duration.total_seconds()      # Total number of seconds between dates

Duration in years
>>> years = divmod(duration_in_s, 31536000)[0]    # Seconds in a year=365*24*60*60 = 31536000.

Duration in days
>>> days  = duration.days                         # Build-in datetime function
>>> days  = divmod(duration_in_s, 86400)[0]       # Seconds in a day = 86400

Duration in hours
>>> hours = divmod(duration_in_s, 3600)[0]        # Seconds in an hour = 3600

Duration in minutes
>>> minutes = divmod(duration_in_s, 60)[0]        # Seconds in a minute = 60

Duration in seconds
[!] See warning about using duration in seconds in the bottom of this post
>>> seconds = duration.seconds                    # Build-in datetime function
>>> seconds = duration_in_s

Duration in microseconds
[!] See warning about using duration in microseconds in the bottom of this post
>>> microseconds = duration.microseconds          # Build-in datetime function

Total duration between the two dates
>>> days    = divmod(duration_in_s, 86400)        # Get days (without [0]!)
>>> hours   = divmod(days[1], 3600)               # Use remainder of days to calc hours
>>> minutes = divmod(hours[1], 60)                # Use remainder of hours to calc minutes
>>> seconds = divmod(minutes[1], 1)               # Use remainder of minutes to calc seconds
>>> print(""Time between dates: %d days, %d hours, %d minutes and %d seconds"" % (days[0], hours[0], minutes[0], seconds[0]))

or simply:
>>> print(now - then)


Edit 2019
Since this answer has gained traction, I'll add a function, which might simplify the usage for some
from datetime import datetime

def getDuration(then, now = datetime.now(), interval = ""default""):

    # Returns a duration as specified by variable interval
    # Functions, except totalDuration, returns [quotient, remainder]

    duration = now - then # For build-in functions
    duration_in_s = duration.total_seconds() 
    
    def years():
      return divmod(duration_in_s, 31536000) # Seconds in a year=31536000.

    def days(seconds = None):
      return divmod(seconds if seconds != None else duration_in_s, 86400) # Seconds in a day = 86400

    def hours(seconds = None):
      return divmod(seconds if seconds != None else duration_in_s, 3600) # Seconds in an hour = 3600

    def minutes(seconds = None):
      return divmod(seconds if seconds != None else duration_in_s, 60) # Seconds in a minute = 60

    def seconds(seconds = None):
      if seconds != None:
        return divmod(seconds, 1)   
      return duration_in_s

    def totalDuration():
        y = years()
        d = days(y[1]) # Use remainder to calculate next variable
        h = hours(d[1])
        m = minutes(h[1])
        s = seconds(m[1])

        return ""Time between dates: {} years, {} days, {} hours, {} minutes and {} seconds"".format(int(y[0]), int(d[0]), int(h[0]), int(m[0]), int(s[0]))

    return {
        'years': int(years()[0]),
        'days': int(days()[0]),
        'hours': int(hours()[0]),
        'minutes': int(minutes()[0]),
        'seconds': int(seconds()),
        'default': totalDuration()
    }[interval]

# Example usage
then = datetime(2012, 3, 5, 23, 8, 15)
now = datetime.now()

print(getDuration(then)) # E.g. Time between dates: 7 years, 208 days, 21 hours, 19 minutes and 15 seconds
print(getDuration(then, now, 'years'))      # Prints duration in years
print(getDuration(then, now, 'days'))       #                    days
print(getDuration(then, now, 'hours'))      #                    hours
print(getDuration(then, now, 'minutes'))    #                    minutes
print(getDuration(then, now, 'seconds'))    #                    seconds

Warning: Caveat about built-in .seconds and .microseconds
datetime.seconds and datetime.microseconds are capped to [0,86400) and [0,10^6) respectively.
They should be used carefully if timedelta is bigger than the max returned value.
Examples:
end is 1h and 200μs after start:
>>> start = datetime(2020,12,31,22,0,0,500)
>>> end = datetime(2020,12,31,23,0,0,700)
>>> delta = end - start
>>> delta.microseconds
RESULT: 200
EXPECTED: 3600000200

end is 1d and 1h after start:
>>> start = datetime(2020,12,30,22,0,0)
>>> end = datetime(2020,12,31,23,0,0)
>>> delta = end - start
>>> delta.seconds
RESULT: 3600
EXPECTED: 90000

    >>> import datetime
>>> first_time = datetime.datetime.now()
>>> later_time = datetime.datetime.now()
>>> difference = later_time - first_time
datetime.timedelta(0, 8, 562000)
>>> seconds_in_day = 24 * 60 * 60
>>> divmod(difference.days * seconds_in_day + difference.seconds, 60)
(0, 8)      # 0 minutes, 8 seconds

Subtracting the later time from the first time difference = later_time - first_time creates a datetime object that only holds the difference.
In the example above it is 0 minutes, 8 seconds and 562000 microseconds.
    Just subtract one from the other. You get a timedelta object with the difference.
>>> import datetime
>>> d1 = datetime.datetime.now()
>>> d2 = datetime.datetime.now() # after a 5-second or so pause
>>> d2 - d1
datetime.timedelta(0, 5, 203000)
>>> dd = d2 - d1
>>> print (dd.days) # get days
>>> print (dd.seconds) # get seconds
>>> print (dd.microseconds) # get microseconds
>>> print (int(round(dd.total_seconds()/60, 0))) # get minutes

    To just find the number of days: timedelta has a 'days' attribute. You can simply query that.

>>>from datetime import datetime, timedelta
>>>d1 = datetime(2015, 9, 12, 13, 9, 45)
>>>d2 = datetime(2015, 8, 29, 21, 10, 12)
>>>d3 = d1- d2
>>>print d3
13 days, 15:59:33
>>>print d3.days
13

    To get the hour, minute and second, you can do this
>>> import datetime
>>> first_time = datetime.datetime.now()
>>> later_time = datetime.datetime.now()
>>> difference = later_time - first_time
>>> m, s = divmod(difference.total_seconds(), 60)
>>> print(""H:M:S is {}:{}:{}"".format(m//60, m%60, s))

    If a, b are datetime objects then to find the time difference between them in Python 3:

from datetime import timedelta

time_difference = a - b
time_difference_in_minutes = time_difference / timedelta(minutes=1)


On earlier Python versions:

time_difference_in_minutes = time_difference.total_seconds() / 60


If a, b are naive datetime objects such as returned by datetime.now() then the result may be wrong if the objects represent local time with different UTC offsets e.g., around DST transitions or for past/future dates. More details: Find if 24 hrs have passed between datetimes - Python.

To get reliable results, use UTC time or timezone-aware datetime objects.
    New at Python 2.7 is the timedelta instance method .total_seconds(). From the Python docs, this is equivalent to (td.microseconds + (td.seconds + td.days * 24 * 3600) * 10**6) / 10**6.

Reference: http://docs.python.org/2/library/datetime.html#datetime.timedelta.total_seconds

>>> import datetime
>>> time1 = datetime.datetime.now()
>>> time2 = datetime.datetime.now() # waited a few minutes before pressing enter
>>> elapsedTime = time2 - time1
>>> elapsedTime
datetime.timedelta(0, 125, 749430)
>>> divmod(elapsedTime.total_seconds(), 60)
(2.0, 5.749430000000004) # divmod returns quotient and remainder
# 2 minutes, 5.74943 seconds

    Just thought it might be useful to mention formatting as well in regards to timedelta. strptime() parses a string representing a time according to a format.

from datetime import datetime

datetimeFormat = '%Y/%m/%d %H:%M:%S.%f'    
time1 = '2016/03/16 10:01:28.585'
time2 = '2016/03/16 09:56:28.067'  
time_dif = datetime.strptime(time1, datetimeFormat) - datetime.strptime(time2,datetimeFormat)
print(time_dif)


This will output:
    0:05:00.518000
    This will give the difference in seconds (then just divide by 60 to get minutes):
import time
import datetime

t_start = datetime.datetime.now()

time.sleep(10)

t_end = datetime.datetime.now()
elapsedTime = (t_end - t_start )

print(elapsedTime.total_seconds())

outputs:
10.009222

This is the simplest way in my opinion, and you don't need to worry about precision or overflow.
For instance, using elapsedTime.seconds you lose a lot of precision (it returns an integer). Also, elapsedTime.microseconds is capped at 10^6, as this answer pointed out. So, for example, for a 10 second sleep(), elapsedTime.microseconds gives 8325  (which is wrong, should be around 10,000,000).
    Use divmod:

now = int(time.time()) # epoch seconds
then = now - 90000 # some time in the past

d = divmod(now-then,86400)  # days
h = divmod(d[1],3600)  # hours
m = divmod(h[1],60)  # minutes
s = m[1]  # seconds

print '%d days, %d hours, %d minutes, %d seconds' % (d[0],h[0],m[0],s)

    This is how I get the number of hours that elapsed between two datetime.datetime objects:

before = datetime.datetime.now()
after  = datetime.datetime.now()
hours  = math.floor(((after - before).seconds) / 3600)

    I use somethign like this :

from datetime import datetime

def check_time_difference(t1: datetime, t2: datetime):
    t1_date = datetime(
        t1.year,
        t1.month,
        t1.day,
        t1.hour,
        t1.minute,
        t1.second)

    t2_date = datetime(
        t2.year,
        t2.month,
        t2.day,
        t2.hour,
        t2.minute,
        t2.second)

    t_elapsed = t1_date - t2_date

    return t_elapsed

# usage 
f = ""%Y-%m-%d %H:%M:%S+01:00""
t1 = datetime.strptime(""2018-03-07 22:56:57+01:00"", f)
t2 = datetime.strptime(""2018-03-07 22:48:05+01:00"", f)
elapsed_time = check_time_difference(t1, t2)

print(elapsed_time)
#return : 0:08:52

    You may find this fast snippet useful in not so much long time intervals:
    from datetime import datetime as dttm
    time_ago = dttm(2017, 3, 1, 1, 1, 1, 1348)
    delta = dttm.now() - time_ago
    days = delta.days # can be converted into years which complicates a bit…
    hours, minutes, seconds = map(int, delta.__format__('').split('.')[0].split(' ')[-1].split(':'))

tested on Python v.3.8.6
    Based on @Attaque great answer, I propose a shorter simplified version of the datetime difference calculator:

seconds_mapping = {
    'y': 31536000,
    'm': 2628002.88, # this is approximate, 365 / 12; use with caution
    'w': 604800,
    'd': 86400,
    'h': 3600,
    'min': 60,
    's': 1,
    'mil': 0.001,
}

def get_duration(d1, d2, interval, with_reminder=False):
    if with_reminder:
        return divmod((d2 - d1).total_seconds(), seconds_mapping[interval])
    else:
        return (d2 - d1).total_seconds() / seconds_mapping[interval]


I've changed it to avoid declaring repetetive functions, removed the pretty print default interval and added support for milliseconds, weeks and ISO months (bare in mind months are just approximate, based on assumption that each month is equal to 365/12).

Which produces:

d1 = datetime(2011, 3, 1, 1, 1, 1, 1000)
d2 = datetime(2011, 4, 1, 1, 1, 1, 2500)

print(get_duration(d1, d2, 'y', True))      # => (0.0, 2678400.0015)
print(get_duration(d1, d2, 'm', True))      # => (1.0, 50397.12149999989)
print(get_duration(d1, d2, 'w', True))      # => (4.0, 259200.00149999978)
print(get_duration(d1, d2, 'd', True))      # => (31.0, 0.0014999997802078724)
print(get_duration(d1, d2, 'h', True))      # => (744.0, 0.0014999997802078724)
print(get_duration(d1, d2, 'min', True))    # => (44640.0, 0.0014999997802078724)
print(get_duration(d1, d2, 's', True))      # => (2678400.0, 0.0014999997802078724)
print(get_duration(d1, d2, 'mil', True))    # => (2678400001.0, 0.0004999997244524721)

print(get_duration(d1, d2, 'y', False))     # => 0.08493150689687975
print(get_duration(d1, d2, 'm', False))     # => 1.019176965856293
print(get_duration(d1, d2, 'w', False))     # => 4.428571431051587
print(get_duration(d1, d2, 'd', False))     # => 31.00000001736111
print(get_duration(d1, d2, 'h', False))     # => 744.0000004166666
print(get_duration(d1, d2, 'min', False))   # => 44640.000024999994
print(get_duration(d1, d2, 's', False))     # => 2678400.0015
print(get_duration(d1, d2, 'mil', False))   # => 2678400001.4999995

    this is to find the difference between current time and 9.30 am

t=datetime.now()-datetime.now().replace(hour=9,minute=30)

    I have used time differences for continuous integration tests to check and improve my functions. Here is simple code if somebody need it

from datetime import datetime

class TimeLogger:
    time_cursor = None

    def pin_time(self):
        global time_cursor
        time_cursor = datetime.now()

    def log(self, text=None) -> float:
        global time_cursor

        if not time_cursor:
            time_cursor = datetime.now()

        now = datetime.now()
        t_delta = now - time_cursor

        seconds = t_delta.total_seconds()

        result = str(now) + ' tl -----------> %.5f' % seconds
        if text:
            result += ""   "" + text
        print(result)

        self.pin_time()

        return seconds


time_logger = TimeLogger()


Using:

from .tests_time_logger import time_logger
class Tests(TestCase):
    def test_workflow(self):
    time_logger.pin_time()

    ... my functions here ...

    time_logger.log()

    ... other function(s) ...

    time_logger.log(text='Tests finished')


and i have something like that in log output

2019-12-20 17:19:23.635297 tl -----------> 0.00007
2019-12-20 17:19:28.147656 tl -----------> 4.51234   Tests finished

    This is my approach using mktime.

from datetime import datetime, timedelta
from time import mktime

yesterday = datetime.now() - timedelta(days=1)
today = datetime.now()

difference_in_seconds = abs(mktime(yesterday.timetuple()) - mktime(today.timetuple()))
difference_in_minutes = difference_in_seconds / 60

    In Other ways to get difference between date;

import dateutil.parser
import datetime
last_sent_date = """" # date string
timeDifference = current_date - dateutil.parser.parse(last_sent_date)
time_difference_in_minutes = (int(timeDifference.days) * 24 * 60) + int((timeDifference.seconds) / 60)


So get output in Min.

Thanks
    import datetime
date = datetime.date(1, 1, 1)
#combine a dummy date to the time
datetime1 = datetime.datetime.combine(date, start_time)
datetime2 = datetime.datetime.combine(date, stop_time)  
#compute the difference
time_elapsed = datetime1 - datetime2

start_time --> start time for datetime object 
end_time--> end time for datetime object 
we cannot directly subtract the datetime.time objects 
hence we need to add a random date to it (we use combine) 
or you can use the ""today"" instead of (1,1,1) 
hope this helps
    Here is an answer that is easy to generalise or turn into a function and which is reasonable compact and easy to follow.
ts_start=datetime(2020, 12, 1, 3, 9, 45)
ts_end=datetime.now()
ts_diff=ts_end-ts_start
secs=ts_diff.total_seconds()
days,secs=divmod(secs,secs_per_day:=60*60*24)
hrs,secs=divmod(secs,secs_per_hr:=60*60)
mins,secs=divmod(secs,secs_per_min:=60)
secs=round(secs, 2)
answer='Duration={} days, {} hrs, {} mins and {} secs'.format(int(days),int(hrs),int(mins),secs)
print(answer)

It gives an answer in the form Duration=270 days, 10 hrs, 32 mins and 42.13 secs
    ","[495, 217, 480, 39, 12, 4, 27, 167, 12, 3, 19, 12, 4, 1, 1, 2, 1, 1, 1, -1, 0]",791380,90,2009-08-28T09:03:15,2022-01-10 09:00:27Z,python 
Pretty printing XML in Python,"
                
What is the best way (or are the various ways) to pretty print XML in Python?
    import xml.dom.minidom

dom = xml.dom.minidom.parse(xml_fname) # or xml.dom.minidom.parseString(xml_string)
pretty_xml_as_string = dom.toprettyxml()

    You have a few options.
xml.etree.ElementTree.indent()
Batteries included, simple to use, pretty output.
But requires Python 3.9+
import xml.etree.ElementTree as ET

element = ET.XML(""<html><body>text</body></html>"")
ET.indent(element)
print(ET.tostring(element, encoding='unicode'))

BeautifulSoup.prettify()
BeautifulSoup may be the simplest solution for Python < 3.9.
from bs4 import BeautifulSoup

bs = BeautifulSoup(open(xml_file), 'xml')
pretty_xml = bs.prettify()
print(pretty_xml)

Output:

<?xml version=""1.0"" encoding=""utf-8""?>
<issues>
 <issue>
  <id>
   1
  </id>
  <title>
   Add Visual Studio 2005 and 2008 solution files
  </title>
 </issue>
</issues>


This is my goto answer. The default arguments work as is. But text contents are spread out on separate lines as if they were nested elements.
lxml.etree.parse()
Prettier output but with arguments.
from lxml import etree

x = etree.parse(FILE_NAME)
pretty_xml = etree.tostring(x, pretty_print=True, encoding=str)

Produces:

  <issues>
    <issue>
      <id>1</id>
      <title>Add Visual Studio 2005 and 2008 solution files</title>
      <details>We need Visual Studio 2005/2008 project files for Windows.</details>
    </issue>
  </issues>


This works for me with no issues.

xml.dom.minidom.parse()
No external dependencies but post-processing.
import xml.dom.minidom as md

dom = md.parse(FILE_NAME)     
# To parse string instead use: dom = md.parseString(xml_string)
pretty_xml = dom.toprettyxml()
# remove the weird newline issue:
pretty_xml = os.linesep.join([s for s in pretty_xml.splitlines()
                              if s.strip()])

The output is the same as above, but it's more code.
    Another solution is to borrow this indent function, for use with the ElementTree library that's built in to Python since 2.5.
Here's what that would look like:

from xml.etree import ElementTree

def indent(elem, level=0):
    i = ""\n"" + level*""  ""
    j = ""\n"" + (level-1)*""  ""
    if len(elem):
        if not elem.text or not elem.text.strip():
            elem.text = i + ""  ""
        if not elem.tail or not elem.tail.strip():
            elem.tail = i
        for subelem in elem:
            indent(subelem, level+1)
        if not elem.tail or not elem.tail.strip():
            elem.tail = j
    else:
        if level and (not elem.tail or not elem.tail.strip()):
            elem.tail = j
    return elem        

root = ElementTree.parse('/tmp/xmlfile').getroot()
indent(root)
ElementTree.dump(root)

    I had some problems with minidom's pretty print.  I'd get a UnicodeError whenever I tried pretty-printing a document with characters outside the given encoding, eg if I had a β in a document and I tried doc.toprettyxml(encoding='latin-1').  Here's my workaround for it:

def toprettyxml(doc, encoding):
    """"""Return a pretty-printed XML document in a given encoding.""""""
    unistr = doc.toprettyxml().replace(u'<?xml version=""1.0"" ?>',
                          u'<?xml version=""1.0"" encoding=""%s""?>' % encoding)
    return unistr.encode(encoding, 'xmlcharrefreplace')

    If you're using a DOM implementation, each has their own form of pretty-printing built-in:

# minidom
#
document.toprettyxml()

# 4DOM
#
xml.dom.ext.PrettyPrint(document, stream)

# pxdom (or other DOM Level 3 LS-compliant imp)
#
serializer.domConfig.setParameter('format-pretty-print', True)
serializer.writeToString(document)


If you're using something else without its own pretty-printer — or those pretty-printers don't quite do it the way you want —  you'd probably have to write or subclass your own serialiser.
    As of Python 3.9, ElementTree has an indent() function for pretty-printing XML trees.
See https://docs.python.org/3/library/xml.etree.elementtree.html#xml.etree.ElementTree.indent.
Sample usage:
import xml.etree.ElementTree as ET

element = ET.XML(""<html><body>text</body></html>"")
ET.indent(element)
print(ET.tostring(element, encoding='unicode'))

The upside is that it does not require any additional libraries. For more information check https://bugs.python.org/issue14465 and https://github.com/python/cpython/pull/15200
    lxml is recent, updated, and includes a pretty print function

import lxml.etree as etree

x = etree.parse(""filename"")
print etree.tostring(x, pretty_print=True)


Check out the lxml tutorial:
http://lxml.de/tutorial.html
    Here's my (hacky?) solution to get around the ugly text node problem.

uglyXml = doc.toprettyxml(indent='  ')

text_re = re.compile('>\n\s+([^<>\s].*?)\n\s+</', re.DOTALL)    
prettyXml = text_re.sub('>\g<1></', uglyXml)

print prettyXml


The above code will produce:

<?xml version=""1.0"" ?>
<issues>
  <issue>
    <id>1</id>
    <title>Add Visual Studio 2005 and 2008 solution files</title>
    <details>We need Visual Studio 2005/2008 project files for Windows.</details>
  </issue>
</issues>


Instead of this:

<?xml version=""1.0"" ?>
<issues>
  <issue>
    <id>
      1
    </id>
    <title>
      Add Visual Studio 2005 and 2008 solution files
    </title>
    <details>
      We need Visual Studio 2005/2008 project files for Windows.
    </details>
  </issue>
</issues>


Disclaimer: There are probably some limitations.
    I wrote a solution to walk through an existing ElementTree and use text/tail to indent it as one typically expects.

def prettify(element, indent='  '):
    queue = [(0, element)]  # (level, element)
    while queue:
        level, element = queue.pop(0)
        children = [(level + 1, child) for child in list(element)]
        if children:
            element.text = '\n' + indent * (level+1)  # for child open
        if queue:
            element.tail = '\n' + indent * queue[0][0]  # for sibling open
        else:
            element.tail = '\n' + indent * (level-1)  # for parent close
        queue[0:0] = children  # prepend so children come before siblings

    from yattag import indent

pretty_string = indent(ugly_string)


It won't add spaces or newlines inside text nodes, unless you ask for it with:

indent(mystring, indent_text = True)


You can specify what the indentation unit should be and what the newline should look like.

pretty_xml_string = indent(
    ugly_xml_string,
    indentation = '    ',
    newline = '\r\n'
)


The doc is on http://www.yattag.org homepage.
    If you have xmllint you can spawn a subprocess and use it. xmllint --format <file> pretty-prints its input XML to standard output.

Note that this method uses an program external to python, which makes it sort of a hack.

def pretty_print_xml(xml):
    proc = subprocess.Popen(
        ['xmllint', '--format', '/dev/stdin'],
        stdin=subprocess.PIPE,
        stdout=subprocess.PIPE,
    )
    (output, error_output) = proc.communicate(xml);
    return output

print(pretty_print_xml(data))

    Here's a Python3 solution that gets rid of the ugly newline issue (tons of whitespace), and it only uses standard libraries unlike most other implementations.

import xml.etree.ElementTree as ET
import xml.dom.minidom
import os

def pretty_print_xml_given_root(root, output_xml):
    """"""
    Useful for when you are editing xml data on the fly
    """"""
    xml_string = xml.dom.minidom.parseString(ET.tostring(root)).toprettyxml()
    xml_string = os.linesep.join([s for s in xml_string.splitlines() if s.strip()]) # remove the weird newline issue
    with open(output_xml, ""w"") as file_out:
        file_out.write(xml_string)

def pretty_print_xml_given_file(input_xml, output_xml):
    """"""
    Useful for when you want to reformat an already existing xml file
    """"""
    tree = ET.parse(input_xml)
    root = tree.getroot()
    pretty_print_xml_given_root(root, output_xml)


I found how to fix the common newline issue here.
    You can try this variation...

Install BeautifulSoup and the backend lxml (parser) libraries:

user$ pip3 install lxml bs4


Process your XML document:

from bs4 import BeautifulSoup

with open('/path/to/file.xml', 'r') as doc: 
    for line in doc: 
        print(BeautifulSoup(line, 'lxml-xml').prettify())  

    You can use popular external library xmltodict, with unparse and pretty=True you will get best result:

xmltodict.unparse(
    xmltodict.parse(my_xml), full_document=False, pretty=True)


full_document=False against <?xml version=""1.0"" encoding=""UTF-8""?> at the top.
    As others pointed out, lxml has a pretty printer built in.

Be aware though that by default it changes CDATA sections to normal text, which can have nasty results.

Here's a Python function that preserves the input file and only changes the indentation (notice the strip_cdata=False). Furthermore it makes sure the output uses UTF-8 as encoding instead of the default ASCII (notice the encoding='utf-8'):

from lxml import etree

def prettyPrintXml(xmlFilePathToPrettyPrint):
    assert xmlFilePathToPrettyPrint is not None
    parser = etree.XMLParser(resolve_entities=False, strip_cdata=False)
    document = etree.parse(xmlFilePathToPrettyPrint, parser)
    document.write(xmlFilePathToPrettyPrint, pretty_print=True, encoding='utf-8')


Example usage:

prettyPrintXml('some_folder/some_file.xml')

    I tried to edit ""ade""s answer above, but Stack Overflow wouldn't let me edit after I had initially provided feedback anonymously.  This is a less buggy version of the function to pretty-print an ElementTree.

def indent(elem, level=0, more_sibs=False):
    i = ""\n""
    if level:
        i += (level-1) * '  '
    num_kids = len(elem)
    if num_kids:
        if not elem.text or not elem.text.strip():
            elem.text = i + ""  ""
            if level:
                elem.text += '  '
        count = 0
        for kid in elem:
            indent(kid, level+1, count < num_kids - 1)
            count += 1
        if not elem.tail or not elem.tail.strip():
            elem.tail = i
            if more_sibs:
                elem.tail += '  '
    else:
        if level and (not elem.tail or not elem.tail.strip()):
            elem.tail = i
            if more_sibs:
                elem.tail += '  '

    Take a look at the vkbeautify module.

It is a python version of my very popular javascript/nodejs plugin with the same name. It can pretty-print/minify XML, JSON and CSS text. Input and output can be string/file in any combinations. It is very compact and doesn't have any dependency.

Examples:

import vkbeautify as vkb

vkb.xml(text)                       
vkb.xml(text, 'path/to/dest/file')  
vkb.xml('path/to/src/file')        
vkb.xml('path/to/src/file', 'path/to/dest/file') 

    An alternative if you don't want to have to reparse, there is the xmlpp.py library with the get_pprint() function. It worked nice and smoothly for my use cases, without having to reparse to an lxml ElementTree object.
    I solved this with some lines of code, opening the file, going trough it and adding indentation, then saving it again. I was working with small xml files, and did not want to add dependencies, or more libraries to install for the user. Anyway, here is what I ended up with:

    f = open(file_name,'r')
    xml = f.read()
    f.close()

    #Removing old indendations
    raw_xml = ''        
    for line in xml:
        raw_xml += line

    xml = raw_xml

    new_xml = ''
    indent = '    '
    deepness = 0

    for i in range((len(xml))):

        new_xml += xml[i]   
        if(i<len(xml)-3):

            simpleSplit = xml[i:(i+2)] == '><'
            advancSplit = xml[i:(i+3)] == '></'        
            end = xml[i:(i+2)] == '/>'    
            start = xml[i] == '<'

            if(advancSplit):
                deepness += -1
                new_xml += '\n' + indent*deepness
                simpleSplit = False
                deepness += -1
            if(simpleSplit):
                new_xml += '\n' + indent*deepness
            if(start):
                deepness += 1
            if(end):
                deepness += -1

    f = open(file_name,'w')
    f.write(new_xml)
    f.close()


It works for me, perhaps someone will have some use of it :)
    I found an esay way to nicely print an xml file:
import xml.etree.ElementTree as ET

xmlTree = ET.parse('your XML file')
xmlRoot = xmlTree.getroot()
xmlDoc =  ET.tostring(xmlRoot, encoding=""unicode"")

print(xmlDoc)

Outuput:
<root>
  <child>
    <subchild>.....</subchild>
  </child>
  <child>
    <subchild>.....</subchild>
  </child>
  ...
  ...
  ...
  <child>
    <subchild>.....</subchild>
  </child>
</root>

    XML pretty print for python looks pretty good for this task.  (Appropriately named, too.)

An alternative is to use pyXML, which has a PrettyPrint function.
    I had this problem and solved it like this:

def write_xml_file (self, file, xml_root_element, xml_declaration=False, pretty_print=False, encoding='unicode', indent='\t'):
    pretty_printed_xml = etree.tostring(xml_root_element, xml_declaration=xml_declaration, pretty_print=pretty_print, encoding=encoding)
    if pretty_print: pretty_printed_xml = pretty_printed_xml.replace('  ', indent)
    file.write(pretty_printed_xml)


In my code this method is called like this:

try:
    with open(file_path, 'w') as file:
        file.write('<?xml version=""1.0"" encoding=""utf-8"" ?>')

        # create some xml content using etree ...

        xml_parser = XMLParser()
        xml_parser.write_xml_file(file, xml_root, xml_declaration=False, pretty_print=True, encoding='unicode', indent='\t')

except IOError:
    print(""Error while writing in log file!"")


This works only because etree by default uses two spaces to indent, which I don't find very much emphasizing the indentation and therefore not pretty. I couldn't ind any setting for etree or parameter for any function to change the standard etree indent. I like how easy it is to use etree, but this was really annoying me.
    For converting an entire xml document to a pretty xml document
(ex: assuming you've extracted [unzipped] a LibreOffice Writer .odt or .ods file, and you want to convert the ugly ""content.xml"" file to a pretty one for automated git version control and git difftooling of .odt/.ods files, such as I'm implementing here)

import xml.dom.minidom

file = open(""./content.xml"", 'r')
xml_string = file.read()
file.close()

parsed_xml = xml.dom.minidom.parseString(xml_string)
pretty_xml_as_string = parsed_xml.toprettyxml()

file = open(""./content_new.xml"", 'w')
file.write(pretty_xml_as_string)
file.close()


References:
- Thanks to Ben Noland's answer on this page which got me most of the way there.
    from lxml import etree
import xml.dom.minidom as mmd

xml_root = etree.parse(xml_fiel_path, etree.XMLParser())

def print_xml(xml_root):
    plain_xml = etree.tostring(xml_root).decode('utf-8')
    urgly_xml = ''.join(plain_xml .split())
    good_xml = mmd.parseString(urgly_xml)
    print(good_xml.toprettyxml(indent='    ',))


It's working well for the xml with Chinese!
    If for some reason you can't get your hands on any of the Python modules that other users mentioned, I suggest the following solution for Python 2.7:

import subprocess

def makePretty(filepath):
  cmd = ""xmllint --format "" + filepath
  prettyXML = subprocess.check_output(cmd, shell = True)
  with open(filepath, ""w"") as outfile:
    outfile.write(prettyXML)


As far as I know, this solution will work on Unix-based systems that have the xmllint package installed.
    I found this question while looking for ""how to pretty print html""
Using some of the ideas in this thread I adapted the XML solutions to work for XML or HTML:
from xml.dom.minidom import parseString as string_to_dom

def prettify(string, html=True):
    dom = string_to_dom(string)
    ugly = dom.toprettyxml(indent=""  "")
    split = list(filter(lambda x: len(x.strip()), ugly.split('\n')))
    if html:
        split = split[1:]
    pretty = '\n'.join(split)
    return pretty

def pretty_print(html):
    print(prettify(html))

When used this is what it looks like:
html = """"""\
<div class=""foo"" id=""bar""><p>'IDK!'</p><br/><div class='baz'><div>
<span>Hi</span></div></div><p id='blarg'>Try for 2</p>
<div class='baz'>Oh No!</div></div>
""""""

pretty_print(html)

Which returns:
<div class=""foo"" id=""bar"">
  <p>'IDK!'</p>
  <br/>
  <div class=""baz"">
    <div>
      <span>Hi</span>
    </div>
  </div>
  <p id=""blarg"">Try for 2</p>
  <div class=""baz"">Oh No!</div>
</div>

    Use etree.indent and etree.tostring
import lxml.etree as etree

root = etree.fromstring('<html><head></head><body><h1>Welcome</h1></body></html>')
etree.indent(root, space=""  "")
xml_string = etree.tostring(root, pretty_print=True).decode()
print(xml_string)

output
<html>
  <head/>
  <body>
    <h1>Welcome</h1>
  </body>
</html>


Removing namespaces and prefixes
import lxml.etree as etree


def dump_xml(element):
    for item in element.getiterator():
        item.tag = etree.QName(item).localname

    etree.cleanup_namespaces(element)
    etree.indent(element, space=""  "")
    result = etree.tostring(element, pretty_print=True).decode()
    return result


root = etree.fromstring('<cs:document xmlns:cs=""http://blabla.com""><name>hello world</name></cs:document>')
xml_string = dump_xml(root)
print(xml_string)

output
<document>
  <name>hello world</name>
</document>

    ","[495, 431, 45, 119, 8, 10, 23, 184, 49, 6, 6, 13, 4, 2, 3, 23, 11, 2, 1, -2, -1, 3, 0, 0, 0, 0, 0, 0]",467571,109,2009-04-15T00:05:41,2022-03-13 03:18:54Z,python xml 
Change date format in a Java string,"
                
I've a String representing a date.

String date_s = ""2011-01-18 00:00:00.0"";


I'd like to convert it to a Date and output it in YYYY-MM-DD format.


  2011-01-18


How can I achieve this?



Okay, based on the answers I retrieved below, here's something I've tried:

String date_s = "" 2011-01-18 00:00:00.0""; 
SimpleDateFormat dt = new SimpleDateFormat(""yyyyy-mm-dd hh:mm:ss""); 
Date date = dt.parse(date_s); 
SimpleDateFormat dt1 = new SimpleDateFormat(""yyyyy-mm-dd"");
System.out.println(dt1.format(date));


But it outputs 02011-00-1 instead of the desired 2011-01-18. What am I doing wrong?
    Use LocalDateTime#parse() (or ZonedDateTime#parse() if the string happens to contain a time zone part) to parse a String in a certain pattern into a LocalDateTime.

String oldstring = ""2011-01-18 00:00:00.0"";
LocalDateTime datetime = LocalDateTime.parse(oldstring, DateTimeFormatter.ofPattern(""yyyy-MM-dd HH:mm:ss.S""));


Use LocalDateTime#format() (or ZonedDateTime#format()) to format a LocalDateTime into a String in a certain pattern.

String newstring = datetime.format(DateTimeFormatter.ofPattern(""yyyy-MM-dd""));
System.out.println(newstring); // 2011-01-18


Or, when you're not on Java 8 yet, use SimpleDateFormat#parse() to parse a String in a certain pattern into a Date.

String oldstring = ""2011-01-18 00:00:00.0"";
Date date = new SimpleDateFormat(""yyyy-MM-dd HH:mm:ss.S"").parse(oldstring);


Use SimpleDateFormat#format() to format a Date into a String in a certain pattern.

String newstring = new SimpleDateFormat(""yyyy-MM-dd"").format(date);
System.out.println(newstring); // 2011-01-18


See also:


Java string to date conversion




Update: as per your failed attempt: the patterns are case sensitive. Read the java.text.SimpleDateFormat javadoc what the individual parts stands for. So stands for example M for months and m for minutes. Also, years exist of four digits yyyy, not five yyyyy. Look closer at the code snippets I posted here above.
    The answer is of course to create a SimpleDateFormat object and use it to parse Strings to Date and to format Dates to Strings.  If you've tried SimpleDateFormat and it didn't work, then please show your code and any errors you may receive.

Addendum:  ""mm"" in the format String is not the same as ""MM"".  Use MM for months and mm for minutes. Also, yyyyy is not the same as yyyy.  e.g.,:

import java.text.ParseException;
import java.text.SimpleDateFormat;
import java.util.Date;

public class FormateDate {

    public static void main(String[] args) throws ParseException {
        String date_s = ""2011-01-18 00:00:00.0"";

        // *** note that it's ""yyyy-MM-dd hh:mm:ss"" not ""yyyy-mm-dd hh:mm:ss""  
        SimpleDateFormat dt = new SimpleDateFormat(""yyyy-MM-dd hh:mm:ss"");
        Date date = dt.parse(date_s);

        // *** same for the format String below
        SimpleDateFormat dt1 = new SimpleDateFormat(""yyyy-MM-dd"");
        System.out.println(dt1.format(date));
    }

}

    We can convert Today's date in the format of 'JUN 12, 2020'.
String.valueOf(DateFormat.getDateInstance().format(new Date())));

    Please refer ""Date and Time Patterns"" here. http://docs.oracle.com/javase/7/docs/api/java/text/SimpleDateFormat.html    

import java.text.SimpleDateFormat;
import java.util.Date;
import java.text.ParseException;

public class DateConversionExample{

  public static void main(String arg[]){

    try{

    SimpleDateFormat sourceDateFormat = new SimpleDateFormat(""yyyy-MM-DD HH:mm:ss"");

    Date date = sourceDateFormat.parse(""2011-01-18 00:00:00.0"");


    SimpleDateFormat targetDateFormat = new SimpleDateFormat(""yyyy-MM-dd"");
    System.out.println(targetDateFormat.format(date));

    }catch(ParseException e){
        e.printStackTrace();
    }
  } 

}

    Formatting are CASE-SENSITIVE so USE MM for month not mm (this is for minute) and yyyy 
For Reference you can use following cheatsheet.

G   Era designator  Text    AD
y   Year    Year    1996; 96
Y   Week year   Year    2009; 09
M   Month in year   Month   July; Jul; 07
w   Week in year    Number  27
W   Week in month   Number  2
D   Day in year Number  189
d   Day in month    Number  10
F   Day of week in month    Number  2
E   Day name in week    Text    Tuesday; Tue
u   Day number of week (1 = Monday, ..., 7 = Sunday)    Number  1
a   Am/pm marker    Text    PM
H   Hour in day (0-23)  Number  0
k   Hour in day (1-24)  Number  24
K   Hour in am/pm (0-11)    Number  0
h   Hour in am/pm (1-12)    Number  12
m   Minute in hour  Number  30
s   Second in minute    Number  55
S   Millisecond Number  978
z   Time zone   General time zone   Pacific Standard Time; PST; GMT-08:00
Z   Time zone   RFC 822 time zone   -0800
X   Time zone   ISO 8601 time zone  -08; -0800; -08:00


Examples:

""yyyy.MM.dd G 'at' HH:mm:ss z""  2001.07.04 AD at 12:08:56 PDT
""EEE, MMM d, ''yy""  Wed, Jul 4, '01
""h:mm a""    12:08 PM
""hh 'o''clock' a, zzzz"" 12 o'clock PM, Pacific Daylight Time
""K:mm a, z"" 0:08 PM, PDT
""yyyyy.MMMMM.dd GGG hh:mm aaa""  02001.July.04 AD 12:08 PM
""EEE, d MMM yyyy HH:mm:ss Z""    Wed, 4 Jul 2001 12:08:56 -0700
""yyMMddHHmmssZ"" 010704120856-0700
""yyyy-MM-dd'T'HH:mm:ss.SSS'Z'""   2001-07-04T12:08:56.235-0700
""yyyy-MM-dd'T'HH:mm:ss.SSSXXX""   2001-07-04T12:08:56.235-07:00
""YYYY-'W'ww-u""  2001-W27-3

    remove one y form the format provide to:
SimpleDateFormat dt1 = new SimpleDateFormat(""yyyyy-mm-dd"");

It should be:
SimpleDateFormat dt1 = new SimpleDateFormat(""yyyy-mm-dd"");

    /**
 * Method will take Date in ""MMMM, dd yyyy HH:mm:s"" format and return time difference like added: 3 min ago
 *
 * @param date : date in ""MMMM, dd yyyy HH:mm:s"" format
 * @return : time difference
 */
private String getDurationTimeStamp(String date) {
    String timeDifference = """";

    //date formatter as per the coder need
    SimpleDateFormat sdf = new SimpleDateFormat(""MMMM, dd yyyy HH:mm:s"");
    TimeZone timeZone = TimeZone.getTimeZone(""EST"");
    sdf.setTimeZone(timeZone);
    Date startDate = null;
    try {
        startDate = sdf.parse(date);
    } catch (ParseException e) {
        MyLog.printStack(e);
    }

    //end date will be the current system time to calculate the lapse time difference
    Date endDate = new Date();

    //get the time difference in milliseconds
    long duration = endDate.getTime() - startDate.getTime();

    long diffInSeconds = TimeUnit.MILLISECONDS.toSeconds(duration);
    long diffInMinutes = TimeUnit.MILLISECONDS.toMinutes(duration);
    long diffInHours = TimeUnit.MILLISECONDS.toHours(duration);
    long diffInDays = TimeUnit.MILLISECONDS.toDays(duration);

    if (diffInDays >= 365) {
        int year = (int) (diffInDays / 365);
        timeDifference = year + mContext.getString(R.string.year_ago);
    } else if (diffInDays >= 30) {
        int month = (int) (diffInDays / 30);
        timeDifference = month + mContext.getString(R.string.month_ago);
    }
    //if days are not enough to create year then get the days
    else if (diffInDays >= 1) {
        timeDifference = diffInDays + mContext.getString(R.string.day_ago);
    }
    //if days value<1 then get the hours
    else if (diffInHours >= 1) {
        timeDifference = diffInHours + mContext.getString(R.string.hour_ago);
    }
    //if hours value<1 then get the minutes
    else if (diffInMinutes >= 1) {
        timeDifference = diffInMinutes + mContext.getString(R.string.min_ago);
    }
    //if minutes value<1 then get the seconds
    else if (diffInSeconds >= 1) {
        timeDifference = diffInSeconds + mContext.getString(R.string.sec_ago);
    } else if (timeDifference.isEmpty()) {
        timeDifference = mContext.getString(R.string.now);
    }

    return mContext.getString(R.string.added) + "" "" + timeDifference;
}

    [edited to include BalusC's corrections]
The SimpleDateFormat class should do the trick:

String pattern = ""yyyy-MM-dd HH:mm:ss.S"";
SimpleDateFormat format = new SimpleDateFormat(pattern);
try {
  Date date = format.parse(""2011-01-18 00:00:00.0"");
  System.out.println(date);
} catch (ParseException e) {
  e.printStackTrace();
}

    Why not simply use this
Date convertToDate(String receivedDate) throws ParseException{
        SimpleDateFormat formatter = new SimpleDateFormat(""dd-MM-yyyy"");
        Date date = formatter.parse(receivedDate);
        return date;
    }

Also, this is the other way :
DateFormat df = new SimpleDateFormat(""dd/MM/yyyy"");
String requiredDate = df.format(new Date()).toString();

or
Date requiredDate = df.format(new Date());

    java.time
The java.util Date-Time API and their formatting API, SimpleDateFormat are outdated and error-prone. It is recommended to stop using them completely and switch to the modern Date-Time API*.
Also, quoted below is a notice from the home page of Joda-Time:

Note that from Java SE 8 onwards, users are asked to migrate to java.time (JSR-310) - a core part of the JDK which replaces this project.

Solution using java.time, the modern Date-Time API:
import java.time.LocalDate;
import java.time.LocalDateTime;
import java.time.format.DateTimeFormatter;
import java.util.Locale;

public class Main {
    public static void main(String[] args) {
        String strDate = ""2011-01-18 00:00:00.0"";
        DateTimeFormatter dtfInput = DateTimeFormatter.ofPattern(""u-M-d H:m:s.S"", Locale.ENGLISH);
        LocalDateTime ldt = LocalDateTime.parse(strDate, dtfInput);
        // Alternatively, the old way:
        // LocalDateTime ldt = dtfInput.parse(strDate, LocalDateTime::from);

        LocalDate date = ldt.toLocalDate();
        System.out.println(date);
    }
}

Output:
2011-01-18

ONLINE DEMO
Some important notes about the solution:

java.time made it possible to call parse and format functions on the Date-Time type itself, in addition to the old way (i.e. calling parse and format functions on the formatter type, which is DateTimeFormatter in case of java.time API).
The modern Date-Time API is based on ISO 8601 and does not require using a DateTimeFormatter object explicitly as long as the Date-Time string conforms to the ISO 8601 standards e.g. I have not used a DateTimeFormatter for the output because LocalDate#toString already returns the string in the required format.
Here, you can use y instead of u but I prefer u to y.

Learn more about the modern Date-Time API from Trail: Date Time.

* For any reason, if you have to stick to Java 6 or Java 7, you can use ThreeTen-Backport which backports most of the java.time functionality to Java 6 & 7. If you are working for an Android project and your Android API level is still not compliant with Java-8, check Java 8+ APIs available through desugaring and How to use ThreeTenABP in Android Project.

    You can just use:

Date yourDate = new Date();

SimpleDateFormat DATE_FORMAT = new SimpleDateFormat(""yyyy-MM-dd"");
String date = DATE_FORMAT.format(yourDate);


It works perfectly!
    You could try Java 8 new date, more information can be found on the Oracle documentation.    

Or you can try the old one 

public static Date getDateFromString(String format, String dateStr) {

    DateFormat formatter = new SimpleDateFormat(format);
    Date date = null;
    try {
        date = (Date) formatter.parse(dateStr);
    } catch (ParseException e) {
        e.printStackTrace();
    }

    return date;
}

public static String getDate(Date date, String dateFormat) {
    DateFormat formatter = new SimpleDateFormat(dateFormat);
    return formatter.format(date);
}

    Other answers are correct, basically you had the wrong number of ""y"" characters in your pattern.

Time Zone

One more problem though… You did not address time zones. If you intended UTC, then you should have said so. If not, the answers are not complete. If all you want is the date portion without the time, then no issue. But if you do further work that may involve time, then you should be specifying a time zone.

Joda-Time

Here is the same kind of code but using the third-party open-source Joda-Time 2.3 library

// © 2013 Basil Bourque. This source code may be used freely forever by anyone taking full responsibility for doing so.

String date_s = ""2011-01-18 00:00:00.0"";

org.joda.time.format.DateTimeFormatter formatter = org.joda.time.format.DateTimeFormat.forPattern( ""yyyy-MM-dd' 'HH:mm:ss.SSS"" );
// By the way, if your date-time string conformed strictly to ISO 8601 including a 'T' rather than a SPACE ' ', you could
// use a formatter built into Joda-Time rather than specify your own: ISODateTimeFormat.dateHourMinuteSecondFraction().
// Like this:
//org.joda.time.DateTime dateTimeInUTC = org.joda.time.format.ISODateTimeFormat.dateHourMinuteSecondFraction().withZoneUTC().parseDateTime( date_s );

// Assuming the date-time string was meant to be in UTC (no time zone offset).
org.joda.time.DateTime dateTimeInUTC = formatter.withZoneUTC().parseDateTime( date_s );
System.out.println( ""dateTimeInUTC: "" + dateTimeInUTC );
System.out.println( ""dateTimeInUTC (date only): "" + org.joda.time.format.ISODateTimeFormat.date().print( dateTimeInUTC ) );
System.out.println( """" ); // blank line.

// Assuming the date-time string was meant to be in Kolkata time zone (formerly known as Calcutta). Offset is +5:30 from UTC (note the half-hour).
org.joda.time.DateTimeZone kolkataTimeZone = org.joda.time.DateTimeZone.forID( ""Asia/Kolkata"" );
org.joda.time.DateTime dateTimeInKolkata = formatter.withZone( kolkataTimeZone ).parseDateTime( date_s );
System.out.println( ""dateTimeInKolkata: "" + dateTimeInKolkata );
System.out.println( ""dateTimeInKolkata (date only): "" + org.joda.time.format.ISODateTimeFormat.date().print( dateTimeInKolkata ) );
// This date-time in Kolkata is a different point in the time line of the Universe than the dateTimeInUTC instance created above. The date is even different.
System.out.println( ""dateTimeInKolkata adjusted to UTC: "" + dateTimeInKolkata.toDateTime( org.joda.time.DateTimeZone.UTC ) );


When run…

dateTimeInUTC: 2011-01-18T00:00:00.000Z
dateTimeInUTC (date only): 2011-01-18

dateTimeInKolkata: 2011-01-18T00:00:00.000+05:30
dateTimeInKolkata (date only): 2011-01-18
dateTimeInKolkata adjusted to UTC: 2011-01-17T18:30:00.000Z

    try
 {
    String date_s = ""2011-01-18 00:00:00.0"";
    SimpleDateFormat simpledateformat = new SimpleDateFormat(""yyyy-MM-dd HH:mm:ss.S"");
    Date tempDate=simpledateformat.parse(date_s);
    SimpleDateFormat outputDateFormat = new SimpleDateFormat(""yyyy-MM-dd"");           
    System.out.println(""Output date is = ""+outputDateFormat.format(tempDate));
  } catch (ParseException ex) 
  {
        System.out.println(""Parse Exception"");
  }

    private SimpleDateFormat dataFormat = new SimpleDateFormat(""dd/MM/yyyy"");

@Override
public Component getTableCellRendererComponent(JTable table, Object value, boolean isSelected, boolean hasFocus, int row, int column) {
    if(value instanceof Date) {
        value = dataFormat.format(value);
    }
    return super.getTableCellRendererComponent(table, value, isSelected, hasFocus, row, column);
};

    You can also use substring()

String date_s = ""2011-01-18 00:00:00.0"";
date_s.substring(0,10);


If you want a space in front of the date, use

String date_s = "" 2011-01-18 00:00:00.0"";
date_s.substring(1,11);

    Using the java.time package in Java 8 and later:

String date = ""2011-01-18 00:00:00.0"";
TemporalAccessor temporal = DateTimeFormatter
    .ofPattern(""yyyy-MM-dd HH:mm:ss.S"")
    .parse(date); // use parse(date, LocalDateTime::from) to get LocalDateTime
String output = DateTimeFormatter.ofPattern(""yyyy-MM-dd"").format(temporal);

       String str = ""2000-12-12"";
   Date dt = null;
   SimpleDateFormat formatter = new SimpleDateFormat(""yyyy-MM-dd"");

    try 
    {
         dt = formatter.parse(str);
    }
    catch (Exception e)
    {
    }

    JOptionPane.showMessageDialog(null, formatter.format(dt));

    public class SystemDateTest {

    String stringDate;

    public static void main(String[] args) {
        SystemDateTest systemDateTest = new SystemDateTest();
        // format date into String
        SimpleDateFormat simpleDateFormat = new SimpleDateFormat(""dd-MM-yyyy hh:mm:ss"");
        systemDateTest.setStringDate(simpleDateFormat.format(systemDateTest.getDate()));
        System.out.println(systemDateTest.getStringDate());
    }

    public Date getDate() {
        return new Date();
    }

    public String getStringDate() {
        return stringDate;
    }

    public void setStringDate(String stringDate) {
        this.stringDate = stringDate;
    }
}

    SimpleDateFormat dt1 = new SimpleDateFormat(""yyyy-mm-dd"");

    Say you want to change 2019-12-20 10:50 AM GMT+6:00 to 2019-12-20 10:50 AM 
first of all you have to understand the date format first one date format is 
yyyy-MM-dd hh:mm a zzz and second one date format will be yyyy-MM-dd hh:mm a 

just return a string from this function like. 

public String convertToOnlyDate(String currentDate) {
    SimpleDateFormat dateFormat = new SimpleDateFormat(""yyyy-MM-dd hh:mm a "");
    Date date;
    String dateString = """";
    try {
        date = dateFormat.parse(currentDate);
        System.out.println(date.toString()); 

        dateString = dateFormat.format(date);
    } catch (ParseException e) {
        e.printStackTrace();
    }
    return dateString;
}


This function will return your desire answer. If you want to customize more just add or remove component from the date format. 
    you have some wrong:
SimpleDateFormat dt1 = new SimpleDateFormat(""yyyyy-mm-dd"");
first :
should be
 new SimpleDateFormat(""yyyy-mm-dd"");
//yyyy 4 not 5
this display 02011, but yyyy it disply 2011
second:
change your code like this
new SimpleDateFormat(""yyyy-MM-dd"");
i hope help you
    ","[495, 530, 114, 1, 11, 168, 4, 1, 12, 30, 1, 8, 5, 9, 8, 4, 5, 15, 6, 7, -1, 0, 0]",1506675,129,2011-01-23T05:09:48,2021-08-27 14:36:43Z,java 
C# naming convention for constants?,"
                
private const int THE_ANSWER = 42;


or

private const int theAnswer = 42;


Personally I think with modern IDEs we should go with camelCase as ALL_CAPS looks strange. What do you think?
    The recommended naming and capitalization convention is to use PascalCasing for constants (Microsoft has a tool named StyleCop that documents all the preferred conventions and can check your source for compliance - though it is a little bit too anally retentive for many people's tastes). e.g.

private const int TheAnswer = 42;


The Pascal capitalization convention is also documented in Microsoft's Framework Design Guidelines.
    Visually, Upper Case is the way to go. It is so recognizable that way.
For the sake of uniqueness and leaving no chance for guessing, I vote for UPPER_CASE!

const int THE_ANSWER = 42;


Note: The Upper Case will be useful when constants are to be used within the same file at the top of the page and for intellisense purposes; however, if they were to be moved to an independent class, using Upper Case would not make much difference, as an example: 

public static class Constant
{
    public static readonly int Cons1 = 1;
    public static readonly int coNs2 = 2;
    public static readonly int cOns3 = 3;
    public static readonly int CONS4 = 4;
}

// Call constants from anywhere
// Since the class has a unique and recognizable name, Upper Case might lose its charm
private void DoSomething(){
var getCons1 = Constant.Cons1;
var getCons2 = Constant.coNs2;
var getCons3 = Constant.cOns3;
var getCons4 = Constant.CONS4;
 }

    Actually, it is 

private const int TheAnswer = 42;


At least if you look at the .NET library, which IMO is the best way to decide naming conventions - so your code doesn't look out of place.
    I actually tend to prefer PascalCase here - but out of habit, I'm guilty of UPPER_CASE...
    The ALL_CAPS is taken from the C and C++ way of working I believe. This article here explains how the style differences came about.

In the new IDE's such as Visual Studio it is easy to identify the types, scope and if they are constant so it is not strictly necessary. 

The FxCop and Microsoft StyleCop software will help give you guidelines and check your code so everyone works the same way.
    First, Hungarian Notation is the practice of using a prefix to display a parameter's data type or intended use.
Microsoft's naming conventions for says no to Hungarian Notation
http://en.wikipedia.org/wiki/Hungarian_notation
http://msdn.microsoft.com/en-us/library/ms229045.aspx

Using UPPERCASE is not encouraged as stated here:
Pascal Case is the acceptable convention and SCREAMING CAPS.
http://en.wikibooks.org/wiki/C_Sharp_Programming/Naming 

Microsoft also states here that UPPERCASE can be used if it is done to match the the existed scheme.
http://msdn.microsoft.com/en-us/library/x2dbyw72.aspx

This pretty much sums it up. 
    I still go with the uppercase for const values, but this is more out of habit than for any particular reason. 

Of course it makes it easy to see immediately that something is a const. The question to me is: Do we really need this information? Does it help us in any way to avoid errors? If I assign a value to the const, the compiler will tell me I did something dumb. 

My conclusion: Go with the camel casing. Maybe I will change my style too ;-)

Edit:

That something smells hungarian is not really a valid argument, IMO. The question should always be: Does it help, or does it hurt?

There are cases when hungarian helps. Not that many nowadays, but they still exist. 
    Leave Hungarian to the Hungarians.

In the example I'd even leave out the definitive article and just go with 

private const int Answer = 42;


Is that answer or is that the answer?

*Made edit as Pascal strictly correct, however I was thinking the question was seeking more of an answer to life, the universe and everything.
    In its article Constants (C# Programming Guide), Microsoft gives the following example:

class Calendar3
{
    const int months = 12;
    const int weeks = 52;
    const int days = 365;

    const double daysPerWeek = (double) days / (double) weeks;
    const double daysPerMonth = (double) days / (double) months;
}


So, for constants, it appears that Microsoft is recommending the use of camelCasing. But note that these constants are defined locally.

Arguably, the naming of externally-visible constants is of greater interest. In practice, Microsoft documents its public constants in the .NET class library as fields. Here are some examples:


Int32.MaxValue
String.Empty (actually, static readonly)
Math.PI
Math.E


The first two are examples of PascalCasing. The third appears to follow Microsoft's Capitalization Conventions for a two-letter acronym (although pi is not an acryonym). And the fourth one seems to suggest that the rule for a two-letter acryonym extends to a single letter acronym or identifier such as E (which represents the mathematical constant e).

Furthermore, in its Capitalization Conventions document, Microsoft very directly states that field identifiers should be named via PascalCasing and gives the following examples for MessageQueue.InfiniteTimeout and UInt32.Min:

public class MessageQueue
{
    public static readonly TimeSpan InfiniteTimeout;
}

public struct UInt32
{
    public const Min = 0;
}


Conclusion: Use PascalCasing for public constants (which are documented as const or static readonly fields).

Finally, as far as I know, Microsoft does not advocate specific naming or capitalization conventions for private identifiers as shown in the examples presented in the question.
    ","[495, 591, 95, 73, 8, 8, 18, 24, 13, 16]",269622,60,2008-10-28T08:16:45,2020-02-16 16:50:56Z,c 
"""use database_name"" command in PostgreSQL","
                
I am beginner to PostgreSQL.

I want to connect to another database from the query editor of Postgres - like the USE command of MySQL or MS SQL Server. 

I found \c databasename by searching the Internet, but its runs only on psql. When I try it from the PostgreSQL query editor I get a syntax error.

I have to change the database by pgscripting. Does anyone know how to do it?
    When you get a connection to PostgreSQL it is always to a particular database.  To access a different database, you must get a new connection.

Using \c in psql closes the old connection and acquires a new one, using the specified database and/or credentials.  You get a whole new back-end process and everything.
    You must specify the database to use on connect; if you want to use psql for your script, you can use ""\c name_database"" 

user_name=# CREATE DATABASE testdatabase; 
user_name=# \c testdatabase 


At this point you might see the following output

You are now connected to database ""testdatabase"" as user ""user_name"".
testdatabase=#


Notice how the prompt changes. Cheers, have just been hustling looking for this too, too little information on postgreSQL compared to MySQL and the rest in my view.
    In pgAdmin you can also use

SET search_path TO your_db_name;

    The basic problem while migrating from MySQL I faced was, I thought of the term database to be same in PostgreSQL also, but it is not. So if we are going to switch the database from our application or pgAdmin, the result would not be as expected.
As in my case, we have separate schemas (Considering PostgreSQL terminology here.) for each customer and separate admin schema. So in application, I have to switch between schemas. 

For this, we can use the SET search_path command. This does switch the current schema to the specified schema name for the current session. 

example:

SET search_path = different_schema_name;


This changes the current_schema to the specified schema for the session. To change it permanently, we have to make changes in postgresql.conf file.
    PgAdmin 4, GUI Tool: Switching between databases

In the PgAdmin Browser on the left hand side, right click on the database you are willing to switch to.
Select a QueryTool from the drop down menu (or any other option that you need, I will stick with the QueryTool for now).
You will see the QueryTool in the PgAdmin window, and on top you will see the active database and the role name.
Now you can write queries against the chosen database.
You can open multiple QueryTools for multiple database, and work with them as you do with your graphical text editor.

In order to be sure that you are querying the proper database, issue the following query:
SELECT session_user, current_database();

    set search_path = 'schema name here'

while connecting to the postgres, you have to opt for default database to connect. If you have nothing, you can use 'postgres' as default.
You can use dbeaver to connect to postgres. UI is good
    Use this commad when first connect to psql

=# psql <databaseName> <usernamePostgresql>

    ","[495, 505, 265, 40, 14, 3, 2, 6]",481074,65,2012-04-26T14:30:52,2021-10-11 14:41:08Z,
How can I use a search engine to search for special characters? [closed],"
                    
            
        
            
                
                    
                        Closed. This question does not meet Stack Overflow guidelines. It is not currently accepting answers.
                        
                    
                
            
        
            
        
                
                    
                
            
                
                    Want to improve this question? Update the question so it's on-topic for Stack Overflow.
                
                    Closed 7 years ago.
            The community reviewed whether to reopen this question 6 months ago and left it closed:
            
                    Original close reason(s) were not resolved
            

            
        
            
                    
                        Improve this question
                    
            

    

Google strips most special characters from the text they index so it's not a good tool for many troubleshooting-related tasks, such as finding out what the variable ""$-"" is in perl, or searching for error output that is loaded with special characters.

Is there a good way to search for such content on the web?

This question is related to the following question: Looking for special characters in Google
    This search engine was made to solve exactly the kind of problem you're having: http://symbolhound.com/

I am the developer of SymbolHound.
    Unfortunately, there doesn't appear to be a magic bullet. Bottom line up front: ""context"".

Google indeed ignores most punctuation, with the following exceptions:


Punctuation in popular terms that have particular meanings, like [ C++ ] or [ C# ] (both are names of programming languages), are not ignored.
The dollar sign ($) is used to indicate prices. [ nikon 400 ] and [ nikon $400 ] will give different results.
The hyphen - is sometimes used as a signal that the two words around it are very strongly connected. (Unless there is no space after the - and a space before it, in which case it is a negative sign.)
The underscore symbol _ is not ignored when it connects two words, e.g. [ quick_sort ].


As such, it is not well suited for these types of searchs. Google Code however does have syntax for searching through their code projects, that includes a robust language/syntax for dealing with ""special characters"".  If looking at someone else's code could help solve a problem, this may be an option. 

Unfortunately, this is not a limitation unique to google.  You may find that your best successes hinge on providing as much 'context' to the problem as possible.  If you are searching to find what $- means, providing information about the problem's domain may yield good results.  

For example, searching ""special perl variables"" quickly yields your answer in the first entry on the results page. 
    A great search engine for special characters that I recenetly found:
amp-what?

You can even search by object name, like ""arrow"", ""chess"", etc...
    duckduckgo.com doesn't ignore special characters, at least if the whole string is between """"

https://duckduckgo.com/?q=%22*222%23%22
    ","[495, 512, 19, -1, -3]",299043,110,2011-01-13T21:42:39,2016-01-14 22:25:26Z,
"Why is 1/1/1970 the ""epoch time""?","
                
Why is


  1 January 1970 00:00:00


considered the epoch time?
    Early versions of unix measured system time in 1/60 s intervals. This meant that a 32-bit unsigned integer could only represent a span of time less than 829 days. For this reason, the time represented by the number 0 (called the epoch) had to be set in the very recent past. As this was in the early 1970s, the epoch was set to 1971-1-1.

Later, the system time was changed to increment every second, which increased the span of time that could be represented by a 32-bit unsigned integer to around 136 years. As it was no longer so important to squeeze every second out of the counter, the epoch was rounded down to the nearest decade, thus becoming 1970-1-1. One must assume that this was considered a bit neater than 1971-1-1.

Note that a 32-bit signed integer using 1970-1-1 as its epoch can represent dates up to 2038-1-19, on which date it will wrap around to 1901-12-13.
    Epoch reference date

An epoch reference date is a point on the timeline from which we count time. Moments before that point are counted with a negative number, moments after are counted with a positive number. 

Many epochs in use


  Why is 1 January 1970 00:00:00 considered the epoch time?


No, not the epoch, an epoch. There are many epochs in use.

This choice of epoch is arbitrary. 

Major computers systems and libraries use any of at least a couple dozen various epochs. One of the most popular epochs is commonly known as Unix Time, using the 1970 UTC moment you mentioned. 

While popular, Unix Time’s 1970 may not be the most common. Also in the running for most common would be January 0, 1900 for countless Microsoft Excel & Lotus 1-2-3 spreadsheets, or January 1, 2001 used by Apple’s Cocoa framework in over a billion iOS/macOS machines worldwide in countless apps. Or perhaps January 6, 1980 used by GPS devices?

Many granularities

Different systems use different granularity in counting time. 

Even the so-called “Unix Time” varies, with some systems counting whole seconds and some counting milliseconds. Many database such as Postgres use microseconds. Some, such as the modern java.time framework in Java 8 and later, use nanoseconds. Some use still other granularities. 

ISO 8601

Because there is so much variance in the use of an epoch reference and in the granularities, it is generally best to avoid communicating moments as a count-from-epoch. Between the ambiguity of epoch & granularity, plus the inability of humans to perceive meaningful values (and therefore miss buggy values), use plain text instead of numbers.

The ISO 8601 standard provides an extensive set of practical well-designed formats for expressing date-time values as text. These formats are easy to parse by machine as well as easy to read by humans across cultures.

These include: 


Date-only: 2019-01-23
Moment in UTC:  2019-01-23T12:34:56.123456Z
Moment with offset-from-UTC: 2019-01-23T18:04:56.123456+05:30
Week of week-based-year: 2019-W23
Ordinal date (1st to 366th day of year): 2019-234 

    History.


  The earliest versions of Unix time had
  a 32-bit integer incrementing at a
  rate of 60 Hz, which was the rate of
  the system clock on the hardware of
  the early Unix systems. The value 60
  Hz still appears in some software
  interfaces as a result. The epoch also
  differed from the current value. The
  first edition Unix Programmer's Manual
  dated November 3, 1971 defines the
  Unix time as ""the time since 00:00:00,
  Jan. 1, 1971, measured in sixtieths of
  a second"".

    http://en.wikipedia.org/wiki/Unix_time#History explains a little about the origins of Unix time and the chosen epoch. The definition of unix time and the epoch date went through a couple of changes before stabilizing on what it is now.
But it does not say why exactly 1/1/1970 was chosen in the end.
Notable excerpts from the Wikipedia page:

The first edition Unix Programmer's Manual dated November 3, 1971 defines the Unix time as ""the time since 00:00:00, Jan. 1, 1971, measured in sixtieths of a second"".
Because of [the] limited range, the epoch was redefined more than once, before the rate was changed to 1 Hz and the epoch was set to its present value.
Several later problems, including the complexity of the present definition, result from Unix time having been defined gradually by usage rather than fully defined to start with.

    Short answer: Why not?

Longer answer: The time itself doesn't really matter, as long as everyone who uses it agrees on its value. As 1/1/70 has been in use for so long, using it will make you code as understandable as possible for as many people as possible.

There's no great merit in choosing an arbitrary epoch just to be different.
    ","[495, 459, 12, 56, 11, -11]",206069,140,2009-07-07T07:40:29,2019-01-21 02:07:29Z,
C# if/then directives for debug vs release,"
                
In Solution properties, I have Configuration set to ""release"" for my one and only project. 

At the beginning of the main routine, I have this code, and it is showing ""Mode=Debug"". 
I also have these two lines at the very top: 

#define DEBUG 
#define RELEASE


Am I testing the right variable? 

#if (DEBUG)
            Console.WriteLine(""Mode=Debug""); 
#elif (RELEASE)
            Console.WriteLine(""Mode=Release""); 
#endif


My goal is to set different defaults for variables based on debug vs release mode. 
    DEBUG/_DEBUG should be defined in VS already.

Remove the #define DEBUG in your code. Set preprocessors in the build configuration for that specific build.

The reason it prints ""Mode=Debug"" is because of your #define and then skips the elif.

The right way to check is:

#if DEBUG
    Console.WriteLine(""Mode=Debug""); 
#else
    Console.WriteLine(""Mode=Release""); 
#endif


Don't check for RELEASE.
    I prefer checking it like this over looking for #define directives:

if (System.Diagnostics.Debugger.IsAttached)
{
   //...
}
else
{
   //...
}


With the caveat that of course you could compile and deploy something in debug mode but still not have the debugger attached.
    By default, Visual Studio defines DEBUG if project is compiled in Debug mode and doesn't define it if it's in Release mode. RELEASE is not defined in Release mode by default. Use something like this:

#if DEBUG
  // debug stuff goes here
#else
  // release stuff goes here
#endif


If you want to do something only in release mode:

#if !DEBUG
  // release...
#endif


Also, it's worth pointing out that you can use [Conditional(""DEBUG"")] attribute on methods that return void to have them only executed if a certain symbol is defined. The compiler would remove all calls to those methods if the symbol is not defined:

[Conditional(""DEBUG"")]
void PrintLog() {
    Console.WriteLine(""Debug info"");
}

void Test() {
    PrintLog();
}

    Be sure to define the DEBUG constant in the Project Build Properties. This will enable the #if DEBUG.  I don't see a pre-defined RELEASE constant, so that could imply that anything Not in a DEBUG block is RELEASE mode.

    A tip that may save you a lot of time - don't forget that even if you choose debug under the build configuration (on vs2012/13 menu it's under BUILD => CONFIGURATION MANAGER) - that's not enough. 

You need to pay attention to the PUBLISH Configuration, as such:

 
    NameSpace

using System.Resources;
using System.Diagnostics;


Method

   private static bool IsDebug()
    {
        object[] customAttributes = Assembly.GetExecutingAssembly().GetCustomAttributes(typeof(DebuggableAttribute), false);
        if ((customAttributes != null) && (customAttributes.Length == 1))
        {
            DebuggableAttribute attribute = customAttributes[0] as DebuggableAttribute;
            return (attribute.IsJITOptimizerDisabled && attribute.IsJITTrackingEnabled);
        }
        return false;
    }

    It is worth noting here that one of the most significant differences between conditionally executing code based on #if DEBUG versus if(System.Diagnostics.Debugger.IsAttached) is that the compiler directive changes the code that is compiled.  That is, if you have two different statements in an #if DEBUG/#else/#endif conditional block, only one of them will appear in the compiled code.  This is an important distinction because it allows you do do things such as conditionally compile method definitions to be public void mymethod() versus internal void mymethod() depending on build type so that you can, for example, run unit tests on debug builds that will not break access control on production builds, or conditionally compile helper functions in debug builds that will not appear in the final code if they would violate security in some way should they escape into the wild.  The IsAttached property, on the other hand, does not affect the compiled code.  Both sets of code are in all of the builds - the IsAttached condition will only affect what is executed.  This by itself can present a security issue.
    I'm not a huge fan of the #if stuff, especially if you spread it all around your code base as it will give you problems where Debug builds pass but Release builds fail if you're not careful.

So here's what I have come up with (inspired by #ifdef in C#):

public interface IDebuggingService
{
    bool RunningInDebugMode();
}

public class DebuggingService : IDebuggingService
{
    private bool debugging;

    public bool RunningInDebugMode()
    {
        //#if DEBUG
        //return true;
        //#else
        //return false;
        //#endif
        WellAreWe();
        return debugging;
    }

    [Conditional(""DEBUG"")]
    private void WellAreWe()
    {
        debugging = true;
    }
}

    bool isDebug = false;
Debug.Assert(isDebug = true); // '=', not '=='


The method Debug.Assert has conditional attribute DEBUG. If it is not defined, the call and the assignment isDebug = true are eliminated:


  If the symbol is defined, the call is included; otherwise, the call (including evaluation of the parameters of the call) is omitted.


If DEBUG is defined, isDebug is set to true (and passed to Debug.Assert , which does nothing in that case).
    If you are trying to use the variable defined for the build type you should remove the two lines ...

#define DEBUG  
#define RELEASE 


... these will cause the #if (DEBUG) to always be true.

Also there isn't a default Conditional compilation symbol for RELEASE.  If you want to define one go to the project properties, click on the Build tab and then add RELEASE to the Conditional compilation symbols text box under the General heading.

The other option would be to do this...

#if DEBUG
    Console.WriteLine(""Debug"");
#else
    Console.WriteLine(""Release"");
#endif

    Remove your defines at the top

#if DEBUG
        Console.WriteLine(""Mode=Debug""); 
#else
        Console.WriteLine(""Mode=Release""); 
#endif

    Slightly modified (bastardized?) version of the answer by Tod Thomson as a static function rather than a separate class (I wanted to be able to call it in a WebForm viewbinding from a viewutils class I already had included).

public static bool isDebugging() {
    bool debugging = false;

    WellAreWe(ref debugging);

    return debugging;
}

[Conditional(""DEBUG"")]
private static void WellAreWe(ref bool debugging)
{
    debugging = true;
}

    Since the purpose of these COMPILER directives are to tell the compiler NOT to include code, debug code,beta code, or perhaps code that is needed by all of your end users, except say those the advertising department, i.e. #Define AdDept you want to be able include or remove them based on your needs. Without having to change your source code if for example a non AdDept merges into the AdDept. Then all that needs to be done is to include the #AdDept directive in the compiler options properties page of an existing version of the program and do a compile and wa la! the merged program's code springs alive!.

You might also want to use a declarative for a new process that is not ready for prime time or that can not be active in the code until it's time to release it.

Anyhow, that's the way I do it.
    I got to thinking about a better way. It dawned on me that #if blocks are effectively comments in other configurations (assuming DEBUG or RELEASE; but true with any symbol)

public class Mytest
    {
        public DateTime DateAndTimeOfTransaction;
    }

    public void ProcessCommand(Mytest Command)
        {
            CheckMyCommandPreconditions(Command);
            // do more stuff with Command...
        }

        [Conditional(""DEBUG"")]
        private static void CheckMyCommandPreconditions(Mytest Command)
        {
            if (Command.DateAndTimeOfTransaction > DateTime.Now)
                throw new InvalidOperationException(""DateTime expected to be in the past"");
        }

    Remove the definitions and check if the conditional is on debug mode. You do not need to check if the directive is on release mode.

Something like this:

#if DEBUG
     Console.WriteLine(""Mode=Debug""); 
#else
    Console.WriteLine(""Mode=Release""); 
#endif

    ","[494, 813, 247, 330, 13, 5, 8, 3, 59, 31, 21, 8, 8, -1, 0, 0]",409680,100,2010-01-20T19:01:11,2020-07-31 13:18:05Z,c 
Setting Environment Variables for Node to retrieve,"
                
I'm trying to follow a tutorial and it says:


  There are a few ways to load credentials.
  
  
  Loaded from environment variables,
  Loaded from a JSON file on disk,
  
  
  The keys need to be as follows:

USER_ID, USER_KEY

  
  ...This means that if you properly set your environment variables, you
  do not need to manage credentials in your application at all.


Based on some Googling, it appears that I need to set the variables in process.env?  How and where do I set these credentials?  Example Please.  
    You can set the environment variable through process global variable as follows:

process.env['NODE_ENV'] = 'production';


Works in all platforms.
    Environment variables (in this case) are being used to pass credentials to your application. USER_ID and USER_KEY can both be accessed from process.env.USER_ID and process.env.USER_KEY respectively. You don't need to edit them, just access their contents.

It looks like they are simply giving you the choice between loading your USER_ID and USER_KEY from either process.env or some specificed file on disk. 

Now, the magic happens when you run the application.

USER_ID=239482 USER_KEY=foobar node app.js

That will pass the user id 239482 and the user key as foobar. This is suitable for testing, however for production, you will probably be configuring some bash scripts to export variables.
    I highly recommend looking into the dotenv package.

https://github.com/motdotla/dotenv

It's kind of similar to the library suggested within the answer from @Benxamin, but it's a lot cleaner and doesn't require any bash scripts. Also worth noting that the code base is popular and well maintained.

Basically you need a .env file (which I highly recommend be ignored from your git/mercurial/etc):

FOO=bar
BAZ=bob


Then in your application entry file put the following line in as early as possible:

require('dotenv').config();


Boom. Done.  'process.env' will now contain the variables above:

console.log(process.env.FOO);
// bar


The '.env' file isn't required so you don't need to worry about your app falling over in it's absence.
    If you want a management option, try the envs npm package. It returns environment values if they are set. Otherwise, you can specify a default value that is stored in a global defaults object variable if it is not in your environment.

Using .env (""dot ee-en-vee"") or environment files is good for many reasons. Individuals may manage their own configs. You can deploy different environments (dev, stage, prod) to cloud services with their own environment settings. And you can set sensible defaults. 

Inside your .env file each line is an entry, like this example:

NODE_ENV=development
API_URL=http://api.domain.com
TRANSLATION_API_URL=/translations/
GA_UA=987654321-0
NEW_RELIC_KEY=hi-mom
SOME_TOKEN=asdfasdfasdf
SOME_OTHER_TOKEN=zxcvzxcvzxcv


You should not include the .env in your version control repository (add it to your .gitignore file).

To get variables from the .env file into your environment, you can use a bash script to do the equivalent of export NODE_ENV=development right before you start your application.

#!/bin/bash
while read line; do export ""$line"";
done <source .env


Then this goes in your application javascript:

var envs = require('envs');

// If NODE_ENV is not set, 
// then this application will assume it's prod by default.
app.set('environment', envs('NODE_ENV', 'production')); 

// Usage examples:
app.set('ga_account', envs('GA_UA'));
app.set('nr_browser_key', envs('NEW_RELIC_BROWSER_KEY'));
app.set('other', envs('SOME_OTHER_TOKEN));

    Like ctrlplusb said, I recommend you to use the package dotenv, but another way to do this is creating a js file and requiring it on the first line of your app server.
env.js:
process.env.VAR1=""foo""
process.env.VAR2=""bar""

app.js:
require('./env') // env.js relative path.
console.log(process.env.VAR1) // foo

    Windows-users: pay attention! These commands are recommended for Unix but on Windows they are only temporary. They set a variable for the current shell only, as soon as you restart your machine or start a new terminal shell, they will be gone.


SET TEST=""hello world"" 
$env:TEST = ""hello world""




To set a persistent environment variable on Windows you must instead use one of the following approaches:

A) .env file in your project - this is the best method because it will mean your can move your project to other systems without having to set up your environment vars on that system beore you can run your code. 


Create an .env file in your project folder root with the content: TEST=""hello world""
Write some node code that will read that file. I suggest installing dotenv ( npm install dotenv --save) and then add require('dotenv').config(); during your node setup code. 
Now your node code will be able to accessprocess.env.TEST


Env-files are a good of keeping api-keys and other secrets that you do not want to have in your code-base. Just make sure to add it to your .gitignore .

B) Use Powershell - this will create a variable that will be accessible in other terminals. But beware, the variable will be lost after you restart your computer.

[Environment]::SetEnvironmentVariable(""TEST"", ""hello world"", ""User"") 

This method is widely recommended on Windows forums, but I don't think people are aware that the variable doesn't persist after a system restart....

C) Use the Windows GUI 


Search for ""Environment Variables"" in the Start Menu Search or in the Control Panel
Select ""Edit the system environment variables"" 
A dialogue will open. Click the button ""Environment Variables"" at the bottom of the dialogue.
Now you've got a little window for editing variables. Just click the ""New"" button to add a new environment variable. Easy.

    If you are using a mac/linux and you want to retrieve local parameters to the machine you're using, this is what you'll do:


In terminal run nano ~/.bash_profile
add a line like: export MY_VAR=var
save & run source ~/.bash_profile
in node use like: console.log(process.env.MY_VAR);

    It depends on your operating system and your shell

On linux with the shell bash, you create environment variables like this(in the console):

export FOO=bar


For more information on environment variables on ubuntu (for example):

Environment variables on ubuntu
    Make your life easier with dotenv-webpack. Simply install it npm install dotenv-webpack --save-dev, then create an .env file in your application's root (remember to add this to .gitignore before you git push). Open this file, and set some environmental variables there, like for example:

ENV_VAR_1=1234
ENV_VAR_2=abcd
ENV_VAR_3=1234abcd


Now, in your webpack config add:

const Dotenv = require('dotenv-webpack');
const webpackConfig = {
  node: { global: true, fs: 'empty' }, // Fix: ""Uncaught ReferenceError: global is not defined"", and ""Can't resolve 'fs'"".
  output: {
    libraryTarget: 'umd' // Fix: ""Uncaught ReferenceError: exports is not defined"".
  },
  plugins: [new Dotenv()]
};
module.exports = webpackConfig; // Export all custom Webpack configs.


Only const Dotenv = require('dotenv-webpack');, plugins: [new Dotenv()], and of course module.exports = webpackConfig; // Export all custom Webpack configs. are required. However, in some scenarios you might get some errors. For these you have the solution as well implying how you can fix certain error.

Now, wherever you want you can simply use process.env.ENV_VAR_1, process.env.ENV_VAR_2, process.env.ENV_VAR_3 in your application.
    Just provide the env values on command line

USER_ID='abc' USER_KEY='def' node app.js

    As expansion of @ctrlplusb answer, 
I would suggest you to also take a look to the env-dot-prop package.

It allows you to set/get properties from process.env using a dot-path.

Let's assume that your process.env contains the following:

process.env = {
  FOO_BAR: 'baz'
  'FOO_🦄': '42'
}


Then you can manipulate the environment variables like that:

const envDotProp = require('env-dot-prop');

console.log(process.env);
//=> {FOO_BAR: 'baz', 'FOO_🦄': '42'}

envDotProp.get('foo');
//=> {bar: 'baz', '🦄': '42'}

envDotProp.get('foo.🦄');
//=> '42'

envDotProp.get('foo.🦄', {parse: true});
//=> 42

envDotProp.set('baz.foo', 'bar');
envDotProp.get('', {parse: true});
//=> {foo: {bar: 'baz', '🦄': 42}, baz: {foo: 'bar'}}

console.log(process.env);
//=> {FOO_BAR: 'baz', 'FOO_🦄': '42', BAZ_FOO: 'bar'}

envDotProp.delete('foo');
envDotProp.get('');
//=> {baz: {foo: 'bar'}}

console.log(process.env);
//=> {BAZ_FOO: 'bar'}


This helps you to parse the environment variables and use them as a config object in your app.
It also helps you implement a 12-factor configuration.
    Step 1: Add your environment variables to their appropriate file. For example, your staging environment could be called .env.staging, which contains the environment variables USER_ID and USER_KEY, specific to your staging environment.

Step 2: In your package.json file, add the following:

""scripts"": {
  ""build"": ""sh -ac '. ./.env.${REACT_APP_ENV}; react-scripts build'"",
  ""build:staging"": ""REACT_APP_ENV=staging npm run build"",
  ""build:production"": ""REACT_APP_ENV=production npm run build"",
  ...
}


then call it in your deploy script like this:

npm run build:staging


Super simple set up and works like a charm!

Source: https://medium.com/@tacomanator/environments-with-create-react-app-7b645312c09d
    A very good way of doing environment variables I have successfully used is below:

A. Have different config files:  


dev.js // this has all environment variables for development only
The file contains:

module.exports = {
 ENV: 'dev',
 someEnvKey1 : 'some DEV Value1',
 someEnvKey2 : 'some DEV Value2'
};

stage.js // this has all environment variables for development only  

..

qa.js // this has all environment variables for qa testing only
The file contains:  

module.exports = {
 ENV: 'dev',
 someEnvKey1 : 'some QA Value1',
 someEnvKey2 : 'some QA Value2'
};



NOTE: the values are changing with the environment, mostly, but keys remain same.


you can have more  
z__prod.js // this has all environment variables for production/live only
NOTE: This file is never bundled for deployment
Put all these config files in /config/ folder

<projectRoot>/config/dev.js
<projectRoot>/config/qa.js
<projectRoot>/config/z__prod.js
<projectRoot>/setenv.js
<projectRoot>/setenv.bat
<projectRoot>/setenv.sh



NOTE: The name of prod is different than others, as it would not be used by all.

B. Set the OS/ Lambda/ AzureFunction/ GoogleCloudFunction environment variables from config file

Now ideally, these config variables in file, should go as OS environment variables (or, LAMBDA function variables, or, Azure function variables, Google Cloud Functions, etc.)  

so, we write automation in Windows OS (or other)


Assume we write 'setenv' bat file, which takes one argument that is environment that we want to set
Now run ""setenv dev""  


a) This takes the input from the passed argument variable ('dev' for now)
b) read the corresponding file ('config\dev.js')
c) sets the environment variables in Windows OS (or other)  

For example,

The setenv.bat contents might be:

    node setenv.js


The setenv.js contents might be:

    // import ""process.env.ENV"".js file (dev.js example)
    // loop the imported file contents
    //     set the environment variables in Windows OS (or, Lambda, etc.)


That's all, your environment is ready for use.

When you do 'setenv qa', all qa environment variables will be ready for use from qa.js, and ready for use by same program (which always asks for process.env.someEnvKey1, but the value it gets is qa one).

Hope that helps.
    For windows users this Stack Overflow question and top answer is quite useful on how to set environement variables via the command line 

How can i set NODE_ENV=production in Windows?
    Came across a nice tool for doing this.

node-env-file

Parses and loads environment files (containing ENV variable exports) into Node.js environment, i.e. process.env - Uses this style:

.env

# some env variables

FOO=foo1
BAR=bar1
BAZ=1
QUX=
# QUUX=

    I was getting undefined after setting a system env var. When I put APP_VERSION in the User env var, then I can display the value from node via process.env.APP_VERSION
    in case you're using visual studio code debugging feature, you can add ""envFile"": ""${workspaceRoot}/.env"" to launch configuration. This way you don't have to use dotenv.
{
        ""cwd"": ""${workspaceRoot}"",
        ""command"": ""npm start"",
        ""name"": ""Run be"",
        ""request"": ""launch"",
        ""type"": ""node-terminal"",
        ""envFile"": ""${workspaceRoot}/.env""
},

    Use cross-env. It will save you a lot of headache
npm i -S cross-env
cross-env PARAM=value node ./index.js
That's usually good for non-credentials. For things like credentials and keys
it's better not to store hardcoded user id and password but use .env file which is not in repo and dotenv
    ","[494, 129, 445, 224, 61, 22, 22, 4, 43, 4, 114, 3, 9, 3, 4, 4, 0, 0, 0]",805456,131,2014-03-10T22:25:57,2022-01-03 07:03:47Z,
How do I remove a substring from the end of a string?,"
                
I have the following code:

url = 'abcdc.com'
print(url.strip('.com'))


I expected: abcdc

I got: abcd

Now I do 

url.rsplit('.com', 1)


Is there a better way?
    strip doesn't mean ""remove this substring"". x.strip(y) treats y as a set of characters and strips any characters in that set from both ends of x.
On Python 3.9 and newer you can use the removeprefix and removesuffix methods to remove an entire substring from either side of the string:
url = 'abcdc.com'
url.removesuffix('.com')    # Returns 'abcdc'
url.removeprefix('abcdc.')  # Returns 'com'

The relevant Python Enhancement Proposal is PEP-616.
On Python 3.8 and older you can use endswith and slicing:
url = 'abcdc.com'
if url.endswith('.com'):
    url = url[:-4]

Or a regular expression:
import re
url = 'abcdc.com'
url = re.sub('\.com$', '', url)

    Starting in Python 3.9, you can use removesuffix instead:
'abcdc.com'.removesuffix('.com')
# 'abcdc'

    def strip_end(text, suffix):
    if suffix and text.endswith(suffix):
        return text[:-len(suffix)]
    return text

    Using replace and count
This might seems a little bit a hack but it ensures you a safe replace without using startswith and if statement, using the count arg of replace you can limit the replace to one:
mystring = ""www.comwww.com""

Prefix:
print(mystring.replace(""www."","""",1))

Suffix (you write the prefix reversed) .com becomes moc.:
print(mystring[::-1].replace(""moc."","""",1)[::-1])

    If you know it's an extension, then

url = 'abcdc.com'
...
url.rsplit('.', 1)[0]  # split at '.', starting from the right, maximum 1 split


This works equally well with abcdc.com or www.abcdc.com or abcdc.[anything] and is more extensible.
    Since it seems like nobody has pointed this on out yet:

url = ""www.example.com""
new_url = url[:url.rfind(""."")]


This should be more efficient than the methods using split() as no new list object is created, and this solution works for strings with several dots.
    Because this is a very popular question i add another, now available, solution. With python 3.9 (https://docs.python.org/3.9/whatsnew/3.9.html) the function removesuffix() will be added (and removeprefix()) and this function is exactly what was questioned here.
url = 'abcdc.com'
print(url.removesuffix('.com'))

output:
'abcdc'

PEP 616 (https://www.python.org/dev/peps/pep-0616/) shows how it will behave (it is not the real implementation):
def removeprefix(self: str, prefix: str, /) -> str:
    if self.startswith(prefix):
        return self[len(prefix):]
    else:
        return self[:]

and what benefits it has against self-implemented solutions:

Less fragile:
The code will not depend on the user to count the length of a literal.

More performant:
The code does not require a call to the Python built-in len function nor to the more expensive str.replace() method.

More descriptive:
The methods give a higher-level API for code readability as opposed to the traditional method of string slicing.


    Assuming you want to remove the domain, no matter what it is (.com, .net, etc). I recommend finding the . and removing everything from that point on.

url = 'abcdc.com'
dot_index = url.rfind('.')
url = url[:dot_index]


Here I'm using rfind to solve the problem of urls like abcdc.com.net which should be reduced to the name abcdc.com. 

If you're also concerned about www.s, you should explicitly check for them:

if url.startswith(""www.""):
   url = url.replace(""www."","""", 1)


The 1 in replace is for strange edgecases like www.net.www.com

If your url gets any wilder than that look at the regex answers people have responded with.
    A broader solution, adding the possibility to replace the suffix (you can remove by replacing with the empty string) and to set the maximum number of replacements:
def replacesuffix(s,old,new='',limit=1):
    """"""
    String suffix replace; if the string ends with the suffix given by parameter `old`, such suffix is replaced with the string given by parameter `new`. The number of replacements is limited by parameter `limit`, unless `limit` is negative (meaning no limit).

    :param s: the input string
    :param old: the suffix to be replaced
    :param new: the replacement string. Default value the empty string (suffix is removed without replacement).
    :param limit: the maximum number of replacements allowed. Default value 1.
    :returns: the input string with a certain number (depending on parameter `limit`) of the rightmost occurrences of string given by parameter `old` replaced by string given by parameter `new`
    """"""
    if s[len(s)-len(old):] == old and limit != 0:
        return replacesuffix(s[:len(s)-len(old)],old,new,limit-1) + new
    else:
        return s

In your case, given the default arguments, the desired result is obtained with:
replacesuffix('abcdc.com','.com')
>>> 'abcdc'

Some more general examples:
replacesuffix('whatever-qweqweqwe','qwe','N',2)
>>> 'whatever-qweNN'

replacesuffix('whatever-qweqweqwe','qwe','N',-1)
>>> 'whatever-NNN'

replacesuffix('12.53000','0',' ',-1)
>>> '12.53   '

    If you mean to only strip the extension:

'.'.join('abcdc.com'.split('.')[:-1])
# 'abcdc'


It works with any extension, with potential other dots existing in filename as well. It simply splits the string as a list on dots and joins it without the last element.
    If you need to strip some end of a string if it exists otherwise do nothing. My best solutions. You probably will want to use one of first 2 implementations however I have included the 3rd for completeness.
For a constant suffix:
def remove_suffix(v, s):
    return v[:-len(s)] if v.endswith(s) else v
remove_suffix(""abc.com"", "".com"") == 'abc'
remove_suffix(""abc"", "".com"") == 'abc'

For a regex:
def remove_suffix_compile(suffix_pattern):
    r = re.compile(f""(.*?)({suffix_pattern})?$"")
    return lambda v: r.match(v)[1]
remove_domain = remove_suffix_compile(r""\.[a-zA-Z0-9]{3,}"")
remove_domain(""abc.com"") == ""abc""
remove_domain(""sub.abc.net"") == ""sub.abc""
remove_domain(""abc."") == ""abc.""
remove_domain(""abc"") == ""abc""

For a collection of constant suffixes the asymptotically fastest way for a large number of calls:
def remove_suffix_preprocess(*suffixes):
    suffixes = set(suffixes)
    try:
        suffixes.remove('')
    except KeyError:
        pass

    def helper(suffixes, pos):
        if len(suffixes) == 1:
            suf = suffixes[0]
            l = -len(suf)
            ls = slice(0, l)
            return lambda v: v[ls] if v.endswith(suf) else v
        si = iter(suffixes)
        ml = len(next(si))
        exact = False
        for suf in si:
            l = len(suf)
            if -l == pos:
                exact = True
            else:
                ml = min(len(suf), ml)
        ml = -ml
        suffix_dict = {}
        for suf in suffixes:
            sub = suf[ml:pos]
            if sub in suffix_dict:
                suffix_dict[sub].append(suf)
            else:
                suffix_dict[sub] = [suf]
        if exact:
            del suffix_dict['']
            for key in suffix_dict:
                suffix_dict[key] = helper([s[:pos] for s in suffix_dict[key]], None)
            return lambda v: suffix_dict.get(v[ml:pos], lambda v: v)(v[:pos])
        else:
            for key in suffix_dict:
                suffix_dict[key] = helper(suffix_dict[key], ml)
            return lambda v: suffix_dict.get(v[ml:pos], lambda v: v)(v)
    return helper(tuple(suffixes), None)
domain_remove = remove_suffix_preprocess("".com"", "".net"", "".edu"", "".uk"", '.tv', '.co.uk', '.org.uk')

the final one is probably significantly faster in pypy then cpython. The regex variant is likely faster than this for virtually all cases that do not involve huge dictionaries of potential suffixes that cannot be easily represented as a regex at least in cPython.
In PyPy the regex variant is almost certainly slower for large number of calls or long strings even if the re module uses a DFA compiling regex engine as the vast majority of the overhead of the lambda's will be optimized out by the JIT.
In cPython however the fact that your running c code for the regex compare almost certainly outweighs the algorithmic advantages of the suffix collection version in almost all cases.
Edit: https://m.xkcd.com/859/
    In my case I needed to raise an exception so I did:

class UnableToStripEnd(Exception):
    """"""A Exception type to indicate that the suffix cannot be removed from the text.""""""

    @staticmethod
    def get_exception(text, suffix):
        return UnableToStripEnd(""Could not find suffix ({0}) on text: {1}.""
                                .format(suffix, text))


def strip_end(text, suffix):
    """"""Removes the end of a string. Otherwise fails.""""""
    if not text.endswith(suffix):
        raise UnableToStripEnd.get_exception(text, suffix)
    return text[:len(text)-len(suffix)]

    This is a perfect use for regular expressions:

>>> import re
>>> re.match(r""(.*)\.com"", ""hello.com"").group(1)
'hello'

    For urls (as it seems to be a part of the topic by the given example), one can do something like this:

import os
url = 'http://www.stackoverflow.com'
name,ext = os.path.splitext(url)
print (name, ext)

#Or:
ext = '.'+url.split('.')[-1]
name = url[:-len(ext)]
print (name, ext)


Both will output:
('http://www.stackoverflow', '.com')

This can also be combined with str.endswith(suffix) if you need to just split "".com"", or anything specific. 
    Python >= 3.9:

'abcdc.com'.removesuffix('.com')


Python < 3.9:

def remove_suffix(text, suffix):
    if text.endswith(suffix):
        text = text[:-len(suffix)]
    return text

remove_suffix('abcdc.com', '.com')

    DSCLAIMER This method has a critical flaw in that the partition is not anchored to the end of the url and may return spurious results. For example, the result for the URL ""www.comcast.net"" is ""www"" (incorrect) instead of the expected ""www.comcast.net"". This solution therefore is evil. Don't use it unless you know what you are doing!
url.rpartition('.com')[0]

This is fairly easy to type and also correctly returns the original string (no error) when the suffix '.com' is missing from url.
    How about url[:-4]?
    import re

def rm_suffix(url = 'abcdc.com', suffix='\.com'):
    return(re.sub(suffix+'$', '', url))


I want to repeat this answer as the most expressive way to do it. Of course, the following would take less CPU time:

def rm_dotcom(url = 'abcdc.com'):
    return(url[:-4] if url.endswith('.com') else url)


However, if CPU is the bottle neck why write in Python?

When is CPU a bottle neck anyway? In drivers, maybe.

The advantages of using regular expression is code reusability. What if you next want to remove '.me', which only has three characters?

Same code would do the trick:

>>> rm_sub('abcdc.me','.me')
'abcdc'

    Here,i have a simplest code.

url=url.split(""."")[0]

    You can use split:

'abccomputer.com'.split('.com',1)[0]
# 'abccomputer'

    I used the built-in rstrip function to do it like follow:

string = ""test.com""
suffix = "".com""
newstring = string.rstrip(suffix)
print(newstring)
test

    Depends on what you know about your url and exactly what you're tryinh to do.  If you know that it will always end in '.com' (or '.net' or '.org') then 

 url=url[:-4]


is the quickest solution. If it's a more general URLs then you're probably better of looking into the urlparse library that comes with python.  

If you on the other hand you simply want to remove everything after the final '.' in a string then    

url.rsplit('.',1)[0]


will work.  Or if you want just want everything up to the first '.' then try

url.split('.',1)[0]

    On Python 3.9+:
text.removesuffix(suffix)

On any Python version:
def remove_suffix(text, suffix):
    return text[:-len(suffix)] if text.endswith(suffix) and len(suffix) != 0 else text

or the one-liner:
remove_suffix = lambda text, suffix: text[:-len(suffix)] if text.endswith(suffix) and len(suffix) != 0 else text

    If you are sure that the string only appears at the end, then the simplest way would be to use 'replace':

url = 'abcdc.com'
print(url.replace('.com',''))

    ","[494, 744, 27, 61, 1, 16, 56, 3, 3, 1, 4, 3, 1, 0, 6, 0, 6, 8, 2, 0, 1, -2, 27, 13, 103]",887306,77,2009-06-24T14:44:01,2022-04-25 23:42:26Z,python 
How to emulate GPS location in the Android Emulator?,"
                
I want to get longitude and latitude in Android emulator for testing.

Can any one guide me how to achieve this?

How do I set the location of the emulator to a test position?
    No one here mentioned the built in solution of the emulator itself, so for future visitors, I'd like to share it with visuals.

First, run your Android Emulator and click on the menu button (3 dots) shown below:



Then from the left pane, select Location and change the coordinates according to your needs. After pressing Send button, changes will immediately take effect (I recommend you to open up Google Maps for better understanding).



Android Studio Version: 2.3.3

In addition, to make your different locations coming to your application in real time, you can use GPX file. It's very easy to create this file from Google Map direction link:


Go to google map, choose a location, then press ""Directions"" and enter the second location.
After route is created, copy a link from the browser
Go to this website: https://mapstogpx.com and paste the link to ""Let's Go"" box
Press the ""Let's Go"" button and GPX file will be downloaded 


Use ""Load GPS/KML"" button to load the created file to your emulator, choose speed, and press green play button on the bottom. Locations will be sent in real time as shown on the picture below.

 
    You can connect to the Emulator via Telnet. You then have a Emulator console that lets you enter certain data like geo fixes, network etc. 

How to use the console is extensively explained here.
To connect to the console open a command line and type

telnet localhost 5554


You then can use the geo command to set a latitude, longitude and if needed altitude on the device that is passed to all programs using the gps location provider. See the link above for further instructions. 

The specific command to run in the console is

geo fix <longitude value> <latitude value>


I found this site useful for finding a realistic lat/lng: http://itouchmap.com/latlong.html

If you need more then one coordinate you can use a kml file with a route as well it is a little bit described in this article. I can't find a better source at the moment.
    Sorry for the NecroPost, but after following some of the suggestions on this question, I set my location to Alaska. However, my device was still showing to be in Mountain View, California (Google's HQ?). So here's how I did a fix:
1) Go to the location settings:

2) Set your test location. I chose Alaska.

3) Google ""My current location"" and click on the map circled in the picture.
Note that even though I set location as Alaska, my Virtual Device still thinks it's in Mountain View, California.

4) Click on this location Icon
Your location should now be updated on your device.
You can verify by Googling ""My current location"" again.

If anyone experienced this same issue, I hope my solution helped you.
    The following solution worked for me - open command line and write:

adb emu geo fix [longtitude] [latitude]

    I was looking for a better way to set the emulator's GPS coordinates than using geo fix and manually determining the specific latitude and longitude coordinates.

Unable to find anything, I put together a little program that uses GWT and the Google Maps API to launch a browser-based map tool to set the GPS location in the emulator:

android-gps-emulator

Hopefully it can be of use to help others who will undoubtedly stumble across this difficulty/question as well.


    Finally with the latest release of Android Studio 4 and his new Emulator update 10/23/2019 it become easier. 
Start your emulator and go to emulator parameters ... > in ""Routes"" tab you can choose two points on the map from/to and start a new route with an adjustable playback speed that can go to more than 1000km/h!  


    1. Android Studio users.
After running the emulator goto Tools->Android->Android device monitor
Click the Emulator Control Tab change from the location controls group.
2. Eclipse users.
First In Eclipse In Menu Select ""Window"" then Select ""Open Perspective"" then Select ""DDMS"".
i.e Window->Open Prespective->DDMS.
You will see on Left Side Devices Panel and on Right Side you will see different tabs.
Select ""Emulator Control"" Tab.
At bottom you will see Location Controls Panel.
Select ""Manual"" Tab.
Enter Longitude and Latitude in Textboxs then Click Send Button.
It will send the position to you emulator and the application.
3. Using telnet.
In the run command type this.
telnet localhost 5554

If you are not using windows you can use any telnet client.
After connecting with telnet use the following command to send your position to emulator.
geo fix long lat    
geo fix -121.45356 46.51119 4392

4. Use the browser based Google maps tool
There is a program that uses GWT and the Google Maps API to launch a browser-based map tool to set the GPS location in the emulator:
android-gps-emulator
    Go to Extended controls in emulate. After You can then set the location for the emulate by searching or dragging the map to the location you want to set.

Finally Click on SET LOCATION button to save.
    In Mac, Linux or Cygwin:

echo 'geo fix -99.133333 19.43333 2202' | nc localhost 5554


That will put you in Mexico City. Change your longitude/latitude/altitude accordingly. That should be enough if you are not interested in nmea. 
    Can't comment yet, so updating @ectomorphs answer here, which when telneting now requires to have an auth token. In linux that's under /home/username/.emulator_console_auth_token

#!/usr/bin/env python
# -*- coding: utf-8 -*-
import sys
import telnetlib
from time import sleep
import random

FILE = open('/home/username/.emulator_console_auth_token', 'r')
AUTH_TOKEN = FILE.read()
FILE.close()

HOST = ""127.0.0.1""
PORT = 5554
TIMEOUT = 10
LAT_SRC = 52.5243700
LNG_SRC = 13.4105300
LAT_DST = 53.5753200
LNG_DST = 10.0153400
SECONDS = 120

LAT_MAX_STEP = ((max(LAT_DST, LAT_SRC) - min(LAT_DST, LAT_SRC)) / SECONDS) * 2
LNG_MAX_STEP = ((max(LNG_DST, LNG_SRC) - min(LNG_DST, LNG_SRC)) / SECONDS) * 2

DIRECTION_LAT = 1 if LAT_DST - LAT_SRC > 0 else -1
DIRECTION_LNG = 1 if LNG_DST - LNG_SRC > 0 else -1

lat = LAT_SRC
lng = LNG_SRC

tn = telnetlib.Telnet(HOST, PORT, TIMEOUT)
tn.set_debuglevel(9)
tn.read_until(""OK"", 5)

tn.write(""auth {0}\n"".format(AUTH_TOKEN))
tn.read_until(""OK"", 5)

tn.read_until(""OK"", 5)

tn.write(""geo fix {0} {1}\n"".format(LNG_SRC, LAT_SRC))
#tn.write(""exit\n"")

for i in range(SECONDS):
    lat += round(random.uniform(0, LAT_MAX_STEP), 7) * DIRECTION_LAT
    lng += round(random.uniform(0, LNG_MAX_STEP), 7) * DIRECTION_LNG

    #tn.read_until(""OK"", 5)
    tn.write(""geo fix {0} {1}\n"".format(lng, lat))
    #tn.write(""exit\n"")
    sleep(1)

tn.write(""geo fix {0} {1}\n"".format(LNG_DST, LAT_DST))
tn.write(""exit\n"")

print tn.read_all()


From a shell script one can set the coorinate like so

#!/usr/bin/env bash
export ATOKEN=`cat ~/.emulator_console_auth_token`
echo -ne ""auth $ATOKEN\ngeo fix -99.133333 19.43333 2202\n""  | nc localhost 5554

    For the new emulator:

http://developer.android.com/tools/devices/emulator.html#extended

Basically, click on the three dots button in the emulator controls (to the right of the emulator) and it will open up a menu which will allow you to control the emulator including location
    For Android Studio users: 

run the emulator,

Then, go to Tools -> Android ->Android device monitor

open the Emulator Control Tab, and use the location controls group.
    If you're using Eclipse, go to Window->Open Perspective->DDMS, then type one in Location Controls and hit Send.
    Assuming you've got a mapview set up and running:

MapView mapView = (MapView) findViewById(R.id.mapview);
final MyLocationOverlay myLocation = new MyLocationOverlay(this, mapView);

mapView.getOverlays().add(myLocation);
myLocation.enableMyLocation();

myLocation.runOnFirstFix(new Runnable() {
    public void run() {
        GeoPoint pt = myLocation.getMyLocation();
    }
});


You'll need the following permission in your manifest:

<uses-permission android:name=""android.permission.ACCESS_FINE_LOCATION""/>


And to send mock coordinates to the emulator from Eclipse, Go to the ""Window"" menu, select ""Show View"" > ""Other"" > ""Emulator control"", and you can send coordinates from the emulator control pane that appears.
    The already mentioned multiple times answer to use the shell command ""geo fix..."" is the correct answer.
But in case you use LocationClient.getLastLocation() to retrieve your data it is worth to mention that it will not work at first. The LocationClient class uses the Google Play Service to retrieve the coordinates. 
For me this started working after running the emulators maps app once. During the first start you are asked to allow google apps access to your location, which I guess does the trick.
    Just make Alberto Gaona's answer into one line

token=$(cat ~/.emulator_console_auth_token); cat <(echo -e ""auth $token \n  geo fix 96.0290791 16.9041016  \n exit"") - | nc localhost 5554


5554 is the emulator port number shown in adb devices.

It would have been better if adb emu work.
    In Linux where communication ports are blocked. navigate the terminal to platform-tools folder inside android sdk and fire this command:

./adb -s #{device_name} emu geo fix #{longitude} #{latitude}

    

Open Android studio->Tools menu->Android-> Android Device Monitor->Emulator Tab->Location control-> Set your required latitude and longitude and check your project as per your need
    I wrote a python script to push gps locations to the emulator via telnet. It defines a source and a destination location. There is also a time offset which lets you control how long coordinates will be pushed to the device. One location is beeing pushed once a second.

In the example below the script moves from Berlin to Hamburg in 120 seconds. One step/gps location per second with random distances. 

#!/usr/bin/python
# -*- coding: utf-8 -*-
import sys
import telnetlib
from time import sleep
import random

HOST = ""127.0.0.1""
PORT = 5554
TIMEOUT = 10
LAT_SRC = 52.5243700
LNG_SRC = 13.4105300
LAT_DST = 53.5753200
LNG_DST = 10.0153400
SECONDS = 120

LAT_MAX_STEP = ((max(LAT_DST, LAT_SRC) - min(LAT_DST, LAT_SRC)) / SECONDS) * 2
LNG_MAX_STEP = ((max(LNG_DST, LNG_SRC) - min(LNG_DST, LNG_SRC)) / SECONDS) * 2

DIRECTION_LAT = 1 if LAT_DST - LAT_SRC > 0 else -1
DIRECTION_LNG = 1 if LNG_DST - LNG_SRC > 0 else -1

lat = LAT_SRC
lng = LNG_SRC

tn = telnetlib.Telnet(HOST, PORT, TIMEOUT)
tn.set_debuglevel(9)
tn.read_until(""OK"", 5)

tn.write(""geo fix {0} {1}\n"".format(LNG_SRC, LAT_SRC))
#tn.write(""exit\n"")

for i in range(SECONDS):
    lat += round(random.uniform(0, LAT_MAX_STEP), 7) * DIRECTION_LAT
    lng += round(random.uniform(0, LNG_MAX_STEP), 7) * DIRECTION_LNG

    #tn.read_until(""OK"", 5)
    tn.write(""geo fix {0} {1}\n"".format(lng, lat))
    #tn.write(""exit\n"")
    sleep(1)

tn.write(""geo fix {0} {1}\n"".format(LNG_DST, LAT_DST))
tn.write(""exit\n"")

print tn.read_all()

    There is a plugin for Android Studio called “Mock Location Plugin”. 
You can emulate multiple points with this plugin.
You can find a detailed manual of use in this link: Android Studio. Simulate multiple GPS points with Mock Location Plugin
    Using the ""geo"" command in the emulator console

To send mock location data from the command line:


Launch your application in the Android emulator and open a terminal/console in your SDK's /tools directory.
Connect to the emulator console:

telnet localhost 5555 (Replace 5555 with whatever port your emulator is running on)
Send the location data:
      * geo fix to send a fixed geo-location.

This command accepts a longitude and latitude in decimal degrees, and an optional altitude in meters. For example:

geo fix -121.45356 46.51119 4392


    I use eclipse plug DDMS function to send GPS.

    See Obtaining User Location

Look under Providing Mock Location Data. You will find the solution for it.
    First go in DDMS section in your eclipse 
Than open emulator Control ....
                             Go To Manual Section
                                           set lat and long and then press Send Button 
    I was trying to set the geo fix through adb for many points and could not get my app to see any GPS data.  But when I tried opening DDMS, selecting my app's process and sending coordinates through the emulator control tab it worked right away.
    Dalvik Debug Monitor > Select Emulator > Emulator Control Tab > Location Controls. 

DDMS -- android_sdk/tools/ddms OR android_sdk/tools/monitor
    If you are using eclipse then using Emulator controller you can manually set latitude and longitude and run your map based  app in emulator
    If you're using Android Studio (1.3):


Click on Menu ""Tools""
""Android""
""Android device monitor""
click on your current Emulator
Tab ""Emulator Control""
go to ""Location Controls"" and enter Lat and Lon

    If the above solutions don't work. Try this:

Inside your android Manifest.xml, add the following two links OUTSIDE of the application tag, but inside your manifest tag of course

<uses-permission android:name=""android.permission.ACCESS_FINE_LOCATION"" ></uses-permission>
<uses-permission android:name=""android.permission.INTERNET"" ></uses-permission>

    I was unable to get a GPS fix on the emulator when emulator was running Android image without Google APIs. As soon as I changed the image to contain Google APIs all of the here mentioned ways to get a GPS fix worked.

Make sure you select an image with Google APIs when creating AVD.
    ","[494, 202, 464, 6, 11, 117, 12, 14, 1, 6, 1, 14, 33, 81, 14, 1, 2, 5, 1, 8, 1, 10, 5, 4, 4, 3, 3, 2, 2, 1, 1]",474075,179,2010-02-17T09:55:51,2021-12-25 03:33:35Z,
"What's the meaning of ""=>"" (an arrow formed from equals & greater than) in JavaScript?","
                
I know that the >= operator means more than or equal to, but I've seen => in some source code. What's the meaning of that operator?

Here's the code:

promiseTargetFile(fpParams, aSkipPrompt, relatedURI).then(aDialogAccepted => {
    if (!aDialogAccepted)
        return;

    saveAsType = fpParams.saveAsType;
    file = fpParams.file;

    continueSave();
}).then(null, Components.utils.reportError);

    What It Is
This is an arrow function. Arrow functions are a short syntax, introduced by ECMAscript 6, that can be used similarly to the way you would use function expressions. In other words, you can often use them in place of expressions like function (foo) {...}. But they have some important differences. For example, they do not bind their own values of this (see below for discussion).
Arrow functions are part of the ECMAscript 6 specification. They are not yet supported in all browsers, but they are partially or fully supported in Node v. 4.0+ and in most modern browsers in use as of 2018. (I’ve included a partial list of supporting browsers below).
You can read more in the Mozilla documentation on arrow functions.
From the Mozilla documentation:

An arrow function expression (also known as fat arrow function) has a shorter syntax compared to function expressions and lexically binds the this value (does not bind its own this, arguments, super, or new.target). Arrow functions are always anonymous. These function expressions are best suited for non-method functions and they can not be used as constructors.

A Note on How this Works in Arrow Functions
One of the most handy features of an arrow function is buried in the text above:

An arrow function... lexically binds the this value (does not bind its own this...)

What this means in simpler terms is that the arrow function retains the this value from its context and does not have its own this. A traditional function may bind its own this value, depending on how it is defined and called. This can require lots of gymnastics like self = this;, etc., to access or manipulate this from one function inside another function. For more info on this topic, see the explanation and examples in the Mozilla documentation.
Example Code
Example (also from the docs):
var a = [
  ""We're up all night 'til the sun"",
  ""We're up all night to get some"",
  ""We're up all night for good fun"",
  ""We're up all night to get lucky""
];

// These two assignments are equivalent:

// Old-school:
var a2 = a.map(function(s){ return s.length });

// ECMAscript 6 using arrow functions
var a3 = a.map( s => s.length );

// both a2 and a3 will be equal to [31, 30, 31, 31]


Notes on Compatibility
You can use arrow functions in Node, but browser support is spotty.
Browser support for this functionality has improved quite a bit, but it still is not widespread enough for most browser-based usages. As of December 12, 2017, it is supported in current versions of:

Chrome (v. 45+)
Firefox (v. 22+)
Edge (v. 12+)
Opera (v. 32+)
Android Browser (v. 47+)
Opera Mobile (v. 33+)
Chrome for Android (v. 47+)
Firefox for Android (v. 44+)
Safari (v. 10+)
iOS Safari (v. 10.2+)
Samsung Internet (v. 5+)
Baidu Browser (v. 7.12+)

Not supported in:

IE (through v. 11)
Opera Mini (through v. 8.0)
Blackberry Browser (through v. 10)
IE Mobile (through v. 11)
UC Browser for Android (through v. 11.4)
QQ (through v. 1.2)

You can find more (and more current) information at CanIUse.com (no affiliation).
    That's known as an Arrow Function, part of the ECMAScript 2015 spec...

var foo = ['a', 'ab', 'abc'];

var bar = foo.map(f => f.length);

console.log(bar); // 1,2,3


Shorter syntax than the previous:

// < ES6:
var foo = ['a', 'ab', 'abc'];

var bar = foo.map(function(f) {
  return f.length;
});
console.log(bar); // 1,2,3


DEMO

The other awesome thing is lexical this... Usually, you'd do something like:

function Foo() {
  this.name = name;
  this.count = 0;
  this.startCounting();
}

Foo.prototype.startCounting = function() {
  var self = this;
  setInterval(function() {
    // this is the Window, not Foo {}, as you might expect
    console.log(this); // [object Window]
    // that's why we reassign this to self before setInterval()
    console.log(self.count);
    self.count++;
  }, 1000)
}

new Foo();


But that could be rewritten with the arrow like this:

function Foo() {
  this.name = name;
  this.count = 0;
  this.startCounting();
}

Foo.prototype.startCounting = function() {
  setInterval(() => {
    console.log(this); // [object Object]
    console.log(this.count); // 1, 2, 3
    this.count++;
  }, 1000)
}

new Foo();


DEMO

MDN
More on Syntax

For more, here's a pretty good answer for when to use arrow functions.
    JavaScript arrow functions are roughly the equivalent of lambda functions in python or blocks in Ruby. These are anonymous functions with their own special syntax and operate in the context of their enclosing scope. This mean they do not have their own ""this"" but instead access the one from the immediate enclosing function.
From the ECMA standard:

An ArrowFunction does not define local bindings for arguments,
super, this, or new.target. Any reference to arguments, super, this, or new.target within an ArrowFunction must resolve to a
binding in a lexically enclosing environment. Typically this will be
the Function Environment of an immediately enclosing function.

Often you can read ""an arrow function expression is a compact alternative to a traditional function expression"", this is not a correct. Arrow function are NOT a shorthand for traditional function, they behave differently that traditional function.
Syntax
// Traditional Function
// Create their own scope inside the function
function (a){
  return a + 100;
}

// Arrow Function 
// Do NOT create their own scope
// (Each step along the way is a valid ""arrow function"")

// 1. Remove the word ""function"" and place arrow between the argument and opening body bracket
(a) => {
  return a + 100;
}

// 2. Remove the body braces and word ""return"" -- the return is implied.
(a) => a + 100;

// 3. Remove the argument parentheses (only valid with exactly one argument)
a => a + 100;

    These are Arrow Functions
Also known as Fat Arrow Functions. They're a clean and consise way to write function expressions, e.g. function() {}.
Arrow Functions can remove the need of function, return and {} when defining functions. They are one-liners, similar to Lambda Expressions in Java or Python.
Example with no parameters
const queue = ['Dave', 'Sarah', 'Sharon'];
const nextCustomer = () => queue[0];

console.log(nextCustomer()); // 'Dave'

If multiple statements need to be made within the same Arrow Function, you need to wrap, in this example, queue[0] in curley brackets {}. In this case the return statement cannot be omitted.
Example with 1 parameter
const queue = ['Dave', 'Sarah', 'Sharon'];
const addCustomer = name => {
  queue.push(name);
};

addCustomer('Toby');

console.log(queue); // ['Dave', 'Sarah', 'Sharon', 'Toby']

You can omit {} from the above.
When there is a single parameter, the brackets () around the parameter can be omitted.
Example with multiple parameters
const addNumbers = (x, y) => x + y

console.log(addNumbers(1, 5)); // 6

A useful example
const fruits = [
    { name: 'Apple', price: 2 },
    { name: 'Bananna', price: 3 },
    { name: 'Pear', price: 1 }
];

If we wanted to get the price of every fruit in a single array, in ES5 we could do:
fruits.map(function(fruit) {
    return fruit.price;
}); // [2, 3, 1]

In ES6 with the new Arrow Functions, we can make this more concise:
fruits.map(fruit => fruit.price); // [2, 3, 1]

Additional information on Arrow Functions can be found here.
    This would be the ""arrow function expression"" introduced in ECMAScript 6.

https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/arrow_functions

For historical purposes (if the wiki page changes later), it is:


  An arrow function expression has a shorter syntax compared to function expressions and lexically binds the this value. Arrow functions are always anonymous.

    Arrow functions which is denoted by symbol (=>) helps you to create anonymous functions and methods. That leads to more shorter syntax. For example, below is a simple “Add” function which returns addition of two numbers.

function Add(num1 , num2 ){
return num1 + num2;
}


The above function becomes shorter by using “Arrow” syntax as shown below.



Above code has two parts as shown in the above diagram: -

Input: — This section specifies the input parameters to the anonymous function.

Logic: — This section comes after the symbol “=>”. This section has the logic of the actual function.

Many developers think that arrow function makes your syntax shorter, simpler and thus makes your code readable.

If you believe the above sentence, then let me assure you it’s a myth. If you think for a moment a properly written function with name is much readable than cryptic functions created in one line using an arrow symbol.


  The main use of arrow function is to ensure that code runs in the
  callers context.


See the below code in which have a global variable ""context"" defined , this global variable is accessed inside a function ""SomeOtherMethod"" which is called from other method ""SomeMethod"".

This ""SomeMethod"" has local ""context"" variable. Now because ""SomeOtherMethod"" is called from """"SomeMethod"" we expect it to display ""local context"" , but it displays ""global context"".

var context = “global context”;

function SomeOtherMethod(){
alert(this.context);
}

function SomeMethod(){
this.context = “local context”;
SomeOtherMethod();
}

var instance = new SomeMethod();


But if replace the call by using Arrow function it will display ""local context"".

var context = ""global context"";

    function SomeMethod(){
        this.context = ""local context"";
        SomeOtherMethod = () => {
            alert(this.context);
        }
        SomeOtherMethod();
    }
    var instance = new SomeMethod();


I would encourage you to read this link ( Arrow function in JavaScript ) which explain all the scenarios of javascript context and in which scenarios the callers context is not respected.

You can also see the demonstration of Arrow function with javascript in this youtube video which demonstrates practically the term Context.
    Dissatisfied with the other answers. The top voted answer as of 2019/3/13 is factually wrong.
The short terse version of what => means is it's a shortcut writing a function AND for binding it to the current this
const foo = a => a * 2;

Is effectively a shortcut for
const foo = function(a) { return a * 2; }.bind(this);

You can see all the things that got shortened. We didn't need function, nor return nor .bind(this) nor even braces or parentheses
A slightly longer example of an arrow function might be
const foo = (width, height) => {
  const area = width * height;
  return area;
};

Showing that if we want multiple arguments to the function we need parentheses and if we want write more than a single expression we need braces and an explicit return.
It's important to understand the .bind part and it's a big topic. It has to do with what this means in JavaScript.
ALL functions have an implicit parameter called this. How this is set when calling a function depends on how that function is called.
Take
function foo() { console.log(this); }

If you call it normally
function foo() { console.log(this); }
foo();

this will be the global object.
If you're in strict mode
`use strict`;
function foo() { console.log(this); }
foo();

// or

function foo() {
   `use strict`;
   console.log(this);
 }
foo();

It will be undefined
You can set this directly using call or apply
function foo(msg) { console.log(msg, this); }

const obj1 = {abc: 123}
const obj2 = {def: 456}

foo.call(obj1, 'hello');  // prints Hello {abc: 123}
foo.apply(obj2, ['hi']);  // prints Hi {def: 456}

You can also set this implicitly using the dot operator .
function foo(msg) { console.log(msg, this); }
const obj = {
   abc: 123,
   bar: foo,
}
obj.bar('Hola');  // prints Hola {abc:123, bar: f}

A problem comes up when you want to use a function as a callback or a listener. You make class and want to assign a function as the callback that accesses an instance of the class.
class ShowName {
  constructor(name, elem) {
    this.name = name;
    elem.addEventListener('click', function() {
       console.log(this.name);  // won't work
    }); 
  }
}

The code above will not work because when the element fires the event and calls the function the this value will not be the instance of the class.
One common way to solve that problem is to use .bind
class ShowName {
  constructor(name, elem) {
    this.name = name;
    elem.addEventListener('click', function() {
       console.log(this.name); 
    }.bind(this); // <=========== ADDED! ===========
  }
}

Because the arrow syntax does the same thing we can write
class ShowName {
  constructor(name, elem) {
    this.name = name;
    elem.addEventListener('click',() => {
       console.log(this.name); 
    });
  }
}

bind effectively makes a new function. If bind did not exist you could basically make your own like this
function bind(functionToBind, valueToUseForThis) {
  return function(...args) {
    functionToBind.call(valueToUseForThis, ...args);
  };
}

In older JavaScript without the spread operator it would be
function bind(functionToBind, valueToUseForThis) {
  return function() {
    functionToBind.apply(valueToUseForThis, arguments);
  };
}

Understanding that code requires an understanding of closures but the short version is bind makes a new function that always calls the original function with the this value that was bound to it. Arrow functions do the same thing since they are a shortcut for bind(this)
    As others have said, it's a new syntax to create functions.

However, this kind of functions differ from normal ones:


They bind the this value. As explained by the spec,


  An ArrowFunction does not define local bindings for arguments,
  super, this, or new.target. Any reference to arguments,
  super, this, or new.target within an ArrowFunction must
  resolve to a binding in a lexically enclosing environment. Typically
  this will be the Function Environment of an immediately enclosing
  function.
  
  Even though an ArrowFunction may contain references to super, the
  function object created in step 4 is not made into a method by
  performing MakeMethod. An ArrowFunction that references super
  is always contained within a non-ArrowFunction and the necessary
  state to implement super is accessible via the scope that is
  captured by the function object of the ArrowFunction.

They are non-constructors.

That means they have no [[Construct]] internal method, and thus can't be instantiated, e.g.

var f = a => a;
f(123);  // 123
new f(); // TypeError: f is not a constructor


    As others have stated, regular (traditional) functions use this from the object that called the function, (e.g. a button that was clicked). Instead, arrow functions use this from the object that defines the function.

Consider two almost identical functions:

regular = function() {
  ' Identical Part Here;
}


arrow = () => {
  ' Identical Part Here;
}


The snippet below demonstrates the fundamental difference between what this represents for each function.  The regular function outputs [object HTMLButtonElement] whereas the arrow function outputs [object Window]. 

<html>
 <button id=""btn1"">Regular: `this` comes from ""this button""</button>
 <br><br>
 <button id=""btn2"">Arrow: `this` comes from object that defines the function</button>
 <p id=""res""/>

 <script>
  regular = function() {
    document.getElementById(""res"").innerHTML = this;
  }

  arrow = () => {
    document.getElementById(""res"").innerHTML = this;
  }

  document.getElementById(""btn1"").addEventListener(""click"", regular);
  document.getElementById(""btn2"").addEventListener(""click"", arrow);
 </script>
</html>

    just to add another example of what a lambda can do without using map:

a = 10
b = 2

var mixed = (a,b) => a * b; 
// OR
var mixed = (a,b) => { (any logic); return a * b };

console.log(mixed(a,b)) 
// 20

    ES6 Arrow functions:

In javascript the => is the symbol of an arrow function expression. A arrow function expression does not have its own this binding and therefore cannot be used as a constructor function. for example:

var words = 'hi from outside object';

let obj = {
  words: 'hi from inside object',
  talk1: () => {console.log(this.words)},
  talk2: function () {console.log(this.words)}
}

obj.talk1();  // doesn't have its own this binding, this === window
obj.talk2();  // does have its own this binding, this is obj


Rules of using arrow functions:


If there is exactly one argument you can omit the parentheses of the argument.
If you return an expression and do this on the same line you can omit the {} and the return statement


For example:

let times2 = val => val * 2;  
// It is on the same line and returns an expression therefore the {} are ommited and the expression returns implictly
// there also is only one argument, therefore the parentheses around the argument are omitted

console.log(times2(3));

    Adding simple CRUD example with Arrowfunction

 //Arrow Function
 var customers   = [
   {
     name: 'Dave',
     contact:'9192631770'
   },
   {
     name: 'Sarah',
     contact:'9192631770'
   },
   {
     name: 'Akhil',
     contact:'9928462656' 
   }],

// No Param READ
 getFirstCustomer = () => { 
   console.log(this);
   return customers[0];
 };
  console.log(""First Customer ""+JSON.stringify(getFirstCustomer())); // 'Dave' 

   //1 Param SEARCH
  getNthCustomer = index=>{
    if( index>customers.length)
    {
     return  ""No such thing"";
   }
   else{
       return customers[index];
     } 
  };
  console.log(""Nth Customer is "" +JSON.stringify(getNthCustomer(1))); 

   //2params ADD
  addCustomer = (name, contact)=> customers.push({
     'name': name,
     'contact':contact
    });
  addCustomer('Hitesh','8888813275');
  console.log(""Added Customer ""+JSON.stringify(customers)); 

  //2 param UPDATE
  updateCustomerName = (index, newName)=>{customers[index].name= newName};
  updateCustomerName(customers.length-1,""HiteshSahu"");
  console.log(""Updated Customer ""+JSON.stringify(customers));

  //1 param DELETE
  removeCustomer = (customerToRemove) => customers.pop(customerToRemove);
  removeCustomer(getFirstCustomer());
  console.log(""Removed Customer ""+JSON.stringify(customers)); 

    I've read, this is a symbol of Arrow Functions in ES6

this 

var a2 = a.map(function(s){ return s.length });


using Arrow Function can be written as

var a3 = a.map( s => s.length );


MDN Docs
    As all of the other answers have already said, it's part of ES2015 arrow function syntax. More specifically, it's not an operator, it's a punctuator token that separates the parameters from the body: ArrowFunction : ArrowParameters => ConciseBody. E.g. (params) => { /* body */ }.
    ","[494, 608, 85, 1, 29, 26, 3, 8, 14, 2, 21, 1, 6, 8, 2]",340838,174,2014-07-23T02:27:02,2021-07-23 20:49:27Z,javascript 
favicon.png vs favicon.ico - why should I use PNG instead of ICO?,"
                
Other than the fact that PNG is a more common image format, is there any technical reason to favor favicon.png vs. favicon.ico?

I'm supporting modern browsers which all support PNG favorite icons.
    All modern browsers (tested with Chrome 4, Firefox 3.5, IE8, Opera 10 and Safari 4) will always request a favicon.ico unless you've specified a shortcut icon via <link>. So if you don't explicitly specify one, it's best to always have a favicon.ico file, to avoid a 404. Yahoo! suggests you make it small and cacheable.

And you don't have to go for a PNG just for the alpha transparency either. ICO files support alpha transparency just fine (i.e. 32-bit color), though hardly any tools allow you to create them. I regularly use Dynamic Drive's FavIcon Generator to create favicon.ico files with alpha transparency. It's the only online tool I know of that can do it.

There's also a free Photoshop plug-in that can create them.
    .png files are nice, but .ico files provide alpha-channel transparency, too, plus they give you backwards compatibility.
Have a look at which type StackOverflow uses for example (note that it's transparent):
<link rel=""shortcut icon"" href=""http://sstatic.net/so/favicon.ico""> 
<link rel=""apple-touch-icon"" href=""http://sstatic.net/so/apple-touch-icon.png""> 

The apple-itouch thingy is for iphone users that make a shortcut to a website.
    PNG has 2 advantages: it has smaller size and it's more widely used and supported (except in case favicons).
As mentioned before ICO, can have multiple size icons, which is useful for desktop applications, but not too much for websites.
I would recommend you to put a favicon.ico in the root of your application. An if you have access to the Head of your website pages use the  tag to point to a png file.
So older browser will show the favicon.ico and newer ones the png.

To create Png and Icon files I would recommend The Gimp.
    Answer replaced (and turned Community Wiki) due to numerous updates and notes from various others in this thread:


ICOs and PNGs both allow full alpha channel based transparency
ICO allows for backwards compatibility to older browsers (e.g. IE6)
PNG probably has broader tooling support for transparency, but you can find tools to create alpha-channel ICOs as well, such as the Dynamic Drive tool and Photoshop plugin mentioned by @mercator.


Feel free to consult the other answers here for more details.
    For what it's worth, I do this:

    <!-- Favicon - Generic -->
    <link rel=""icon"" href=""path/favicon-32_x_32.png"" sizes=""32x32"">
    <link rel=""icon"" href=""path/favicon-57_x_57.png"" sizes=""57x57"">
    <link rel=""icon"" href=""path/favicon-76_x_76.png"" sizes=""76x76"">
    <link rel=""icon"" href=""path/favicon-96_x_96.png"" sizes=""96x96"">
    <link rel=""icon"" href=""path/favicon-128_x_128.png"" sizes=""128x128"">
    <link rel=""icon"" href=""path/favicon-192_x_192.png"" sizes=""192x192"">
    <link rel=""icon"" href=""path/favicon-228_x_228.png"" sizes=""228x228"">
    <!-- Favicon - Android -->
    <link rel=""shortcut icon"" href=""path/favicon-196_x_196.png"" sizes=""196x196"">
    <!-- Favicon - iOS -->
    <link rel=""apple-touch-icon"" href=""path/favicon-120_x_120.png"" sizes=""120x120"">
    <link rel=""apple-touch-icon"" href=""path/favicon-152_x_152.png"" sizes=""152x152"">
    <link rel=""apple-touch-icon"" href=""path/favicon-180_x_180.png"" sizes=""180x180"">


And I still keep the favicon.ico in root.
    An ico can be a png.  

More precisely, you can store one or more png inside this minimal container format, instead of the usual bitmap+alpha that everyone strongly associates with ico.

Support is old, appearing in Windows Vista (2007) and is well supported by browsers, though not necessarily by icon editing software.

Any valid png (whole including header) can be prepended by a 6 byte ico header and 16 byte image directory.
GIMP has native support. Simply export as ico and tick ""Compressed (PNG)"".
    The theoretical advantage of *.ico files is that they are containers than can hold more than one icon. You could for instance store an image with alpha channel and a 16 colour version for legacy systems, or you could add 32x32 and 48x48 icons (which would show up when e.g. dragging a link to Windows explorer).

This good idea, however, tends to clash with browser implementations.
    Avoid PNG in any case if you want reliable IE6 compatibility.
    Some social tools like Google+ use a simple method to get a favicon for external links, fetching
http://your.domainname.com/favicon.ico

Since they don't prefetch the HTML content, the <link> tag will not work. In this case, you might want to use a mod_rewrite rule or just place the file in the default location.
    ","[494, 385, 59, 17, 262, 6, 9, 28, 5, 12]",339284,123,2009-08-27T22:39:16,2021-08-29 08:01:59Z,
What is the purpose of the vshost.exe file?,"
                
When I create and compile a ""Hello, World!"" application in C#, I get three files in the Debug folder apart from the main exe (e.g. HelloWorld.exe)


HelloWorld.vshost.exe
HelloWorld.pdb
HelloWorld.vshost.exe.manifest


What purpose do these files serve?
    
.exe - the 'normal' executable
.vshost.exe - a special version of the executable to aid debuging; see MSDN for details
.pdb - the Program Data Base with debug symbols
.vshost.exe.manifest - a kind of configuration file containing mostly dependencies on libraries

    The vshost.exe file is the executable run by Visual Studio (Visual Studio host executable). This is the executable that links to Visual Studio and improves debugging.

When you're distributing your application to others, you do not use the vshost.exe or .pdb (debug database) files.
    The vshost.exe feature was introduced with Visual Studio 2005 (to answer your comment).

The purpose of it is mostly to make debugging launch quicker - basically there's already a process with the framework running, just ready to load your application as soon as you want it to.

See this MSDN article and this blog post for more information.
    Adding on, you can turn off the creation of vshost files for your Release build configuration and have it enabled for Debug.

Steps


Project Properties > Debug > Configuration (Release) > Disable the Visual Studio hosting process
Project Properties > Debug > Configuration (Debug) > Enable the Visual Studio hosting process




Reference


MSDN How to: Disable the Hosting Process
MSDN Hosting Process (vshost.exe)


Excerpt from MSDN How to: Disable the Hosting Process

Calls to certain APIs can be affected when the hosting process is enabled. In these cases, it is necessary to disable the hosting process to return the correct results.

To disable the hosting process


Open an executable project in Visual Studio. Projects that do not produce executables (for example, class library or service projects) do not have this option.
On the Project menu, click Properties.
Click the Debug tab.
Clear the Enable the Visual Studio hosting process check box.


When the hosting process is disabled, several debugging features are unavailable or experience decreased performance. For more information, see Debugging and the Hosting Process.


  In general, when the hosting process is disabled:
  
  
  The time needed to begin debugging .NET Framework applications increases.
  Design-time expression evaluation is unavailable.
  Partial trust debugging is unavailable.
  

    I'm not sure, but I believe it is a debugging optimization. However, I usually turn it off (see Debug properties for the project) and I don't notice any slowdown and I see no limitations when it comes to debugging.
    It seems to be a long-running framework process for debugging (to decrease load times?). I discovered that when you start your application twice from the debugger often the same vshost.exe process will be used. It just unloads all user-loaded DLLs first. This does odd things if you are fooling around with API hooks from managed processes.
    ","[494, 177, 64, 418, 24, 10, 2]",195369,72,2009-04-21T19:24:48,2020-02-22 01:34:36Z,c 
beyond top level package error in relative import,"
                
It seems there are already quite some questions here about relative import in python 3, but after going through many of them I still didn't find the answer for my issue. 
so here is the question. 

I have a package shown below

package/
   __init__.py
   A/
      __init__.py
      foo.py
   test_A/
      __init__.py
      test.py


and I have a single line in test.py:

from ..A import foo


now, I am in the folder of package, and I run 

python -m test_A.test


I got message

""ValueError: attempted relative import beyond top-level package""


but if I am in the parent folder of package, e.g., I run:

cd ..
python -m package.test_A.test


everything is fine. 

Now my question is: 
when I am in the folder of package, and I run the module inside the test_A sub-package as test_A.test, based on my understanding, ..A goes up only one level, which is still within the package folder, why it gives message saying beyond top-level package. What is exactly the reason that causes this error message?
    EDIT: There are better/more coherent answers to this question in other questions: 


Sibling package imports
Relative imports for the billionth time




Why doesn't it work? It's because python doesn't record where a package was loaded from. So when you do python -m test_A.test, it basically just discards the knowledge that test_A.test is actually stored in package (i.e. package is not considered a package). Attempting from ..A import foo is trying to access information it doesn't have any more (i.e. sibling directories of a loaded location). It's conceptually similar to allowing from ..os import path in a file in math. This would be bad because you want the packages to be distinct. If they need to use something from another package, then they should refer to them globally with from os import path and let python work out where that is with $PATH and $PYTHONPATH.

When you use python -m package.test_A.test, then using from ..A import foo resolves just fine because it kept track of what's in package and you're just accessing a child directory of a loaded location.

Why doesn't python consider the current working directory to be a package? NO CLUE, but gosh it would be useful.
    import sys
sys.path.append("".."") # Adds higher directory to python modules path.


Try this.
Worked for me.
    Assumption:
If you are in the package directory, A and test_A are separate packages. 

Conclusion:
..A imports are only allowed within a package. 

Further notes:
Making the relative imports only available within packages is useful if you want to force that packages can be placed on any path located on sys.path.

EDIT:


  Am I the only one who thinks that this is insane!? Why in the world is the current working directory not considered to be a package? – Multihunter


The current working directory is usually located in sys.path. So, all files there are importable. This is behavior since Python 2 when packages did not yet exist. Making the running directory a package would allow imports of modules as ""import .A"" and as ""import A"" which then would be two different modules. Maybe this is an inconsistency to consider.
    This is very tricky in Python.
I'll first comment on why you're having that problem and then I will mention two possible solutions.
What's going on?
You must take this paragraph from the Python documentation into consideration:

Note that relative imports are based on the name of the current
module. Since the name of the main module is always ""main"",
modules intended for use as the main module of a Python application
must always use absolute imports.

And also the following from PEP 328:

Relative imports use a module's name attribute to determine that
module's position in the package hierarchy. If the module's name does
not contain any package information (e.g. it is set to 'main')
then relative imports are resolved as if the module were a top level
module, regardless of where the module is actually located on the file
system.

Relative imports work from the filename (__name__ attribute), which can take two values:

It's the filename, preceded by the folder strucutre, separated by dots.
For eg: package.test_A.test
Here Python knows the parent directories: before test comes test_A and then package.
So you can use the dot notation for relative import.

#  package.test_A/test.py
from ..A import foo

You can then have like a root file in the root directory which calls test.py:
#  root.py
from package.test_A import test


When you run the module (test.py) directly, it becomes the entry point to the program , so __name__ == __main__. The filename has no indication of the directory structure, so Python doesn't know how to go up in the directory. For Python, test.py becomes the top-level script, there is nothing above it. That's why you cannot use relative import.


Possible Solutions
A) One way to solve this is to have a root file (in the root directory) which calls the modules/packages, like this:


root.py imports test.py. (entry point, __name__ == __main__).
test.py (relative) imports foo.py.
foo.py says the module has been imported.

The output is:
package.A.foo has been imported
Module's name is:  package.test_A.test

B) If you want to execute the code as a module and not as a top-level script, you can try this from the command line:
python -m package.test_A.test

Any suggestions are welcomed.
You should also check: Relative imports for the billionth time , specially BrenBarn's answer.
    None of these solutions worked for me in 3.6, with a folder structure like:

package1/
    subpackage1/
        module1.py
package2/
    subpackage2/
        module2.py


My goal was to import from module1 into module2. What finally worked for me was, oddly enough:

import sys
sys.path.append(""."")


Note the single dot as opposed to the two-dot solutions mentioned so far.



Edit: The following helped clarify this for me:

import os
print (os.getcwd())


In my case, the working directory was (unexpectedly) the root of the project.
    In my case, I had to change to this:
Solution 1(more better which depend on current py file path. Easy to deploy)
Use pathlib.Path.parents make code cleaner
import sys
import os
import pathlib
target_path = pathlib.Path(os.path.abspath(__file__)).parents[3]
sys.path.append(target_path)
from utils import MultiFileAllowed

Solution 2
import sys
import os
sys.path.append(os.getcwd())
from utils import MultiFileAllowed

    This is actually a lot simpler than what other answers make it out to be.
TL;DR: Import A directly instead of attempting a relative import.
The current working directory is not a package, unless you import the folder package from a different folder. So the behavior of your package will work fine if you intend it to be imported by other applications. What's not working is the tests...
Without changing anything in your directory structure, all that needs to be changed is how test.py imports foo.py.
from A import foo

Now running python -m test_A.test from the package directory will run without an ImportError.
Why does that work?
Your current working directory is not a package, but it is added to the path. Therefore you can import folder A and its contents directly. It is the same reason you can import any other package that you have installed... they're all included in your path.
    As the most popular answer suggests, basically its because your PYTHONPATH or sys.path includes . but not your path to your package. And the relative import is relative to your current working directory, not the file where the import happens; oddly.

You could fix this by first changing your relative import to absolute and then either starting it with:

PYTHONPATH=/path/to/package python -m test_A.test


OR forcing the python path when called this way, because:

With python -m test_A.test you're executing test_A/test.py with __name__ == '__main__' and __file__ == '/absolute/path/to/test_A/test.py'

That means that in test.py you could use your absolute import semi-protected in the main case condition and also do some one-time Python path manipulation:

from os import path
…
def main():
…
if __name__ == '__main__':
    import sys
    sys.path.append(path.join(path.dirname(__file__), '..'))
    from A import foo

    exit(main())

    from package.A import foo

I think it's clearer than

import sys
sys.path.append("".."")

    In my humble opinion, I understand this question in this way:

[CASE 1] When you start an absolute-import like

python -m test_A.test


or

import test_A.test


or 

from test_A import test


you're actually setting the import-anchor to be test_A, in other word, top-level package is test_A . So, when we have test.py do from ..A import xxx, you are escaping from the anchor, and Python does not allow this.

[CASE 2] When you do

python -m package.test_A.test


or

from package.test_A import test


your anchor becomes package, so package/test_A/test.py doing from ..A import xxx does not escape the anchor(still inside package folder), and Python happily accepts this.

In short:


Absolute-import changes current anchor (=redefines what is the top-level package); 
Relative-import does not change the anchor but confines to it.


Furthermore, we can use full-qualified module name(FQMN) to inspect this problem.

Check FQMN in each case:


[CASE2] test.__name__ = package.test_A.test
[CASE1] test.__name__ = test_A.test


So, for CASE2, an from .. import xxx will result in a new module with FQMN=package.xxx, which is acceptable.

While for CASE1, the .. from within from .. import xxx will jump out of the starting node(anchor) of test_A, and this is NOT allowed by Python.
    if you have an __init__.py in an upper folder, you can initialize the import as
import file/path as alias in that init file. Then you can use it on lower scripts as:

import alias

    Having
package/
   __init__.py
   A/
      __init__.py
      foo.py
   test_A/
      __init__.py
      test.py


in A/__init__.py import foo:

from .foo import foo

when importing A/ from test_A/

import sys, os
sys.path.append(os.path.abspath('../A'))
# then import foo
import foo


    Edit: 2020-05-08: Is seems the website I quoted is no longer controlled by the person who wrote the advice, so I'm removing the link to the site. Thanks for letting me know baxx.



If someone's still struggling a bit after the great answers already provided, I found advice on a website that no longer is available.

Essential quote from the site I mentioned:


  ""The same can be specified programmatically in this way:
  
  import sys
  
  sys.path.append('..')
  
  Of course the code above must be written before the other import
  statement.


It's pretty obvious that it has to be this way, thinking on it after the fact. I was trying to use the sys.path.append('..') in my tests, but ran into the issue posted by OP. By adding the import and sys.path defintion before my other imports, I was able to solve the problem.
    Not sure in python 2.x but in python 3.6, assuming you are trying to run the whole suite, you just have to use -t


  -t, --top-level-directory directory
  Top level directory of project (defaults to start directory)


So, on a structure like

project_root
  |
  |----- my_module
  |          \
  |           \_____ my_class.py
  |
  \ tests
      \___ test_my_func.py



One could for example use:

python3 unittest discover -s /full_path/project_root/tests -t /full_path/project_root/

And still import the my_module.my_class without major dramas.
    ","[494, 245, 237, 56, 29, 43, 4, 5, 16, 22, 2, 6, 0, 9, 0]",484964,139,2015-06-05T14:46:31,2022-02-07 14:13:46Z,python 
When to use an interface instead of an abstract class and vice versa?,"
                
This may be a generic OOP question. I wanted to do a generic comparison between an interface and an abstract class on the basis of their usage. 

When would one want to use an interface and when would one want to use an abstract class?
    I wrote an article about that:

Abstract classes and interfaces

Summarizing: 

When we talk about abstract classes we are defining characteristics of an object type; specifying what an object is.  

When we talk about an interface and define capabilities that we promise to provide, we are talking about establishing a contract about what the object can do.
    An abstract class can have shared state or functionality. An interface is only a promise to provide the state or functionality. A good abstract class will reduce the amount of code that has to be rewritten because it's functionality or state can be shared. The interface has no defined information to be shared
    If you are looking at java as OOP language,

""interface does not provide method implementation"" is no longer valid with Java 8 launch. Now java provides implementation in interface for default methods.

In simple terms, I would like to use

interface: To implement a contract by multiple unrelated objects. It provides ""HAS A"" capability. 

abstract class: To implement the same or different behaviour among multiple related objects. It establishes ""IS A"" relation.

Oracle website provides key differences between interface and abstract class.

Consider using abstract classes if :


You want to share code among several closely related classes.
You expect that classes that extend your abstract class have many common methods or fields, or require access modifiers other than public (such as protected and private).
You want to declare non-static or non-final fields. 


Consider using interfaces if :


You expect that unrelated classes would implement your interface. For example,many unrelated objects can implement Serializable interface.
You want to specify the behaviour of a particular data type, but not concerned about who implements its behaviour.
You want to take advantage of multiple inheritance of type.


Example:

Abstract class ( IS A relation)

Reader is an abstract class.

BufferedReader is a Reader

FileReader is a Reader

FileReader and BufferedReader are used for common purpose : Reading data, and they are related through Reader class.

Interface ( HAS A capability )

Serializable is an interface. 

Assume that you have two classes in your application, which are implementing Serializable interface

Employee implements Serializable

Game implements Serializable

Here you can't establish any relation through Serializable interface between Employee and Game, which are meant for different purpose. Both are capable of Serializing the state and the comparasion ends there.

Have a look at these posts :

How should I have explained the difference between an Interface and an Abstract class?
    Classes may inherit from only one base class, so if you want to use abstract classes to provide polymorphism to a group of classes, they must all inherit from that class. Abstract classes may also provide members that have already been implemented. Therefore, you can ensure a certain amount of identical functionality with an abstract class, but cannot with an interface. 

Here are some recommendations to help you to decide whether to use an interface or an abstract class to provide polymorphism for your components.

 If you anticipate creating multiple versions of your component, create an abstract class. Abstract classes provide a simple and easy way to version your components. By updating the base class, all inheriting classes are automatically updated with the change. Interfaces, on the other hand, cannot be changed once created in that way. If a new version of an interface is required, you must create a whole new interface.
    If the functionality you are creating will be useful across a wide range of disparate objects, use an interface. Abstract classes should be used primarily for objects that are closely related, whereas interfaces are best suited for providing common functionality to unrelated classes.
    
    If you are designing small, concise bits of functionality, use interfaces. If you are designing large functional units, use an abstract class.
    If you want to provide common, implemented functionality among all implementations of your component, use an abstract class. Abstract classes allow you to partially implement your class, whereas interfaces contain no implementation for any members.

Copied from:

http://msdn.microsoft.com/en-us/library/scsyfw1d%28v=vs.71%29.aspx
    When to prefer an abstract class over interface?


If one plans on updating a base class throughout the life of a program/project, it is best to allow that the base class be an abstract class
If one is trying to build a backbone for objects that are closely related in a hierarchy, it is highly beneficial to use an abstract class


When to prefer an interface over abstract class?


If one is not dealing with a massive hierarchical type of framework, interfaces would be a great choice
Because multiple inheritance is not supported with abstract classes(diamond problem), interfaces can save the day 

    My two cents:

An interface basically defines a contract, that any implementing class must adhere to(implement the interface members). It does not contain any code.

On the other hand, an abstract class can contain code, and there might be some methods marked as abstract which an inheriting class must implement.

The rare situations I've used abstract classes is when i have some default functionality that the inheriting class might not be interesting in overriding, in say an abstract base class, that some specialized classes inherit from.

Example(a very rudimentary one!):Consider a base class called Customer which has abstract methods like CalculatePayment(), CalculateRewardPoints() and some non-abstract methods like GetName(), SavePaymentDetails(). 

Specialized classes like RegularCustomer  and GoldCustomer will inherit from the Customer base class and implement their own CalculatePayment() and CalculateRewardPoints() method logic, but re-use the GetName() and SavePaymentDetails() methods.

You can add more functionality to an abstract class(non abstract methods that is) without affecting child classes which were using an older version. Whereas adding methods to an interface would affect all classes implementing it as they would now need to implement the newly added interface members.

An abstract class with all abstract members would be similar to an interface.
    1.If you are creating something that provides common functionality to unrelated classes, use an interface.

2.If you are creating something for objects that are closely related in a hierarchy, use an abstract class.
    When to do what is a very simple thing if you have the concept clear in your mind. 

Abstract classes can be Derived whereas Interfaces can be Implemented. There is some difference between the two. When you derive an Abstract class, the relationship between the derived class and the base class is 'is a' relationship. e.g., a Dog is an Animal, a Sheep is an Animal which means that a Derived class is inheriting some properties from the base class.

Whereas for implementation of interfaces, the relationship is ""can be"". e.g., a Dog can be a spy dog. A dog can be a circus dog. A dog can be a race dog. Which means that you implement certain methods to acquire something. 

I hope I am clear.
    This can be a very difficult call to make...

One pointer I can give: An object can implement many interfaces, whilst an object can only inherit one base class( in a modern  OO language like c#, I know C++ has multiple inheritance - but isn't that frowned upon?)
    Consider using abstract classes if any of these statements apply to your situation:


You want to share code among several closely related classes.
You expect that classes that extend your abstract class have many common methods or fields or require access modifiers other than public (such as protected and private).
You want to declare non-static or non-final fields. This enables you to define methods that can access and modify the state of the object to which they belong.




Consider using interfaces if any of these statements apply to your situation:


You expect that unrelated classes would implement your interface. For example, the interfaces Comparable and Cloneable are implemented by many unrelated classes.
You want to specify the behavior of a particular data type, but not concerned about who implements its behavior.
You want to take advantage of multiple inheritances.


Source
    The short answer: An abstract class allows you to create functionality that subclasses can implement or override. An interface only allows you to define functionality, not implement it. And whereas a class can extend only one abstract class, it can take advantage of multiple interfaces.
    Personally, I almost never have the need to write abstract classes.

Most times I see abstract classes being (mis)used, it's because the author of the abstract class is using the ""Template method"" pattern.

The problem with ""Template method"" is that it's nearly always somewhat re-entrant - the ""derived"" class knows about not just the ""abstract"" method of its base class that it is implementing, but also about the public methods of the base class, even though most times it does not need to call them.

(Overly simplified) example:

abstract class QuickSorter
{
    public void Sort(object[] items)
    {
        // implementation code that somewhere along the way calls:
        bool less = compare(x,y);
        // ... more implementation code
    }
    abstract bool compare(object lhs, object rhs);
}


So here, the author of this class has written a generic algorithm and intends for people to use it by ""specializing"" it by providing their own ""hooks"" - in this case, a ""compare"" method.

So the intended usage is something like this:

class NameSorter : QuickSorter
{
    public bool compare(object lhs, object rhs)
    {
        // etc.
    }
}


The problem with this is that you've unduly coupled together two concepts:


A way of comparing two items (what item should go first)
A method of sorting items (i.e. quicksort vs merge sort etc.)


In the above code, theoretically, the author of the ""compare"" method can re-entrantly call back into the superclass ""Sort"" method... even though in practise they will never want or need to do this.

The price you pay for this unneeded coupling is that it's hard to change the superclass, and in most OO languages, impossible to change it at runtime.

The alternative method is to use the ""Strategy"" design pattern instead:

interface IComparator
{
    bool compare(object lhs, object rhs);
}

class QuickSorter
{
    private readonly IComparator comparator;
    public QuickSorter(IComparator comparator)
    {
        this.comparator = comparator;
    }

    public void Sort(object[] items)
    {
        // usual code but call comparator.Compare();
    }
}

class NameComparator : IComparator
{
    bool compare(object lhs, object rhs)
    {
        // same code as before;
    }
}


So notice now: All we have are interfaces, and concrete implementations of those interfaces. In practise, you don't really need anything else to do a high level OO design.

To ""hide"" the fact that we've implemented ""sorting of names"" by using a ""QuickSort"" class and a ""NameComparator"", we might still write a factory method somewhere:

ISorter CreateNameSorter()
{
    return new QuickSorter(new NameComparator());
}


Any time you have an abstract class you can do this... even when there is a natural re-entrant relationship between the base and derived class, it usually pays to make them explicit.

One final thought: All we've done above is ""compose"" a ""NameSorting"" function by using a ""QuickSort"" function and a ""NameComparison"" function... in a functional programming language, this style of programming becomes even more natural, with less code.
    Use an abstract class if you want to provide some basic implementations.
    Basic thumb rule is: For ""Nouns"" use Abstract class and for ""Verbs"" use interface

E.g: car is an abstract class and drive, we can make it an interface.
    I think the most succinct way of putting it is the following:

Shared properties => abstract class.
Shared functionality => interface.

And to put it less succinctly...

Abstract Class Example:  

public abstract class BaseAnimal
{
    public int NumberOfLegs { get; set; }

    protected BaseAnimal(int numberOfLegs)
    {
        NumberOfLegs = numberOfLegs;
    }
}

public class Dog : BaseAnimal
{
    public Dog() : base(4) { }
}

public class Human : BaseAnimal 
{
    public Human() : base(2) { }
}


Since animals have a shared property - number of legs in this case - it makes sense to make an abstract class containing this shared property. This also allows us to write common code that operates on that property. For example:

public static int CountAllLegs(List<BaseAnimal> animals)
{
    int legCount = 0;
    foreach (BaseAnimal animal in animals)
    {
        legCount += animal.NumberOfLegs;
    }
    return legCount;
}


Interface Example:

public interface IMakeSound
{
    void MakeSound();
}

public class Car : IMakeSound
{
    public void MakeSound() => Console.WriteLine(""Vroom!"");
}

public class Vuvuzela : IMakeSound
{
    public void MakeSound() => Console.WriteLine(""VZZZZZZZZZZZZZ!"");        
}


Note here that Vuvuzelas and Cars are completely different things, but they have shared functionality: making a sound. Thus, an interface makes sense here. Further, it will allow programmers to group things that make sounds together under a common interface -- IMakeSound in this case. With this design, you could write the following code:

List<IMakeSound> soundMakers = new List<ImakeSound>();
soundMakers.Add(new Car());
soundMakers.Add(new Vuvuzela());
soundMakers.Add(new Car());
soundMakers.Add(new Vuvuzela());
soundMakers.Add(new Vuvuzela());

foreach (IMakeSound soundMaker in soundMakers)
{
    soundMaker.MakeSound();
}


Can you tell what that would output?

Lastly, you can combine the two.

Combined Example:

public interface IMakeSound
{
    void MakeSound();
}

public abstract class BaseAnimal : IMakeSound
{
    public int NumberOfLegs { get; set; }

    protected BaseAnimal(int numberOfLegs)
    {
        NumberOfLegs = numberOfLegs;
    }

    public abstract void MakeSound();
}

public class Cat : BaseAnimal
{
    public Cat() : base(4) { }

    public override void MakeSound() => Console.WriteLine(""Meow!"");
}

public class Human : BaseAnimal 
{
    public Human() : base(2) { }

    public override void MakeSound() => Console.WriteLine(""Hello, world!"");
}


Here, we're requiring all BaseAnimals make a sound, but we don't know its implementation yet. In such a case, we can abstract the interface implementation and delegate its implementation to its subclasses.

One last point, remember how in the abstract class example we were able to operate on the shared properties of different objects and in the interface example we were able to invoke the shared functionality of different objects? In this last example, we could do both. 
    OK, having just ""grokked"" this myself - here it is in layman's terms (feel free to correct me if I am wrong) - I know this topic is oooooold, but someone else might stumble across it one day...

Abstract classes allow you to create a blueprint, and allow you to additionally CONSTRUCT (implement) properties and methods you want ALL its descendants to possess. 

An interface on the other hand only allows you to declare that you want properties and/or methods with a given name to exist in all classes that implement it - but doesn't specify how you should implement it. Also, a class can implement MANY interfaces, but can only extend ONE Abstract class. An Interface is more of a high level architectural tool (which becomes clearer if you start to grasp design patterns) - an Abstract has a foot in both camps and can perform some of the dirty work too. 

Why use one over the other? The former allows for a more concrete definition of descendants - the latter allows for greater polymorphism. This last point is important to the end user/coder, who can utilise this information to implement the A.P.I(nterface) in a variety of combinations/shapes to suit their needs. 

I think this was the ""lightbulb"" moment for me - think about interfaces less from the author's perpective and more from that of any coder coming later in the chain who is adding implementation to a project, or extending an API.
    For me,  I would go with interfaces in many cases. But  I prefer abstract classes in some cases.

Classes in OO generaly refers to implementation.  I use abstract classes when I want to force some implementation details to the childs else I go with interfaces.

Of course, abstract classes are useful not only in forcing  implementation but also in sharing some specific details among many related classes.
    in java you can inherit from one (abstract) class to ""provide"" functionality and you can implement many interfaces to ""ensure"" functionality
    I wrote an article of when to use an abstract class and when to use an interface. There is a lot more of a difference between them other than ""one IS-A... and one CAN-DO..."". To me, those are canned answers. I mention a few reasons when to use either of them. Hope it helps.

http://codeofdoom.com/wordpress/2009/02/12/learn-this-when-to-use-an-abstract-class-and-an-interface/
    The answers vary between languages. For example, in Java a class can implement (inherit from) multiple interfaces but only inherit from one abstract class. So interfaces give you more flexibility. But this is not true in C++.
    Purely on the basis of inheritance, you would use an Abstract where you're defining clearly descendant, abstract relationships (i.e. animal->cat) and/or require inheritance of virtual or non-public properties, especially shared state (which Interfaces cannot support).

You should try and favour composition (via dependency injection) over inheritance where you can though, and note that Interfaces being contracts support unit-testing, separation of concerns and (language varying) multiple inheritance in a way Abstracts cannot.
    One interesting location where interfaces fare better than abstract classes is when you need to add extra functionality to a group of (related or unrelated) objects. If you cannot give them a base abstract class (e.g., they are sealed or already have a parent), you can give them a dummy (empty) interface instead, and then simply write extension methods for that interface.
    An abstract class can have implementations.

An interface doesn't have implementations, it simply defines a kind of contract.

There can also be some language-dependent differences: for example C# does not have multiple inheritance, but multiple interfaces can be implemented in a class.
    If we have an implementation that will be the same for all the derived classes and at that time it is better to use the abstract class over an interface. when we have an interface, we can move our implementation to any class that implements interface. In abstract class, it avoids code duplication and share the implementation for all derived class. The interfaces allow to develop loosely coupled systems which helps for better testing.
    Both are contract for class definition:

Conclusion 1: Both intent is object generalization

In defining abstract classes, they can have default implementation also.

Conclusion 2: distinguish is in Behavioral generalization Design

In utilizing abstract classes, classes can inherit from just one abstract class

Conclusion 3: abstract class has limitation in utilizing. It means
limitation in Behavioral generalization.

Final Conclusion-When to use which: Distinguish is in behavioral generalization level
In designing behavioral of classes, If functionality is just conceptually limited among determined classes or in other word, is share among determined class, use abstract class. but if functionality is more general than determined classes or we can/want add functionality to other classes, use interface as a contract.
    ","[493, 498, 483, 65, 10, 12, 45, 13, 31, 1, 4, 1, 84, 2, 0, 7, 40, 2, 1, 10, 2, 1, 1, 0, 0, 0]",375026,276,2009-01-26T08:47:38,2022-04-17 15:12:31Z,
How do you change text to bold in Android?,"
                
How do you change text/font settings in an Android TextView?  

For example, how do you make the text bold?
    To do this in the layout.xml file:

android:textStyle


Examples:

android:textStyle=""bold|italic""


Programmatically the method is:

setTypeface(Typeface tf)


Sets the typeface and style in which the text should be displayed. Note that not all Typeface families actually have bold and italic variants, so you may need to use setTypeface(Typeface, int) to get the appearance that you actually want.
    Here is the solution

TextView questionValue = (TextView) findViewById(R.layout.TextView01);
questionValue.setTypeface(null, Typeface.BOLD);

    Define a new style with the format you want in the style.xml file in the values folder

<style name=""TextViewStyle"" parent=""AppBaseTheme"">
    <item name=""android:textStyle"">bold</item>
    <item name=""android:typeface"">monospace</item>
    <item name=""android:textSize"">16sp</item>
    <item name=""android:textColor"">#5EADED</item>

</style>


Then apply this style to the TextView by writing the following code with the properties of the TextView

style=""@style/TextViewStyle""

    From the XML you can set the textStyle to bold as below
<TextView
   android:layout_width=""wrap_content""
   android:layout_height=""wrap_content""
   android:text=""Bold text""
   android:textStyle=""bold""/>

You can set the TextView to bold programmatically as below
textview.setTypeface(Typeface.DEFAULT_BOLD);

    Through XML:
 android:textStyle=""bold""

Through Java:
//Let's say you have a textview 
textview.setTypeface(null, Typeface.BOLD);

    4 ways to make Android TextView bold- Full answer is here.


Using android:textStyle attribute

<TextView
    android:layout_width=""wrap_content""
    android:layout_height=""wrap_content""
    android:text=""TEXTVIEW 1""
    android:textStyle=""bold""
    />

Use bold|italic for bold and italic.
using setTypeface() method

textview2.setTypeface(null, Typeface.BOLD);
textview2.setText(""TEXTVIEW 2"");

HtmlCompat.fromHtml() method, Html.fromHtml() was deprecated in API level 24.

 String html=""This is <b>TEXTVIEW 3</b>"";
 textview3.setText(HtmlCompat.fromHtml(html,Typeface.BOLD));


    editText.setTypeface(Typeface.createFromAsset(getAssets(), ttfFilePath));
etitText.setTypeface(et.getTypeface(), Typeface.BOLD);


will set both typface as well as style to Bold.
    For case where you are using custom fonts, but do not have bold typeface for the font you can use:

myTextView.setText(Html.fromHtml(""<b>"" + myText + ""</b>"");

    in file .xml, set

android:textStyle=""bold"" 


will set text type is bold.
    Simply you can do the following:

Set the attribute in XML

  android:textStyle=""bold""


Programatically the method is:

TextView Tv = (TextView) findViewById(R.id.TextView);

Typeface boldTypeface = Typeface.defaultFromStyle(Typeface.BOLD);

Tv.setTypeface(boldTypeface);


Hope this helps you thank you.
    In my case, Passing value through string.xml worked out with html Tag..

<string name=""your_string_tag""> <b> your_text </b></string>
    If you're drawing it then this will do it:

TextPaint.setFlags(Paint.FAKE_BOLD_TEXT_FLAG);

    It's very easy

setTypeface(Typeface.DEFAULT_BOLD);

    In XML 

android:textStyle=""bold"" //only bold
android:textStyle=""italic"" //only italic
android:textStyle=""bold|italic"" //bold & italic


You can only use specific fonts sans, serif & monospace via xml, Java code can use custom fonts

android:typeface=""monospace"" // or sans or serif


Programmatically (Java code)

TextView textView = (TextView) findViewById(R.id.TextView1);

textView.setTypeface(Typeface.SANS_SERIF); //only font style
textView.setTypeface(null,Typeface.BOLD); //only text style(only bold)
textView.setTypeface(null,Typeface.BOLD_ITALIC); //only text style(bold & italic)
textView.setTypeface(Typeface.SANS_SERIF,Typeface.BOLD); 
                                         //font style & text style(only bold)
textView.setTypeface(Typeface.SANS_SERIF,Typeface.BOLD_ITALIC);
                                         //font style & text style(bold & italic)

    The best way to go is: 

TextView tv = findViewById(R.id.textView);
tv.setTypeface(Typeface.DEFAULT_BOLD);

    In the ideal world you would set the text style attribute in you layout XML definition like that:

<TextView
    android:id=""@+id/TextView""
    android:layout_width=""wrap_content""
    android:layout_height=""wrap_content""
    android:textStyle=""bold""/>


There is a simple way to achieve the same result dynamically in your code by using setTypeface method. You need to pass and object of Typeface class, which will describe the font style for that TextView. So to achieve the same result as with the XML definition above you can do the following:

TextView Tv = (TextView) findViewById(R.id.TextView);
Typeface boldTypeface = Typeface.defaultFromStyle(Typeface.BOLD);
Tv.setTypeface(boldTypeface);


The first line will create the object form predefined style (in this case Typeface.BOLD, but there are many more predefined). Once we have an instance of typeface we can set it on the TextView. And that's it our content will be displayed on the style we defined.

I hope it helps you a lot.For better info you can visit


  http://developer.android.com/reference/android/graphics/Typeface.html

    Assuming you are a new starter on Android Studio,
Simply you can get it done in design view XML by using

android:textStyle=""bold""          //to make text bold
android:textStyle=""italic""        //to make text italic
android:textStyle=""bold|italic""   //to make text bold & italic

    You can use this for font 

create a Class Name TypefaceTextView and extend the TextView

private static Map mTypefaces;

public TypefaceTextView(final Context context) {
    this(context, null);
}

public TypefaceTextView(final Context context, final AttributeSet attrs) {
    this(context, attrs, 0);
}

public TypefaceTextView(final Context context, final AttributeSet attrs, final int defStyle) {
    super(context, attrs, defStyle);
    if (mTypefaces == null) {
        mTypefaces = new HashMap<String, Typeface>();
    }

    if (this.isInEditMode()) {
        return;
    }

    final TypedArray array = context.obtainStyledAttributes(attrs, styleable.TypefaceTextView);
    if (array != null) {
        final String typefaceAssetPath = array.getString(
                R.styleable.TypefaceTextView_customTypeface);

        if (typefaceAssetPath != null) {
            Typeface typeface = null;

            if (mTypefaces.containsKey(typefaceAssetPath)) {
                typeface = mTypefaces.get(typefaceAssetPath);
            } else {
                AssetManager assets = context.getAssets();
                typeface = Typeface.createFromAsset(assets, typefaceAssetPath);
                mTypefaces.put(typefaceAssetPath, typeface);
            }

            setTypeface(typeface);
        }
        array.recycle();
    }
}


paste the font in the fonts folder created in the asset folder 

<packagename.TypefaceTextView
        android:layout_width=""0dp""
        android:layout_height=""match_parent""
        android:layout_weight=""1.5""
        android:gravity=""center""
        android:text=""TRENDING TURFS""
        android:textColor=""#000""
        android:textSize=""20sp""
        app:customTypeface=""fonts/pompiere.ttf"" />**here pompiere.ttf is the font name**


Place the lines  in the parent layout in the xml

 xmlns:app=""http://schemas.android.com/apk/res/com.mediasters.wheresmyturf""
xmlns:custom=""http://schemas.android.com/apk/res-auto""

    Set the attribute

android:textStyle=""bold""

    In Kotlin we can do in one line
 TEXT_VIEW_ID.typeface = Typeface.defaultFromStyle(Typeface.BOLD)

    You can do this
ty.setTypeface(Typeface.createFromAsset(ctx.getAssets(), ""fonts/magistral.ttf""), Typeface.BOLD);

    textView.setPaintFlags(textView.getPaintFlags() | Paint.FAKE_BOLD_TEXT_FLAG)

To remove, use
textView.setPaintFlags(textView.getPaintFlags() & ~Paint.FAKE_BOLD_TEXT_FLAG)

Or in Kotlin:
fun TextView.makeBold() {
    this.paintFlags = this.paintFlags or Paint.FAKE_BOLD_TEXT_FLAG
}

fun TextView.removeBold() {
    this.paintFlags = this.paintFlags and (Paint.FAKE_BOLD_TEXT_FLAG.inv())
}

    ","[493, 611, 371, 11, 24, 10, 8, 2, 25, 9, 83, 5, 17, 19, 54, 9, 16, 6, 5, 22, 0, 0, 0]",524915,46,2011-01-25T10:17:50,2022-01-07 18:22:59Z,
Git: How to update/checkout a single file from remote origin master?,"
                
The scenario:


I make some changes in a single file locally and run git add, git commit and git push
The file is pushed to the remote origin master repository
I have another local repository that is deployed via Capistrano with the ""remote_cache"" method from that remote repository
Now I don't want to deploy the whole application but just update/checkout that single file.


Is this somehow possible with git? I wasn't able to find anything that would work nor was I able to figure it out. With SVN I just did svn up file and voila.
    It is possible to do (in the deployed repository)

git fetch
git checkout origin/master -- path/to/file


The fetch will download all the recent changes, but it will not put it in your current checked out code (working area).

The checkout will update the working tree with the particular file from the downloaded changes (origin/master).

At least this works for me for those little small typo fixes, where it feels weird to create a branch etc just to change one word in a file.
    Simply It works for me
git checkout origin/develop file_name.php

    Following code worked for me:
git fetch
git checkout <branch from which file needs to be fetched> <filepath> 

    With Git 2.23 (August 2019) and the new (still experimental) command git restore, seen in ""How to reset all files from working directory but not from staging area?"", that would be:

git fetch
git restore -s origin/master -- path/to/file


The idea is: git restore only deals with files, not files and branches as git checkout does.
See ""Confused by git checkout"": that is where git switch comes in)



codersam adds in the comments:


  in my case I wanted to get the data from my upstream (from which I forked).
  So just changed to:

git restore -s upstream/master -- path/to/file


    What you can do is:


Update your local git repo:

git fetch
Build a local branch and checkout on it:

git branch pouet && git checkout pouet
Apply the commit you want on this branch:

git cherry-pick abcdefabcdef

(abcdefabcdef is the sha1 of the commit you want to apply)

    git archive --format=zip --remote=ssh://<user>@<host>/repos/<repo name> <tag or HEAD> <filename> > <output file name>.zip

    Or git stash (if you have changes) on the branch you're on, checkout master, pull for the latest changes, grab that file to your desktop (or the entire app). Checkout the branch you were on. Git stash apply back to the state you were at, then fix the changes manually or drag it replacing the file.

This way is not sooooo cool but it def works if you guys can't figure anything else out. 
    I think I have found an easy hack out.

Delete the file that you have on the local repository (the file that you want updated from the latest commit in the remote server)

And then do a git pull

Because the file is deleted, there will be no conflict 
    ","[493, 1124, 13, 71, 64, 10, 19, 2, -15]",693621,128,2010-07-26T11:44:59,2021-08-13 08:32:52Z,
How do you reinstall an app's dependencies using npm?,"
                
Is there a simple way to reinstall all packages that my app depends on (i.e. they are in my apps node_modules folder)?
    The easiest way that I can see is delete node_modules folder and execute npm install.
    You can do this with one simple command:
npm ci

Here's an excerpt from npm ci documentation:

In short, the main differences between using npm install and npm ci are:

The project must have an existing package-lock.json or npm-shrinkwrap.json.
If dependencies in the package lock do not match those in package.json, npm ci will exit with an error, instead of updating the package lock.
npm ci can only install entire projects at a time: individual dependencies cannot be added with this command.
If a node_modules is already present, it will be automatically removed before npm ci begins its install.
It will never write to package.json or any of the package-locks: installs are essentially frozen.


    As of npm cli v6.5.0 you can use the backronym:
npm clean-install

Sources:
https://github.com/npm/cli/releases/tag/v6.5.0
https://github.com/npm/cli/commit/fc1a8d185fc678cdf3784d9df9eef9094e0b2dec
    The right way is to execute npm update. It's a really powerful command, it updates the missing packages and also checks if a newer version of package already installed can be used. 

Read Intro to NPM to understand what you can do with npm.
    npm updated the CLI command for install and added the --force flag.

npm install --force


The --force (or -f) argument will force npm to fetch remote resources even if a local copy exists on disk.

See npm install
    Most of the time I use the following command to achieve a complete reinstall of all the node modules (be sure you are in the project folder).

rm -rf node_modules && npm install


You can also run npm cache clean after removing the node_modules folder to be sure there aren't any cached dependencies.
    Delete node_module and re-install again by command
rm -rf node_modules && npm i

    You can use the reinstall module found in npm.

After installing it, you can use the following command:

reinstall


The only difference with manually removing node_modules folder and making npm install is that this command automatically clear npm's cache. So, you can get three steps in one command.

upd: npx reinstall is a way to run this command without globally installing package (only for npm5+)
    Follow this step to re install node modules and update them

works even if node_modules folder does not exist. now execute the following command synchronously. you can also use ""npm update"" but I think this'd preferred way

npm outdated // not necessary to run this command, but this will show outdated dependencies

npm install -g npm-check-updates // to install the ""ncu"" package

ncu -u --packageFile=package.json // to update dependencies version in package.json...don't run this command if you don't need to update the version

npm install: will install dependencies in your package.json file.


if you're okay with the version of your dependencies in your package.json file, no need to follow those steps just run 

 npm install

    For Windows you can use

(if exist node_modules rmdir node_modules /q /s) && npm install


which removes node_modules directory and performs npm install then. Removal before install assures that all packages are reinstalled.
    ","[493, 805, 77, 21, 126, 78, 93, 6, 20, 1, 2]",501448,72,2012-10-12T20:18:08,2021-10-26 13:59:51Z,
How to diff a commit with its parent,"
                
Aside from writing an alias or script, is there a shorter command for getting the diff for a particular commit?
git diff 15dc8^..15dc8

If you only give the single commit id git diff 15dc8, it diffs that commit against HEAD.
    Use git show $COMMIT. It'll show you the log message for the commit, and the diff of that particular commit.
    Use:
git diff 15dc8^!

as described in the following fragment of git-rev-parse(1) man page (or in modern Git gitrevisions(7) man page):

Two other shorthands for naming a set that is formed by a commit and its
parent commits exist. The r1^@ notation means all  parents of r1.  r1^!
includes commit r1 but excludes all of its parents.

This means that you can use 15dc8^! as a shorthand for 15dc8^..15dc8 anywhere in Git where revisions are needed.  For the diff command, the git diff 15dc8^..15dc8 is understood as git diff 15dc8^ 15dc8, which means the difference between parent of commit (15dc8^) and commit (15dc8).
Note: the description in git-rev-parse(1) man page talks about revision ranges, where it needs to work also for merge commits, with more than one parent. Then r1^! is ""r1 --not r1^@"" i.e. ""r1 ^r1^1 ^r1^2 ...""

Also, you can use git show COMMIT to get the commit description and diff for a commit. If you want only the diff, you can use git diff-tree -p COMMIT.
    If you know how far back, you can try something like:

# Current branch vs. parent
git diff HEAD^ HEAD

# Current branch, diff between commits 2 and 3 times back
git diff HEAD~3 HEAD~2


Prior commits work something like this:

# Parent of HEAD
git show HEAD^1

# Grandparent
git show HEAD^2


There are a lot of ways you can specify commits:

# Great grandparent
git show HEAD~3


See this page for details.
    Paul's solution did what I was hoping it would.
$ git diff HEAD^1

Also, it's useful to add aliases like hobs mentioned. If you put the following in the [alias] section of your ~/.gitconfig file then you can use the shorthand to view diff between head and previous.
[alias]
    diff-last = diff HEAD^1

Then running $ git diff-last will get you your result. Note that this will also include any changes you've not yet committed as well as the diff between commits. If you want to ignore changes you've not yet committed, then you can use diff to compare the HEAD with its parent directly:
$ git diff HEAD^1 HEAD

    Many of the mentioned examples (e.g. git diff 15dc8^!, or git diff 15dc8^..15dc8) don't work if you are using Z shell and have extendedglob option set. You can fix it by one of the following three ways:

unsetopt extendedglob (and/or remove it from .zshrc)

setopt NO_NOMATCH (and/or set it in .zshrc)

escape the caret and bang every time with a backslash, e.g., git diff 15dc8\^\!


    As mipadi points out, you can use git show $COMMIT, but this also shows some headers and the commit message. If you want a straight diff, use git show --pretty=format:%b $COMMIT.
This is, obviously not a very short hand, so I'm keeping this alias in my .gitconfig
    [alias]
      sd = show --pretty=format:%b

This enables me to use git sd $COMMITto show diff.
    git diff 15dc8 15dce~1


~1 means 'parent', ~2 'grandparent, etc.
    This uses aliases, so it doesn't answer your question exactly, but I find these useful for doing what you intend...
alias gitdiff-1=""git log --reverse|grep commit|cut -d ' ' -f2|tail -n 2|head -n 2|xargs echo|sed -e 's/\s/../'|xargs -n 1 git diff""
alias gitdiff-2=""git log --reverse|grep commit|cut -d ' ' -f2|tail -n 3|head -n 2|xargs echo|sed -e 's/\s/../'|xargs -n 1 git diff""
alias gitdiff-3=""git log --reverse|grep commit|cut -d ' ' -f2|tail -n 4|head -n 2|xargs echo|sed -e 's/\s/../'|xargs -n 1 git diff""

alias gitlog-1=""git log --reverse|grep commit|cut -d ' ' -f2|tail -n 2|head -n 2|xargs echo|sed -e 's/\s/../'|xargs -n 1 git log --summary""
alias gitlog-2=""git log --reverse|grep commit|cut -d ' ' -f2|tail -n 3|head -n 2|xargs echo|sed -e 's/\s/../'|xargs -n 1 git log --summary""
alias gitlog-3=""git log --reverse|grep commit|cut -d ' ' -f2|tail -n 4|head -n 2|xargs echo|sed -e 's/\s/../'|xargs -n 1 git log --summary""

    ","[493, 674, 468, 58, 3, 6, 11, 3, 0]",151542,115,2009-01-12T18:03:57,2021-07-07 17:53:45Z,
The use of Swift 3 @objc inference in Swift 4 mode is deprecated?,"
                
Briefly, while using Xcode 9 Beta, I have run into the following warning:


  The use of Swift 3 @objc inference in Swift 4 mode is deprecated. Please address deprecated @objc inference warnings, test your code with “Use of deprecated Swift 3 @objc inference” logging enabled, and disable Swift 3 @objc inference.**


After some research, I still have no idea how to fix the issue. 
I would greatly appreciate any tips on how to fix this issue as well as an explanation of what is going on. 

My goal is to grasp a better understanding of what is happening with my code. 
    I got rid of this warning by changing the ""Swift 3 @objc Inference"" build setting of my targets to ""Default"".

From this article:

Before Swift 4, the compiler made some Swift declarations automatically available to Objective-C. For example, if one subclassed from NSObject, the compiler created Objective-C entry points for all methods in such classes. The mechanism is called @objc inference.
In Swift 4, such automatic @objc inference is deprecated because it is costly to generate all those Objective-C entry points. When ""Swift 3 @objc Inference"" setting is set to ""On"", it allows the old code to work. However, it will show deprecation warnings that need to be addressed. It is recommended to ""fix"" these warnings and switch the setting to ""Default"", which is the default for new Swift projects.

Please also refer to this Swift proposal for more information.
    Migrator cannot identify all the functions that need @objc
Inferred Objective-C thunks marked as deprecated to help you find them
• Build warnings about deprecated methods
• Console messages when running deprecated thunks


    You can try to ""Pod update"" and/or ""flutter clean""

I also set this setting in xcode.

The Objective-C interface setting is as follows:


    - What is @objc inference? What is going on?

In Swift 3, the compiler infers @objc in a number of places so you wouldn't have to. In other words, it makes sure to add @objc for you!

In Swift 4, the compiler no longer does this (as much). You now must add @objc explicitly.

By default, if you have a pre-Swift 4 project, you will get warnings about this. In a Swift 4 project, you will get build errors. This is controlled via the SWIFT_SWIFT3_OBJC_INFERENCE build setting. In a pre-Swift 4 project this is set to On. I would recommend to set this to Default (or Off), which is now the default option on a new project. 

It will take some time to convert everything, but since it's the default for Swift 4, it's worth doing it.

- How do I stop the compiler warnings/errors?

There are two ways to go about converting your code so the compiler doesn't complain.

One is to use @objc on each function or variable that needs to be exposed to the Objective-C runtime:

@objc func foo() {

}


The other is to use @objcMembers by a Class declaration. This makes sure to automatically add @objc to ALL the functions and variables in the class. This is the easy way, but it has a cost, for example, it can increase the size of your application by exposing functions that did not need to be exposed.

@objcMembers class Test {

}




- What is @objc and why is it necessary?

If you introduce new methods or variables to a Swift class, marking them as @objc exposes them to the Objective-C runtime. This is necessary when you have Objective-C code that uses your Swift class, or, if you are using Objective-C-type features like Selectors. For example, the target-action pattern:
button.addTarget(self, action:#selector(didPressButton), for:.touchUpInside)

- Why would I not mark everything @objc?

There are negatives that come with marking something as @objc:


Increased application binary size 
No function overloading




Please keep in mind that this is a very high-level summary and that it is more complicated than I wrote. I would recommend reading the actual proposal for more information.

Sources:


https://github.com/apple/swift-evolution/blob/master/proposals/0160-objc-inference.md
https://developer.apple.com/library/content/documentation/Swift/Conceptual/BuildingCocoaApps/WritingSwiftClassesWithObjective-CBehavior.html#//apple_ref/doc/uid/TP40014216-CH5-ID86

    I'm an occasional iOS dev (soon to be more) but I still couldn't find the setting as guided by the other answer (since I did not have that Keychain item the answer shows), so now that I found it I thought I might just add this snapshot with the highlighted locations that you will need to click and find.


Start in the upper left
Choose the project folder icon
Choose your main project name below the project folder icon.
Choose Build Settings on the right side.
Choose your project under TARGETS.
Scroll very far down (or search for the word inference in search
text box)



    I had this warning with ""Swift 3 @objc Inference"" = ""Default"" setting. Then I realized that is was set for the Project - not for the target. So, make sure that you have ""Default"" setting in your target to get rid of the warning.
    Indeed, you'll get rid of those warnings by disabling Swift 3 @objc Inference.
However, subtle issues may pop up. For example, KVO will stop working.
This code worked perfectly under Swift 3:

for (key, value) in jsonDict {
    if self.value(forKey: key) != nil {
        self.setValue(value, forKey: key)
    }
}


After migrating to Swift 4, and setting ""Swift 3 @objc Inference"" to default, certain features of my project stopped working.
It took me some debugging and research to find a solution for this.
According to my best knowledge, here are the options:


Enable ""Swift 3 @objc Inference"" (only works if you migrated an existing project from Swift 3) 
Mark the affected methods and properties as @objc 
Re-enable ObjC inference for the entire class using @objcMembers 


Re-enabling @objc inference leaves you with the warnings, but it's the quickest solution. Note that it's only available for projects migrated from an earlier Swift version.
The other two options are more tedious and require some code-digging and extensive testing.

See also https://github.com/apple/swift-evolution/blob/master/proposals/0160-objc-inference.md
    Swift 3 @objc Inference
The use of Swift 3 @objc inference in Swift 4 mode is deprecated. Please address deprecated @objc inference warnings, test your code with “Use of deprecated Swift 3 @objc inference” logging enabled, and then disable inference by changing the ""Swift 3 @objc Inference"" build setting to ""Default"" for the ""XMLParsingURL"" target.

got to the 


First step got Build Setting
Search in to Build Setting Inference
change swift 3 @objc Inference Default


enter image description here
    You can simply pass to ""default"" instead of ""ON"". Seems more adherent to Apple logic.

(but all the other comments about the use of @obj remains valid.)
    All you need just run a test wait till finish, after that go to  Build Setting,  Search in to Build Setting Inference,
change swift 3 @objc Inference to (Default). that's all what i did and worked perfect.
    
  The use of Swift 3 @objc inference in Swift 4 mode is deprecated?


use func call @objc 

func call(){

foo()

}

@objc func foo() {

}

    On top of what @wisekiddo said, you can also modify your build settings in the project.pbxproj file by setting the Swift 3 @obj Inference to default like SWIFT_SWIFT3_OBJC_INFERENCE = Default; for your build flavors (i.e. debug and release), especially if you're coming from some other environment besides Xcode
    ","[493, 824, 49, 7, 272, 7, 12, 7, 2, 8, 0, 0, 0]",103446,96,2017-06-05T23:49:05,2019-04-23 10:46:49Z,swift 
jQuery same click event for multiple elements,"
                
Is there any way to execute same code for different elements on the page?

$('.class1').click(function() {
   some_function();
});

$('.class2').click(function() {
   some_function();
});


instead to do something like:

$('.class1').$('.class2').click(function() {
   some_function();
});


Thanks
    $('.class1, .class2').on('click', some_function);


Or:

$('.class1').add('.class2').on('click', some_function);


This also works with existing objects:

const $class1 = $('.class1');
const $class2 = $('.class2');
$class1.add($class2).on('click', some_function);

    I normally use on instead of click. It allow me to add more events listeners to a specific function.
$(document).on(""click touchend"", "".class1, .class2, .class3"", function () {
     //do stuff
});

    Add a comma separated list of classes like this :

jQuery(document).ready(function($) {

$('.class, .id').click(function() { 

//  Your code

    }

});

    If you have or want to keep your elements as variables (jQuery objects), you can also loop over them:

var $class1 = $('.class1');
var $class2 = $('.class2');

$([$class1,$class2]).each(function() {
    $(this).on('click', function(e) {
        some_function();
    });
});

    $('.class1, .class2').click(some_function);


Make sure you put a space like $('.class1,space here.class2') or else it won't work.
    We can code like following also, I have used blur event here.

$(""#proprice, #proqty"").blur(function(){
      var price=$(""#proprice"").val();
      var qty=$(""#proqty"").val();
      if(price != '' || qty != '')
      {
          $(""#totalprice"").val(qty*price);
      }
  });

    Simply use $('.myclass1, .myclass2, .myclass3') for multiple selectors. Also, you dont need lambda functions to bind an existing function to the click event.
    Another alternative, assuming your elements are stored as variables (which is often a good idea if you're accessing them multiple times in a function body):

function disableMinHeight() {
    var $html = $(""html"");
    var $body = $(""body"");
    var $slideout = $(""#slideout"");

    $html.add($body).add($slideout).css(""min-height"", 0);
};


Takes advantage of jQuery chaining and allows you to use references.
    I have a link to an object containig many input fields, which requires to be handled by the same event. So I simply use find() to get all the inside objects, that need to have the event

var form = $('<form></form>');
// ... apending several input fields

form.find('input').on('change', onInputChange);


In case your objects are one level down the link children() instead find() method can be used.
    In addition to the excellent examples and answers above, you can also do a ""find"" for two different elements using their classes. For example:

<div class=""parent"">
<div class=""child1"">Hello</div>
<div class=""child2"">World</div>
</div>

<script>
var x = jQuery('.parent').find('.child1, .child2').text();
console.log(x);
</script>


This should output ""HelloWorld"".
    ","[493, 959, 130, 4, 9, 43, 4, 19, 11, 1, 1]",504657,80,2009-08-21T17:59:15,2020-09-05 13:05:32Z,
"What is the difference between association, aggregation and composition?","
                
What is the difference between association, aggregation, and composition? 
Please explain in terms of implementation.
    For two objects, Foo and Bar the relationships can be defined
Association - I have a relationship with an object.  Foo uses Bar
public class Foo {         
    private Bar bar;
};

NB: See Fowler's definition - the key is that Bar is semantically related to Foo rather than just a dependency (like an int or string).
Composition - I own an object and I am responsible for its lifetime. When Foo dies, so does Bar
public class Foo {
    private Bar bar = new Bar(); 
}

Aggregation - I have an object which I've borrowed from someone else.  When Foo dies, Bar may live on.
public class Foo { 
    private Bar bar; 
    Foo(Bar bar) { 
       this.bar = bar; 
    }
}

    Association is generalized concept of relations. It includes both Composition and Aggregation.
Composition(mixture) is a way to wrap simple objects or data types into a single unit. Compositions are a critical building block of many basic data structures
Aggregation(The formation of a number of things into a cluster) differs from ordinary composition in that it does not imply ownership. In composition, when the owning object is destroyed, so are the contained objects. In aggregation, this is not necessarily true.
Trick to remember the difference :

""Has-A"": Aggregation
""Part-Of"": cOmPositoin
""Is-a"": Inheritance





context
Aggregation
Composition




Life time
objects have their own lifetime and there is no owner
controlled by whole or parent that owns it


Scope
parent objects and child objects are independent
parent object also means the death of its children.


Relationship
Has-a
Part-of


Strength
weak relationship
strong relationship.


Real-life example
Car and Driver
Car and wheels




Now let observe the following image


Analogy:
Composition: The following picture is image composition i.e. using individual images making one image.

Aggregation : collection of image in single location

For example, A university owns various departments, and each department has a number of professors. If the university closes, the departments will no longer exist, but the professors in those departments will continue to exist. Therefore, a University can be seen as a composition of departments, whereas departments have an aggregation of professors. In addition, a Professor could work in more than one department, but a department could not be part of more than one university.
    Dependency (references)
It means there is no conceptual link between two objects. e.g. EnrollmentService object references Student & Course objects (as method parameters or return types)
public class EnrollmentService {
    public void enroll(Student s, Course c){}
}

Association (has-a)
It means there is almost always a link between objects (they are associated).
Order object has a Customer object
public class Order {
    private Customer customer
}

Aggregation (has-a + whole-part)
Special kind of association where there is whole-part relation between two objects. they might live without each other though.
public class PlayList {
    private List<Song> songs;
}

OR
public class Computer {
    private Monitor monitor;
}

Note: the trickiest part is to distinguish aggregation from normal association. Honestly, I think this is open to different interpretations.
Composition (has-a + whole-part + ownership)
Special kind of aggregation. An Apartment is composed of some Rooms. A Room cannot exist without an Apartment. when an apartment is deleted, all associated rooms are deleted as well.
public class Apartment{
    private Room bedroom;
    public Apartment() {
       bedroom = new Room();
    }
}

    I know this question is tagged as C# but the concepts are pretty generic questions like this redirect here. So I am going to provide my point of view here (a bit biased from java point of view where I am more comfortable).

When we think of Object-oriented nature we always think of Objects, class (objects blueprints) and the relationship between them. Objects are related and interact with each other via methods. In other words the object of one class may use services/methods provided by the object of another class. This kind of relationship is termed as association..

Aggregation and Composition are subsets of association meaning they are specific cases of association.




In both aggregation and composition object of one class ""owns"" object of another class.
But there is a subtle difference. In Composition the object of class that is owned by the object of it's owning class cannot live on it's own(Also called ""death relationship""). It will always live as a part of it's owning object where as in Aggregation the dependent object is standalone and can exist even if the object of owning class is dead. 
So in composition if owning object is garbage collected the owned object will also be which is not the case in aggregation.


Confused? 

Composition Example : Consider the example of a Car and an engine that is very specific to that car (meaning it cannot be used in any other car). This type of relationship between Car and SpecificEngine class is called Composition. An object of the Car class cannot exist without an object of SpecificEngine class and object of SpecificEngine has no significance without Car class. To put in simple words Car class solely ""owns"" the SpecificEngine class.

Aggregation Example : Now consider class Car and class Wheel. Car needs a Wheel object to function. Meaning the Car object owns the Wheel object but we cannot say the Wheel object has no significance without the Car Object. It can very well be used in a Bike, Truck or different Cars Object.

Summing it up - 

To sum it up association is a very generic term used to represent when a class uses the functionalities provided by another class. We say it's composition if one parent class object owns another child class object and that child class object cannot meaningfully exist without the parent class object. If it can then it is called Aggregation.

More details here. 
I am the author of http://opensourceforgeeks.blogspot.in and have added a link above to the relevant post for more context.
    As others said, an association is a relationship between objects, aggregation and composition are types of association.

From an implementation point of view, an aggregation is obtained by having a class member by reference. For example, if class A aggregates an object of class B, you'll have something like this (in C++):

class A {
    B & element;
  // or B * element;
};


The semantics of aggregation is that when an object A is destroyed, the B object it is storing will still exists. When using composition, you have a stronger relationship, usually by storing the member by value:

class A {
    B element;
};


Here, when an A object is destroyed, the B object it contains will be destroyed too. The easiest way to achieve this is by storing the member by value, but you could also use some smart pointer, or delete the member in the destructor:

class A {
    std::auto_ptr<B> element;
};

class A {
    B * element;

    ~A() {
        delete B;
    }
};


The important point is that in a composition, the container object owns the contained one, whereas in aggregation, it references it.
    In a very simple sentence:
Aggregation and Composition are subsets of association.


A uses B -> this is an aggregation
A needs B -> is composition.


Read more here.
    It's amazing how much confusion exists about the distinction between the three relationship concepts association, aggregation and composition. 

Notice that the terms aggregation and composition have been used in the C++ community, probably for some time before they have been defined as special cases of association in UML Class Diagrams.

The main problem is the widespread and ongoing misunderstanding (even among expert software developers) that the concept of composition implies a life-cycle dependency between the whole and its parts such that the parts cannot exist without the whole, ignoring the fact that there are also cases of part-whole-associations with non-shareable parts where the parts can be detached from, and survive the destruction of, the whole. 

As far as I can see, this confusion has two roots:


In the C++ community, the term ""aggregation"" was used in the sense of a class defining an attribute for referencing objects of another independent class (see, e.g., [1]), which is the sense of association in UML Class Diagrams. The term ""composition"" was used for classes that define component objects for their objects, such that on destruction of the composite object, these component objects are being destroyed as well.
In UML Class Diagrams, both ""aggregation"" and ""composition"" have been defined as special cases of associations representing part-whole relationships (which have been discussed in philosophy for a long time). In their definitions, the distinction between an ""aggregation"" and a ""composition"" is based on the fact if it allows sharing a part between two or more wholes. They define ""compositions"" as having non-shareable (exclusive) parts, while ""aggregations"" may share their parts. In addition they say something like the following: very often, but not in all cases, compositions come with a life-cycle dependency between the whole and its parts such that the parts cannot exist without the whole.


Thus, while UML has put the terms ""aggregation"" and ""composition"" in the right context (of part-whole relationships), they have not managed to define them in a clear and unambiguous manner, capturing the intuitions of developers. However, this is not surprising because there are so many different properties (and implementation nuances) these relationships can have, and developers do not agree on how to implement them. 

See also my extended answer to the SO question of Apr 2009 listed below.

And the property that was assumed to define ""composition"" between OOP objects in the C++ community (and this belief is still widely held): the run-time life-cycle dependency between the two related objects (the composite and its component), is not really characteristic for ""composition"" because we can have such dependencies due to referential integrity also in other types of associations.

For instance, the following code pattern for ""composition"" was proposed in an SO answer:

final class Car {    
  private final Engine engine;

  Car(EngineSpecs specs) {
    engine = new Engine(specs);
  }

  void move() {
    engine.work();
  }
}


The respondent claimed that it would be characteristic for ""composition"" that no other class could reference/know the component. However, this is certainly not true for all possible cases of ""composition"". In particular, in the case of a car's engine, the maker of the car, possibly implemented with the help of another class, may have to reference the engine for being able to contact the car's owner whenever there is an issue with it.

[1] http://www.learncpp.com/cpp-tutorial/103-aggregation/

Appendix - Incomplete list of repeatedly asked questions about composition versus aggregation on StackOverflow

[Apr 2009] 
Aggregation versus Composition [closed as primarily opinion-based by]
[Apr 2009] 
What is the difference between Composition and Association relationship? 
[May 2009] 
Difference between association, aggregation and composition
[May 2009] 
What is the difference between composition and aggregation? [duplicate]
[Oct 2009]
What is the difference between aggregation, composition and dependency? [marked as duplicate]
[Nov 2010] 
Association vs. Aggregation [marked as duplicate]
[Aug 2012] 
Implementation difference between Aggregation and Composition in Java
[Feb 2015] 
UML - association or aggregation (simple code snippets)
    Association, Aggregation, Composition are about Has a relationship.
Aggregation and Composition are subsets of Association  which describe relationship more accurately

Aggregation - independent relationship. An object can be passed and saved inside class via constructor, method, setter...
Composition - dependent relationship. An object is created by owner object
*Association is an alternative for sybtyping

        Simple rules:
    A ""owns"" B = Composition : B has no meaning or purpose in the system 
    without A
    A ""uses"" B = Aggregation : B exists independently (conceptually) from A
    A ""belongs/Have"" B= Association; And B exists just have a relation
    Example 1:

    A Company is an aggregation of Employees.
    A Company is a composition of Accounts. When a Company ceases to do 
    business its Accounts cease to exist but its People continue to exist. 
    Employees have association relationship with each other.

    Example 2: (very simplified)
    A Text Editor owns a Buffer (composition). A Text Editor uses a File 
    (aggregation). When the Text Editor is closed,
    the Buffer is destroyed but the File itself is not destroyed.

    From a post by Robert Martin in comp.object:

Association represents the ability of one instance to send a message to another instance. This is typically implemented with a pointer or reference instance variable, although it might also be implemented as a method argument, or the creation of a local variable.

//[Example:]

//|A|----------->|B|

class A
{
  private:
    B* itsB;
};


Aggregation [...] is the typical whole/part relationship. This is exactly the same as an association with the exception that instances cannot have cyclic aggregation relationships (i.e. a part cannot contain its whole).

//[Example:]

//|Node|<>-------->|Node|

class Node
{
  private:
    vector<Node*> itsNodes;
};


The fact that this is aggregation means that the instances of Node cannot form a cycle. Thus, this is a Tree of Nodes not a graph of Nodes.

Composition [...] is exactly like Aggregation except that the lifetime of the 'part' is controlled by the 'whole'. This control may be direct or transitive. That is, the 'whole' may take direct responsibility for creating or destroying the 'part', or it may accept an already created part, and later pass it on to some other whole that assumes responsibility for it.

//[Example:]

//|Car|<#>-------->|Carburetor|

class Car
{
  public:
    virtual ~Car() {delete itsCarb;}
  private:
    Carburetor* itsCarb
};

    Association
Association  represents the relationship between two classes.It can be unidirectional(one way) or bidirectional(two way)
for example:

unidirectional


Customer places orders


bidirectional


A is married to B
B is married to A

Aggregation
Aggregation is a kind of association.But with specific features.Aggregation is the relationship in one larger ""whole"" class contains one or more smaller ""parts"" classes.Conversely, a smaller ""part"" class is a part of ""whole"" larger class.
for example:

club has members

A club(""whole"") is made up of several club members(""parts"").Member have life to outside the club. If the club(""whole"") were to die, members(""parts"") would not die with it. Because member can belong to multiple clubs(""whole"").
Composition
This is a stronger form of aggregation.""Whole"" is responsible for the creation or destruction of its ""parts""
For example:

A school has departments

In this case school(""whole"") were to die, department(""parts"") would die with it.
Because each part can belong to only one ""whole"".
    https://www.linkedin.com/pulse/types-relationships-object-oriented-programming-oop-sarah-el-dawody/

Composition: is a ""part-of"" relationship.

for example “engine is part of the car”, “heart is part of the body”.



Association: is a “has-a” type relationship

For example, suppose we have two classes then these two classes are said to be “has-a” relationships if both of these entities share each other’s object for some work and at the same time they can exist without each other's dependency or both have their own lifetime.



The above example showing an association relationship because of both Employee and Manager class using the object of each other and both their own independent life cycle.

Aggregation: is based is on ""has-a"" relationship and it's is \\a special form of association

for example, “Student” and “address”. Each student must have an address so the relationship between Student class and Address class will be “Has-A” type relationship but vice versa is not true.


    Association is a relationship between two separate classes and the association can be of any type say one to one, one to may etc. It joins two entirely separate entities.

Aggregation is a special form of association which is a unidirectional one way relationship between classes (or entities), for e.g. Wallet and Money classes. Wallet has Money but money doesn’t need to have Wallet necessarily so its a one directional relationship. In this relationship both the entries can survive if other one ends. In our example if Wallet class is not present, it does not mean that the Money class cannot exist.

Composition is a restricted form of Aggregation in which two entities (or you can say classes) are highly dependent on each other. For e.g. Human and Heart. A human needs heart to live and a heart needs a Human body to survive. In other words when the classes (entities) are dependent on each other and their life span are same (if one dies then another one too) then its a composition. Heart class has no sense if Human class is not present.
    From: Remo H. Jansen book “Beginning React: Learning TypeScript 2.x - Second Edition” :

We call association those relationships whose objects have an independent life cycle where there is no ownership of the objects. Let's take a look at an example of a teacher and a student. Multiple students can be associated with a single teacher, and a single student can be associated with multiple teachers, but both have independent life cycles (both can create and delete independently). So, when a teacher leaves the school, we don't need to delete any students, and when a student leaves the school, we don't need to delete any teachers.

We call aggregation those relationships whose objects have an independent life cycle, but there is ownership, and child objects cannot belong to another parent object. Let's take an example of a cell phone and a cell phone battery. A single battery can belong to a phone, but if the phone stops working, and we delete it from our database, the phone battery will not be deleted because it may still be functional. So, in aggregation, while there is ownership, objects have their life cycle

We use the term composition to refer to relationships whose objects don't have an independent life cycle, and if the parent object is deleted, all child objects will also be deleted. Let's take an example of the relationship between questions and answers. Single questions can have multiple answers, and answers cannot belong to multiple questions. If we delete questions, answers will automatically be deleted.
    Problem with these answers is they are half the story: they explain that aggregation and composition are forms of association, but they don't say if it is possible for an association to be neither of those. 

I gather based on some brief readings of many posts on SO and some UML docs that there are 4 main concrete forms of class association: 


composition: A is-composed-of-a B; B doesn't exist without A, like a room in a home
aggregation: A has-a B; B can exist without A, like a student in a classroom
dependency: A uses-a B; no lifecycle dependency between A and B, like a method call parameter, return value, or a temporary created during a method call
generalization: A is-a B


When a relationship between two entities isn't one of these, it can just be called ""an association"" in the generic sense of the term, and further described other ways (note, stereotype, etc). 

My guess is that the ""generic association"" is intended to be used primarily in two circumstances: 


when the specifics of a relationship are still being worked out; such relationship in a diagram should be converted as soon as possible to what it actually is/will be (one of the other 4). 
when a relationship doesn't match any of those 4 predetermined by UML; the ""generic"" association still gives you a way of representing a relationship that is ""not one of the other ones"", so that you aren't stuck using an incorrect relationship with a note ""this is not actually aggregation, it's just that UML doesn't have any other symbol we could use""

    Composition (If you remove ""whole"", “part” is also removed automatically– “Ownership”)


Create objects of your existing class inside the new class. This is called composition because the new class is composed of objects of existing classes.
Typically use normal member variables.
Can use pointer values if the composition class automatically handles allocation/deallocation responsible for creation/destruction of subclasses.




Composition in C++ 

#include <iostream>
using namespace std;
/********************** Engine Class ******************/
class Engine
{
    int nEngineNumber;
    public:
    Engine(int nEngineNo);
    ~Engine(void);
};
Engine::Engine(int nEngineNo)
{
    cout<<"" Engine :: Constructor "" <<endl;
}
Engine::~Engine(void)
{
    cout<<"" Engine :: Destructor "" <<endl;
}
/********************** Car Class ******************/
class Car
{
    int nCarColorNumber;
    int nCarModelNumber;
    Engine objEngine;
    public:
    Car (int, int,int);
    ~Car(void);
};
Car::Car(int nModelNo,int nColorNo, int nEngineNo):
nCarModelNumber(nModelNo),nCarColorNumber(nColorNo),objEngine(nEngineNo)
{
    cout<<"" Car :: Constructor "" <<endl;
}
Car::~Car(void)
{
    cout<<"" Car :: Destructor "" <<endl;
    Car
    Engine
    Figure 1 : Composition
}
/********************** Bus Class ******************/
class Bus
{
    int nBusColorNumber;
    int nBusModelNumber;
    Engine* ptrEngine;
    public:
    Bus(int,int,int);
    ~Bus(void);
};
Bus::Bus(int nModelNo,int nColorNo, int nEngineNo):
nBusModelNumber(nModelNo),nBusColorNumber(nColorNo)
{
    ptrEngine = new Engine(nEngineNo);
    cout<<"" Bus :: Constructor "" <<endl;
}
Bus::~Bus(void)
{
    cout<<"" Bus :: Destructor "" <<endl;
    delete ptrEngine;
}
/********************** Main Function ******************/
int main()
{
    freopen (""InstallationDump.Log"", ""w"", stdout);
    cout<<""--------------- Start Of Program --------------------""<<endl;
    // Composition using simple Engine in a car object
    {
        cout<<""------------- Inside Car Block ------------------""<<endl;
        Car objCar (1, 2,3);
    }
    cout<<""------------- Out of Car Block ------------------""<<endl;
    // Composition using pointer of Engine in a Bus object
    {
        cout<<""------------- Inside Bus Block ------------------""<<endl;
        Bus objBus(11, 22,33);
    }
    cout<<""------------- Out of Bus Block ------------------""<<endl;
    cout<<""--------------- End Of Program --------------------""<<endl;
    fclose (stdout);
}


Output

--------------- Start Of Program --------------------
------------- Inside Car Block ------------------
Engine :: Constructor
Car :: Constructor
Car :: Destructor
Engine :: Destructor
------------- Out of Car Block ------------------
------------- Inside Bus Block ------------------
Engine :: Constructor
Bus :: Constructor
Bus :: Destructor
Engine :: Destructor
------------- Out of Bus Block ------------------
--------------- End Of Program --------------------


Aggregation (If you remove ""whole"", “Part” can exist – “ No Ownership”)


An aggregation is a specific type of composition where no ownership between the complex object and the subobjects is implied. When an aggregate is destroyed, the subobjects are not destroyed.
Typically use pointer variables/reference variable that point to an object that lives outside the scope of the aggregate class
Can use reference values that point to an object that lives outside the scope of the aggregate class
Not responsible for creating/destroying subclasses




Aggregation Code in C++ 

#include <iostream>
#include <string>
using namespace std;
/********************** Teacher Class ******************/
class Teacher
{
    private:
    string m_strName;
    public:
    Teacher(string strName);
    ~Teacher(void);
    string GetName();
};
Teacher::Teacher(string strName) : m_strName(strName)
{
    cout<<"" Teacher :: Constructor --- Teacher Name :: ""<<m_strName<<endl;
}
Teacher::~Teacher(void)
{
    cout<<"" Teacher :: Destructor --- Teacher Name :: ""<<m_strName<<endl;
}
string Teacher::GetName()
{
    return m_strName;
}
/********************** Department Class ******************/
class Department
{
    private:
    Teacher *m_pcTeacher;
    Teacher& m_refTeacher;
    public:
    Department(Teacher *pcTeacher, Teacher& objTeacher);
    ~Department(void);
};
Department::Department(Teacher *pcTeacher, Teacher& objTeacher)
: m_pcTeacher(pcTeacher), m_refTeacher(objTeacher)
{
    cout<<"" Department :: Constructor "" <<endl;
}
Department::~Department(void)
{
    cout<<"" Department :: Destructor "" <<endl;
}
/********************** Main Function ******************/
int main()
{
    freopen (""InstallationDump.Log"", ""w"", stdout);
    cout<<""--------------- Start Of Program --------------------""<<endl;
    {
        // Create a teacher outside the scope of the Department
        Teacher objTeacher(""Reference Teacher"");
        Teacher *pTeacher = new Teacher(""Pointer Teacher""); // create a teacher
        {
            cout<<""------------- Inside Block ------------------""<<endl;
            // Create a department and use the constructor parameter to pass the teacher to it.
            Department cDept(pTeacher,objTeacher);
            Department
            Teacher
            Figure 2: Aggregation
        } // cDept goes out of scope here and is destroyed
        cout<<""------------- Out of Block ------------------""<<endl;
        // pTeacher still exists here because cDept did not destroy it
        delete pTeacher;
    }
    cout<<""--------------- End Of Program --------------------""<<endl;
    fclose (stdout);
}


Output 

--------------- Start Of Program --------------------
Teacher :: Constructor --- Teacher Name :: Reference Teacher
Teacher :: Constructor --- Teacher Name :: Pointer Teacher
------------- Inside Block ------------------
Department :: Constructor
Department :: Destructor
------------- Out of Block ------------------
Teacher :: Destructor --- Teacher Name :: Pointer Teacher
Teacher :: Destructor --- Teacher Name :: Reference Teacher
--------------- End Of Program --------------------

    I think this link will do your homework: http://ootips.org/uml-hasa.html

To understand the terms I remember an example in my early programming days:

If you have a 'chess board' object that contains 'box' objects that is composition because if the 'chess board' is deleted there is no reason for the boxes to exist anymore.

If you have a 'square' object that have a 'color' object and the square gets deleted the 'color' object may still exist, that is aggregation

Both of them are associations, the main difference is conceptual
    I'd like to illustrate how the three terms are implemented in Rails. ActiveRecord calls any type of relationship between two models an association. One would not find very often the terms composition and aggregation, when reading documentation or articles, related to ActiveRecord. An association is created by adding one of the association class macros to the body of the class. Some of these macros are belongs_to, has_one, has_many etc..

If we want to set up a composition or aggregation, we need to add belongs_to to the owned model (also called child) and has_one or has_many to the owning model (also called parent). Wether we set up composition or aggregation depends on the options we pass to the belongs_to call in the child model. Prior to Rails 5, setting up belongs_to without any options created an aggregation, the child could exist without a parent. If we wanted a composition, we needed to explicitly declare this by adding the option required: true:

class Room < ActiveRecord::Base
  belongs_to :house, required: true
end


In Rails 5 this was changed. Now, declaring a belongs_to association creates a composition by default, the child cannot exist without a parent. So the above example can be re-written as:

class Room < ApplicationRecord
  belongs_to :house
end


If we want to allow the child object to exist without a parent, we need to declare this explicitly via the option optional

class Product < ApplicationRecord
  belongs_to :category, optional: true
end

    Composition:
This is where once you destroy an object (School), another object (Classrooms) which is bound to it would get destroyed too. Both of them can't exist independently. 

Aggregation:
This is sorta the exact opposite of the above (Composition) association where once you kill an object (Company), the other object (Employees) which is bound to it can exist on its own.

Association.
Composition and Aggregation are the two forms of association.
    It's important to understand why we should even bother with using more than once relationship line. The most obvious reason is to describe parent-child relationship between classes (when parent deleted all its child’s are deleted as a result), but more impotently, we want to distinguish between simple association and composition in order to place implicit restrictions on the visibility and propagation of changes to the related classes, a matter which plays an important role in understanding and reducing system complexity.


  Association


The most abstract way to describe static relationship between classes is using the Association link, which simply states that there is some kind of a link or a dependency between two classes or more.

Weak Association

ClassA may be linked to ClassB in order to show that one of its methods includes parameter of ClassB instance, or returns instance of ClassB. 

Strong Association

ClassA may also be linked to ClassB in order to show that it holds a reference to ClassB instance.


  Aggregation (Shared Association)


In cases where there’s a part-of relationship between ClassA (whole) and ClassB (part), we can be more specific and use the aggregation link instead of the association link, highlighting that ClassB can also be aggregated by other classes in the application (therefore aggregation is also known as shared association). 



It’s important to note that the aggregation link doesn’t state in any way that ClassA owns ClassB nor that there’s a parent-child relationship (when parent deleted all its child’s are being deleted as a result) between the two. Actually, quite the opposite! The aggregation link usually used to stress the point that ClassA is not the exclusive container of ClassB, as in fact ClassB has another container.   

Aggregation v.s. Association
The association link can replace the aggregation link in every situation, while aggregation cannot replace association in situations where there’s only a ‘weak link’ between the classes, i.e. ClassA has method/s that contain parameter of ClassB but ClassA doesn’t hold reference to ClassB instance.

Martin Fowler suggest that the aggregation link should not be used at all because it has no added value and it disturb consistency, Quoting  Jim Rumbaugh ""Think of it as a modeling placebo"".


  Composition (Not-Shared Association)


We should be more specific and use the composition link in cases where in addition to the part-of relationship between ClassA and ClassB - there’s a strong lifecycle dependency between the two, meaning that when ClassA is deleted then ClassB is also deleted as a result 



The composition link shows that a class (container, whole) has exclusive ownership over other class/s (parts), meaning that the container object and its parts constitute a parent-child/s relationship. 

Unlike association and aggregation, when using the composition relationship, the composed class cannot appear as a return type or parameter type of the composite class. Thus, changes to the composed class cannot propagate to the rest of the system. Consequently, usage of composition limits complexity growth as the system grows.


  Measuring system complexity


System complexity can be measured simply by looking at a UML class diagram and evaluating the association, aggregation, and composition relationship lines. The way to measure complexity is to determine how many classes can be affected by changing a particular class. If class A exposes class B, then any given class that uses class A can theoretically be affected by changes to class B. The sum of the number of potentially affected classes for every class in the system is the total system complexity.

You can read more on my blog: 
http://aviadezra.blogspot.com/2009/05/uml-association-aggregation-composition.html


    ","[493, 521, 132, 104, 168, 27, 3, 19, 4, 5, 31, 14, 5, 2, 3, 6, 7, 5, 2, 4, 10]",422810,366,2009-05-20T02:47:49,2022-03-04 02:45:37Z,
How can I change property names when serializing with Json.net?,"
                
I have some data in a C# DataSet object. I can serialize it right now using a Json.net converter like this

DataSet data = new DataSet();
// do some work here to populate 'data'
string output = JsonConvert.SerializeObject(data);


However, this uses the property names from data when printing to the .json file. I would like to change the property names to be something different (say, change 'foo' to 'bar').

In the Json.net documentation, under 'Serializing and Deserializing JSON' → 'Serialization Attributes' it says ""JsonPropertyAttribute... allows the name to be customized"". But there is no example. Does anyone know how to use a JsonPropertyAttribute to change the property name to something else?

(Direct link to documentation)

Json.net's documentation seems to be sparse. If you have a great example I'll try to get it added to the official documentation.
Thanks!
    You could decorate the property you wish controlling its name with the [JsonProperty] attribute which allows you to specify a different name:

using Newtonsoft.Json;
// ...

[JsonProperty(PropertyName = ""FooBar"")]
public string Foo { get; set; }


Documentation: Serialization Attributes
    If you don't have access to the classes to change the properties, or don't want to always use the same rename property, renaming can also be done by creating a custom resolver. 

For example, if you have a class called MyCustomObject, that has a property called LongPropertyName, you can use a custom resolver like this…

public class CustomDataContractResolver : DefaultContractResolver
{
  public static readonly CustomDataContractResolver Instance = new CustomDataContractResolver ();

  protected override JsonProperty CreateProperty(MemberInfo member, MemberSerialization memberSerialization)
  {
    var property = base.CreateProperty(member, memberSerialization);
    if (property.DeclaringType == typeof(MyCustomObject))
    {
      if (property.PropertyName.Equals(""LongPropertyName"", StringComparison.OrdinalIgnoreCase))
      {
        property.PropertyName = ""Short"";
      }
    }
    return property;
  }
}


Then call for serialization and supply the resolver:

 var result = JsonConvert.SerializeObject(myCustomObjectInstance,
                new JsonSerializerSettings { ContractResolver = CustomDataContractResolver.Instance });


And the result will be shortened to {""Short"":""prop value""} instead of {""LongPropertyName"":""prop value""}

More info on custom resolvers here 
    There is still another way to do it, which is using a particular NamingStrategy, which can be applied to a class or a property by decorating them with [JSonObject] or [JsonProperty].

There are predefined naming strategies like CamelCaseNamingStrategy, but you can implement your own ones.

The implementation of different naming strategies can be found here: https://github.com/JamesNK/Newtonsoft.Json/tree/master/Src/Newtonsoft.Json/Serialization
    ","[493, 875, 95, 8]",368260,58,2012-01-09T23:24:07,2019-04-02 14:56:32Z,c 
"What is the difference between \r\n, \r, and \n? [duplicate]","
                    
            
        
            
                
                    
                        This question already has answers here:
                        
                    
                
            
                    
                        Difference between \n and \r?
                            
                                (11 answers)
                            
                    
                Closed 9 years ago.
        

    

What is difference in a string between \r\n, \r and \n? How is a string affected by each?
I have to replace the occurrences of \r\n and \r with \n, but I cannot get how are they different in a string...
I know that \r is like hitting enter and \n is for a new line.
    
\r = CR (Carriage Return) → Used as a new line character in Mac OS before X
\n = LF (Line Feed) → Used as a new line character in Unix/Mac OS X
\r\n = CR + LF → Used as a new line character in Windows

    All 3 of them represent the end of a line. But...


\r (Carriage Return) → moves the cursor to the beginning of the line without advancing to the next line
\n (Line Feed) → moves the cursor down to the next line without returning to the beginning of the line — In a *nix environment \n moves to the beginning of the line.
\r\n (End Of Line) → a combination of \r and \n

    A carriage return (\r) makes the cursor jump to the first column (begin of the line) while the newline (\n) jumps to the next line and might also to the beginning of that line. So to be sure to be at the first position within the next line one uses both.
    They are normal symbols as 'a' or 'ю' or any other. Just (invisible) entries in a string.
\r moves cursor to the beginning of the line.
\n goes one line down.

As for your replacement, you haven't specified what language you're using, so here's the sketch:

someString.replace(""\r\n"", ""\n"").replace(""\r"", ""\n"")
    ","[493, 624, 248, 14, 28]",1108489,160,2013-03-15T13:01:36,2021-08-17 15:22:28Z,
Why does GCC generate 15-20% faster code if I optimize for size instead of speed?,"
                
I first noticed in 2009 that GCC (at least on my projects and on my machines) have the tendency to generate noticeably faster code if I optimize for size (-Os) instead of speed (-O2 or -O3), and I have been wondering ever since why.

I have managed to create (rather silly) code that shows this surprising behavior and is sufficiently small to be posted here.

const int LOOP_BOUND = 200000000;

__attribute__((noinline))
static int add(const int& x, const int& y) {
    return x + y;
}

__attribute__((noinline))
static int work(int xval, int yval) {
    int sum(0);
    for (int i=0; i<LOOP_BOUND; ++i) {
        int x(xval+sum);
        int y(yval+sum);
        int z = add(x, y);
        sum += z;
    }
    return sum;
}

int main(int , char* argv[]) {
    int result = work(*argv[1], *argv[2]);
    return result;
}


If I compile it with -Os, it takes 0.38 s to execute this program, and 0.44 s if it is compiled with -O2 or -O3. These times are obtained consistently and with practically no noise (gcc 4.7.2, x86_64 GNU/Linux, Intel Core i5-3320M).

(Update: I have moved all assembly code to GitHub: They made the post bloated and apparently add very little value to the questions as the fno-align-* flags have the same effect.)

Here is the generated assembly with -Os and -O2.

Unfortunately, my understanding of assembly is very limited, so I have no idea whether what I did next was correct: I grabbed the assembly for -O2 and merged all its differences into the assembly for -Os except the .p2align lines, result here. This code still runs in 0.38s and the only difference is the .p2align stuff.

If I guess correctly, these are paddings for stack alignment. According to Why does GCC pad functions with NOPs? it is done in the hope that the code will run faster, but apparently this optimization backfired in my case.

Is it the padding that is the culprit in this case? Why and how?

The noise it makes pretty much makes timing micro-optimizations impossible.

How can I make sure that such accidental lucky / unlucky alignments are not interfering when I do micro-optimizations (unrelated to stack alignment) on C or C++ source code?



UPDATE:

Following Pascal Cuoq's answer I tinkered a little bit with the alignments. By passing -O2 -fno-align-functions -fno-align-loops to gcc, all .p2align are gone from the assembly and the generated executable runs in 0.38s. According to the gcc documentation:


  -Os enables all -O2 optimizations [but] -Os disables the following optimization flags:

  -falign-functions  -falign-jumps  -falign-loops
  -falign-labels  -freorder-blocks  -freorder-blocks-and-partition
  -fprefetch-loop-arrays



So, it pretty much seems like a (mis)alignment issue.

I am still skeptical about -march=native as suggested in Marat Dukhan's answer. I am not convinced that it isn't just interfering with this (mis)alignment issue; it has absolutely no effect on my machine. (Nevertheless, I upvoted his answer.)



UPDATE 2:

We can take -Os out of the picture. The following times are obtained by compiling with


-O2 -fno-omit-frame-pointer 0.37s
-O2 -fno-align-functions -fno-align-loops 0.37s
-S -O2 then manually moving the assembly of add() after work() 0.37s
-O2 0.44s


It looks like to me the distance of add() from the call site matters a lot. I have tried perf, but the output of perf stat and perf report makes very little sense to me. However, I could only get one consistent result out of it:

-O2:

 602,312,864 stalled-cycles-frontend   #    0.00% frontend cycles idle
       3,318 cache-misses
 0.432703993 seconds time elapsed
 [...]
 81.23%  a.out  a.out              [.] work(int, int)
 18.50%  a.out  a.out              [.] add(int const&, int const&) [clone .isra.0]
 [...]
       ¦   __attribute__((noinline))
       ¦   static int add(const int& x, const int& y) {
       ¦       return x + y;
100.00 ¦     lea    (%rdi,%rsi,1),%eax
       ¦   }
       ¦   ? retq
[...]
       ¦            int z = add(x, y);
  1.93 ¦    ? callq  add(int const&, int const&) [clone .isra.0]
       ¦            sum += z;
 79.79 ¦      add    %eax,%ebx


For fno-align-*:

 604,072,552 stalled-cycles-frontend   #    0.00% frontend cycles idle
       9,508 cache-misses
 0.375681928 seconds time elapsed
 [...]
 82.58%  a.out  a.out              [.] work(int, int)
 16.83%  a.out  a.out              [.] add(int const&, int const&) [clone .isra.0]
 [...]
       ¦   __attribute__((noinline))
       ¦   static int add(const int& x, const int& y) {
       ¦       return x + y;
 51.59 ¦     lea    (%rdi,%rsi,1),%eax
       ¦   }
[...]
       ¦    __attribute__((noinline))
       ¦    static int work(int xval, int yval) {
       ¦        int sum(0);
       ¦        for (int i=0; i<LOOP_BOUND; ++i) {
       ¦            int x(xval+sum);
  8.20 ¦      lea    0x0(%r13,%rbx,1),%edi
       ¦            int y(yval+sum);
       ¦            int z = add(x, y);
 35.34 ¦    ? callq  add(int const&, int const&) [clone .isra.0]
       ¦            sum += z;
 39.48 ¦      add    %eax,%ebx
       ¦    }


For -fno-omit-frame-pointer:

 404,625,639 stalled-cycles-frontend   #    0.00% frontend cycles idle
      10,514 cache-misses
 0.375445137 seconds time elapsed
 [...]
 75.35%  a.out  a.out              [.] add(int const&, int const&) [clone .isra.0]                                                                                     ¦
 24.46%  a.out  a.out              [.] work(int, int)
 [...]
       ¦   __attribute__((noinline))
       ¦   static int add(const int& x, const int& y) {
 18.67 ¦     push   %rbp
       ¦       return x + y;
 18.49 ¦     lea    (%rdi,%rsi,1),%eax
       ¦   const int LOOP_BOUND = 200000000;
       ¦
       ¦   __attribute__((noinline))
       ¦   static int add(const int& x, const int& y) {
       ¦     mov    %rsp,%rbp
       ¦       return x + y;
       ¦   }
 12.71 ¦     pop    %rbp
       ¦   ? retq
 [...]
       ¦            int z = add(x, y);
       ¦    ? callq  add(int const&, int const&) [clone .isra.0]
       ¦            sum += z;
 29.83 ¦      add    %eax,%ebx


It looks like we are stalling on the call to add() in the slow case.

I have examined everything that perf -e can spit out on my machine; not just the stats that are given above.

For the same executable, the stalled-cycles-frontend shows linear correlation with the execution time; I did not notice anything else that would correlate so clearly. (Comparing stalled-cycles-frontend for different executables doesn't make sense to me.)

I included the cache misses as it came up as the first comment. I examined all the cache misses that can be measured on my machine by perf, not just the ones given above. The cache misses are very very noisy and show little to no correlation with the execution times.
    By default compilers optimize for ""average"" processor. Since different processors favor different instruction sequences, compiler optimizations enabled by -O2 might benefit average processor, but decrease performance on your particular processor (and the same applies to -Os). If you try the same example on different processors, you will find that on some of them benefit from -O2 while other are more favorable to -Os optimizations.

Here are the results for time ./test 0 0 on several processors (user time reported):

Processor (System-on-Chip)             Compiler   Time (-O2)  Time (-Os)  Fastest
AMD Opteron 8350                       gcc-4.8.1    0.704s      0.896s      -O2
AMD FX-6300                            gcc-4.8.1    0.392s      0.340s      -Os
AMD E2-1800                            gcc-4.7.2    0.740s      0.832s      -O2
Intel Xeon E5405                       gcc-4.8.1    0.603s      0.804s      -O2
Intel Xeon E5-2603                     gcc-4.4.7    1.121s      1.122s       -
Intel Core i3-3217U                    gcc-4.6.4    0.709s      0.709s       -
Intel Core i3-3217U                    gcc-4.7.3    0.708s      0.822s      -O2
Intel Core i3-3217U                    gcc-4.8.1    0.708s      0.944s      -O2
Intel Core i7-4770K                    gcc-4.8.1    0.296s      0.288s      -Os
Intel Atom 330                         gcc-4.8.1    2.003s      2.007s      -O2
ARM 1176JZF-S (Broadcom BCM2835)       gcc-4.6.3    3.470s      3.480s      -O2
ARM Cortex-A8 (TI OMAP DM3730)         gcc-4.6.3    2.727s      2.727s       -
ARM Cortex-A9 (TI OMAP 4460)           gcc-4.6.3    1.648s      1.648s       -
ARM Cortex-A9 (Samsung Exynos 4412)    gcc-4.6.3    1.250s      1.250s       -
ARM Cortex-A15 (Samsung Exynos 5250)   gcc-4.7.2    0.700s      0.700s       -
Qualcomm Snapdragon APQ8060A           gcc-4.8       1.53s       1.52s      -Os


In some cases you can alleviate the effect of disadvantageous optimizations by asking gcc to optimize for your particular processor (using options -mtune=native or -march=native):

Processor            Compiler   Time (-O2 -mtune=native) Time (-Os -mtune=native)
AMD FX-6300          gcc-4.8.1         0.340s                   0.340s
AMD E2-1800          gcc-4.7.2         0.740s                   0.832s
Intel Xeon E5405     gcc-4.8.1         0.603s                   0.803s
Intel Core i7-4770K  gcc-4.8.1         0.296s                   0.288s


Update: on Ivy Bridge-based Core i3 three versions of gcc (4.6.4, 4.7.3, and 4.8.1) produce binaries with significantly different performance, but the assembly code has only subtle variations. So far, I have no explanation of this fact.

Assembly from gcc-4.6.4 -Os (executes in 0.709 secs):

00000000004004d2 <_ZL3addRKiS0_.isra.0>:
  4004d2:       8d 04 37                lea    eax,[rdi+rsi*1]
  4004d5:       c3                      ret

00000000004004d6 <_ZL4workii>:
  4004d6:       41 55                   push   r13
  4004d8:       41 89 fd                mov    r13d,edi
  4004db:       41 54                   push   r12
  4004dd:       41 89 f4                mov    r12d,esi
  4004e0:       55                      push   rbp
  4004e1:       bd 00 c2 eb 0b          mov    ebp,0xbebc200
  4004e6:       53                      push   rbx
  4004e7:       31 db                   xor    ebx,ebx
  4004e9:       41 8d 34 1c             lea    esi,[r12+rbx*1]
  4004ed:       41 8d 7c 1d 00          lea    edi,[r13+rbx*1+0x0]
  4004f2:       e8 db ff ff ff          call   4004d2 <_ZL3addRKiS0_.isra.0>
  4004f7:       01 c3                   add    ebx,eax
  4004f9:       ff cd                   dec    ebp
  4004fb:       75 ec                   jne    4004e9 <_ZL4workii+0x13>
  4004fd:       89 d8                   mov    eax,ebx
  4004ff:       5b                      pop    rbx
  400500:       5d                      pop    rbp
  400501:       41 5c                   pop    r12
  400503:       41 5d                   pop    r13
  400505:       c3                      ret


Assembly from gcc-4.7.3 -Os (executes in 0.822 secs):

00000000004004fa <_ZL3addRKiS0_.isra.0>:
  4004fa:       8d 04 37                lea    eax,[rdi+rsi*1]
  4004fd:       c3                      ret

00000000004004fe <_ZL4workii>:
  4004fe:       41 55                   push   r13
  400500:       41 89 f5                mov    r13d,esi
  400503:       41 54                   push   r12
  400505:       41 89 fc                mov    r12d,edi
  400508:       55                      push   rbp
  400509:       bd 00 c2 eb 0b          mov    ebp,0xbebc200
  40050e:       53                      push   rbx
  40050f:       31 db                   xor    ebx,ebx
  400511:       41 8d 74 1d 00          lea    esi,[r13+rbx*1+0x0]
  400516:       41 8d 3c 1c             lea    edi,[r12+rbx*1]
  40051a:       e8 db ff ff ff          call   4004fa <_ZL3addRKiS0_.isra.0>
  40051f:       01 c3                   add    ebx,eax
  400521:       ff cd                   dec    ebp
  400523:       75 ec                   jne    400511 <_ZL4workii+0x13>
  400525:       89 d8                   mov    eax,ebx
  400527:       5b                      pop    rbx
  400528:       5d                      pop    rbp
  400529:       41 5c                   pop    r12
  40052b:       41 5d                   pop    r13
  40052d:       c3                      ret


Assembly from gcc-4.8.1 -Os (executes in 0.994 secs):

00000000004004fd <_ZL3addRKiS0_.isra.0>:
  4004fd:       8d 04 37                lea    eax,[rdi+rsi*1]
  400500:       c3                      ret

0000000000400501 <_ZL4workii>:
  400501:       41 55                   push   r13
  400503:       41 89 f5                mov    r13d,esi
  400506:       41 54                   push   r12
  400508:       41 89 fc                mov    r12d,edi
  40050b:       55                      push   rbp
  40050c:       bd 00 c2 eb 0b          mov    ebp,0xbebc200
  400511:       53                      push   rbx
  400512:       31 db                   xor    ebx,ebx
  400514:       41 8d 74 1d 00          lea    esi,[r13+rbx*1+0x0]
  400519:       41 8d 3c 1c             lea    edi,[r12+rbx*1]
  40051d:       e8 db ff ff ff          call   4004fd <_ZL3addRKiS0_.isra.0>
  400522:       01 c3                   add    ebx,eax
  400524:       ff cd                   dec    ebp
  400526:       75 ec                   jne    400514 <_ZL4workii+0x13>
  400528:       89 d8                   mov    eax,ebx
  40052a:       5b                      pop    rbx
  40052b:       5d                      pop    rbp
  40052c:       41 5c                   pop    r12
  40052e:       41 5d                   pop    r13
  400530:       c3                      ret

    My colleague helped me find a plausible answer to my question. He noticed the importance of the 256 byte boundary. He is not registered here and encouraged me to post the answer myself (and take all the fame).



Short answer:


  Is it the padding that is the culprit in this case? Why and how?


It all boils down to alignment. Alignments can have a significant impact on the performance, that is why we have the -falign-* flags in the first place.

I have submitted a (bogus?) bug report to the gcc developers. It turns out that the default behavior is ""we align loops to 8 byte by default but try to align it to 16 byte if we don't need to fill in over 10 bytes."" Apparently, this default is not the best choice in this particular case and on my machine. Clang 3.4 (trunk) with -O3 does the appropriate alignment and the generated code does not show this weird behavior.

Of course, if an inappropriate alignment is done, it makes things worse. An unnecessary / bad alignment just eats up bytes for no reason and potentially increases cache misses, etc.


  The noise it makes pretty much makes timing micro-optimizations
  impossible.
  
  How can I make sure that such accidental lucky / unlucky alignments
  are not interfering when I do micro-optimizations (unrelated to stack
  alignment) on C or C++ source codes?


Simply by telling gcc to do the right alignment:

g++ -O2 -falign-functions=16 -falign-loops=16



Long answer:

The code will run slower if:


an XX byte boundary cuts add() in the middle (XX being machine dependent).
if the call to add() has to jump over an XX byte boundary and the target is not aligned.
if  add() is not aligned.
if the loop is not aligned.


The first 2 are beautifully visible on the codes and results that Marat Dukhan kindly posted. In this case, gcc-4.8.1 -Os (executes in 0.994 secs):

00000000004004fd <_ZL3addRKiS0_.isra.0>:
  4004fd:       8d 04 37                lea    eax,[rdi+rsi*1]
  400500:       c3   


a 256 byte boundary cuts add() right in the middle and neither add() nor the loop is aligned. Surprise, surprise, this is the slowest case!

In case gcc-4.7.3 -Os (executes in 0.822 secs), the 256 byte boundary only cuts into a cold section (but neither the loop, nor add() is cut):

00000000004004fa <_ZL3addRKiS0_.isra.0>:
  4004fa:       8d 04 37                lea    eax,[rdi+rsi*1]
  4004fd:       c3                      ret

[...]

  40051a:       e8 db ff ff ff          call   4004fa <_ZL3addRKiS0_.isra.0>


Nothing is aligned, and the call to add() has to jump over the 256 byte boundary. This code is the second slowest.

In case gcc-4.6.4 -Os (executes in 0.709 secs), although nothing is aligned, the call to add() doesn't have to jump over the 256 byte boundary and the target is exactly 32 byte away:

  4004f2:       e8 db ff ff ff          call   4004d2 <_ZL3addRKiS0_.isra.0>
  4004f7:       01 c3                   add    ebx,eax
  4004f9:       ff cd                   dec    ebp
  4004fb:       75 ec                   jne    4004e9 <_ZL4workii+0x13>


This is the fastest of all three. Why the 256 byte boundary is speacial on his machine, I will leave it up to him to figure it out. I don't have such a processor.

Now, on my machine I don't get this 256 byte boundary effect. Only the function and the loop alignment kicks in on my machine. If I pass g++ -O2 -falign-functions=16 -falign-loops=16 then everything is back to normal: I always get the fastest case and the time isn't sensitive to the -fno-omit-frame-pointer flag anymore. I can pass g++ -O2 -falign-functions=32 -falign-loops=32 or any multiples of 16, the code is not sensitive to that either.


  I first noticed in 2009 that gcc (at least on my projects and on my
  machines) have the tendency to generate noticeably faster code if I
  optimize for size (-Os) instead of speed (-O2 or -O3) and I have been
  wondering ever since why.


A likely explanation is that I had hotspots which were sensitive to the alignment, just like the one in this example. By messing with the flags (passing -Os instead of -O2), those hotspots were aligned in a lucky way by accident and the code became faster. It had nothing to do with optimizing for size: These were by sheer accident that the hotspots got aligned better. From now on, I will check the effects of alignment on my projects.

Oh, and one more thing. How can such hotspots arise, like the one shown in the example? How can the inlining of such a tiny function like add() fail?

Consider this:

// add.cpp
int add(const int& x, const int& y) {
    return x + y;
}


and in a separate file:

// main.cpp
int add(const int& x, const int& y);

const int LOOP_BOUND = 200000000;

__attribute__((noinline))
static int work(int xval, int yval) {
    int sum(0);
    for (int i=0; i<LOOP_BOUND; ++i) {
        int x(xval+sum);
        int y(yval+sum);
        int z = add(x, y);
        sum += z;
    }
    return sum;
}

int main(int , char* argv[]) {
    int result = work(*argv[1], *argv[2]);
    return result;
}


and compiled as: g++ -O2 add.cpp main.cpp. 

      gcc won't inline add()!

That's all, it's that easy to  unintendedly create hotspots like the one in the OP. Of course it is partly my fault: gcc is an excellent compiler. If compile the above as: g++ -O2 -flto add.cpp main.cpp, that is, if I perform link time optimization, the code runs in 0.19s! 

(Inlining is artificially disabled in the OP, hence, the code in the OP was 2x slower).
    I'm adding this post-accept to point out that the effects of alignment on overall performance of programs - including big ones - has been studied.  For example, this article (and I believe a version of this also appeared in CACM) shows how link order and OS environment size changes alone were sufficient to shift performance significantly.  They attribute this to alignment of ""hot loops"".

This paper, titled ""Producing wrong data without doing anything obviously wrong!"" says that inadvertent experimental bias due to nearly uncontrollable differences in program running environments probably renders many benchmark results meaningless. 

I think you're encountering a different angle on the same observation.  

For performance-critical code, this is a pretty good argument for systems that assess the environment at installation or run time and choose the local best among differently optimized versions of key routines. 
    I think that you can obtain the same result as what you did:


  I grabbed the assembly for -O2 and merged all its differences into the assembly for -Os except the .p2align lines:


… by using -O2 -falign-functions=1 -falign-jumps=1 -falign-loops=1 -falign-labels=1. I have been compiling everything with these options, that were faster than plain -O2 everytime I bothered to measure, for 15 years.

Also, for a completely different context (including a different compiler), I noticed that the situation is similar: the option that is supposed to “optimize code size rather than speed” optimizes for code size and speed.


  If I guess correctly, these are paddings for stack alignment.


No, this has nothing to do with the stack, the NOPs that are generated by default and that options -falign-*=1 prevent are for code alignment.


  According to Why does GCC pad functions with NOPs? it is done in the hope that the code will run faster but apparently this optimization backfired in my case.
  
  Is it the padding that is the culprit in this case? Why and how?


It is very likely that the padding is the culprit. The reason padding is felt to be necessary and is useful in some cases is that code is typically fetched in lines of 16 bytes (see Agner Fog's optimization resources for the details, which vary by model of processor). Aligning a function, loop, or label on a 16-bytes boundary means that the chances are statistically increased that one fewer lines will be necessary to contain the function or loop. Obviously, it backfires because these NOPs reduce code density and therefore cache efficiency. In the case of loops and label, the NOPs may even need to be executed once (when execution arrives to the loop/label normally, as opposed to from a jump).
    If your program is bounded by the CODE L1 cache, then optimizing for size suddenly starts to pay out.

When last I checked, the compiler is not smart enough to figure this out in all cases.

In your case, -O3 probably generates code enough for two cache lines, but -Os fits in one cache line.
    I'm by no means an expert in this area, but I seem to remember that modern processors are quite sensitive when it comes to branch prediction. The algorithms used to predict the branches are (or at least were back in the days I wrote assembler code) based on several properties of the code, including the distance of a target and on the direction.

The scenario which comes to mind is small loops. When the branch was going backwards and the distance was not too far, the branch predicition was optimizing for this case as all the small loops are done this way. The same rules might come into play when you swap the location of add and work in the generated code or when the position of both slightly changes.

That said, I have no idea how to verify that and I just wanted to let you know that this might be something you want to look into.
    ","[493, 565, 206, 79, 35, 12, 7]",112447,214,2013-10-19T20:36:16,2019-11-27 04:49:59Z,c 
What are the differences between a multidimensional array and an array of arrays in C#?,"
                
What are the differences between multidimensional arrays double[,] and array-of-arrays double[][] in C#?

If there is a difference, what is the best use for each one?
    Update .NET 6:
With the release of .NET 6 I decided it was a good time to revisit this topic. I rewrote the test code for new .NET and ran it with the requirement of each part running at least a second. The benchmark was done on AMD Ryzen 5600x.
Results? It's complicated. It seems that Single array is the most performant for smaller and large arrays (< ~25x25x25 & > ~200x200x200) and Jagged arrays being fastest in between. Unfortunately it seems from my testing that multi-dimensional are by far the slowest option. At best performing twice as slow as the fastest option. But! It depends on what you need the arrays for because jagged arrays can take much longer to initialize on 50^3 cube the initialization was roughly 3 times longer than single dimensional. Multi-dimensional was only a little bit slower than single dimensional.
The conclusion? If you need fast code, benchmark it yourself on the machine it's going to run on. CPU architecture can complete change the relative performance of each method.
Numbers!
Method name         Ticks/Iteration     Scaled to the best
Array size 1x1x1 (10,000,000 iterations):
Jagged:             0.15                4.28
Single:             0.035               1
Multi-dimensional:  0.77                22

Array size 10x10x10 (25,000 iterations):
Jagged:             15                  1.67
Single:             9                   1
Multi-dimensional:  56                  6.2

Array size 25x25x25 (25,000 iterations):
Jagged:             157                 1.3
Single:             120                 1
Multi-dimensional:  667                 5.56

Array size 50x50x50 (10,000 iterations):
Jagged:             1,140               1
Single:             2,440               2.14
Multi-dimensional:  5,210               4.57

Array size 100x100x100 (10,000 iterations):
Jagged:             9,800               1
Single:             19,800              2
Multi-dimensional:  41,700              4.25

Array size 200x200x200 (1,000 iterations):
Jagged:             161,622             1
Single:             175,507             1.086
Multi-dimensional:  351,275             2.17

Array size 500x500x500 (100 iterations):
Jagged:             4,057.413           1.5
Single:             2,709,301           1
Multi-dimensional:  5,359,393           1.98

Don't trust me? Run it yourself and verify.
Note: the constant size seems to give jagged arrays an edge, but is not significant enough to change the order in my benchmarks. I have measured in some instance ~7% decrease in performance when using size from user input for jagged arrays, no difference for single arrays and very small difference (~1% or less) for multi-dimensional arrays. It is most prominent in the middle where jagged arrays take the lead.
    using System.Diagnostics;

const string Format = ""{0,7:0.000} "";
const int TotalPasses = 25000;
const int Size = 50;
Stopwatch timer = new();

var functionList = new List<Action> { Jagged, Single, SingleStandard, Multi };

Console.WriteLine(""{0,5}{1,20}{2,20}{3,20}{4,20}"", ""Run"", ""Ticks"", ""ms"", ""Ticks/Instance"", ""ms/Instance"");

foreach (var item in functionList)
{
    var warmup = Test(item);
    var run = Test(item);

    Console.WriteLine($""{item.Method.Name}:"");
    PrintResult(""warmup"", warmup);
    PrintResult(""run"", run);
    Console.WriteLine();
}

static void PrintResult(string name, long ticks)
{
    Console.WriteLine(""{0,10}{1,20}{2,20}{3,20}{4,20}"", name, ticks, string.Format(Format, (decimal)ticks / TimeSpan.TicksPerMillisecond), (decimal)ticks / TotalPasses, (decimal)ticks / TotalPasses / TimeSpan.TicksPerMillisecond);
}

long Test(Action func)
{
    timer.Restart();
    func();
    timer.Stop();
    return timer.ElapsedTicks;
}

static void Jagged()
{
    for (var passes = 0; passes < TotalPasses; passes++)
    {
        var jagged = new int[Size][][];
        for (var i = 0; i < Size; i++)
        {
            jagged[i] = new int[Size][];
            for (var j = 0; j < Size; j++)
            {
                jagged[i][j] = new int[Size];
                for (var k = 0; k < Size; k++)
                {
                    jagged[i][j][k] = i * j * k;
                }
            }
        }
    }
}

static void Multi()
{
    for (var passes = 0; passes < TotalPasses; passes++)
    {
        var multi = new int[Size, Size, Size];
        for (var i = 0; i < Size; i++)
        {
            for (var j = 0; j < Size; j++)
            {
                for (var k = 0; k < Size; k++)
                {
                    multi[i, j, k] = i * j * k;
                }
            }
        }
    }
}

static void Single()
{
    for (var passes = 0; passes < TotalPasses; passes++)
    {
        var single = new int[Size * Size * Size];
        for (var i = 0; i < Size; i++)
        {
            int iOffset = i * Size * Size;
            for (var j = 0; j < Size; j++)
            {
                var jOffset = iOffset + j * Size;
                for (var k = 0; k < Size; k++)
                {
                    single[jOffset + k] = i * j * k;
                }
            }
        }
    }
}

static void SingleStandard()
{
    for (var passes = 0; passes < TotalPasses; passes++)
    {
        var single = new int[Size * Size * Size];
        for (var i = 0; i < Size; i++)
        {
            for (var j = 0; j < Size; j++)
            {
                for (var k = 0; k < Size; k++)
                {
                    single[i * Size * Size + j * Size + k] = i * j * k;
                }
            }
        }
    }
}

Lesson learned: Always include CPU in benchmarks, because it makes a difference. Did it this time? I don't know but I suspect it might've.

Original answer:
I would like to update on this, because in .NET Core multi-dimensional arrays are faster than jagged arrays. I ran the tests from John Leidegren and these are the results on .NET Core 2.0 preview 2. I increased the dimension value to make any possible influences from background apps less visible.
Debug (code optimalization disabled)
Running jagged 
187.232 200.585 219.927 227.765 225.334 222.745 224.036 222.396 219.912 222.737 

Running multi-dimensional  
130.732 151.398 131.763 129.740 129.572 159.948 145.464 131.930 133.117 129.342 

Running single-dimensional  
 91.153 145.657 111.974  96.436 100.015  97.640  94.581 139.658 108.326  92.931 


Release (code optimalization enabled)
Running jagged 
108.503 95.409 128.187 121.877 119.295 118.201 102.321 116.393 125.499 116.459 

Running multi-dimensional 
 62.292  60.627  60.611  60.883  61.167  60.923  62.083  60.932  61.444  62.974 

Running single-dimensional 
 34.974  33.901  34.088  34.659  34.064  34.735  34.919  34.694  35.006  34.796 

I looked into disassemblies and this is what I found
jagged[i][j][k] = i * j * k; needed 34 instructions to execute
multi[i, j, k] = i * j * k; needed 11 instructions to execute
single[i * dim * dim + j * dim + k] = i * j * k; needed 23 instructions to execute
I wasn't able to identify why single-dimensional arrays were still faster than multi-dimensional but my guess is that it has to do with some optimalization made on the CPU
    Preface: This comment is intended to address the answer provided by okutane, but because of SO's silly reputation system, I can not post it where it belongs.

Your assertion that one is slower than the other because of the method calls isn't correct.  One is slower than the other because of more complicated bounds-checking algorithms.  You can easily verify this by looking, not at the IL, but at the compiled assembly.  For example, on my 4.5 install, accessing an element (via pointer in edx) stored in a two-dimensional array pointed to by ecx with indexes stored in eax and edx looks like so:

sub eax,[ecx+10]
cmp eax,[ecx+08]
jae oops //jump to throw out of bounds exception
sub edx,[ecx+14]
cmp edx,[ecx+0C]
jae oops //jump to throw out of bounds exception
imul eax,[ecx+0C]
add eax,edx
lea edx,[ecx+eax*4+18]


Here, you can see that there's no overhead from method calls.  The bounds checking is just very convoluted thanks to the possibility of non-zero indexes, which is a functionality not on offer with jagged arrays.  If we remove the sub,cmp,and jmps for the non-zero cases, the code pretty much resolves to (x*y_max+y)*sizeof(ptr)+sizeof(array_header).  This calculation is about as fast (one multiply could be replaced by a shift, since that's the whole reason we choose bytes to be sized as powers of two bits) as anything else for random access to an element.  

Another complication is that there are plenty of cases where a modern compiler will optimize away the nested bounds-checking for element access while iterating over a single-dimension array.  The result is code that basically just advances an index pointer over the contiguous memory of the array.  Naive iteration over multi-dimensional arrays generally involves an extra layer of nested logic, so a compiler is less likely to optimize the operation.  So, even though the bounds-checking overhead of accessing a single element amortizes out to constant runtime with respect to array dimensions and sizes, a simple test-case to measure the difference may take many times longer to execute.
    Array of arrays (jagged arrays) are faster than multi-dimensional arrays and can be used more effectively. Multidimensional arrays have nicer syntax.

If you write some simple code using jagged and multidimensional arrays and then inspect the compiled assembly with an IL disassembler you will see that the storage and retrieval from jagged (or single dimensional) arrays are simple IL instructions while the same operations for multidimensional arrays are method invocations which are always slower.

Consider the following methods:

static void SetElementAt(int[][] array, int i, int j, int value)
{
    array[i][j] = value;
}

static void SetElementAt(int[,] array, int i, int j, int value)
{
    array[i, j] = value;
}


Their IL will be the following:

.method private hidebysig static void  SetElementAt(int32[][] 'array',
                                                    int32 i,
                                                    int32 j,
                                                    int32 'value') cil managed
{
  // Code size       7 (0x7)
  .maxstack  8
  IL_0000:  ldarg.0
  IL_0001:  ldarg.1
  IL_0002:  ldelem.ref
  IL_0003:  ldarg.2
  IL_0004:  ldarg.3
  IL_0005:  stelem.i4
  IL_0006:  ret
} // end of method Program::SetElementAt

.method private hidebysig static void  SetElementAt(int32[0...,0...] 'array',
                                                    int32 i,
                                                    int32 j,
                                                    int32 'value') cil managed
{
  // Code size       10 (0xa)
  .maxstack  8
  IL_0000:  ldarg.0
  IL_0001:  ldarg.1
  IL_0002:  ldarg.2
  IL_0003:  ldarg.3
  IL_0004:  call       instance void int32[0...,0...]::Set(int32,
                                                           int32,
                                                           int32)
  IL_0009:  ret
} // end of method Program::SetElementAt


When using jagged arrays you can easily perform such operations as row swap and row resize. Maybe in some cases usage of multidimensional arrays will be more safe, but even Microsoft FxCop tells that jagged arrays should be used instead of multidimensional when you use it to analyse your projects.
    A multidimensional array creates a nice linear memory layout while a jagged array implies several extra levels of indirection.
Looking up the value jagged[3][6] in a jagged array var jagged = new int[10][5] works like this: Look up the element at index 3 (which is an array) and look up the element at index 6 in that array (which is a value). For each dimension in this case, there's an additional look up (this is an expensive memory access pattern).
A multidimensional array is laid out linearly in memory, the actual value is found by multiplying together the indexes. However, given the array var mult = new int[10,30], the Length property of that multidimensional array returns the total number of elements i.e. 10 * 30 = 300.
The Rank property of a jagged array is always 1, but a multidimensional array can have any rank. The GetLength method of any array can be used to get the length of each dimension. For the multidimensional array in this example mult.GetLength(1) returns 30.
Indexing the multidimensional array is faster. e.g. given the multidimensional array in this example mult[1,7] = 30 * 1 + 7 = 37, get the element at that index 37. This is a better memory access pattern because only one memory location is involved, which is the base address of the array.
A multidimensional array therefore allocates a continuous memory block, while a jagged array does not have to be square, e.g. jagged[1].Length does not have to equal jagged[2].Length, which would be true for any multidimensional array.
Performance
Performance wise, multidimensional arrays should be faster. A lot faster, but due to a really bad CLR implementation they are not.
 23.084  16.634  15.215  15.489  14.407  13.691  14.695  14.398  14.551  14.252 
 25.782  27.484  25.711  20.844  19.607  20.349  25.861  26.214  19.677  20.171 
  5.050   5.085   6.412   5.225   5.100   5.751   6.650   5.222   6.770   5.305 

The first row are timings of jagged arrays, the second shows multidimensional arrays and the third, well that's how it should be. The program is shown below, FYI this was tested running mono. (The windows timings are vastly different, mostly due to the CLR implementation variations).
On windows, the timings of the jagged arrays are greatly superior, about the same as my own interpretation of what multidimensional array look up should be like, see 'Single()'. Sadly the windows JIT-compiler is really stupid, and this unfortunately makes these performance discussions difficult, there are too many inconsistencies.
These are the timings I got on windows, same deal here, the first row are jagged arrays, second multidimensional and third my own implementation of multidimensional, note how much slower this is on windows compared to mono.
  8.438   2.004   8.439   4.362   4.936   4.533   4.751   4.776   4.635   5.864
  7.414  13.196  11.940  11.832  11.675  11.811  11.812  12.964  11.885  11.751
 11.355  10.788  10.527  10.541  10.745  10.723  10.651  10.930  10.639  10.595

Source code:
using System;
using System.Diagnostics;
static class ArrayPref
{
    const string Format = ""{0,7:0.000} "";
    static void Main()
    {
        Jagged();
        Multi();
        Single();
    }

    static void Jagged()
    {
        const int dim = 100;
        for(var passes = 0; passes < 10; passes++)
        {
            var timer = new Stopwatch();
            timer.Start();
            var jagged = new int[dim][][];
            for(var i = 0; i < dim; i++)
            {
                jagged[i] = new int[dim][];
                for(var j = 0; j < dim; j++)
                {
                    jagged[i][j] = new int[dim];
                    for(var k = 0; k < dim; k++)
                    {
                        jagged[i][j][k] = i * j * k;
                    }
                }
            }
            timer.Stop();
            Console.Write(Format,
                (double)timer.ElapsedTicks/TimeSpan.TicksPerMillisecond);
        }
        Console.WriteLine();
    }

    static void Multi()
    {
        const int dim = 100;
        for(var passes = 0; passes < 10; passes++)
        {
            var timer = new Stopwatch();
            timer.Start();
            var multi = new int[dim,dim,dim];
            for(var i = 0; i < dim; i++)
            {
                for(var j = 0; j < dim; j++)
                {
                    for(var k = 0; k < dim; k++)
                    {
                        multi[i,j,k] = i * j * k;
                    }
                }
            }
            timer.Stop();
            Console.Write(Format,
                (double)timer.ElapsedTicks/TimeSpan.TicksPerMillisecond);
        }
        Console.WriteLine();
    }

    static void Single()
    {
        const int dim = 100;
        for(var passes = 0; passes < 10; passes++)
        {
            var timer = new Stopwatch();
            timer.Start();
            var single = new int[dim*dim*dim];
            for(var i = 0; i < dim; i++)
            {
                for(var j = 0; j < dim; j++)
                {
                    for(var k = 0; k < dim; k++)
                    {
                        single[i*dim*dim+j*dim+k] = i * j * k;
                    }
                }
            }
            timer.Stop();
            Console.Write(Format,
                (double)timer.ElapsedTicks/TimeSpan.TicksPerMillisecond);
        }
        Console.WriteLine();
    }
}

    Jagged arrays are arrays of arrays or arrays in which each row contains an array of its own.
These arrays can have lengths different than those in the other rows.
Declaration and Allocation an Array of Arrays
The only difference in the declaration of the jagged arrays compared to the regular multidimensional array is that we do not have just one pair of brackets. With the jagged arrays, we have a pair of brackets per dimension. We allocate them this way:
int[][] exampleJaggedArray;
jaggedArray = new int[2][];
jaggedArray[0] = new int[5];
jaggedArray[1] = new int[3];

The Initializing an array of arrays
int[][] exampleJaggedArray = {
new int[] {5, 7, 2},
new int[] {10, 20, 40},
new int[] {3, 25}
};

Memory Allocation
Jagged arrays are an aggregation of references. A jagged array does not directly contain any arrays, but rather has elements pointing to them. The size is unknown and that is why CLR just keeps references to the internal arrays. After we allocate memory for one array-element of the jagged array, then the reference starts pointing to the newly created block in the dynamic memory.
The variable exampleJaggedArray is stored in the execution stack of the program and points to a block in the dynamic memory, which contains a sequence of three references to other three blocks in memory; each of them contains an array of integer numbers – the elements of the jagged array:
    I thought I'd chime in here from the future with some performance results from .NET 5, seen as that will be the platform which everyone uses from now on.
These are the same tests that John Leidegren used (in 2009).
My results (.NET 5.0.1):
  Debug:
  (Jagged)
  5.616   4.719   4.778   5.524   4.559   4.508   5.913   6.107   5.839   5.270
  
  (Multi)
  6.336   7.477   6.124   5.817   6.516   7.098   5.272   6.091  25.034   6.023
  
  (Single)
  4.688   3.494   4.425   6.176   4.472   4.347   4.976   4.754   3.591   4.403


  Release(code optimizations on):
  (Jagged)
  2.614   2.108   3.541   3.065   2.172   2.936   1.681   1.724   2.622   1.708

  (Multi)
  3.371   4.690   4.502   4.153   3.651   3.637   3.580   3.854   3.841   3.802

  (Single)
  1.934   2.102   2.246   2.061   1.941   1.900   2.172   2.103   1.911   1.911

Ran on a a 6 core 3.7GHz AMD Ryzen 1600 machine.
It looks as though the performance ratio is still roughly the same. I'd say unless you're really optimizing hard, just use multi-dimensional arrays as the syntax is slightly easier to use.
    Simply put multidimensional arrays are similar to a table in DBMS.
Array of Array (jagged array) lets you have each element hold another array of the same type of variable length.

So, if you are sure that the structure of data looks like a table (fixed rows/columns), you can use a multi-dimensional array. Jagged array are fixed elements & each element can hold an array of variable length

E.g. Psuedocode:

int[,] data = new int[2,2];
data[0,0] = 1;
data[0,1] = 2;
data[1,0] = 3;
data[1,1] = 4;


Think of the above as a 2x2 table:


1 | 2
3 | 4



int[][] jagged = new int[3][]; 
jagged[0] = new int[4] {  1,  2,  3,  4 }; 
jagged[1] = new int[2] { 11, 12 }; 
jagged[2] = new int[3] { 21, 22, 23 }; 


Think of the above as each row having variable number of columns:


 1 |  2 |  3 | 4
11 | 12
21 | 22 | 23


    Multi-dimension arrays are (n-1)-dimension matrices.

So int[,] square = new int[2,2] is square matrix 2x2, int[,,] cube = new int [3,3,3] is a cube - square matrix 3x3. Proportionality is not required.

Jagged arrays are just array of arrays - an array where each cell contains an array.

So MDA are proportional, JD may be not! Each cell can contains an array of arbitrary length!
    In addition to the other answers, note that a multidimensional array is allocated as one big chunky object on the heap.  This has some implications:


Some multidimensional arrays will get allocated on the Large Object Heap (LOH) where their equivalent jagged array counterparts would otherwise not have.
The GC will need to find a single contiguous free block of memory to allocate a multidimensional array, whereas a jagged array might be able to fill in gaps caused by heap fragmentation... this isn't usually an issue in .NET because of compaction, but the LOH doesn't get compacted by default (you have to ask for it, and you have to ask every time you want it).
You'll want to look into <gcAllowVeryLargeObjects> for multidimensional arrays way before the issue will ever come up if you only ever use jagged arrays.

    This might have been mentioned in the above answers but not explicitly: with jagged array you can use array[row] to refer a whole row of data, but this is not allowed for multi-d arrays. 
    I am parsing .il files generated by ildasm to build a database of assemnblies, classes, methods, and stored procedures for use doing a conversion. I came across the following, which broke my parsing.

.method private hidebysig instance uint32[0...,0...] 
        GenerateWorkingKey(uint8[] key,
                           bool forEncryption) cil managed


The book Expert .NET 2.0 IL Assembler, by Serge Lidin, Apress, published 2006, Chapter 8, Primitive Types and Signatures, pp. 149-150 explains. 

<type>[] is termed a Vector of <type>, 

<type>[<bounds> [<bounds>**] ] is termed an array of <type>

** means may be repeated, [ ] means optional.

Examples: Let <type> = int32.

1) int32[...,...] is a two-dimensional array of undefined lower bounds and sizes

2) int32[2...5] is a one-dimensional array of lower bound 2 and size 4.

3) int32[0...,0...] is a two-dimensional array of lower bounds 0 and undefined size.

Tom
    Using a test based on the one by John Leidegren, I benchmarked the result using .NET 4.7.2, which is the relevant version for my purposes and thought I could share. I originally started with this comment in the dotnet core GitHub repository.
It appears that the performance varies greatly as the array size changes, at least on my setup, 1 processor xeon with 4physical 8logical.
w = initialize an array, and put int i * j in it.
wr = do w, then in another loop set int x to [i,j]
As array size grows, multidimensional appears to outperform.




Size
rw
Method
Mean
Error
StdDev
Gen 0/1k Op
Gen 1/1k Op
Gen 2/1k Op
Allocated Memory/Op




1800*500
w
Jagged
2.445 ms
0.0959 ms
0.1405 ms
578.1250
281.2500
85.9375
3.46 MB


1800*500
w
Multi
3.079 ms
0.2419 ms
0.3621 ms
269.5313
269.5313
269.5313
3.43 MB


2000*4000
w
Jagged
50.29 ms
3.262 ms
4.882 ms
5937.5000
3375.0000
937.5000
30.62 MB


2000*4000
w
Multi
26.34 ms
1.797 ms
2.690 ms
218.7500
218.7500
218.7500
30.52 MB


2000*4000
wr
Jagged
55.30 ms
3.066 ms
4.589 ms
5937.5000
3375.0000
937.5000
30.62 MB


2000*4000
wr
Multi
32.23 ms
2.798 ms
4.187 ms
285.7143
285.7143
285.7143
30.52 MB


1000*2000
wr
Jagged
11.18 ms
0.5397 ms
0.8078 ms
1437.5000
578.1250
234.3750
7.69 MB


1000*2000
wr
Multi
6.622 ms
0.3238 ms
0.4847 ms
210.9375
210.9375
210.9375
7.63 MB




Update: last two tests with double[,] instead of int[,]. The difference appears significant considering the errors. With int, ratio of mean for jagged vs md is between 1.53x and 1.86x, with doubles it is 1.88x and 2.42x.




Size
rw
Method
Mean
Error
StdDev
Gen 0/1k Op
Gen 1/1k Op
Gen 2/1k Op
Allocated Memory/Op




1000*2000
wr
Jagged
26.83 ms
1.221 ms
1.790 ms
3062.5000
1531.2500
531.2500
15.31 MB


1000*2000
wr
Multi
12.61 ms
1.018 ms
1.524 ms
156.2500
156.2500
156.2500
15.26 MB



    ","[493, 68, 50, 352, 204, 1, 3, 76, 15, 4, 7, 2, 0]",153723,139,2009-02-28T07:55:41,2021-12-10 11:34:18Z,c 
What is the purpose of a self executing function in javascript?,"
                
In javascript, when would you want to use this:

(function(){
    //Bunch of code...
})();


over this:

//Bunch of code...

    It's all about variable scoping. Variables declared in the self executing function are, by default, only available to code within the self executing function. This allows code to be written without concern of how variables are named in other blocks of JavaScript code.

For example, as mentioned in a comment by Alexander:

(function() {
  var foo = 3;
  console.log(foo);
})();

console.log(foo);


This will first log 3 and then throw an error on the next console.log because foo is not defined.
    Simplistic. So very normal looking, its almost comforting:
var userName = ""Sean"";

console.log(name());

function name() {
  return userName;
}

However, what if I include a really handy javascript library to my page that translates advanced characters into their base level representations?
Wait... what?
I mean, if someone types in a character with some kind of accent on it, but I only want 'English' characters A-Z in my program? Well... the Spanish 'ñ' and French 'é' characters can be translated into base characters of 'n' and 'e'.
So someone nice person has written a comprehensive character converter out there that I can include in my site... I include it.
One problem: it has a function in it called 'name' same as my function.
This is what's called a collision. We've got two functions declared in the same scope with the same name. We want to avoid this.
So we need to scope our code somehow.
The only way to scope code in javascript is to wrap it in a function:
function main() {
  // We are now in our own sound-proofed room and the 
  // character-converter library's name() function can exist at the 
  // same time as ours. 

  var userName = ""Sean"";

  console.log(name());

  function name() {
    return userName;
  }
}

That might solve our problem. Everything is now enclosed and can only be accessed from within our opening and closing braces.
We have a function in a function... which is weird to look at, but totally legal.
Only one problem. Our code doesn't work.
Our userName variable is never echoed into the console!
We can solve this issue by adding a call to our function after our existing code block...
function main() {
  // We are now in our own sound-proofed room and the 
  // character-converter libarary's name() function can exist at the 
  // same time as ours. 

  var userName = ""Sean"";

  console.log(name());

  function name() {
    return userName;
  }
}

main();

Or before!
main();

function main() {
  // We are now in our own sound-proofed room and the 
  // character-converter libarary's name() function can exist at the 
  // same time as ours. 

  var userName = ""Sean"";

  console.log(name());

  function name() {
    return userName;
  }
}

A secondary concern: What are the chances that the name 'main' hasn't been used yet? ...so very, very slim.
We need MORE scoping. And some way to automatically execute our main() function.
Now we come to auto-execution functions (or self-executing, self-running, whatever).
((){})();

The syntax is awkward as sin. However, it works.
When you wrap a function definition in parentheses, and include a parameter list (another set or parentheses!) it acts as a function call.
So lets look at our code again, with some self-executing syntax:
(function main() {
  var userName = ""Sean"";
                
    console.log(name());
                
    function name() {
      return userName;
    }
  }
)();

So, in most tutorials you read, you will now be bombarded with the term 'anonymous self-executing' or something similar.
After many years of professional development, I strongly urge you to name every function you write for debugging purposes.
When something goes wrong (and it will), you will be checking the backtrace in your browser. It is always easier to narrow your code issues when the entries in the stack trace have names!
Hugely long-winded and I hope it helps!
    I've read all answers, something very important is missing here, I'll KISS. There are 2 main reasons, why I need Self-Executing Anonymous Functions, or better said ""Immediately-Invoked Function Expression (IIFE)"":


Better namespace management (Avoiding Namespace Pollution -> JS Module)
Closures (Simulating Private Class Members, as known from OOP)


The first one has been explained very well. For the second one, please study following example:

var MyClosureObject = (function (){
  var MyName = 'Michael Jackson RIP';
  return {
    getMyName: function () { return MyName;},
    setMyName: function (name) { MyName = name}
  }
}());


Attention 1: We are not assigning a function to MyClosureObject, further more the result of invoking that function. Be aware of () in the last line. 

Attention 2: What do you additionally have to know about functions in Javascript is that the inner functions get access to the parameters and variables of the functions, they are defined within.

Let us try some experiments:

I can get MyName using getMyName and it works:

 console.log(MyClosureObject.getMyName()); 
 // Michael Jackson RIP


The following ingenuous approach would not work:

console.log(MyClosureObject.MyName); 
// undefined


But I can set an another name and get the expected result:

MyClosureObject.setMyName('George Michael RIP');
console.log(MyClosureObject.getMyName()); 
// George Michael RIP


Edit: In the example above MyClosureObject is designed to be used without the newprefix, therefore by convention it should not be capitalized. 
    Namespacing. JavaScript's scopes are function-level.
    I can't believe none of the answers mention implied globals.

The (function(){})() construct does not protect against implied globals, which to me is the bigger concern, see http://yuiblog.com/blog/2006/06/01/global-domination/

Basically the function block makes sure all the dependent ""global vars"" you defined are confined to your program, it does not protect you against defining implicit globals. JSHint or the like can provide recommendations on how to defend against this behavior.

The more concise var App = {} syntax provides a similar level of protection, and may be wrapped in the function block when on 'public' pages. (see Ember.js or SproutCore for real world examples of libraries that use this construct)

As far as private properties go, they are kind of overrated unless you are creating a public framework or library, but if you need to implement them, Douglas Crockford has some good ideas.
    Short answer is :  to prevent pollution of the Global (or higher) scope.

IIFE (Immediately Invoked Function Expressions) is the best practice for writing scripts as plug-ins, add-ons, user scripts or whatever scripts are expected to work with other people's scripts. This ensures that any variable you define does not give undesired effects on other scripts.

This is the other way to write IIFE expression. I personally prefer this following method:

void function() {
  console.log('boo!');
  // expected output: ""boo!""
}();


https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/void

From the example above it is very clear that IIFE can also affect efficiency and performance, because the function that is expected to be run only once will be executed once and then dumped into the void for good. This means that function or method declaration does not remain in memory.
    Given your simple question: ""In javascript, when would you want to use this:...""

I like @ken_browning and @sean_holding's answers, but here's another use-case that I don't see mentioned:

let red_tree = new Node(10);

(async function () {
    for (let i = 0; i < 1000; i++) {
        await red_tree.insert(i);
    }
})();

console.log('----->red_tree.printInOrder():', red_tree.printInOrder());


where Node.insert is some asynchronous action.

I can't just call await without the async keyword at the declaration of my function, and i don't need a named function for later use, but need to await that insert call or i need some other richer features (who knows?).
    First you must visit MDN IIFE , Now some points about this 


this is Immediately Invoked Function Expression. So when your javascript file invoked from HTML this function called immediately.
This prevents accessing variables within the IIFE idiom as well as polluting the global scope.

    Scope isolation, maybe.  So that the variables inside the function declaration don't pollute the outer namespace.

Of course, on half the JS implementations out there, they will anyway.
    Self executing function are used to manage the scope of a Variable.
The scope of a variable is the region of your program in which it is defined.
A global variable has global scope; it is defined everywhere in your JavaScript code and can be accessed from anywhere within the script, even in your functions. On the other hand, variables declared within a function are defined only within the body of the function.
They are local variables, have local scope and can only be accessed within that function. Function parameters also count as local variables and are defined only within the body of the function.
As shown below, you can access the global variables variable inside your function and also note that within the body of a function, a local variable takes precedence over a global variable with the same name.
var globalvar = ""globalvar""; // this var can be accessed anywhere within the script

function scope() {
    alert(globalvar);
    var localvar = ""localvar""; //can only be accessed within the function scope
}

scope(); 

So basically a self executing function allows code to be written without concern of how variables are named in other blocks of javascript code.
    (function(){
    var foo = {
        name: 'bob'
    };
    console.log(foo.name); // bob
})();
console.log(foo.name); // Reference error


Actually, the above function will be treated as function expression without a name.

The main purpose of wrapping a function with close and open parenthesis is to avoid polluting the global space. 

The variables and functions inside the function expression became private (i.e) they will not be available outside of the function.
    Here's a solid example of how a self invoking anonymous function could be useful.

for( var i = 0; i < 10; i++ ) {
  setTimeout(function(){
    console.log(i)
  })
}


Output: 10, 10, 10, 10, 10...

for( var i = 0; i < 10; i++ ) {
  (function(num){
    setTimeout(function(){
      console.log(num)
    })
  })(i)
}


Output: 0, 1, 2, 3, 4...
    Is there a parameter and the ""Bunch of code"" returns a function?

var a = function(x) { return function() { document.write(x); } }(something);


Closure. The value of something gets used by the function assigned to a. something could have some varying value (for loop) and every time a has a new function.
    One difference is that the variables that you declare in the function are local, so they go away when you exit the function and they don't conflict with other variables in other or same code.
    Self invoked function in javascript:

A self-invoking expression is invoked (started) automatically, without being called. A self-invoking expression is invoked right after its created. This is basically used for avoiding naming conflict as well as for achieving encapsulation. The variables or declared objects are not accessible outside this function. For avoiding the problems of minimization(filename.min) always use self executed function.
    
  Self-invocation (also known as
  auto-invocation) is when a function
  executes immediately upon its
  definition. This is a core pattern and
  serves as the foundation for many
  other patterns of JavaScript
  development.


I am a great fan :) of it because:


It keeps code to a minimum
It enforces separation of behavior from presentation
It provides a closure which prevents naming conflicts


Enormously – (Why you should say its good?)


It’s about defining and executing a function all at once.
You could have that self-executing function return a value and pass the function as a param to another function.
It’s good for encapsulation.
It’s also good for block scoping.
Yeah, you can enclose all your .js files in a self-executing function and can prevent global namespace pollution. ;)


More here.
    IIRC it allows you to create private properties and methods.
    Since functions in Javascript are first-class object, by defining it that way, it effectively defines a ""class"" much like C++ or C#.

That function can define local variables, and have functions within it.  The internal functions (effectively instance methods) will have access to the local variables (effectively instance variables), but they will be isolated from the rest of the script.
    It looks like this question has been answered all ready, but I'll post my input anyway.

I know when I like to use self-executing functions.

var myObject = {
    childObject: new function(){
        // bunch of code
    },
    objVar1: <value>,
    objVar2: <value>
}


The function allows me to use some extra code to define the childObjects attributes and properties for cleaner code, such as setting commonly used variables or executing mathematic equations; Oh! or error checking. as opposed to being limited to nested object instantiation syntax of...

object: {
    childObject: {
        childObject: {<value>, <value>, <value>}
    }, 
    objVar1: <value>,
    objVar2: <value>
}


Coding in general has a lot of obscure ways of doing a lot of the same things, making you wonder, ""Why bother?"" But new situations keep popping up where you can no longer rely on basic/core principals alone.
    You can use this function to return values :
var Test = (function (){
        
        
        const alternative = function(){ return 'Error Get Function '},
        methods = {
            GetName: alternative,
            GetAge:alternative
            }
            
            

// If the condition is not met, the default text will be returned
// replace to  55 < 44
if( 55 > 44){



// Function one
methods.GetName = function (name) {
        
        return name;

};

// Function Two

methods.GetAge = function (age) {
        
        return age;

};





}










    return methods;
    
    
    }());
    
    
    
    
    
    
    
    // Call
   console.log( Test.GetName(""Yehia"") );

    console.log( Test.GetAge(66) );

    ","[493, 464, 118, 12, 21, 14, 2, 1, 2, 7, 2, 1, 5, 7, 3, 1, 32, -4, 1, 0, 0]",196154,166,2009-02-26T20:53:52,2021-10-19 17:24:10Z,javascript 
"What does a ""Cannot find symbol"" or ""Cannot resolve symbol"" error mean?","
                
Please explain the following about ""Cannot find symbol"", ""Cannot resolve symbol"" or ""Symbol not found"" errors (in Java):

What do they mean?
What things can cause them?
How does the programmer go about fixing them?

This question is designed to seed a comprehensive Q&A about these common compilation errors in Java.
    0. Is there any difference between the two errors?
Not really. ""Cannot find symbol"", ""Cannot resolve symbol"" and ""Symbol not found"" all mean the same thing.  Different Java compilers use different phraseology.
1. What does a ""Cannot find symbol"" error mean?
Firstly, it is a compilation error1.  It means that either there is a problem in your Java source code, or there is a problem in the way that you are compiling it.
Your Java source code consists of the following things:

Keywords: like class, while, and so on.
Literals: like true, false, 42, 'X' and ""Hi mum!"".
Operators and other non-alphanumeric tokens: like +, =, {, and so on.
Identifiers: like Reader, i, toString, processEquibalancedElephants, and so on.
Comments and whitespace.

A ""Cannot find symbol"" error is about the identifiers.  When your code is compiled, the compiler needs to work out what each and every identifier in your code means.
A ""Cannot find symbol"" error means that the compiler cannot do this.  Your code appears to be referring to something that the compiler doesn't understand.
2. What can cause a ""Cannot find symbol"" error?
As a first order, there is only one cause.  The compiler looked in all of the places where the identifier should be defined, and it couldn't find the definition.  This could be caused by a number of things.  The common ones are as follows:

For identifiers in general:

Perhaps you spelled the name incorrectly; i.e. StringBiulder instead of StringBuilder.  Java cannot and will not attempt to compensate for bad spelling or typing errors.
Perhaps you got the case wrong; i.e. stringBuilder instead of StringBuilder.  All Java identifiers are case sensitive.
Perhaps you used underscores inappropriately; i.e. mystring and my_string are different.  (If you stick to the Java style rules, you will be largely protected from this mistake ...)
Perhaps you are trying to use something that was declared ""somewhere else""; i.e. in a different context to where you have implicitly told the compiler to look.  (A different class?  A different scope?  A different package?  A different code-base?)


For identifiers that should refer to variables:

Perhaps you forgot to declare the variable.
Perhaps the variable declaration is out of scope at the point you tried to use it.  (See example below)


For identifiers that should be method or field names:

Perhaps you are trying to refer to an inherited method or field that wasn't declared in the parent / ancestor classes or interfaces.

Perhaps you are trying to refer to a method or field that does not exist (i.e. has not been declared) in the type you are using; e.g. ""rope"".push()2.

Perhaps you are trying to use a method as a field, or vice versa; e.g. ""rope"".length or someArray.length().

Perhaps you are mistakenly operating on an array rather than array element; e.g.
    String strings[] = ...
    if (strings.charAt(3)) { ... }
    // maybe that should be 'strings[0].charAt(3)'




For identifiers that should be class names:

Perhaps you forgot to import the class.

Perhaps you used ""star"" imports, but the class isn't defined in any of the packages that you imported.

Perhaps you forgot a new as in:
    String s = String();  // should be 'new String()'




For cases where type or instance doesn't appear to have the member (e.g. method or field) you were expecting it to have:

Perhaps you have declared a nested class or a generic parameter that shadows the type you were meaning to use.
Perhaps you are shadowing a static or instance variable.
Perhaps you imported the wrong type; e.g. due to IDE completion or auto-correction may have suggested java.awt.List rather than java.util.List.
Perhaps you are using (compiling against) the wrong version of an API.
Perhaps you forgot to cast your object to an appropriate subclass.
Perhaps you have declared your variable's type to be a supertype of the one with the member you are looking for.



The problem is often a combination of the above.  For example, maybe you ""star"" imported java.io.* and then tried to use the Files class ... which is in java.nio not java.io.  Or maybe you meant to write File ... which is a class in java.io.

Here is an example of how incorrect variable scoping can lead to a ""Cannot find symbol"" error:
List<String> strings = ...

for (int i = 0; i < strings.size(); i++) {
    if (strings.get(i).equalsIgnoreCase(""fnord"")) {
        break;
    }
}
if (i < strings.size()) {
    ...
}

This will give a ""Cannot find symbol"" error for i in the if statement.  Though we previously declared i, that declaration is only in scope for the for statement and its body.  The reference to i in the if statement cannot see that declaration of i.  It is out of scope.
(An appropriate correction here might be to move the if statement inside the loop, or to declare i before the start of the loop.)

Here is an example that causes puzzlement where a typo leads to a seemingly inexplicable ""Cannot find symbol"" error:
for (int i = 0; i < 100; i++); {
    System.out.println(""i is "" + i);
}

This will give you a compilation error in the println call saying that i cannot be found.  But (I hear you say) I did declare it!
The problem is the sneaky semicolon ( ; ) before the {.  The Java language syntax defines a semicolon in that context to be an empty statement.  The empty statement then becomes the body of the for loop.  So that code actually means this:
for (int i = 0; i < 100; i++); 

// The previous and following are separate statements!!

{
    System.out.println(""i is "" + i);
}

The { ... } block is NOT the body of the for loop, and therefore the previous declaration of i in the for statement is out of scope in the block.

Here is another example of ""Cannot find symbol"" error that is caused by a typo.
int tmp = ...
int res = tmp(a + b);

Despite the previous declaration, the tmp in the tmp(...) expression is erroneous.  The compiler will look for a method called tmp, and won't find one.  The previously declared tmp is in the namespace for variables, not the namespace for methods.
In the example I came across, the programmer had actually left out an operator.  What he meant to write was this:
int res = tmp * (a + b);


There is another reason why the compiler might not find a symbol if you are compiling from the command line.  You might simply have forgotten to compile or recompile some other class.  For example, if you have classes Foo and Bar where Foo uses Bar.  If you have never compiled Bar and you run javac Foo.java, you are liable to find that the compiler can't find the symbol Bar.  The simple answer is to compile Foo and Bar together; e.g. javac Foo.java Bar.java or javac *.java.  Or better still use a Java build tool; e.g. Ant, Maven, Gradle and so on.
There are some other more obscure causes too ... which I will deal with below.
3. How do I fix these errors ?
Generally speaking, you start out by figuring out what caused the compilation error.

Look at the line in the file indicated by the compilation error message.
Identify which symbol that the error message is talking about.
Figure out why the compiler is saying that it cannot find the symbol; see above!

Then you think about what your code is supposed to be saying.  Then finally you work out what correction you need to make to your source code to do what you want.
Note that not every ""correction"" is correct. Consider this:
for (int i = 1; i < 10; i++) {
    for (j = 1; j < 10; j++) {
        ...
    }
}

Suppose that the compiler says ""Cannot find symbol"" for j.  There are many ways I could ""fix"" that:

I could change the inner for to for (int j = 1; j < 10; j++) - probably correct.
I could add a declaration for j before the inner for loop, or the outer for loop - possibly correct.
I could change j to i in the inner for loop - probably wrong!
and so on.

The point is that you need to understand what your code is trying to do in order to find the right fix.
4.  Obscure causes
Here are a couple of cases where the ""Cannot find symbol"" is seemingly inexplicable ... until you look closer.

Incorrect dependencies: If you are using an IDE or a build tool that manages the build path and project dependencies, you may have made a mistake with the dependencies; e.g. left out a dependency, or selected the wrong version.  If you are using a build tool (Ant, Maven, Gradle, etc), check the project's build file.  If you are using an IDE, check the project's build path configuration.

Cannot find symbol 'var': You are probably trying to compile source code that uses local variable type inference (i.e. a var declaration) with an older compiler or older --source level.  The var was introduced in Java 10.  Check your JDK version and your build files, and (if this occurs in an IDE), the IDE settings.

You are not compiling / recompiling:  It sometimes happens that new Java programmers don't understand how the Java tool chain works, or haven't implemented a repeatable ""build process""; e.g. using an IDE, Ant, Maven, Gradle and so on.  In such a situation, the programmer can end up chasing his tail looking for an illusory error that is actually caused by not recompiling the code properly, and the like.
Another example of this is when you use (Java 9+) java SomeClass.java to compile and run a class.  If the class depends on another class that you haven't compiled (or recompiled), you are liable to get ""Cannot resolve symbol"" errors referring to the 2nd class.  The other source file(s) are not automatically compiled.  The java command's new ""compile and run"" mode is not designed for running programs with multiple source code files.

An earlier build problem:  It is possible that an earlier build failed in a way that gave a JAR file with missing classes.  Such a failure would typically be noticed if you were using a build tool.  However if you are getting JAR files from someone else, you are dependent on them building properly, and noticing errors.  If you suspect this, use tar -tvf to list the contents of the suspect JAR file.

IDE issues: People have reported cases where their IDE gets confused and the compiler in the IDE cannot find a class that exists ... or the reverse situation.

This could happen if the IDE has been configured with the wrong JDK version.

This could happen if the IDE's caches get out of sync with the file system.  There are IDE specific ways to fix that.

This could be an IDE bug.  For instance @Joel Costigliola described a scenario where Eclipse did not handle a Maven ""test"" tree correctly: see this answer.  (Apparently that particular bug was been fixed a long time ago.)



Android issues: When you are programming for Android, and you have ""Cannot find symbol"" errors related to R, be aware that the R symbols are defined by the context.xml file.  Check that your context.xml file is correct and in the correct place, and that the corresponding R class file has been generated / compiled.  Note that the Java symbols are case sensitive, so the corresponding XML ids are be case sensitive too.
Other symbol errors on Android are likely to be due to previously mention reasons; e.g. missing or incorrect dependencies, incorrect package names, method or fields that don't exist in a particular API version, spelling / typing errors, and so on.

Hiding system classes: I've seen cases where the compiler complains that substring is an unknown symbol in something like the following
String s = ...
String s1 = s.substring(1);

It turned out that the programmer had created their own version of String and that his version of the class didn't define a substring methods.  I've seen people do this with System, Scanner and other classes.
Lesson: Don't define your own classes with the same names as common library classes!
The problem can also be solved by using the fully qualified names.  For example, in the example above, the programmer could have written:
java.lang.String s = ...
java.lang.String s1 = s.substring(1);


Homoglyphs:  If you use UTF-8 encoding for your source files, it is possible to have identifiers that look the same, but are in fact different because they contain homoglyphs.   See this page for more information.
You can avoid this by restricting yourself to ASCII or Latin-1 as the source file encoding, and using Java \uxxxx escapes for other characters.



1 - If, perchance, you do see this in a runtime exception or error message, then either you have configured your IDE to run code with compilation errors, or your application is generating and compiling code .. at runtime.
2 - The three basic principles of Civil Engineering: water doesn't flow uphill, a plank is stronger on its side, and you can't push on a rope.
    SOLVED
Using IntelliJ
Select Build->Rebuild Project will solve it
    You'll also get this error if you forget a new:

String s = String();


versus

String s = new String();


because the call without the new keyword will try and look for a (local) method called String without arguments - and that method signature is likely not defined.
    One more example of 'Variable is out of scope'

As I've seen that kind of questions a few times already, maybe one more example to what's illegal even if it might feel okay.

Consider this code:

if(somethingIsTrue()) {
  String message = ""Everything is fine"";
} else {
  String message = ""We have an error"";
}
System.out.println(message);


That's invalid code. Because neither of the variables named message is visible outside of their respective scope - which would be the surrounding brackets {} in this case. 

You might say: ""But a variable named message is defined either way - so message is defined after the if"". 

But you'd be wrong. 

Java has no free() or delete operators, so it has to rely on tracking variable scope to find out when variables are no longer used (together with references to these variables of cause). 

It's especially bad if you thought you did something good. I've seen this kind of error after ""optimizing"" code like this:

if(somethingIsTrue()) {
  String message = ""Everything is fine"";
  System.out.println(message);
} else {
  String message = ""We have an error"";
  System.out.println(message);
}


""Oh, there's duplicated code, let's pull that common line out"" -> and there it it.

The  most common way to deal with this kind of scope-trouble would be to pre-assign the else-values to the variable names in the outside scope and then reassign in if:

String message = ""We have an error"";
if(somethingIsTrue()) {
  message = ""Everything is fine"";
} 
System.out.println(message);

    One way to get this error in Eclipse : 


Define a class A in src/test/java.
Define another class B in src/main/java that uses class A.


Result : Eclipse will compile the code, but maven will give ""Cannot find symbol"".

Underlying cause : Eclipse is using a combined build path for the main and test trees.  Unfortunately, it does not support using different build paths for different parts of an Eclipse project, which is what Maven requires.

Solution : 


Don't define your dependencies that way; i.e. don't make this mistake.
Regularly build your codebase using Maven so that you pick up this mistake early.  One way to do that is to use a CI server.

    ""Can not find "" means that , compiler who can't find appropriate variable, method ,class etc...if you got that error massage , first of all you want to find code line where get error massage..And then you will able to find which variable , method or class have not define before using it.After confirmation  initialize that variable ,method or class can be used for later require...Consider the following example.

I'll create a demo class and print a name...

class demo{ 
      public static void main(String a[]){
             System.out.print(name);
      }
}


Now look at the result..



That error says, ""variable name can not find""..Defining and initializing value for 'name' variable  can be abolished that error..Actually like this,

class demo{ 
      public static void main(String a[]){

             String name=""smith"";

             System.out.print(name);
      }
}


Now look at the new output...



Ok Successfully solved that error..At the same time , if you could get ""can not find method "" or ""can not find class"" something , At first,define a class or method and after use that.. 
    If eclipse Java build path is mapped to 7, 8 and in Project pom.xml Maven properties java.version is mentioned higher Java version(9,10,11, etc..,) than 7,8 you need to update in pom.xml file.

In Eclipse if Java is mapped to Java version 11 and in pom.xml it is mapped to Java version 8. Update Eclipse support to Java 11 by go through below steps in eclipse IDE
Help -> Install New Software -> 

Paste following link http://download.eclipse.org/eclipse/updates/4.9-P-builds at Work With

or

Add (Popup window will open) ->

Name: Java 11 support
Location: http://download.eclipse.org/eclipse/updates/4.9-P-builds

then update Java version in Maven properties of pom.xml file as below

<java.version>11</java.version>
<maven.compiler.source>${java.version}</maven.compiler.source>
<maven.compiler.target>${java.version}</maven.compiler.target>


Finally do right click on project Debug as -> Maven clean, Maven build steps
    If you're getting this error in the build somewhere else, while your IDE says everything is perfectly fine, then check that you are using the same Java versions in both places.

For example, Java 7 and Java 8 have different APIs, so calling a non-existent API in an older Java version would cause this error.
    There can be various scenarios as people have mentioned above. A couple of things which have helped me resolve this.


If you are using IntelliJ

File -> 'Invalidate Caches/Restart'


OR


The class being referenced was in another project and that dependency was not added to the Gradle build file of my project. So I added the dependency using

compile project(':anotherProject')


and it worked. HTH!
    I too was getting this error. (for which I googled and I was directed to this page)

Problem: I was calling a static method defined in the class of a project A from a class defined in another project B. 
I was getting the following error:

error: cannot find symbol


Solution: I resolved this by first building the project where the method is defined then the project where the method was being called from.
    you compiled your code using maven compile and then used maven test to run it worked fine. Now if you changed something in your code and then without compiling you are running it, you will get this error.

Solution: Again compile it and then run test. For me it worked this way.
    In my case - I had to perform below operations:


Move context.xml file from src/java/package to the resource directory (IntelliJ
IDE)
Clean target directory.

    For hints, look closer at the class name name that throws an error and the line number, example:
Compilation failure
[ERROR] \applications\xxxxx.java:[44,30] error: cannot find symbol

One other cause is unsupported method of for java version say jdk7 vs 8.
Check your %JAVA_HOME% 
    
I solved this error like this... The craziness of android. I had the package name as Adapter and the I refactor the name to adapter with an ""a"" instead of ""A"" and solved the error.
    I had the same problem on compiling my project, I checked my java compiler version, it used to be working on java 1.8 but accidentally set to java 17, I changed it back to version 1.8 and my issue resolved.
    We got the error in a Java project that is set up as a Gradle multi-project build. It turned out that one of the sub-projects was missing the Gradle Java Library plugin.
This prevented the sub-project's class files from being visible to other projects in the build.
After adding the Java library plugin to the sub-project's build.gradle in the following way, the error went away:
plugins {
    ...
    id 'java-library'
}

    Re: 4.4: An earlier build problem in Stephen C's excellent answer:
I encountered this scenario when developing an osgi application.
I had a java project A that was a dependency of B.
When building B, there was the error:
Compilation failure: org.company.projectA.bar.xyz does not exist

But in eclipse, there was no compile problem at all.
Investigation
When i looked in A.jar, there were classes for org.company.projectA.foo.abc but none for org.company.projectA.bar.xyz.
The reason for the missing classes, was that in the A/pom.xml, was an entry to export the relevant packages.
<plugin>
    <groupId>org.apache.felix</groupId>
    <artifactId>maven-bundle-plugin</artifactId>
    ...
    <configuration>
        <instructions>
            ....
            <Export-Package>org.company.projectA.foo.*</Export-Package>
        </instructions>
    </configuration>
</plugin>


Solution
Add the missing packages like so:
<Export-Package>org.company.projectA.foo.*,org.company.projectA.bar.*</Export-Package>

and rebuild everything.
Now the A.jar includes all the expected classes, and everything compiles.
    ","[493, 513, 12, 33, 17, 13, 6, 3, 4, 2, 2, 1, 1, 0, -2, -1, 0, 0]",1345490,147,2014-09-07T01:12:08,2022-03-15 08:56:38Z,java 
Can anonymous class implement interface?,"
                
Is it possible to have an anonymous type implement an interface?

I've got a piece of code that I would like to work, but don't know how to do this.

I've had a couple of answers that either say no, or create a class that implements the interface construct new instances of that. This isn't really ideal, but I'm wondering if there is a mechanism to create a thin dynamic class on top of an interface which would make this simple.

public interface DummyInterface
{
    string A { get; }
    string B { get; }
}

public class DummySource
{
    public string A { get; set; }
    public string C { get; set; }
    public string D { get; set; }
}

public class Test
{
    public void WillThisWork()
    {
        var source = new DummySource[0];
        var values = from value in source
                     select new
                     {
                         A = value.A,
                         B = value.C + ""_"" + value.D
                     };

        DoSomethingWithDummyInterface(values);

    }

    public void DoSomethingWithDummyInterface(IEnumerable<DummyInterface> values)
    {
        foreach (var value in values)
        {
            Console.WriteLine(""A = '{0}', B = '{1}'"", value.A, value.B);
        }
    }
}


I've found an article Dynamic interface wrapping that describes one approach. Is this the best way of doing this?
    No, anonymous types cannot implement an interface. From the C# programming guide:


  Anonymous types are class types that consist of one or more public read-only properties. No other kinds of class members such as methods or events are allowed. An anonymous type cannot be cast to any interface or type except for object.

    The best solution is just not to use anonymous classes.

public class Test
{
    class DummyInterfaceImplementor : IDummyInterface
    {
        public string A { get; set; }
        public string B { get; set; }
    }

    public void WillThisWork()
    {
        var source = new DummySource[0];
        var values = from value in source
                     select new DummyInterfaceImplementor()
                     {
                         A = value.A,
                         B = value.C + ""_"" + value.D
                     };

        DoSomethingWithDummyInterface(values.Cast<IDummyInterface>());

    }

    public void DoSomethingWithDummyInterface(IEnumerable<IDummyInterface> values)
    {
        foreach (var value in values)
        {
            Console.WriteLine(""A = '{0}', B = '{1}'"", value.A, value.B);
        }
    }
}


Note that you need to cast the result of the query to the type of the interface. There might be a better way to do it, but I couldn't find it.
    Casting anonymous types to interfaces has been something I've wanted for a while but unfortunately the current implementation forces you to have an implementation of that interface.

The best solution around it is having some type of dynamic proxy that creates the implementation for you. Using the excellent LinFu project you can replace

select new
{
  A = value.A,
  B = value.C + ""_"" + value.D
};


with

 select new DynamicObject(new
 {
   A = value.A,
   B = value.C + ""_"" + value.D
 }).CreateDuck<DummyInterface>();

    While the answers in the thread are all true enough, I cannot resist the urge to tell you that it in fact is possible to have an anonymous class implement an interface, even though it takes a bit of creative cheating to get there.
Back in 2008 I was writing a custom LINQ provider for my then employer, and at one point I needed to be able to tell ""my"" anonymous classes from other anonymous ones, which meant having them implement an interface that I could use to type check them. The way we solved it was by using aspects (we used PostSharp), to add the interface implementation directly in the IL. So, in fact, letting anonymous classes implement interfaces is doable, you just need to bend the rules slightly to get there.
    The answer to the question specifically asked is no. But have you been looking at mocking frameworks? I use MOQ but there's millions of them out there and they allow you to implement/stub (partially or fully) interfaces in-line. Eg.

public void ThisWillWork()
{
    var source = new DummySource[0];
    var mock = new Mock<DummyInterface>();

    mock.SetupProperty(m => m.A, source.Select(s => s.A));
    mock.SetupProperty(m => m.B, source.Select(s => s.C + ""_"" + s.D));

    DoSomethingWithDummyInterface(mock.Object);
}

    Anonymous types can implement interfaces via a dynamic proxy.

I wrote an extension method on GitHub and a blog post http://wblo.gs/feE to support this scenario. 

The method can be used like this:

class Program
{
    static void Main(string[] args)
    {
        var developer = new { Name = ""Jason Bowers"" };

        PrintDeveloperName(developer.DuckCast<IDeveloper>());

        Console.ReadKey();
    }

    private static void PrintDeveloperName(IDeveloper developer)
    {
        Console.WriteLine(developer.Name);
    }
}

public interface IDeveloper
{
    string Name { get; }
}

    Another option is to create a single, concrete implementing class that takes lambdas in the constructor.

public interface DummyInterface
{
    string A { get; }
    string B { get; }
}

// ""Generic"" implementing class
public class Dummy : DummyInterface
{
    private readonly Func<string> _getA;
    private readonly Func<string> _getB;

    public Dummy(Func<string> getA, Func<string> getB)
    {
        _getA = getA;
        _getB = getB;
    }

    public string A => _getA();

    public string B => _getB();
}

public class DummySource
{
    public string A { get; set; }
    public string C { get; set; }
    public string D { get; set; }
}

public class Test
{
    public void WillThisWork()
    {
        var source = new DummySource[0];
        var values = from value in source
                     select new Dummy // Syntax changes slightly
                     (
                         getA: () => value.A,
                         getB: () => value.C + ""_"" + value.D
                     );

        DoSomethingWithDummyInterface(values);

    }

    public void DoSomethingWithDummyInterface(IEnumerable<DummyInterface> values)
    {
        foreach (var value in values)
        {
            Console.WriteLine(""A = '{0}', B = '{1}'"", value.A, value.B);
        }
    }
}


If all you are ever going to do is convert DummySource to DummyInterface, then it would be simpler to just have one class that takes a DummySource in the constructor and implements the interface.

But, if you need to convert many types to DummyInterface, this is much less boiler plate.
    No; an anonymous type can't be made to do anything except have a few properties. You will need to create your own type. I didn't read the linked article in depth, but it looks like it uses Reflection.Emit to create new types on the fly; but if you limit discussion to things within C# itself you can't do what you want.
    Using Roslyn, you can dynamically create a class which inherits from an interface (or abstract class).
I use the following to create concrete classes from abstract classes.
In this example, AAnimal is an abstract class.
var personClass = typeof(AAnimal).CreateSubclass(""Person"");

Then you can instantiate some objects:
var person1 = Activator.CreateInstance(personClass);
var person2 = Activator.CreateInstance(personClass);

Without a doubt this won't work for every case, but it should be enough to get you started:
using Microsoft.CodeAnalysis;
using Microsoft.CodeAnalysis.CSharp;
using System;
using System.Collections.Generic;
using System.IO;
using System.Linq;
using System.Reflection;

namespace Publisher
{
    public static class Extensions
    {
        public static Type CreateSubclass(this Type baseType, string newClassName, string newNamespace = ""Magic"")
        {
            //todo: handle ref, out etc.
            var concreteMethods = baseType
                                    .GetMethods()
                                    .Where(method => method.IsAbstract)
                                    .Select(method =>
                                    {
                                        var parameters = method
                                                            .GetParameters()
                                                            .Select(param => $""{param.ParameterType.FullName} {param.Name}"")
                                                            .ToString("", "");

                                        var returnTypeStr = method.ReturnParameter.ParameterType.Name;
                                        if (returnTypeStr.Equals(""Void"")) returnTypeStr = ""void"";

                                        var methodString = @$""
                                        public override {returnTypeStr} {method.Name}({parameters})
                                        {{
                                            Console.WriteLine(""""{newNamespace}.{newClassName}.{method.Name}() was called"""");
                                        }}"";

                                        return methodString.Trim();
                                    })
                                    .ToList();

            var concreteMethodsString = concreteMethods
                                        .ToString(Environment.NewLine + Environment.NewLine);

            var classCode = @$""
            using System;

            namespace {newNamespace}
            {{
                public class {newClassName}: {baseType.FullName}
                {{
                    public {newClassName}()
                    {{
                    }}

                    {concreteMethodsString}
                }}
            }}
            "".Trim();

            classCode = FormatUsingRoslyn(classCode);


            /*
            var assemblies = new[]
            {
                MetadataReference.CreateFromFile(typeof(object).Assembly.Location),
                MetadataReference.CreateFromFile(baseType.Assembly.Location),
            };
            */

            var assemblies = AppDomain
                        .CurrentDomain
                        .GetAssemblies()
                        .Where(a => !string.IsNullOrEmpty(a.Location))
                        .Select(a => MetadataReference.CreateFromFile(a.Location))
                        .ToArray();

            var syntaxTree = CSharpSyntaxTree.ParseText(classCode);

            var compilation = CSharpCompilation
                                .Create(newNamespace)
                                .AddSyntaxTrees(syntaxTree)
                                .AddReferences(assemblies)
                                .WithOptions(new CSharpCompilationOptions(OutputKind.DynamicallyLinkedLibrary));

            using (var ms = new MemoryStream())
            {
                var result = compilation.Emit(ms);
                //compilation.Emit($""C:\\Temp\\{newNamespace}.dll"");

                if (result.Success)
                {
                    ms.Seek(0, SeekOrigin.Begin);
                    Assembly assembly = Assembly.Load(ms.ToArray());

                    var newTypeFullName = $""{newNamespace}.{newClassName}"";

                    var type = assembly.GetType(newTypeFullName);
                    return type;
                }
                else
                {
                    IEnumerable<Diagnostic> failures = result.Diagnostics.Where(diagnostic =>
                        diagnostic.IsWarningAsError ||
                        diagnostic.Severity == DiagnosticSeverity.Error);

                    foreach (Diagnostic diagnostic in failures)
                    {
                        Console.Error.WriteLine(""{0}: {1}"", diagnostic.Id, diagnostic.GetMessage());
                    }

                    return null;
                }
            }
        }

        public static string ToString(this IEnumerable<string> list, string separator)
        {
            string result = string.Join(separator, list);
            return result;
        }

        public static string FormatUsingRoslyn(string csCode)
        {
            var tree = CSharpSyntaxTree.ParseText(csCode);
            var root = tree.GetRoot().NormalizeWhitespace();
            var result = root.ToFullString();
            return result;
        }
    }
}

    ","[493, 378, 11, 48, 93, 9, 16, 2, 13, 0]",178526,47,2008-10-10T12:20:32,2021-02-24 19:24:12Z,c 
Error related to only_full_group_by when executing a query in MySql,"
                
I have upgraded my system and have installed MySql 5.7.9 with php for a web application I am working on. I have a query that is dynamically created, and when run in older versions of MySql it works fine.  Since upgrading to 5.7 I get this error:


  Expression #1 of SELECT list is not in GROUP BY clause and contains
  nonaggregated column 'support_desk.mod_users_groups.group_id' which is
  not functionally dependent on columns in GROUP BY clause; this is
  incompatible with sql_mode=only_full_group_by


Note the Manual page for Mysql 5.7 on the topic of Server SQL Modes.

This is the query that is giving me trouble:

SELECT mod_users_groups.group_id AS 'value', 
       group_name AS 'text' 
FROM mod_users_groups
LEFT JOIN mod_users_data ON mod_users_groups.group_id = mod_users_data.group_id 
WHERE  mod_users_groups.active = 1 
  AND mod_users_groups.department_id = 1 
  AND mod_users_groups.manage_work_orders = 1 
  AND group_name != 'root' 
  AND group_name != 'superuser' 
GROUP BY group_name 
HAVING COUNT(`user_id`) > 0 
ORDER BY group_name


I did some googling on the issue, but I don't understand only_full_group_by enough to figure out what I need to do to fix the query. Can I just turn off the only_full_group_by option, or is there something else I need to do?

Let me know if you need more information.
    Use ANY_VALUE() to refer to the nonaggregated column.

SELECT name,           address , MAX(age) FROM t GROUP BY name; -- fails
SELECT name, ANY_VALUE(address), MAX(age) FROM t GROUP BY name; -- works


From MySQL 5.7 docs:


  You can achieve the same effect without disabling ONLY_FULL_GROUP_BY
  by using ANY_VALUE() to refer to the nonaggregated column.
  
  ...
  
  This query might be invalid with ONLY_FULL_GROUP_BY enabled because the nonaggregated address column in the select list is not named in the GROUP BY clause:

SELECT name, address, MAX(age) FROM t GROUP BY name;

  
  ...
  
  If you know that, for a given data set, each name value in fact uniquely determines the address value, address is effectively functionally dependent on name. To tell MySQL to accept the query, you can use the ANY_VALUE() function:

SELECT name, ANY_VALUE(address), MAX(age) FROM t GROUP BY name;


    you can turn off the warning message as explained in the other answers or you can understand what's happening and fix it.

As of MySQL 5.7.5, the default SQL mode includes ONLY_FULL_GROUP_BY which means when you are grouping rows and then selecting something out of that groups, you need to explicitly say which row should that selection be made from.


Mysql needs to know which row in the group you're looking for, which gives you two options


You can also add the column you want to the group statement group by rect.color, rect.value which can be what you want in some cases otherwise would return duplicate results with the same color which you may not want
you could also use aggregate functions of mysql to indicate which row you are looking for inside the groups like AVG() MIN() MAX() complete list 
AND finally you can use ANY_VALUE() if you are sure that all the results inside the group are the same. doc

    Go to mysql or phpmyadmin and select database
then simply execute this query and it will work.
Its working fine for me.

SET GLOBAL sql_mode=(SELECT REPLACE(@@sql_mode,'ONLY_FULL_GROUP_BY',''));

    If you have this error with Symfony using doctrine query builder, and if this error is caused by an orderBy :

Pay attention to select the column you want to groupBy, and use addGroupBy instead of groupBy :

$query = $this->createQueryBuilder('smth')->addGroupBy('smth.mycolumn');


Works on Symfony3 -
    You can try to disable the only_full_group_by setting by executing the following:

mysql> set global sql_mode='STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION';
mysql> set session sql_mode='STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION';


MySQL 8 does not accept NO_AUTO_CREATE_USER so that needs to be removed.
    I would just add group_id to the GROUP BY. 

When SELECTing a column that is not part of the GROUP BY there could be multiple values for that column within the groups, but there will only be space for a single value in the results. So, the database usually needs to be told exactly how to make those multiple values into one value. Commonly, this is done with an aggregate function like COUNT(), SUM(), MAX() etc... I say usually because most other popular database systems insist on this. However, in MySQL prior to version 5.7 the default behaviour has been more forgiving because it will not complain and then arbitrarily choose any value! It also has an ANY_VALUE() function that could be used as another solution to this question if you really needed the same behaviour as before. This flexibility comes at a cost because it is non-deterministic, so I would not recommend it unless you have a very good reason for needing it. MySQL are now turning on the only_full_group_by setting by default for good reasons, so it's best to get used to it and make your queries comply with it.

So why my simple answer above? I've made a couple of assumptions:

1) the group_id is unique. Seems reasonable, it is an 'ID' after all.

2) the group_name is also unique. This may not be such a reasonable assumption. If this is not the case and you have some duplicate group_names and you then follow my advice to add group_id to the GROUP BY, you may find that you now get more results than before because the groups with the same name will now have separate rows in the results. To me, this would be better than having these duplicate groups hidden because the database has quietly selected a value arbitrarily!    

It's also good practice to qualify all the columns with their table name or alias when there's more than one table involved... 

SELECT 
  g.group_id AS 'value', 
  g.group_name AS 'text' 
FROM mod_users_groups g
LEFT JOIN mod_users_data d ON g.group_id = d.group_id 
WHERE g.active = 1 
  AND g.department_id = 1 
  AND g.manage_work_orders = 1 
  AND g.group_name != 'root' 
  AND g.group_name != 'superuser' 
GROUP BY 
  g.group_name, 
  g.group_id 
HAVING COUNT(d.user_id) > 0 
ORDER BY g.group_name

    If you don't want to make any changes in your current query then follow the below steps -


vagrant ssh into your box
Type: sudo vim /etc/mysql/my.cnf
Scroll to the bottom of file and type A to enter insert mode
Copy and paste  

[mysqld]
sql_mode = STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION

Type esc to exit input mode
Type :wq to save and close vim.
Type sudo service mysql restart to restart MySQL.

    I had to edit the below file on my Ubuntu 18.04:
/etc/mysql/mysql.conf.d/mysqld.cnf
with
sql_mode=STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION

and
sudo service mysql restart
    I am using Laravel 5.3, mysql 5.7.12, on laravel homestead (0.5.0, I believe)

Even after explicitly setting editing /etc/mysql/my.cnf to reflect:

[mysqld]
sql_mode = STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION


I was still receiving the error. 

I had to change config/database.php from true to false:

    'mysql' => [
        'strict' => false, //behave like 5.6
        //'strict' => true //behave like 5.7
    ], 


Further reading:

https://laracasts.com/discuss/channels/servers/set-set-sql-mode-on-homestead
https://mattstauffer.co/blog/strict-mode-and-other-mysql-customizations-in-laravel-5-2
    I will try to explain you what this error is about.
Starting from MySQL 5.7.5, option ONLY_FULL_GROUP_BY is enabled by default.
Thus, according to standart SQL92 and earlier:


  does not permit queries for which the select list, HAVING condition,
  or ORDER BY list refer to nonaggregated columns that are neither named
  in the GROUP BY clause nor are functionally dependent on (uniquely
  determined by) GROUP BY columns


(read more in docs)

So, for example:

SELECT * FROM `users` GROUP BY `name`;


You will get error message after executing query above.


  #1055 - Expression #1 of SELECT list is not in GROUP BY clause and contains nonaggregated column 'testsite.user.id' which is not
  functionally dependent on columns in GROUP BY clause; this is
  incompatible with sql_mode=only_full_group_by


Why?
Because MySQL dont exactly understand, what certain values from grouped records to retrieve, and this is the point.

I.E. lets say you have this records in your users table:


And you will execute invalid query showen above.
And you will get error shown above, because, there is 3 records with name John, and it is nice, but, all of them have different email field values.
So, MySQL simply don't understand which of them to return in resulting grouped record.

You can fix this issue, by simply changing your query like this:

SELECT `name` FROM `users` GROUP BY `name`


Also, you may want to add more fields to SELECT section, but you cant do that, if they are not aggregated, but there is crutch you could use (but highly not reccomended):

SELECT ANY_VALUE(`id`), ANY_VALUE(`email`), `name` FROM `users` GROUP BY `name`




Now, you may ask, why using ANY_VALUE is highly not recommended?
Because MySQL don't exactly know what value of grouped records to retrieve, and by using this function, you asking it to fetch any of them (in this case, email of first record with name = John was fetched).
Exactly I cant come up with any ideas on why you would want this behaviour to exist.
Please, if you dont understand me, read more about how grouping in MySQL works, it is very simple.

And by the end, here is one more simple, yet valid query.
If you want to query total users count according to available ages, you may want to write down this query

SELECT `age`, COUNT(`age`) FROM `users` GROUP BY `age`;


Which is fully valid, according to MySQL rules.
And so on.
It is important to understand what exactly the problem is and only then write down the solution.
    If you are using wamp 3.0.6 or any upper version other than the stable 2.5 you might face this issue, firstly the issue is with sql . you have to name the fields accordingly. but there is another way by which you can solve it. click on green icon of wamp. mysql->mysql settings-> sql_mode->none. or from console you can change the default values. 

mysql> set global sql_mode='STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION';
mysql> set session sql_mode='STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION';

    Addition of lines (mention below) in file : /etc/mysql/my.cnf

[mysqld]
sql_mode = STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION


Work fine for me. 
Server version: 5.7.18-0ubuntu0.16.04.1 - (Ubuntu)
    This is what helped me to understand the entire issue: 


https://stackoverflow.com/a/20074634/1066234
https://dev.mysql.com/doc/refman/5.7/en/group-by-handling.html


And in the following another example of a problematic query.

Problematic:

SELECT COUNT(*) as attempts, SUM(elapsed) as elapsedtotal, userid, timestamp, questionid, answerid, SUM(correct) as correct, elapsed, ipaddress FROM `gameplay`
                        WHERE timestamp >= DATE_SUB(NOW(), INTERVAL 1 DAY)
                        AND cookieid = #


Solved by adding this to the end:

  GROUP BY timestamp, userid, cookieid, questionid, answerid, elapsed, ipaddress


Note: See the error message in PHP, it tells you where the problem lies.

Example: 


  MySQL query error 1140: In aggregated query without GROUP BY, expression #4 of SELECT list contains nonaggregated column 'db.gameplay.timestamp'; this is incompatible with sql_mode=only_full_group_by - Query: SELECT COUNT(*) as attempts, SUM(elapsed) as elapsedtotal, userid, timestamp, questionid, answerid, SUM(correct) as correct, elapsed, ipaddress FROM gameplay
                              WHERE timestamp >= DATE_SUB(NOW(), INTERVAL 1 DAY)
                              AND userid = 1


In this case, expression #4 was missing in the GROUP BY.
    You can add a unique index to group_id; if you are sure that group_id is unique. 

It can solve your case without modifying the query.

A late answer, but it has not been mentioned yet in the answers. Maybe it should complete the already comprehensive answers available. At least it did solve my case when I had to split a table with too many fields.
    For mac:

1.Copy the default my-default.cnf to /etc/my.cnf

sudo cp $(brew --prefix mysql)/support-files/my-default.cnf /etc/my.cnf


2.Change sql_mode in my.cnf using your favorite editor and set it to this

sql_mode=STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION


3.Restart MySQL server.

mysql.server restart

    Apologies for not using your exact SQL

I used this query to overcome the Mysql warning.

SELECT count(*) AS cnt, `regions_id`
FROM regionables 
WHERE `regionable_id` = '115' OR `regionable_id` = '714'
GROUP BY `regions_id`
HAVING cnt > 1


note the key for me being

count(*) AS cnt

    For localhost / wampserver 3 we can set sql-mode = user_mode to remove this error:

click on wamp icon -> MySql -> MySql Setting -> sql-mode -> user_mode


then restart wamp or apache
    The consensus answer above is good but if you've got problems running queries within stored procedures after fixing your my.cnf file, then try loading your SPs again.
I suspect MySQL must have compiled the SPs with the default only_full_group_by set originally. Therefore, even when I changed my.cnf and restarted mysqld it had no effect on the SPs, and they kept failing with ""SELECT list is not in GROUP BY clause and contains nonaggregated column  ... which is not functionally dependent on columns in GROUP BY clause; this is incompatible with sql_mode=only_full_group_by"".
Reloading the SPs must have caused them to be recompiled now with only_full_group_by disabled. After that, they seem to work as expected.
    ","[492, 100, 359, 29, 3, 388, 395, 181, 3, 43, 58, 20, 19, 7, 4, 10, 1, 7, 0]",676808,162,2015-12-06T07:42:07,2020-08-11 14:42:05Z,sql 
"""Agreeing to the Xcode/iOS license requires admin privileges, please re-run as root via sudo."" when using GCC","
                
While attempting to compile my C program, running the following command: 

gcc pthread.c -o pthread


Returns:


  Agreeing to the Xcode/iOS license requires admin privileges, please re-run as root via sudo.


and my code does not compile.

Why is this happening and how can I fix this problem?
    Open up Xcode, and accept the new user agreement.  This was happening because a new version of Xcode was downloaded and the new agreement was not accepted.
    sudo xcodebuild -license


will take care of it with no trouble on the command line.  Note that you'll have to manually scroll through the license, and agree to its terms at the end, unless you add ""accept"" to the command line :

sudo xcodebuild -license accept

    I had the same issue, after accepting the license launching XCode or running sudo xcodebuild -license accept i had to restart my Mac – otherwise it did not worked.
    I'm facing the same issue.

The issue because of X-Code.


  Solution: 
  1. Open X-code and accept user agreement (T&C).
  or
  2. Restart your MAC, It will resolve automatically.

    I had the same issue when I tried to use git.

It is possible to install git without it. And I doubt that gcc on mac is truly dependent on XCode. And I don't want to use root to accept something unless I'm sure I need it.

I uninstalled XCode by navigating to the applications folder and dragging XCode to the trash.

Now my git commands work as usual.  I'll re-install XCode if/when I truly need it.
    You don't need to fiddle around with any command :) 

Once the XCode is updated, open the Xcode IDE program. Please accept terms and conditions. 

You are all set to go :))
    Agreeing to the Xcode/iOS license requires admin privileges, please re-run as root via sudo.

A new version of OSX or XCode was installed and Apple wants you to agree to their Terms and Conditions. So just launch Xcode and ""Agree"" to them.
    Got stuck as I was trying to a go get ... I think it was related to git.
Here is how was able to fix it ...


I entered the following in terminal:

sudo xcodebuild -license

This will open the agreement. Go all the way to end and type ""agree"". 


That takes care of go get issues.

It was quite interesting how unrelated things were.
    Opening XCode and accepting the license fixes the issue.
    Follow these steps:


Open Terminal. 
Enter this command: sudo xcodebuild --license.
Enter system password.
Agree to the license.

    If you have similar issues in Intellij do as others said above me :


Open Terminal. 
Enter this command: sudo xcodebuild --license.
Enter system password.
Go to the end of file: Press space(button) to do that.
Type 'Agree' to the license.


And you are done.!!
    ","[492, 810, 561, 5, 2, 3, 15, 7, 114, 27, 5, 0]",207419,61,2014-10-04T21:25:32,2019-12-26 06:25:55Z,
Terminating a script in PowerShell,"
                
I've been looking for a way to terminate a PowerShell (PS1) script when an unrecoverable error occurs within a function. For example:

function foo() {
    # Do stuff that causes an error
    $host.Exit()
}


Of course there's no such thing as $host.Exit(). There is $host.SetShouldExit(), but this actually closes the console window, which is not what I want. What I need is something equivalent to Python's sys.exit() that will simply stop execution of the current script without further adieu.

Edit: Yeah, it's just exit. Duh.
    I realize this is an old post but I find myself coming back to this thread a lot as it is one of the top search results when searching for this topic. However, I always leave more confused then when I came due to the conflicting information. Ultimately I always have to perform my own tests to figure it out. So this time I will post my findings.

TL;DR Most people will want to use Exit to terminate a running scripts. However, if your script is merely declaring functions to later be used in a shell, then you will want to use Return in the definitions of said functions.

Exit vs Return vs Break


Exit: This will ""exit"" the currently running context. If you call this command from a script it will exit the script. If you call this command from the shell it will exit the shell. 

If a function calls the Exit command it will exit what ever context it is running in. So if that function is only called from within a running script it will exit that script. However, if your script merely declares the function so that it can be used from the current shell and you run that function from the shell, it will exit the shell because the shell is the context in which the function contianing the Exit command is running.

Note: By default if you right click on a script to run it in PowerShell, once the script is done running, PowerShell will close automatically. This has nothing to do with the Exit command or anything else in your script. It is just a default PowerShell behavior for scripts being ran using this specific method of running a script. The same is true for batch files and the Command Line window.
Return: This will return to the previous call point. If you call this command from a script (outside any functions) it will return to the shell. If you call this command from the shell it will return to the shell (which is the previous call point for a single command ran from the shell). If you call this command from a function it will return to where ever the function was called from. 

Execution of any commands after the call point that it is returned to will continue from that point. If a script is called from the shell and it contains the Return command outside any functions then when it returns to the shell there are no more commands to run thus making a Return used in this way essentially the same as Exit.
Break: This will break out of loops and switch cases. If you call this command while not in a loop or switch case it will break out of the script. If you call Break inside a loop that is nested inside a loop it will only break out of the loop it was called in. 

There is also an interesting feature of Break where you can prefix a loop with a label and then you can break out of that labeled loop even if the Break command is called within several nested groups within that labeled loop.

While ($true) {
    # Code here will run

    :myLabel While ($true) {
        # Code here will run

        While ($true) {
            # Code here will run

            While ($true) {
                # Code here will run
                Break myLabel
                # Code here will not run
            }

            # Code here will not run
        }

        # Code here will not run
    }

    # Code here will run
}


    You should use the exit keyword.
    I thought up a neat little trick to do just that, when I wanted a function to exit a script without throwing an error, but not exit the console if the function was used from there. It involves the $PSScriptRoot automatic variable that is only defined when running a script.
if($PSScriptRoot){exit}

    I coincidentally found out that Break <UnknownLabel> (e.g. simply Break Script, where the label Script doesn't exists) appears to break out of the entire script (even from within a function) and keeps the host alive.
This way you could create a function that breaks the script from anywhere (e.g. a recursive loop) without knowing the current scope (and creating labels):

Function Quit($Text) {
    Write-Host ""Quiting because: "" $Text
    Break Script
} 

    Exit will exit PowerShell too. If you wish to ""break"" out of just the current function or script - use Break :)

If ($Breakout -eq $true)
{
     Write-Host ""Break Out!""
     Break
}
ElseIf ($Breakout -eq $false)
{
     Write-Host ""No Breakout for you!""
}
Else
{
    Write-Host ""Breakout wasn't defined...""
}

    Write-Error is for non-terminating errors and throw is for terminating errors

The Write-Error cmdlet declares a non-terminating error. By default,
errors are sent in the error stream to the host program to be
displayed, along with output.
Non-terminating errors write an error to the error stream, but
they do not stop command processing. If a non-terminating error is
declared on one item in a collection of input items, the command
continues to process the other items in the collection.
To declare a
terminating error, use the Throw keyword. For more information, see
about_Throw (http://go.microsoft.com/fwlink/?LinkID=145153).

    Throwing an exception will be good especially if you want to clarify the error reason:

throw ""Error Message""


This will generate a terminating error.
    May be it is better to use ""trap"". A PowerShell trap specifies a codeblock to run when a terminating or error occurs. Type

Get-Help about_trap


to learn more about the trap statement.
    Terminates this process and gives the underlying operating system the specified exit code.

https://msdn.microsoft.com/en-us/library/system.environment.exit%28v=vs.110%29.aspx

[Environment]::Exit(1)

This will allow you to exit with a specific exit code, that can be picked up from the caller.
    I used this for a reruning of a program. I don't know if it would help, but it is a simple if statement requiring only two different entry's. It worked in powershell for me.

$rerun = Read-Host ""Rerun report (y/n)?""

if($rerun -eq ""y"") { Show-MemoryReport }
if($rerun -eq ""n"") { Exit }


Don't know if this helps, but i believe this would be along the lines of terminating a program after you have run it. However in this case, every defined input requires a listed and categorized output. You could also have the exit call up a new prompt line and terminate the program that way.
    I think you are looking for Return instead of Break. Break is typically used for loops and only breaks from the innermost code block. Use Return to exit a function or script.
    ","[492, 710, 459, 3, 15, 89, 58, 27, 14, 36, 5, 26]",1168593,72,2010-01-07T17:42:14,2021-12-17 08:03:48Z,powershell 
Iterating through a range of dates in Python,"
                
I have the following code to do this, but how can I do it better? Right now I think it's better than nested loops, but it starts to get Perl-one-linerish when you have a generator in a list comprehension. 

day_count = (end_date - start_date).days + 1
for single_date in [d for d in (start_date + timedelta(n) for n in range(day_count)) if d <= end_date]:
    print strftime(""%Y-%m-%d"", single_date.timetuple())


Notes


I'm not actually using this to print. That's just for demo purposes. 
The start_date and end_date variables are datetime.date objects because I don't need the timestamps. (They're going to be used to generate a report).


Sample Output

For a start date of 2009-05-30 and an end date of 2009-06-09:

2009-05-30
2009-05-31
2009-06-01
2009-06-02
2009-06-03
2009-06-04
2009-06-05
2009-06-06
2009-06-07
2009-06-08
2009-06-09

    Why are there two nested iterations? For me it produces the same list of data with only one iteration:
for single_date in (start_date + timedelta(n) for n in range(day_count)):
    print ...

And no list gets stored, only one generator is iterated over. Also the ""if"" in the generator seems to be unnecessary.
After all, a linear sequence should only require one iterator, not two.
Update after discussion with John Machin:
Maybe the most elegant solution is using a generator function to completely hide/abstract the iteration over the range of dates:
from datetime import date, timedelta

def daterange(start_date, end_date):
    for n in range(int((end_date - start_date).days)):
        yield start_date + timedelta(n)

start_date = date(2013, 1, 1)
end_date = date(2015, 6, 2)
for single_date in daterange(start_date, end_date):
    print(single_date.strftime(""%Y-%m-%d""))

NB: For consistency with the built-in range() function this iteration stops before reaching the end_date. So for inclusive iteration use the next day, as you would with range().
    This might be more clear:
from datetime import date, timedelta

start_date = date(2019, 1, 1)
end_date = date(2020, 1, 1)
delta = timedelta(days=1)
while start_date <= end_date:
    print(start_date.strftime(""%Y-%m-%d""))
    start_date += delta

    Use the dateutil library:

from datetime import date
from dateutil.rrule import rrule, DAILY

a = date(2009, 5, 30)
b = date(2009, 6, 9)

for dt in rrule(DAILY, dtstart=a, until=b):
    print dt.strftime(""%Y-%m-%d"")


This python library has many more advanced features, some very useful, like relative deltas—and is implemented as a single file (module) that's easily included into a project.
    Pandas is great for time series in general, and has direct support for date ranges.

import pandas as pd
daterange = pd.date_range(start_date, end_date)


You can then loop over the daterange to print the date:

for single_date in daterange:
    print (single_date.strftime(""%Y-%m-%d""))


It also has lots of options to make life easier. For example if you only wanted weekdays, you would just swap in bdate_range. See http://pandas.pydata.org/pandas-docs/stable/timeseries.html#generating-ranges-of-timestamps

The power of Pandas is really its dataframes, which support vectorized operations (much like numpy) that make operations across large quantities of data very fast and easy.

EDIT:
You could also completely skip the for loop and just print it directly, which is easier and more efficient:

print(daterange)

    This is the most human-readable solution I can think of.

import datetime

def daterange(start, end, step=datetime.timedelta(1)):
    curr = start
    while curr < end:
        yield curr
        curr += step

    Numpy's arange function can be applied to dates:

import numpy as np
from datetime import datetime, timedelta
d0 = datetime(2009, 1,1)
d1 = datetime(2010, 1,1)
dt = timedelta(days = 1)
dates = np.arange(d0, d1, dt).astype(datetime)


The use of astype is to convert from numpy.datetime64 to an array of datetime.datetime objects.
    Why not try:

import datetime as dt

start_date = dt.datetime(2012, 12,1)
end_date = dt.datetime(2012, 12,5)

total_days = (end_date - start_date).days + 1 #inclusive 5 days

for day_number in range(total_days):
    current_date = (start_date + dt.timedelta(days = day_number)).date()
    print current_date

    For completeness, Pandas also has a period_range function for timestamps that are out of bounds:

import pandas as pd

pd.period_range(start='1/1/1626', end='1/08/1627', freq='D')

    import datetime

def daterange(start, stop, step=datetime.timedelta(days=1), inclusive=False):
  # inclusive=False to behave like range by default
  if step.days > 0:
    while start < stop:
      yield start
      start = start + step
      # not +=! don't modify object passed in if it's mutable
      # since this function is not restricted to
      # only types from datetime module
  elif step.days < 0:
    while start > stop:
      yield start
      start = start + step
  if inclusive and start == stop:
    yield start

# ...

for date in daterange(start_date, end_date, inclusive=True):
  print strftime(""%Y-%m-%d"", date.timetuple())


This function does more than you strictly require, by supporting negative step, etc. As long as you factor out your range logic, then you don't need the separate day_count and most importantly the code becomes easier to read as you call the function from multiple places.
    For those who are interested in Pythonic functional way:
from datetime import date, timedelta
from itertools import count, takewhile

for d in takewhile(lambda x: x<=date(2009,6,9), map(lambda x:date(2009,5,30)+timedelta(days=x), count())):
    print(d)

    You can use Arrow:
This is example from the docs, iterating over hours:
from arrow import Arrow

>>> start = datetime(2013, 5, 5, 12, 30)
>>> end = datetime(2013, 5, 5, 17, 15)
>>> for r in Arrow.range('hour', start, end):
...     print repr(r)
...
<Arrow [2013-05-05T12:30:00+00:00]>
<Arrow [2013-05-05T13:30:00+00:00]>
<Arrow [2013-05-05T14:30:00+00:00]>
<Arrow [2013-05-05T15:30:00+00:00]>
<Arrow [2013-05-05T16:30:00+00:00]>

To iterate over days, you can use like this:
>>> start = Arrow(2013, 5, 5)
>>> end = Arrow(2013, 5, 5)
>>> for r in Arrow.range('day', start, end):
...     print repr(r)

(Didn't check if you can pass datetime.date objects, but anyways Arrow objects are easier in general)
    Using pendulum.period:
import pendulum

start = pendulum.from_format('2020-05-01', 'YYYY-MM-DD', formatter='alternative')
end = pendulum.from_format('2020-05-02', 'YYYY-MM-DD', formatter='alternative')

period = pendulum.period(start, end)

for dt in period:
    print(dt.to_date_string())

    from datetime import date,timedelta
delta = timedelta(days=1)
start = date(2020,1,1)
end=date(2020,9,1)
loop_date = start
while loop_date<=end:
    print(loop_date)
    loop_date+=delta

    What about the following for doing a range incremented by days:

for d in map( lambda x: startDate+datetime.timedelta(days=x), xrange( (stopDate-startDate).days ) ):
  # Do stuff here



startDate and stopDate are datetime.date objects


For a generic version:

for d in map( lambda x: startTime+x*stepTime, xrange( (stopTime-startTime).total_seconds() / stepTime.total_seconds() ) ):
  # Do stuff here



startTime and stopTime are datetime.date or datetime.datetime object
(both should be the same type)
stepTime is a timedelta object


Note that .total_seconds() is only supported after python 2.7 If you are stuck with an earlier version you can write your own function:

def total_seconds( td ):
  return float(td.microseconds + (td.seconds + td.days * 24 * 3600) * 10**6) / 10**6

    import datetime

def daterange(start, stop, step_days=1):
    current = start
    step = datetime.timedelta(step_days)
    if step_days > 0:
        while current < stop:
            yield current
            current += step
    elif step_days < 0:
        while current > stop:
            yield current
            current += step
    else:
        raise ValueError(""daterange() step_days argument must not be zero"")

if __name__ == ""__main__"":
    from pprint import pprint as pp
    lo = datetime.date(2008, 12, 27)
    hi = datetime.date(2009, 1, 5)
    pp(list(daterange(lo, hi)))
    pp(list(daterange(hi, lo, -1)))
    pp(list(daterange(lo, hi, 7)))
    pp(list(daterange(hi, lo, -7))) 
    assert not list(daterange(lo, hi, -1))
    assert not list(daterange(hi, lo))
    assert not list(daterange(lo, hi, -7))
    assert not list(daterange(hi, lo, 7)) 

    Show the last n days from today:

import datetime
for i in range(0, 100):
    print((datetime.date.today() + datetime.timedelta(i)).isoformat())


Output: 

2016-06-29
2016-06-30
2016-07-01
2016-07-02
2016-07-03
2016-07-04

    You can generate a series of date between two dates using the pandas library simply and trustfully

import pandas as pd

print pd.date_range(start='1/1/2010', end='1/08/2018', freq='M')


You can change the frequency of generating dates by setting freq as  D, M, Q, Y
(daily, monthly, quarterly, yearly
)
    for i in range(16):
    print datetime.date.today() + datetime.timedelta(days=i)

    This function has some extra features:


can pass a string matching the DATE_FORMAT for start or end and it is converted to a date object
can pass a date object for start or end
error checking in case the end is older than the start

import datetime
from datetime import timedelta


DATE_FORMAT = '%Y/%m/%d'

def daterange(start, end):
      def convert(date):
            try:
                  date = datetime.datetime.strptime(date, DATE_FORMAT)
                  return date.date()
            except TypeError:
                  return date

      def get_date(n):
            return datetime.datetime.strftime(convert(start) + timedelta(days=n), DATE_FORMAT)

      days = (convert(end) - convert(start)).days
      if days <= 0:
            raise ValueError('The start date must be before the end date.')
      for n in range(0, days):
            yield get_date(n)


start = '2014/12/1'
end = '2014/12/31'
print list(daterange(start, end))

start_ = datetime.date.today()
end = '2015/12/1'
print list(daterange(start, end))


    Here's code for a general date range function, similar to Ber's answer, but more flexible:

def count_timedelta(delta, step, seconds_in_interval):
    """"""Helper function for iterate.  Finds the number of intervals in the timedelta.""""""
    return int(delta.total_seconds() / (seconds_in_interval * step))


def range_dt(start, end, step=1, interval='day'):
    """"""Iterate over datetimes or dates, similar to builtin range.""""""
    intervals = functools.partial(count_timedelta, (end - start), step)

    if interval == 'week':
        for i in range(intervals(3600 * 24 * 7)):
            yield start + datetime.timedelta(weeks=i) * step

    elif interval == 'day':
        for i in range(intervals(3600 * 24)):
            yield start + datetime.timedelta(days=i) * step

    elif interval == 'hour':
        for i in range(intervals(3600)):
            yield start + datetime.timedelta(hours=i) * step

    elif interval == 'minute':
        for i in range(intervals(60)):
            yield start + datetime.timedelta(minutes=i) * step

    elif interval == 'second':
        for i in range(intervals(1)):
            yield start + datetime.timedelta(seconds=i) * step

    elif interval == 'millisecond':
        for i in range(intervals(1 / 1000)):
            yield start + datetime.timedelta(milliseconds=i) * step

    elif interval == 'microsecond':
        for i in range(intervals(1e-6)):
            yield start + datetime.timedelta(microseconds=i) * step

    else:
        raise AttributeError(""Interval must be 'week', 'day', 'hour' 'second', \
            'microsecond' or 'millisecond'."")

    > pip install DateTimeRange

from datetimerange import DateTimeRange

def dateRange(start, end, step):
        rangeList = []
        time_range = DateTimeRange(start, end)
        for value in time_range.range(datetime.timedelta(days=step)):
            rangeList.append(value.strftime('%m/%d/%Y'))
        return rangeList

    dateRange(""2018-09-07"", ""2018-12-25"", 7)  

    Out[92]: 
    ['09/07/2018',
     '09/14/2018',
     '09/21/2018',
     '09/28/2018',
     '10/05/2018',
     '10/12/2018',
     '10/19/2018',
     '10/26/2018',
     '11/02/2018',
     '11/09/2018',
     '11/16/2018',
     '11/23/2018',
     '11/30/2018',
     '12/07/2018',
     '12/14/2018',
     '12/21/2018']

    I have a similar problem, but I need to iterate monthly instead of daily.

This is my solution

import calendar
from datetime import datetime, timedelta

def days_in_month(dt):
    return calendar.monthrange(dt.year, dt.month)[1]

def monthly_range(dt_start, dt_end):
    forward = dt_end >= dt_start
    finish = False
    dt = dt_start

    while not finish:
        yield dt.date()
        if forward:
            days = days_in_month(dt)
            dt = dt + timedelta(days=days)            
            finish = dt > dt_end
        else:
            _tmp_dt = dt.replace(day=1) - timedelta(days=1)
            dt = (_tmp_dt.replace(day=dt.day))
            finish = dt < dt_end


Example #1

date_start = datetime(2016, 6, 1)
date_end = datetime(2017, 1, 1)

for p in monthly_range(date_start, date_end):
    print(p)


Output

2016-06-01
2016-07-01
2016-08-01
2016-09-01
2016-10-01
2016-11-01
2016-12-01
2017-01-01


Example #2

date_start = datetime(2017, 1, 1)
date_end = datetime(2016, 6, 1)

for p in monthly_range(date_start, date_end):
    print(p)


Output

2017-01-01
2016-12-01
2016-11-01
2016-10-01
2016-09-01
2016-08-01
2016-07-01
2016-06-01

    Slightly different approach to reversible steps by storing range args in a tuple. 

def date_range(start, stop, step=1, inclusive=False):
    day_count = (stop - start).days
    if inclusive:
        day_count += 1

    if step > 0:
        range_args = (0, day_count, step)
    elif step < 0:
        range_args = (day_count - 1, -1, step)
    else:
        raise ValueError(""date_range(): step arg must be non-zero"")

    for i in range(*range_args):
        yield start + timedelta(days=i)

    import datetime
from dateutil.rrule import DAILY,rrule

date=datetime.datetime(2019,1,10)

date1=datetime.datetime(2019,2,2)

for i in rrule(DAILY , dtstart=date,until=date1):
     print(i.strftime('%Y%b%d'),sep='\n')


OUTPUT:

2019Jan10
2019Jan11
2019Jan12
2019Jan13
2019Jan14
2019Jan15
2019Jan16
2019Jan17
2019Jan18
2019Jan19
2019Jan20
2019Jan21
2019Jan22
2019Jan23
2019Jan24
2019Jan25
2019Jan26
2019Jan27
2019Jan28
2019Jan29
2019Jan30
2019Jan31
2019Feb01
2019Feb02

    ","[492, 711, 308, 188, 111, 15, 13, 12, 8, 17, 2, 1, 2, 1, 1, 6, 8, 3, 4, 1, 1, 2, 3, 0, 0]",432564,157,2009-06-29T20:16:02,2021-12-16 16:56:51Z,python 
How do I use hexadecimal color strings in Flutter?,"
                
How do I convert a hexadecimal color string like #b74093 to a Color in Flutter?
I want to use a HEX color code in Dart.
    In Flutter, the Color class only accepts integers as parameters, or there is the possibility to use the named constructors fromARGB and fromRGBO.
So we only need to convert the string #b74093 to an integer value. Also we need to respect that opacity always needs to be specified.
255 (full) opacity is represented by the hexadecimal value FF. This already leaves us with 0xFF. Now, we just need to append our color string like this:
const color = const Color(0xffb74093); // Second `const` is optional in assignments.

The letters can by choice be capitalized or not:
const color = const Color(0xFFB74093);


If you want to use percentage opacity values, you can replace the first FF with the values from this table (also works for the other color channels).
Extension class
Starting with Dart 2.6.0, you can create an extension for the Color class that lets you use hexadecimal color strings to create a Color object:
extension HexColor on Color {
  /// String is in the format ""aabbcc"" or ""ffaabbcc"" with an optional leading ""#"".
  static Color fromHex(String hexString) {
    final buffer = StringBuffer();
    if (hexString.length == 6 || hexString.length == 7) buffer.write('ff');
    buffer.write(hexString.replaceFirst('#', ''));
    return Color(int.parse(buffer.toString(), radix: 16));
  }

  /// Prefixes a hash sign if [leadingHashSign] is set to `true` (default is `true`).
  String toHex({bool leadingHashSign = true}) => '${leadingHashSign ? '#' : ''}'
      '${alpha.toRadixString(16).padLeft(2, '0')}'
      '${red.toRadixString(16).padLeft(2, '0')}'
      '${green.toRadixString(16).padLeft(2, '0')}'
      '${blue.toRadixString(16).padLeft(2, '0')}';
}

The fromHex method could also be declared in a mixin or class because the HexColor name needs to be explicitly specified in order to use it, but the extension is useful for the toHex method, which can be used implicitly. Here is an example:
void main() {
  final Color color = HexColor.fromHex('#aabbcc');

  print(color.toHex());
  print(const Color(0xffaabbcc).toHex());
}

Disadvantage of using hex strings
Many of the other answers here show how you can dynamically create a Color from a hex string, like I did above. However, doing this means that the color cannot be a const.
Ideally, you would assign your colors the way I explained in the first part of this answer, which is more efficient when instantiating colors a lot, which is usually the case for Flutter widgets.
    If you want to use the hexadecimal code of a color which is in the format #123456, then it is very easy to do. Create a variable of type Color and assign the following values to it.
Color myHexColor = Color(0xff123456)

// Here you notice I use the 0xff and that is the opacity or transparency
// of the color and you can also change these values.

Use myHexColor and you are ready to go.
If you want to change the opacity of color direct from the hexadecimal code, then change the ff value in 0xff to the respective value from the table below. (alternatively you can use
myHexColor.withOpacity(0.2)

it is easier way to do it. 0.2 is mean 20% opacity)
Hexadecimal opacity values
100% — FF

95% — F2

90% — E6

85% — D9

80% — CC

75% — BF

70% — B3

65% — A6

60% — 99

55% — 8C

50% — 80

45% — 73

40% — 66

35% — 59

30% — 4D

25% — 40

20% — 33

15% — 26

10% — 1A

5% — 0D

0% — 00

    The Color class expects an ARGB integer. Since you try to use it with an RGB value, represent it as int and prefix it with 0xff.
Color mainColor = Color(0xffb74093);


If you get annoyed by this and still wish to use strings, you can extend Color and add a string constructor
class HexColor extends Color {
  static int _getColorFromHex(String hexColor) {
    hexColor = hexColor.toUpperCase().replaceAll(""#"", """");
    if (hexColor.length == 6) {
      hexColor = ""FF"" + hexColor;
    }
    return int.parse(hexColor, radix: 16);
  }

  HexColor(final String hexColor) : super(_getColorFromHex(hexColor));
}

Usage
Color color1 = HexColor(""b74093"");
Color color2 = HexColor(""#b74093"");
Color color3 = HexColor(""#88b74093""); // If you wish to use ARGB format

    Easy way:
String color = yourHexColor.replaceAll('#', '0xff');

Usage:
Container(
    color: Color(int.parse(color)),
)

    How to use a hexadecimal color code #B74093 in Flutter
Simply remove the # sign from the hexadecimal color code and add 0xFF with the color code inside the Color class:
#b74093 will become Color(0xffb74093) in Flutter
#B74093 will become Color(0xFFB74093) in Flutter
Tthe ff or FF in Color(0xFFB74093) defines the opacity.
Hexadecimal colors example with all opacity types in Dartpad

    Simple extension based on @Serdar answer https://stackoverflow.com/a/57943307/4899849
extension HexString on String {
  int getHexValue() => int.parse(replaceAll('#', '0xff'));
}

Usage:
'#b74093'.getHexValue()

    There is another solution. If you store your color as a normal hexadecimal string and don't want to add opacity to it (leading ""FF""):

Convert your hexadecimal string to int
To convert a hexadecimal string to an integer, do one of the following:
 var myInt = int.parse(hexString, radix: 16);

or
 var myInt = int.parse(""0x$hexString"");

as a prefix of 0x (or -0x) will make int.parse default to a radix of 16.

Add opacity to your color via code
 Color color = new Color(myInt).withOpacity(1.0);



    To convert from a hexadecimal string to integer, do:
int hexToInt(String hex)
{
  int val = 0;
  int len = hex.length;
  for (int i = 0; i < len; i++) {
    int hexDigit = hex.codeUnitAt(i);
    if (hexDigit >= 48 && hexDigit <= 57) {
      val += (hexDigit - 48) * (1 << (4 * (len - 1 - i)));
    } else if (hexDigit >= 65 && hexDigit <= 70) {
      // A..F
      val += (hexDigit - 55) * (1 << (4 * (len - 1 - i)));
    } else if (hexDigit >= 97 && hexDigit <= 102) {
      // a..f
      val += (hexDigit - 87) * (1 << (4 * (len - 1 - i)));
    } else {
      throw new FormatException(""Invalid hexadecimal value"");
    }
  }
  return val;
}

Call example:
Color color = new Color(hexToInt(""FFB74093""));

    Thanks for asking this question, simples solution is as:
// Color to Hex String
colorToHexString(Color color) {
  return '#FF${color.value.toRadixString(16).substring(2, 8)}';
}

// Hex String to Color
hexStringToColor(String hexColor) {
  hexColor = hexColor.toUpperCase().replaceAll(""#"", """");
  if (hexColor.length == 6) {
    hexColor = ""FF"" + hexColor;
  }
  return Color(int.parse(hexColor, radix: 16));
}

// How to call function
String hexCode = colorToHexString(Colors.green);
Color bgColor = hexStringToColor(hexCode);
print(""$hexCode = $bgColor"");

Enjoy code and help others :)
    In Flutter, to create a color from RGB with alpha, use:
return new Container(
  color: new Color.fromRGBO(0, 0, 0, 0.5),
);

How to use hexadecimal color:
return new Container(
  color: new Color(0xFF4286f4),
);
// 0xFF -> the opacity (FF for opaque)
// 4286f4 -> the hexadecimal color

Hexadecimal color with opacity:
return new Container(
  color: new Color(0xFF4286f4).withOpacity(0.5),
);

// Or change the ""FF"" value
100% — FF
 95% — F2
 90% — E6
 85% — D9
 80% — CC
 75% — BF
 70% — B3
 65% — A6
 60% — 99
 55% — 8C
 50% — 80
 45% — 73
 40% — 66
 35% — 59
 30% — 4D
 25% — 40
 20% — 33
 15% — 26
 10% — 1A
 5% — 0D
 0% — 00

For more, see the official documentation page, Color class - dart:ui library - Dart API.
    I have created this Flutter extention function of String class.. kinda useful if you also hate 0xFFF 😎
extension on String {
  Color parse() {
    var hexColor = this.replaceAll(""#"", """");
    if (hexColor.length == 6) {
      hexColor = ""FF"" + hexColor;
    }
    if (hexColor.length == 8) {
      return Color(int.parse(""0x$hexColor""));
    }
  }
}

you can use to any hexadecimal color code string as follows...
'#bdbdbd'.parse() // this will return Color class object which you use in widget... 

    A simple function without using a class:

Color _colorFromHex(String hexColor) {
  final hexCode = hexColor.replaceAll('#', '');
  return Color(int.parse('FF$hexCode', radix: 16));
}


You can use it like this:

Color color1 = _colorFromHex(""b74093"");
Color color2 = _colorFromHex(""#b74093"");

    You can use this
Color getColorFromColorCode(String code){
  return Color(int.parse(code.substring(1, 7), radix: 16) + 0xFF000000);
}

    File utils.dart
///
/// Convert a color hex-string to a Color object.
///
Color getColorFromHex(String hexColor) {
  hexColor = hexColor.toUpperCase().replaceAll('#', '');

  if (hexColor.length == 6) {
    hexColor = 'FF' + hexColor;
  }

  return Color(int.parse(hexColor, radix: 16));
}

Example usage
Text(
  'Hello, World!',
  style: TextStyle(
    color: getColorFromHex('#aabbcc'),
    fontWeight: FontWeight.bold,
  )
)

    Add this function in your file -

Color parseColor(String color) {
  String hex = color.replaceAll(""#"", """");
  if (hex.isEmpty) hex = ""ffffff"";
  if (hex.length == 3) {
    hex = '${hex.substring(0, 1)}${hex.substring(0, 1)}${hex.substring(1, 2)}${hex.substring(1, 2)}${hex.substring(2, 3)}${hex.substring(2, 3)}';
  }
  Color col = Color(int.parse(hex, radix: 16)).withOpacity(1.0);
  return col;
}

And use it like -
Container(
    color: parseColor(""#b74093"")
)

    Use hexcolor for bringing hexadecimal colors to the Dart hexcolorPlugin:
hexcolor: ^2.0.3

Sample usage
import 'package:hexcolor/hexcolor.dart';
Container(
    decoration: new BoxDecoration(
        color: Hexcolor('#34cc89'),
    ),
    child: Center(
        child: Text(
            'Running on: $_platformVersion\n',
            style: TextStyle(color: Hexcolor(""#f2f2f2"")),
        ),
    ),
),

    This was the solution for me:
String hexString = ""45a3df"";
Color(int.parse(""0xff${hexString}""));

It was the only way that didn't require additional steps.
    ""#b74093""? OK...
To HEX Recipe
int getColorHexFromStr(String colorStr)
{
  colorStr = ""FF"" + colorStr;
  colorStr = colorStr.replaceAll(""#"", """");
  int val = 0;
  int len = colorStr.length;
  for (int i = 0; i < len; i++) {
    int hexDigit = colorStr.codeUnitAt(i);
    if (hexDigit >= 48 && hexDigit <= 57) {
      val += (hexDigit - 48) * (1 << (4 * (len - 1 - i)));
    } else if (hexDigit >= 65 && hexDigit <= 70) {
      // A..F
      val += (hexDigit - 55) * (1 << (4 * (len - 1 - i)));
    } else if (hexDigit >= 97 && hexDigit <= 102) {
      // a..f
      val += (hexDigit - 87) * (1 << (4 * (len - 1 - i)));
    } else {
      throw new FormatException(""An error occurred when converting a color"");
    }
  }
  return val;
}

    There isn't any need to use functions.
For example, to give a color to a container using colorcode:
Container
(
    color:Color(0xff000000)
)

Here the 0xff is the format followed by color code
    Unfortunately, the Color class constructor in Flutter does not accept a simple hexadecimal string (like #bfeb91 in CSS).
Instead, it requires an integer like 0xFFBFEB91.
So here we convert a hexadecimal string to an integer.
A simple function
Give this function a hexadecimal string and it will return you a Color!
Color _getColorFromHex(String hexColor) {
  hexColor = hexColor.replaceAll(""#"", """");
  if (hexColor.length == 6) {
    hexColor = ""FF"" + hexColor;
  }
  if (hexColor.length == 8) {
    return Color(int.parse(""0x$hexColor""));
  }
}

Use it like this
Text(
  'Hello, World!',
  style: TextStyle(backgroundColor: _getColorFromHex('ff00aa')), // Or 'bfeb91', or 'ffbfeb91'
),

As a String extension
Leveraging the power of Dart extensions, we can augment String with a function that returns a Color:
extension ColorExtension on String {
  toColor() {
    var hexColor = this.replaceAll(""#"", """");
    if (hexColor.length == 6) {
      hexColor = ""FF"" + hexColor;
    }
    if (hexColor.length == 8) {
      return Color(int.parse(""0x$hexColor""));
    }
  }
}

Use it like this:
Text(
  'Hello, World!',
  style: TextStyle(backgroundColor: '#bfeb91'.toColor()), // Or 'bfeb91', or 'ffbfeb91'
),

    The easiest way is to convert it into an integer. For example, #BCE6EB. You would add 0xFF and you would then remove the hashtag making it:
0XFFBCE6EB
Then let’s say you were to implement it by doing:
backgroundColor: Color(0xffbce6eb)
If you can only use a hexadecimal then I suggest using the Hexcolor package.
    You can use the package from_css_color to get Color out of a hexadecimal string. It supports both three-digit and six-digit RGB hexadecimal notation.
Color color = fromCSSColor('#ff00aa')

For optimisation sake, create a Color instance once for each color and store it somewhere for later usage.
    As the Color constructor does not support hexadecimal string, so we should find other alternatives.
There are several possibilities:
1- The first one is to create a small function that will allow you to convert a color hex-string to a Color object.
Code:
   Color colorFromHex(String hexColor) {
   final hexCode = hexColor.replaceAll('#', '');
   if (hexColor.length == 6) {
    hexColor = 'FF' + hexColor; // FF as the opacity value if you don't add it.
   }
  return Color(int.parse('FF$hexCode', radix: 16));
}

Usage:
 Container(
          color: colorFromHex('abcdff'),
          child: Text(
            'Never stop learning',
            style: TextStyle(color: colorFromHex('bbffffcc')),
          ),
        )

2- The second possibility is to use the supercharged package. Supercharged brings all the comfort features from languages like Kotlin to all Flutter developers.
Add the dependency supercharged: ^1.X.X (find recent version) to your project and start using Supercharged everywhere:
import 'package:supercharged/supercharged.dart';

Now ,transform any String to colors
Code :
""#ff00ff"".toColor(); // Painless hex to color
""red"".toColor(); // Supports all web color names

You can also use the hexcolor package which is also great.
    You can click on Color Widget and it tells you with much deeper information what those letters stand for.
You can also use the Color.fromARGB() method to create custom colors which is much easier to me. Use the Flutter Doctor Color Picker website to pick any color you want for your Flutter application.
    Use hexadecimal numbers with the fromRGB constructor:
Color.fromRGBO(0xb7, 0x40, 0x93, 1),

    For general reference. There is a simpler way using the library Supercharged. Although you can use extension methods with all solutions mentioned, you find practical user library toolkit.
""#ff00ff"".toColor(); // Painless hex to color
""red"".toColor(); // Supports all web color names

Easier, right?
Supercharged
    If you need a hexadecimal color desperately in your application, there is one simple step you can follow:

Convert your hexadecimal color into RGB format simply from here.

Get your RGB values.

In Flutter, you have an simple option to use RGB color:
 Color.fromRGBO(r_value, g_value, b_value, opacity) will do the job for you.

Go ahead and tweak O_value to get the color you want.


    // call this line for set color
color: HexColor(HexColor.Primarycolor)
i have create a class HexColor and defile all color in this class. this is 100% working code
class HexColor extends Color {
    static int _getColorFromHex(String hexColor) {
    hexColor = hexColor.toUpperCase().replaceAll(""#"", """");

      if (hexColor.length == 6) {
       hexColor = ""FF"" + hexColor;
       }

    return int.parse(hexColor, radix: 16);
   }

 static var Primarycolor=""FF3E3F"";

  static var Accentcolor=""b74093"";

  static var white=""b74093"";

static var black=""b74093"";

HexColor(final String hexColor) : super(_getColorFromHex(hexColor));
}

    I'm using this material_color_gen package it works like a charm
material_color_gen: ^2.0.0

Using :
import 'package:material_color_gen/material_color_gen.dart';
primarySwatch: Color(0xFFFF0000).toMaterialColor()

This is a HexColor example: #ff0000
Change # with 0xFF result is: 0xFFFF0000
Official link :
https://pub.dev/packages/material_color_gen
    import 'package:flutter/material.dart';
class HexToColor extends Color{
  static _hexToColor(String code) {
    return int.parse(code.substring(1, 7), radix: 16) + 0xFF000000;
  }
  HexToColor(final String code) : super(_hexToColor(code));
}

Import the new class and use it like this:
HexToColor('#F2A03D')

    ","[492, 757, 83, 248, 38, 43, 3, 22, 25, 21, 11, 3, 23, 11, 10, 7, 14, 17, 5, 10, 5, 7, 2, 5, 3, 5, 6, 1, 1, 1, 4]",416101,80,2018-04-28T21:25:28,2022-03-07 17:35:12Z,dart 
How do I match any character across multiple lines in a regular expression?,"
                
For example, this regex

(.*)<FooBar>


will match:

abcde<FooBar>


But how do I get it to match across multiple lines?

abcde
fghij<FooBar>

    Try this:  

((.|\n)*)<FooBar>


It basically says ""any character or a newline"" repeated zero or more times.
    The question is, can the . pattern match any character? The answer varies from engine to engine. The main difference is whether the pattern is used by a POSIX or non-POSIX regex library.
A special note about lua-patterns: they are not considered regular expressions, but . matches any character there, the same as POSIX-based engines.
Another note on matlab and octave: the . matches any character by default (demo): str = ""abcde\n        fghij<Foobar>""; expression = '(.*)<Foobar>*'; [tokens,matches] = regexp(str,expression,'tokens','match'); (tokens contain a abcde\n        fghij item).
Also, in all of boost's regex grammars the dot matches line breaks by default. Boost's ECMAScript grammar allows you to turn this off with regex_constants::no_mod_m (source).
As for oracle (it is POSIX based), use the n option (demo): select regexp_substr('abcde' || chr(10) ||'     fghij<Foobar>', '(.*)<Foobar>', 1, 1, 'n', 1) as results from dual
POSIX-based engines:
A mere . already matches line breaks, so there isn't a need to use any modifiers, see bash (demo).
The tcl (demo), postgresql (demo), r (TRE, base R default engine with no perl=TRUE, for base R with perl=TRUE or for stringr/stringi patterns, use the (?s) inline modifier) (demo) also treat . the same way.
However, most POSIX-based tools process input line by line. Hence, . does not match the line breaks just because they are not in scope. Here are some examples how to override this:

sed - There are multiple workarounds. The most precise, but not very safe, is sed 'H;1h;$!d;x; s/\(.*\)><Foobar>/\1/' (H;1h;$!d;x; slurps the file into memory). If whole lines must be included, sed '/start_pattern/,/end_pattern/d' file (removing from start will end with matched lines included) or sed '/start_pattern/,/end_pattern/{{//!d;};}' file (with matching lines excluded) can be considered.
perl - perl -0pe 's/(.*)<FooBar>/$1/gs' <<< ""$str"" (-0 slurps the whole file into memory, -p prints the file after applying the script given by -e). Note that using -000pe will slurp the file and activate 'paragraph mode' where Perl uses consecutive newlines (\n\n) as the record separator.
gnu-grep - grep -Poz '(?si)abc\K.*?(?=<Foobar>)' file. Here, z enables file slurping, (?s) enables the DOTALL mode for the . pattern, (?i) enables case insensitive mode, \K omits the text matched so far, *? is a lazy quantifier, (?=<Foobar>) matches the location before <Foobar>.
pcregrep - pcregrep -Mi ""(?si)abc\K.*?(?=<Foobar>)"" file (M enables file slurping here). Note pcregrep is a good solution for macOS grep users.

See demos.
Non-POSIX-based engines:

php - Use the s modifier PCRE_DOTALL modifier: preg_match('~(.*)<Foobar>~s', $s, $m) (demo)

c# - Use RegexOptions.Singleline flag (demo):  - var result = Regex.Match(s, @""(.*)<Foobar>"", RegexOptions.Singleline).Groups[1].Value;- var result = Regex.Match(s, @""(?s)(.*)<Foobar>"").Groups[1].Value;

powershell - Use the (?s) inline option: $s = ""abcde`nfghij<FooBar>""; $s -match ""(?s)(.*)<Foobar>""; $matches[1]

perl - Use the s modifier (or (?s) inline version at the start) (demo): /(.*)<FooBar>/s

python - Use the re.DOTALL (or re.S) flags or (?s) inline modifier (demo): m = re.search(r""(.*)<FooBar>"", s, flags=re.S) (and then if m:, print(m.group(1)))

java - Use Pattern.DOTALL modifier (or inline (?s) flag) (demo): Pattern.compile(""(.*)<FooBar>"", Pattern.DOTALL)

kotlin - Use RegexOption.DOT_MATCHES_ALL : ""(.*)<FooBar>"".toRegex(RegexOption.DOT_MATCHES_ALL)

groovy - Use (?s) in-pattern modifier (demo): regex = /(?s)(.*)<FooBar>/

scala - Use (?s) modifier (demo): ""(?s)(.*)<Foobar>"".r.findAllIn(""abcde\n    fghij<Foobar>"").matchData foreach { m => println(m.group(1)) }

javascript - Use [^] or workarounds [\d\D] / [\w\W] / [\s\S] (demo): s.match(/([\s\S]*)<FooBar>/)[1]

c++ (std::regex) Use [\s\S] or the JavaScript workarounds (demo): regex rex(R""(([\s\S]*)<FooBar>)"");

vba vbscript - Use the same approach as in JavaScript, ([\s\S]*)<Foobar>.  (NOTE: The MultiLine property of the RegExp object is sometimes erroneously thought to be the option to allow . match across line breaks, while, in fact, it only changes the ^ and $ behavior to match start/end of lines rather than strings, the same as in JavaScript regex)
behavior.)

ruby - Use the /m MULTILINE modifier (demo): s[/(.*)<Foobar>/m, 1]

rtrebase-r - Base R PCRE regexps - use (?s): regmatches(x, regexec(""(?s)(.*)<FooBar>"",x, perl=TRUE))[[1]][2] (demo)

ricustringrstringi - in stringr/stringi regex funtions that are powered with the ICU regex engine. Also use (?s): stringr::str_match(x, ""(?s)(.*)<FooBar>"")[,2] (demo)

go - Use the inline modifier (?s) at the start (demo): re: = regexp.MustCompile(`(?s)(.*)<FooBar>`)

swift - Use dotMatchesLineSeparators or (easier) pass the (?s) inline modifier to the pattern: let rx = ""(?s)(.*)<Foobar>""

objective-c - The same as Swift. (?s) works the easiest, but here is how the option can be used: NSRegularExpression* regex = [NSRegularExpression regularExpressionWithPattern:pattern options:NSRegularExpressionDotMatchesLineSeparators error:&regexError];

re2, google-apps-script - Use the (?s) modifier (demo): ""(?s)(.*)<Foobar>"" (in Google Spreadsheets, =REGEXEXTRACT(A2,""(?s)(.*)<Foobar>""))


NOTES ON (?s):
In most non-POSIX engines, the (?s) inline modifier (or embedded flag option) can be used to enforce . to match line breaks.
If placed at the start of the pattern, (?s) changes the bahavior of all . in the pattern. If the (?s) is placed somewhere after the beginning, only those .s will be affected that are located to the right of it unless this is a pattern passed to Python's re. In Python re, regardless of the (?s) location, the whole pattern . is affected. The (?s) effect is stopped using (?-s). A modified group can be used to only affect a specified range of a regex pattern (e.g., Delim1(?s:.*?)\nDelim2.* will make the first .*? match across newlines and the second .* will only match the rest of the line).
POSIX note:
In non-POSIX regex engines, to match any character, [\s\S] / [\d\D] / [\w\W] constructs can be used.
In POSIX, [\s\S] is not matching any character (as in JavaScript or any non-POSIX engine), because regex escape sequences are not supported inside bracket expressions. [\s\S] is parsed as bracket expressions that match a single character, \ or s or S.
    It depends on the language, but there should be a modifier that you can add to the regex pattern. In PHP it is:

/(.*)<FooBar>/s


The s at the end causes the dot to match all characters including newlines.
    We can also use
(.*?\n)*?

to match everything including newline without being greedy.
This will make the new line optional
(.*?|\n)*?

    In notepad++ you can use this
<table (.|\r\n)*</table>

It will match the entire table starting from

 rows and columns

You can make it greedy, using the following, that way it will match the first, second and so forth tables and not all at once
<table (.|\r\n)*?</table>

    ([\s\S]*)<FooBar>

The dot matches all except newlines (\r\n). So use \s\S, which will match ALL characters. 
    Use RegexOptions.Singleline. It changes the meaning of . to include newlines.
Regex.Replace(content, searchText, replaceText, RegexOptions.Singleline);

    In many regex dialects, /[\S\s]*<Foobar>/ will do just what you want. Source
    Generally, . doesn't match newlines, so try ((.|\n)*)<foobar>.
    If you're using Eclipse search, you can enable the ""DOTALL"" option to make '.' match any character including line delimiters: just add ""(?s)"" at the beginning of your search string. Example: 

(?s).*<FooBar>

    Option 1

One way would be to use the s flag (just like the accepted answer):

/(.*)<FooBar>/s


Demo 1

Option 2

A second way would be to use the m (multiline) flag and any of the following patterns:

/([\s\S]*)<FooBar>/m


or 

/([\d\D]*)<FooBar>/m


or 

/([\w\W]*)<FooBar>/m


Demo 2

RegEx Circuit

jex.im visualizes regular expressions: 


    Note that (.|\n)* can be less efficient than (for example) [\s\S]* (if your language's regexes support such escapes) and than finding how to specify the modifier that makes . also match newlines.  Or you can go with POSIXy alternatives like [[:space:][:^space:]]*.
    ""."" normally doesn't match line-breaks. Most regex engines allows you to add the S-flag (also called DOTALL and SINGLELINE) to make ""."" also match newlines.
If that fails, you could do something like [\S\s].
    Try: .*\n*.*<FooBar> assuming you are also allowing blank newlines. As you are allowing any character including nothing before <FooBar>.
    For Eclipse, the following expression worked:

Foo
jadajada Bar""

Regular expression:
Foo[\S\s]{1,10}.*Bar*

    In JavaScript you can use [^]* to search for zero to infinite characters, including line breaks.
$(""#find_and_replace"").click(function() {
  var text = $(""#textarea"").val();
  search_term = new RegExp(""[^]*<Foobar>"", ""gi"");;
  replace_term = ""Replacement term"";
  var new_text = text.replace(search_term, replace_term);
  $(""#textarea"").val(new_text);
});<script src=""https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js""></script>
<button id=""find_and_replace"">Find and replace</button>
<br>
<textarea ID=""textarea"">abcde
fghij&lt;Foobar&gt;</textarea>

    In a Java-based regular expression, you can use [\s\S].
    In Ruby you can use the 'm' option (multiline):
/YOUR_REGEXP/m

See the Regexp documentation on ruby-doc.org for more information.
    Often we have to modify a substring with a few keywords spread across lines preceding the substring. Consider an XML element:
<TASK>
  <UID>21</UID>
  <Name>Architectural design</Name>
  <PercentComplete>81</PercentComplete>
</TASK>

Suppose we want to modify the 81, to some other value, say 40.  First identify .UID.21..UID., then skip all characters including \n till .PercentCompleted.. The regular expression pattern and the replace specification are:
String hw = new String(""<TASK>\n  <UID>21</UID>\n  <Name>Architectural design</Name>\n  <PercentComplete>81</PercentComplete>\n</TASK>"");
String pattern = new String (""(<UID>21</UID>)((.|\n)*?)(<PercentComplete>)(\\d+)(</PercentComplete>)"");
String replaceSpec = new String (""$1$2$440$6"");
// Note that the group (<PercentComplete>) is $4 and the group ((.|\n)*?) is $2.

String iw = hw.replaceFirst(pattern, replaceSpec);
System.out.println(iw);

<TASK>
  <UID>21</UID>
  <Name>Architectural design</Name>
  <PercentComplete>40</PercentComplete>
</TASK>

The subgroup (.|\n) is probably the missing group $3. If we make it non-capturing by (?:.|\n) then the $3 is  (<PercentComplete>). So the pattern and replaceSpec can also  be:
pattern = new String(""(<UID>21</UID>)((?:.|\n)*?)(<PercentComplete>)(\\d+)(</PercentComplete>)"");
replaceSpec = new String(""$1$2$340$5"")

and the replacement works correctly as before.
    Use:
/(.*)<FooBar>/s

The s causes dot (.) to match carriage returns.
    Solution:
Use pattern modifier sU will get the desired matching in PHP.
Example:
preg_match('/(.*)/sU', $content, $match);

Sources:

Pattern Modifiers

    In the context of use within languages, regular expressions act on strings, not lines. So you should be able to use the regex normally, assuming that the input string has multiple lines.

In this case, the given regex will match the entire string, since ""<FooBar>"" is present. Depending on the specifics of the regex implementation, the $1 value (obtained from the ""(.*)"") will either be ""fghij"" or ""abcde\nfghij"". As others have said, some implementations allow you to control whether the ""."" will match the newline, giving you the choice.

Line-based regular expression use is usually for command line things like egrep.
    I had the same problem and solved it in probably not the best way but it works.  I replaced all line breaks before I did my real match:
mystring = Regex.Replace(mystring, ""\r\n"", """")

I am manipulating HTML so line breaks don't really matter to me in this case.
I tried all of the suggestions above with no luck. I am using .NET 3.5 FYI.
    I wanted to match a particular if block in Java:
   ...
   ...
   if(isTrue){
       doAction();

   }
...
...
}

If I use the regExp
if \(isTrue(.|\n)*}

it included the closing brace for the method block, so I used
if \(!isTrue([^}.]|\n)*}

to exclude the closing brace from the wildcard match.
    Typically searching for three consecutive lines in PowerShell, it would look like:
$file = Get-Content file.txt -raw

$pattern = 'lineone\r\nlinetwo\r\nlinethree\r\n'     # ""Windows"" text
$pattern = 'lineone\nlinetwo\nlinethree\n'           # ""Unix"" text
$pattern = 'lineone\r?\nlinetwo\r?\nlinethree\r?\n'  # Both

$file -match $pattern

# output
True

Bizarrely, this would be Unix text at the prompt, but Windows text in a file:
$pattern = 'lineone
linetwo
linethree
'

Here's a way to print out the line endings:
'lineone
linetwo
linethree
' -replace ""`r"",'\r' -replace ""`n"",'\n'

# Output
lineone\nlinetwo\nlinethree\n

    ","[492, 547, 150, 289, 17, 2, 40, 4, 42, 2, 72, -1, 5, 9, 1, 8, 1, 4, 18, 0, 5, 2, 1, 1, 0, 0]",806824,109,2008-10-01T18:48:22,2022-03-25 14:03:37Z,matlab bash r perl php c powershell perl python java kotlin 
Run MySQLDump without Locking Tables,"
                
I want to copy a live production database into my local development database.  Is there a way to do this without locking the production database?

I'm currently using:

mysqldump -u root --password=xxx -h xxx my_db1 | mysql -u root --password=xxx -h localhost my_db1


But it's locking each table as it runs.
    Does the --lock-tables=false option work?
According to the man page, if you are dumping InnoDB tables you can use the --single-transaction option:
--lock-tables, -l

Lock all tables before dumping them. The tables are locked with READ
LOCAL to allow concurrent inserts in the case of MyISAM tables. For
transactional tables such as InnoDB and BDB, --single-transaction is
a much better option, because it does not need to lock the tables at
all.

For innodb DB:
mysqldump --single-transaction=TRUE -u username -p DB

    --skip-add-locks helped for me
    This is about as late compared to the guy who said he was late as he was to the original answer, but in my case (MySQL via WAMP on Windows 7), I had to use:

--skip-lock-tables

    This is ages too late, but good for anyone that is searching the topic.  If you're not innoDB, and you're not worried about locking while you dump simply use the option:

--lock-tables=false

    If you use the Percona XtraDB Cluster -
I found that adding
--skip-add-locks
to the mysqldump command
Allows the Percona XtraDB Cluster to run the dump file
without an issue about LOCK TABLES commands in the dump file.
    For InnoDB tables use flag --single-transaction


  it dumps the consistent state of the database at the time when BEGIN
  was issued without blocking any applications


MySQL DOCS

http://dev.mysql.com/doc/refman/5.1/en/mysqldump.html#option_mysqldump_single-transaction
    The answer varies depending on what storage engine you're using.  The ideal scenario is if you're using InnoDB.  In that case you can use the --single-transaction flag, which will give you a coherent snapshot of the database at the time that the dump begins.
    To dump large tables, you should combine the --single-transaction option with --quick.

http://dev.mysql.com/doc/refman/5.1/en/mysqldump.html#option_mysqldump_single-transaction
        mysqldump -uuid -ppwd --skip-opt --single-transaction --max_allowed_packet=1G -q db |   mysql -u root --password=xxx -h localhost db

    When using MySQL Workbench, at Data Export, click in Advanced Options and uncheck the ""lock-tables"" options.

 
    Honestly, I would setup replication for this, as if you don't lock tables you will get inconsistent data out of the dump.

If the dump takes longer time, tables which were already dumped might have changed along with some table which is only about to be dumped.

So either lock the tables or use replication.
    Due to https://dev.mysql.com/doc/refman/5.7/en/mysqldump.html#option_mysqldump_lock-tables :


  Some options, such as --opt (which is enabled by default), automatically enable --lock-tables. If you want to override this, use --skip-lock-tables at the end of the option list.

    As none of these approaches worked for me, I simply did a:

mysqldump [...] | grep -v ""LOCK TABLE"" | mysql [...]


It will exclude both LOCK TABLE <x> and UNLOCK TABLES commands.

Note: Hopefully your data doesn't contain that string in it!
    Another late answer:

If you are trying to make a hot copy of server database (in a linux environment) and the database engine of all tables is MyISAM you should use mysqlhotcopy.

Acordingly to documentation:


  It uses FLUSH TABLES, LOCK TABLES, and cp or scp to make a database
  backup. It is a fast way to make a backup of the database or single
  tables, but it can be run only on the same machine where the database
  directories are located.  mysqlhotcopy works only for backing up
  MyISAM and ARCHIVE tables.


The LOCK TABLES time depends of the time the server can copy MySQL files (it doesn't make a dump).
    ","[492, 701, 45, 13, 305, 1, 13, 47, 18, 6, 3, 10, 1, -2, 0]",427114,118,2008-09-19T19:07:09,2021-04-07 07:53:09Z,
How to disable JavaScript in Chrome Developer Tools?,"
                
I am trying to debug the features of a website when users disable their JavaScript. I was wondering how do you disable JavaScript for a page from the Google Chrome DevTools?
    Click the gear icon in the corner of the Developer Tools, click Settings, then under Debugger, check Disable Javascript, as shown in the following video:

    Official documentation: Disable JavaScript With Chrome DevTools

There's now a command menu built into DevTools that makes it easier to disable JavaScript. This has been around as of April 2016 or so.


Open DevTools.
Press Command+Shift+P (Mac) or Control+Shift+P (Windows, Linux) to open the Command Menu. Make sure that your cursor's focus is on the DevTools window, not your browser viewport.
Type Disable JavaScript (or some version of that... it's a fuzzy search) and then press Enter.


Use the Enable JavaScript command when you want to turn it back on.


    Update August 2020

Developer Tools (F12)
Click the Gear icon



Should open the Preference tab
Disable Javascript option is on the far right


Original answer

Developer Tools (F12)
Three vertical dots in upper right
Settings
Under the ""Preferences"" tab on the left



There will be a ""Debugger"" section with the option (probably on far right)


    Using only the keyboard at least for Windows 10: 


F12, shows Developer Tools
F1, shows Settings
tab, moves to the ""Disable Javascript"" check box
space, toggles the option
esc, hides Settings

    Full and fast instructions for Chrome browsers (Opera incl.)

The first way


If Developer Tools aren't open then press F12 key on keyboard to show the Developer Tools. In Opera browser you have to use key combination Ctrl + Shift + i on keyboard to open it.
To show the settings just press F1 key on keyboard. The Developer Tools window must be focused when you are doing it. Or if you want to open the settings with the mouse then you have to click on ⋮ button in the top right corner of the Developer Tools, then click Settings in the menu.


Then you have to scroll down the settings window to bottom and then you will see the checkbox for disabling JavaScript like follows:



Just click on this checkbox and push esc key on keyboard for hide the settings. If you want to enable it then you have to do the same way again.

The second way


If Developer Tools aren't open then open it like in the first way is described.
Press the key combination Ctrl + Shift + P (for Windows or Linux) or Cmd (⌘) + Shift + P (for Mac) to open the Command Menu. Be sure that the focus is on the DevTools window.
Type there ""Disable JavaScript"" and then press Enter or click it with the mouse. If you want to turn back the enanled JS then open the Command Menu again and type there ""Enable JavaScript"" and then press Enter or click it with the mouse. You could also write just only ""JavaScript"" or ""Java"" there and then choose it with the mouse.




If all this does not work

For some reason it is possible that it does not work. I this case open a new empty site in ""Incognito Mode"" and do all this there.

The quickest way

In Chrome Web Store or on Opera Addon site you can find and install extensions which do it per one click. Just search ""Javascript Switcher"":


For Chrome browser
For Opera browser

    This extension makes it faster (I am the author) : Quick Javascript Switcher
It is open source: https://github.com/maximelebreton/quick-javascript-switcher
    chrome://settings/content Javascript/Manage Exceptions
    The quickest way is problably this one:


F12 to open the dev console
ctrl + shift + p to open the command tool (windows)
Type 'disable javascript' and hit enter

    Press F8 for temporarily freezing / unfreezing JS (with DevTools open). 

This is very useful for debugging UI issues on elements that may lose focus if you click or press anything outside of that element. (Chrome 71.0.3578.98, Ubuntu 18.10)
    The fast way:

1) just click on CTRL + SHIFT + P

2) fill the field by the 3 letters dis and will appear this box and select the item Disable Javascript


.

that's all folks!
    On OSX, I had to click the triple vertical dots, and uncheck a box in the settings section. Which can also be opened with f1
    
Click the ⋮ menu in the corner of the Developer Tools, click Settings
Click on Advanced at the bottom
Click on Content Settings
Click on JavaScript
Switch off

    On Mac OS X:


Preferences
Show advanced settings
Press the ""content settings"" button
Scroll to the ""JavaScript"" section
Check the checkbox in front of ""Do not allow any site to run JavaScript""


The Chrome Quick JavaScript Switcher extension is a lot easier though :-)
    
Go to options (Windows: three vertical dots in the top right) -> Settings, or hit F1. 
In the General section you find ""disable JavaScript""


The gear icon is no longer part of developer tools. Since Chome 30.0 it is not even possible to bring it back (In Google Chrome Developer Tools, the toolbar icons disappeared. What gives?)
    Paste it: chrome://settings/content

Go to ""Javascript"" section and disable it.
    Chrome://chrome/settings/Privacy/Content settings/JavaScript


and there you can PASTE your website's URL in Manage exceptions.. and change  the JavaScript priority from ALLOW to BLOCK.
    To temporarily block JavaScript on a domain :


Click on the Button left to the address on the address bar (which says View site information)
In the drop-down next to JavaScript, select Always block on this site
Reload Page

    You can also run Chrome with JavaScript disabled by default by using the flag:

-disable-javascript


You would use this for example by running Chrome like this:

C:\Documents and Settings\%username%\Local Settings\Application Data\Google\Chrome"" -disable-javascript

    This is the latest setting for the windows 

Settings > Advanced > Privacy and security > Site Settings > Javascript > Blocked then get switch on and off

    good question, i try so many way, but it is curry and boring, until i find shortcut.


alt + cmd + i, this open dev tools, unless you use pocket, that need set other shortcut.
shift + cmd + p, then input: javascript


only two shortcut, but i think safari is more convenient for that.
    There's a settings in chrome
open the menu from chrome,
click settings > type in ""javascript"" in the search bar > click site settings > click javascript.
from here you can toggle javascript specifically to a site using their url.
or just click the big button to allow/block it to all sites.

    ","[492, 638, 102, 213, 5, 3, 21, 38, 9, 2, 3, 7, 3, 3, 3, 1, 0, 3, 12, 0, 0, 0]",435057,49,2012-11-15T20:11:55,2021-09-18 16:13:27Z,javascript 
Should I use px or rem value units in my CSS? [closed],"
                    
            
        
            
                
                    
                        Closed. This question is opinion-based. It is not currently accepting answers.
                        
                    
                
            
        
            
        
                
                    
                
            
                
                    Want to improve this question? Update the question so it can be answered with facts and citations by editing this post.
                
                    Closed 2 years ago.
            The community reviewed whether to reopen this question 6 months ago and left it closed:
            
                    Original close reason(s) were not resolved
            

            
        
            
                    
                        Improve this question
                    
            

    

I am designing a new website and I want it to be compatible with as much browsers and browser settings as possible. I am trying to decide what unit of measurement I should use for the sizes of my fonts and elements, but am unable to find a conclusive answer.
My question is: should I use px or rem in my CSS?

So far I know that using px isn't compatible with users who adjust their base font size in their browser.
I've disregarded ems because they are more of a hassle to maintain, compared to rems, as they cascade.
Some say that rems are resolution independent and therefore more desirable. But others say that most modern browsers zoom all elements equally anyway, so using px is not a problem.

I'm asking this because there are a lot of different opinions as to what is the most desirable measure of distance in CSS, and I am not sure which is best.
    I would like to praise josh3736's answer for providing some excellent historical context. While it's well articulated, the CSS landscape has changed in the almost five years since this question was asked. When this question was asked, px was the correct answer, but that no longer holds true today.

tl;dr: use rem
Unit Overview
Historically px units typically represented one device pixel. With devices having higher and higher pixel density this no longer holds for many devices, such as with Apple's Retina Display.
rem units represent the root em size. It's the font-size of whatever matches :root. In the case of HTML, it's the <html> element; for SVG, it's the <svg> element. The default font-size in every browser* is 16px.
On Using px
The majority of CSS examples on the internet use px values because they were the de-facto standard. pt, in and a variety of other units could have been used in theory, but they didn't handle small values well as you'd quickly need to resort to fractions, which were longer to type, and harder to reason about.
If you wanted a thin border, with px you could use 1px, with pt you'd need to use 0.75pt for consistent results, and that's just not very convenient.
On Using rem
rem's default value of 16px isn't a very strong argument for its use. Writing 0.0625rem is worse than writing 0.75pt, so why would anyone use rem?
There are two parts to rem's advantage over other units.

User preferences are respected
You can change the apparent px value of rem to whatever you'd like

Respecting User Preferences
Browser zoom has changed a lot over the years. Historically many browsers would only scale up font-size, but that changed pretty rapidly when websites realized that their beautiful pixel-perfect designs were breaking any time someone zoomed in or out. At this point, browsers scale the entire page, so font-based zooming is out of the picture.
Respecting a user's wishes is not out of the picture. Just because a browser is set to 16px by default, doesn't mean any user can't change their preferences to 24px or 32px to correct for low vision or poor visibility (e.x. screen glare). If you base your units off of rem, any user at a higher font-size will see a proportionally larger site. Borders will be bigger, padding will be bigger, margins will be bigger, everything will scale up fluidly.
If you base your media queries on rem, you can also make sure that the site your users see fits their screen. A user with font-size set to 32px on a 640px wide browser, will effectively be seeing your site as shown to a user at 16px on a 320px wide browser. There's absolutely no loss for RWD in using rem.
Changing Apparent px Value
Because rem is based on the font-size of the :root node, if you want to change what 1rem represents, all you have to do is change the font-size:
:root {
  font-size: 100px;
}
body {
  font-size: 1rem;
}<p>Don't ever actually do this, please</p>

Whatever you do, don't set the :root element's font-size to a px value.
If you set the font-size on html to a px value, you've blown away the user's preferences without a way to get them back.
If you want to change the apparent value of rem, use % units.
The math for this is reasonably straight-forward.
The apparent font-size of :root is 16px, but lets say we want to change it to 20px. All we need to do is multiply 16 by some value to get 20.
Set up your equation:
16 * X = 20

And solve for X:
X = 20 / 16
X = 1.25
X = 125%

:root {
  font-size: 125%;
}<p>If you're using the default font-size, I'm 20px tall.</p>

Doing everything in multiples of 20 isn't all that great, but a common suggestion is to make the apparent size of rem equal to 10px. The magic number for that is 10/16 which is 0.625, or 62.5%.
:root {
  font-size: 62.5%;
}<p>If you're using the default font-size, I'm 10px tall.</p>

The problem now is that your default font-size for the rest of the page is set way too small, but there's a simple fix for that: Set a font-size on body using rem:
:root {
  font-size: 62.5%;
}

body {
  font-size: 1.6rem;
}<p>I'm the default font-size</p>

It's important to note, with this adjustment in place, the apparent value of rem is 10px which means any value you might have written in px can be converted directly to rem by bumping a decimal place.
padding: 20px;

turns into
padding: 2rem;

The apparent font-size you choose is up to you, so if you want there's no reason you can't use:
:root {
  font-size: 6.25%;
}
body {
  font-size: 16rem;
}

and have 1rem equal 1px.
So there you have it, a simple solution to respect user wishes while also avoiding over-complicating your CSS.
Wait, so what's the catch?
I was afraid you might ask that. As much as I'd like to pretend that rem is magic and solves-all-things, there are still some issues of note. Nothing deal-breaking in my opinion, but I'm going to call them out so you can't say I didn't warn you.
Media Queries (use em)
One of the first issues you'll run into with rem involves media queries. Consider the following code:
:root {
  font-size: 1000px;
}
@media (min-width: 1rem) {
  :root {
    font-size: 1px;
  }
}

Here the value of rem changes depending on whether the media-query applies, and the media query depends on the value of rem, so what on earth is going on?
rem in media queries uses the initial value of font-size and should not (see Safari section) take into account any changes that may have happened to the font-size of the :root element. In other words, it's apparent value is always 16px.
This is a bit annoying, because it means that you have to do some fractional calculations, but I have found that most common media queries already use values that are multiples of 16.
|   px | rem |
+------+-----+
|  320 |  20 |
|  480 |  30 |
|  768 |  48 |
| 1024 |  64 |
| 1200 |  75 |
| 1600 | 100 |

Additionally if you're using a CSS preprocessor, you can use mixins or variables to manage your media queries, which will mask the issue entirely.
Safari
Unfortunately there's a known bug with Safari where changes to the :root font-size do actually change the calculated rem values for media query ranges. This can cause some very strange behavior if the font-size of the :root element is changed within a media query. Fortunately the fix is simple: use em units for media queries.
Context Switching
If you switch between projects various different projects, it's quite possible that the apparent font-size of rem will have different values. In one project, you might be using an apparent size of 10px where in another project the apparent size might be 1px. This can be confusing and cause issues.
My only recommendation here is to stick with 62.5% to convert rem to an apparent size of 10px, because that has been more common in my experience.
Shared CSS Libraries
If you're writing CSS that's going to be used on a site that you don't control, such as for an embedded widget, there's really no good way to know what apparent size rem will have. If that's the case, feel free to keep using px.
If you still want to use rem though, consider releasing a Sass or LESS version of the stylesheet with a variable to override the scaling for the apparent size of rem.

* I don't want to spook anyone away from using rem, but I haven't been able to officially confirm that every browser uses 16px by default. You see, there are a lot of browsers and it wouldn't be all that hard for one browser to have diverged ever so slightly to, say 15px or 18px. In testing, however I have not seen a single example where a browser using default settings in a system using default settings had any value other than 16px. If you find such an example, please share it with me.
    TL;DR: use px.
The Facts

First, it's extremely important to know that per spec, the CSS px unit does not equal one physical display pixel.  This has always been true – even in the 1996 CSS 1 spec.
CSS defines the reference pixel, which measures the size of a pixel on a 96 dpi display.  On a display that has a dpi substantially different than 96dpi (like Retina displays), the user agent rescales the px unit so that its size matches that of a reference pixel.  In other words, this rescaling is exactly why 1 CSS pixel equals 2 physical Retina display pixels.
That said, up until 2010 (and the mobile zoom situation notwithstanding), the px almost always did equal one physical pixel, because all widely available displays were around 96dpi.

Sizes specified in ems are relative to the parent element.  This leads to the em's ""compounding problem"" where nested elements get progressively larger or smaller.  For example:
  body { font-size:20px; } 
  div { font-size:0.5em; }

Gives us:
  <body> - 20px
      <div> - 10px
          <div> - 5px
              <div> - 2.5px
                  <div> - 1.25px


The CSS3 rem, which is always relative only to the root html element, is now supported on 99.67% of all browsers in use.


The Opinion
I think everyone agrees that it's good to design your pages to be accommodating to everyone, and to make consideration for the visually impaired.  One such consideration (but not the only one!) is allowing users to make the text of your site bigger, so that it's easier to read.
In the beginning, the only way to provide users a way to scale text size was by using relative size units (such as ems).  This is because the browser's font size menu simply changed the root font size.  Thus, if you specified font sizes in px, they wouldn't scale when changing the browser's font size option.
Modern browsers (and even the not-so-modern IE7) all changed the default scaling method to simply zooming in on everything, including images and box sizes.  Essentially, they make the reference pixel larger or smaller.
Yes, someone could still change their browser default stylesheet to tweak the default font size (the equivalent of the old-style font size option), but that's a very esoteric way of going about it and I'd wager nobody1 does it.  (In Chrome, it's buried under the advanced settings, Web content, Font Sizes.  In IE9, it's even more hidden.  You have to press Alt, and go to View, Text Size.)  It's much easier to just select the Zoom option in the browser's main menu (or use Ctrl++/-/mouse wheel).
1 - within statistical error, naturally
If we assume most users scale pages using the zoom option, I find relative units mostly irrelevant.  It's much easier to develop your page when everything is specified in the same unit (images are all dealt with in pixels), and you don't have to worry about compounding.    (""I was told there would be no math"" – there's dealing with having to calculate what 1.5em actually works out to.)
One other potential problem of using only relative units for font sizes is that user-resized fonts may break assumptions your layout makes.  For example, this might lead to text getting clipped or running too long.  If you use absolute units, you don't have to worry about unexpected font sizes from breaking your layout.
So my answer is use pixel units.  I use px for everything.  Of course, your situation may vary, and if you must support IE6 (may the gods of the RFCs have mercy on you), you'll have to use ems anyway.
    Yes, REM and PX are relative yet other answers have suggested to go for REM over PX, I would also like to back this up using an accessibility example.
When user sets different font-size on browser, REM automatically scale up and down elements like fonts, images etc on the webpage which is not the case with PX.

In the below gif left side text is set using font size REM unit while right side font is set by PX unit.


As you can see that REM is scaling up/down automatically when I resize
the default font-size of webpage.(bottom-right side)

Default font-size of a webpage is 16px which is equal to 1 rem (only for default html page i.e. html{font-size:100%}), so, 1.25rem is equal to 20px.
P.S: who else is using REM? CSS Frameworks! like Bootstrap 4, Bulma CSS etc, so better get along with it.
    pt is similar to rem, in that it's relatively fixed, but almost always DPI-independent, even when non-compliant browsers treat px in a device-dependent fashion.  rem varies with the font size of the root element, but you can use something like Sass/Compass to do this automatically with pt.

If you had this:

html {
    font-size: 12pt;
}


then 1rem would always be 12pt.  rem and em are only as device-independent as the elements on which they rely; some browsers don't behave according to spec, and treat px literally.  Even in the old days of the Web, 1 point was consistently regarded as 1/72 inch--that is, there are 72 points in an inch.

If you have an old, non-compliant browser, and you have:

html {
    font-size: 16px;
}


then 1rem is going to be device-dependent.  For elements that would inherit from html by default, 1em would also be device-dependent.  12pt would be the hopefully guaranteed device-independent equivalent: 16px / 96px * 72pt = 12pt, where 96px = 72pt = 1in.

It can get pretty complicated to do the math if you want to stick to specific units.  For example, .75em of html = .75rem = 9pt, and .66em of .75em of html = .5rem = 6pt.  A good rule of thumb:


Use pt for absolute sizes.  If you really need this to be dynamic relative to the root element, you're asking too much of CSS; you need a language that compiles to CSS, like Sass/SCSS.
Use em for relative sizes. It's pretty handy to be able to say, ""I want the margin on the left to be about the maximum width of a letter,"" or, ""Make this element's text just a bit bigger than its surroundings.""  <h1> is a good element on which to use a font size in ems, since it might appear in various places, but should always be bigger than nearby text.  This way, you don't have to have a separate font size for every class that's applied to h1: the font size will adapt automatically.
Use px for very tiny sizes.  At very small sizes, pt can get blurry in some browsers at 96 DPI, since pt and px don't quite line up.  If you just want to create a thin, one-pixel border, say so.  If you have a high-DPI display, this won't be obvious to you during testing, so be sure to test on a generic 96-DPI display at some point.
Don't deal in subpixels to make things fancy on high-DPI displays. Some browsers might support it--particularly on high-DPI displays--but it's a no-no.  Most users prefer big and clear, though the web has taught us developers otherwise.  If you want to add extended detail for your users with state-of-the-art screens, you can use vector graphics (read: SVG), which you should be doing anyway.

    This article describes pretty well the pros and cons of px, em, and rem.

The author finally concludes that the best method is probably to use both px and rem, declaring px first for older browsers and redeclaring rem for newer browsers:

html { font-size: 62.5%; } 
body { font-size: 14px; font-size: 1.4rem; } /* =14px */
h1   { font-size: 24px; font-size: 2.4rem; } /* =24px */

    As a reflex answer, I would recommend using rem, because it allows you to change the ""zoom level"" of the whole document at once, if necessary. In some cases, when you want the size to be relative to the parent element, then use em.

But rem support is spotty, IE8 needs a polyfill, and Webkit is exhibiting a bug. Moreover, sub-pixel calculation can cause things such as one pixel lines to sometimes disappear. The remedy is to code in pixels for such very small elements. That introduces even more complexity.

So, overall, ask yourself whether it's worth it - how important and likely it is that you change the ""zoom level"" of the whole document within CSS?

For some cases it's yes, for some cases it'll be no.

So, it depends on your needs, and you have to weight pros and cons, because using rem and em introduces some additional considerations in comparison to the ""normal"" pixel-based workflow.

Keep in mind that it's easy to switch (or rather convert) your CSS from px to rem (JavaScript is another story), because the following two blocks of CSS code would produce the same result:

html {
}

body {
  font-size:14px;
}

.someElement {
  width: 12px;
}




html {
  font-size:1px;
}

body {
  font-size:14rem;
}

.someElement {
  width: 12rem;
}

    Yes. Or, rather, no. 

Er, I mean, it doesn't matter. Use the one that makes sense for your particular project. PX and EM or both equally valid but will behave a bit different depending on your overall page's CSS architecture. 

UPDATE:

To clarify, I'm stating that usually it likely doesn't matter which you use. At times, you may specifically want to choose one over the other. EMs are nice if you can start from scratch and want to use a base font size and make everything relative to that. 

PXs are often needed when you're retrofitting a redesign onto an existing code base and need the specificity of px to prevent bad nesting issues.
    I've found the best way to program the font sizes of a website are to define a base font size for the body and then use em's (or rem's) for every other font-size I declare after that.  That's personal preference I suppose, but it's served me well and also made it very easy to incorporate a more responsive design.

As far as using rem units go, I think it's good to find a balance between being progressive in your code, but to also offer support for older browsers.  Check out this link about browser support for rem units, that should help out a good amount on your decision.
    Half (but only half) snarky answer (the other half is bitter disdain of the reality of bureaucracy):
Use vh
Everything is always sized to browser window.
Always allow scroll down, but disable horizontal scroll.
Set body width to be a static 50vh, and never code css that floats or breaks out of the parent div. (If they try to mock up something that looks like it does, clever use of a background gif can throw them off track.) And style only using tables so everything is held rigidly into place as expected. Include a javascript function to undo any ctrl+/- activity the user may do.
Users will hate you, because the site doesn't flow differently based on what they're using (such as text being too small to read on phones). Your coworkers will hate you because nobody in their right mind does this and it will likely break their work (though not yours). Your programming professors will hate you because this is not a good idea. Your UX designer will hate you because it will reveal the corners they cut in designing UX mock-ups that they have to do in order to meet deadlines.
Nearly everyone will hate you, except the people who tell you to make things match the mock-up and to do so quickly. Those people, however (which generally include the project managers), will be ecstatic by your accuracy and fast turn around time. And everyone knows their opinion is the only one that matters to your paycheck.
    josh3736's answer is a good one, but to provide a counterpoint 3 years later:

I recommend using rem units for fonts, if only because it makes it easier for you, the developer, to change sizes. It's true that users very rarely change the default font size in their browsers, and that modern browser zoom will scale up px units. But what if your boss comes to you and says ""don't enlarge the images or icons, but make all the fonts bigger"". It's much easier to just change the root font size and let all the other fonts scale relative to that, then to change px sizes in dozens or hundreds of css rules.

I think it still makes sense to use px units for some images, or for certain layout elements that should always be the same size regardless of the scale of the design.

Caniuse.com may have said that only 75% of browsers when josh3736 posted his answer in 2012, but as of March 27 they claim 93.78% support. Only IE8 doesn't support it among the browsers they track.
    ","[492, 363, 533, 32, 1, 56, 9, -4, 1, -2, 7]",242777,244,2012-08-03T15:59:25,2021-10-04 13:57:34Z,html css 
How to delete a column from a table in MySQL,"
                
Given the table created using: 

CREATE TABLE tbl_Country
(
  CountryId INT NOT NULL AUTO_INCREMENT,
  IsDeleted bit,
  PRIMARY KEY (CountryId) 
)


How can I delete the column IsDeleted?
    ALTER TABLE tbl_Country DROP COLUMN IsDeleted;


Here's a working example.

Note that the COLUMN keyword is optional, as MySQL will accept just DROP IsDeleted. Also, to drop multiple columns, you have to separate them by commas and include the DROP for each one.

ALTER TABLE tbl_Country
  DROP COLUMN IsDeleted,
  DROP COLUMN CountryName;


This allows you to DROP, ADD and ALTER multiple columns on the same table in the one statement. From the MySQL reference manual:


  You can issue multiple ADD, ALTER, DROP, and CHANGE clauses in a single ALTER TABLE statement, separated by commas. This is a MySQL extension to standard SQL, which permits only one of each clause per ALTER TABLE statement.

    To delete a single column:
ALTER TABLE `table1` DROP `column1`;

To delete multiple columns:
ALTER TABLE `table1`
DROP `column1`,
DROP `column2`,
DROP `column3`;

    It is worth mentioning that MySQL 8.0.23 and above supports Invisible Columns
CREATE TABLE tbl_Country(
  CountryId INT NOT NULL AUTO_INCREMENT,
  IsDeleted bit,
  PRIMARY KEY (CountryId) 
);

INSERT INTO tbl_Country VALUES (1, 1), (2,0);

ALTER TABLE tbl_Country ALTER COLUMN IsDeleted SET INVISIBLE;

SELECT * FROM tbl_Country;
CountryId
1
2

ALTER TABLE tbl_Country DROP COLUMN IsDeleted;

db<>fiddle demo
It may be useful in scenarios when there is need to ""hide"" a column for a time being before it could be safely dropped(like reworking corresponding application/reports etc.).
    If you are running MySQL 5.6 onwards, you can make this operation online, allowing other sessions to read and write to your table while the operation is been performed:

ALTER TABLE tbl_Country DROP COLUMN IsDeleted, ALGORITHM=INPLACE, LOCK=NONE;

    Use ALTER TABLE with DROP COLUMN to drop a column from a table, and CHANGE or MODIFY to change a column.

ALTER TABLE tbl_Country DROP COLUMN IsDeleted;
ALTER TABLE tbl_Country MODIFY IsDeleted tinyint(1) NOT NULL;
ALTER TABLE tbl_Country CHANGE IsDeleted IsDeleted tinyint(1) NOT NULL;

    ALTER TABLE `tablename` DROP `columnname`;


Or,

ALTER TABLE `tablename` DROP COLUMN `columnname`;

    Use ALTER:

ALTER TABLE `tbl_Country` DROP COLUMN `column_name`;

    You can use

alter table <tblname> drop column <colname>

    ALTER TABLE tbl_Country DROP columnName;

    ","[492, 769, 38, 3, 13, 99, 14, 10, 17, 8]",777018,62,2012-12-20T09:04:03,2021-10-12 05:30:51Z,
Using Caps Lock as Esc in Mac OS X,"
                
How do I make Caps Lock work like Esc in Mac OS X?
    Since macOS 10.12.1 it is possible to remap Caps Lock to Esc natively (System Preferences -> Keyboard -> Modifier Keys).


    Edit: As described in this answer, newer versions of MacOS now have native support for rebinding Caps Lock to Escape. Thus it is no longer necessary to install third-party software to achieve this.



Here's my attempt at a comprehensive, visual walk-through answer (with links) of how to achieve this using Seil (formerly known as PCKeyboardHack).


First, go into the System Preferences, choose Keyboard, then the Keyboard Tab (first tab), and click Modifier Keys:




In the popup dialog set Caps Lock Key to No Action:



2) Now, click here to download Seil and install it:



3) After the installation you will have a new Application installed ( Mountain Lion and newer ) and  if you are on an older OS you may have to check for a new System Preferences pane:



4) Check the box that says ""Change Caps Lock"" and enter ""53"" as the code for the escape key:



And you're done! If it doesn't work immediately, you may need to restart your machine.

Impressed? Want More Control?

You may also want to check out KeyRemap4MacBook which is actually the flagship keyboard remapping tool from pqrs.org - it's also free.

If you like these tools you can make a donation. I have no affiliation with them but I've been using these tools for a long time and have to say the guys over there have been doing an excellent job maintaining these, adding features and fixing bugs.

Here's a screenshot to show a few of the (hundreds of) pre-selectable options:



PQRS also has a great utility called NoEjectDelay that you can use in combination with KeyRemap4MacBook for reprogramming the Eject key. After a little tweaking I have mine set to toggle the AirPort Wifi.

These utilities offer unlimited flexibility when remapping the Mac keyboard. Have fun!
    I wasn't happy with any of the answers here, and went looking for a command-line solution.
In macOS Sierra 10.12, Apple introduced a new way for users to remap keys.

No need to fiddle around with system GUIs
No special privileges are required
Completely customisable
No need to install any 3rd-party crap like PCKeyboardHack / Seil / Karabiner / KeyRemap4MacBook / DoubleCommand / NoEjectDelay

If that sounds good to you, take a look at hidutil.
For example, to remap caps-lock to escape, refer to the key table and find that caps-lock has usage code 0x39 and escape has usage code 0x29.  Put these codes or'd with the hex value 0x700000000 in the source and dest like this:
hidutil property --set '{""UserKeyMapping"":[{""HIDKeyboardModifierMappingSrc"":0x700000039,""HIDKeyboardModifierMappingDst"":0x700000029}]}'

You may add other mappings in the same command.  Personally, I like to remap caps-lock to backspace, and remap backspace to delete:
hidutil property --set '{""UserKeyMapping"":[{""HIDKeyboardModifierMappingSrc"":0x700000039,""HIDKeyboardModifierMappingDst"":0x70000002A}, {""HIDKeyboardModifierMappingSrc"":0x70000002A,""HIDKeyboardModifierMappingDst"":0x70000004C}]}'

To see the current mapping:
hidutil property --get ""UserKeyMapping""

Your changes will be lost at system reboot.  If you want them to persist, configure them in a launch agent. Here's mine:
<?xml version=""1.0"" encoding=""UTF-8""?>
<!DOCTYPE plist PUBLIC ""-//Apple//DTD PLIST 1.0//EN"" ""http://www.apple.com/DTDs/PropertyList-1.0.dtd"">
<!-- Place in ~/Library/LaunchAgents/ -->
<!-- launchctl load com.ldaws.CapslockBackspace.plist -->
<plist version=""1.0"">
  <dict>
    <key>Label</key>
    <string>com.ldaws.CapslockEsc</string>
    <key>ProgramArguments</key>
    <array>
      <string>/usr/bin/hidutil</string>
      <string>property</string>
      <string>--set</string>
      <string>{""UserKeyMapping"":[{""HIDKeyboardModifierMappingSrc"":0x700000039,""HIDKeyboardModifierMappingDst"":0x70000002A},{""HIDKeyboardModifierMappingSrc"":0x70000002A,""HIDKeyboardModifierMappingDst"":0x70000004C}]}</string>
    </array>
    <key>RunAtLoad</key>
    <true/>
  </dict>
</plist>

I've placed this content into a file located at  ~/Library/LaunchAgents/com.ldaws.CapslockBackspace.plist and then executed:
launchctl load com.ldaws.CapslockBackspace.plist

    It is now much easier to map the Caps Lock key to Esc with macOS Sierra.


Open System Preferences → Keyboard.
Click the Modifier Keys button in the bottom right-hand corner.
Click the drop down box next to the hardware key that you’d like to remap, and select Escape.
Click OK and close System Preferences.




https://9to5mac.com/2016/10/25/remap-escape-key-action-macbook-pro-macos-sierra-10-12-1-modifier-keys/
    In case you don't want to install a third-party app and you really only care about vim inside iTerm, the following works:

Remap CapsLock to Help as described here.

Short version: use plutil or similar to edit ~/Library/Preferences/ByHost/.GlobalPreferences*.plist, it should look similar to this:

<key>HIDKeyboardModifierMappingDst</key>
<integer>6</integer>
<key>HIDKeyboardModifierMappingSrc</key>
<integer>0</integer>


Restart! A simple log-out and log-in did not work for me.

In iTerm, add a new key mapping for Help: send hex code 0x1b, which corresponds to Escape.

I know this is not exactly what was asked for, but I assume the intent of many people looking for a solution like this is actually this more specialized variant.
    The only thing I know how to do is to map Caps Lock to Control, or Option, or Command.  This can be done via the Keyboard & Mouse pane of System Preferences.  Click on ""Modifier Keys"" on the bottom left and you'll be able to remap Caps Lock, Control, Option, and Command, to any of those.

@Craig:
This suggests that Caps Lock can be used as a normal -- that is, non-toggle -- key.  On my MacBook, since I have re-mapped Caps Lock to Control, the Caps Lock light never lights up.  It simply acts like the Control key.


    Open up Keyboard preferences and click modifier keys... you can change the caps lock key to control, option, escape, or command.


    It's possible.

Solution 1

From an arcticle on TrueAffection.net.


  
    Download PCKeyboardHack and install it.
    Go to PCKeyboardHack in System Preferences.
    Enable ‘Change Caps Lock’ and set the keycode to 53.
  


Solution 2

This solution doesn't involve patching the keyboard driver, but gives you a Vim specific solution.

OS X supports mapping the Caps Lock key to a whole bunch of keys, but you have to do it 'by hand', editting .plist files.  The process is described in this article.  As addendum to that hint I suggest you first set Caps-Lock to None in the System Preferences, then you only need to change one value in the .plist file.  Also, you can of course use the Property List Editor instead of going through the XML conversion steps.

The trick is to map the Caps Lock key to the Help key (code 6), which isn't on most keyboards.  But if it is, it will be treated as the insert key, which you probably don't use anyway, since you ask about remapping your Caps Lock to prevent stretching your hands ;)

You can then map the Help and the Insert key to Esc in vim.

map  <Help> <Esc>
map! <Help> <Esc>
map  <Insert> <Esc>
map! <Insert> <Esc>


This will work for gvim (Vim.app).  I didn't get it to work with vim in the Terminal and I haven't tested it with MacVim.

So, it's rather a complicated, half-baked solution or installing a third-party piece of hackery.  Your pick ;)

Edit: Just noticed solution 3, if you're using MacVim you can use Ctrl, Option and Command as Esc.  With the System Preferences it's trivial to map Caps Lock to one of those keys.
    Seil isn't yet available on macOS Sierra (10.12 beta). As such, I've been using Keyboard Maestro with these settings: 

Credit to this github comment: https://github.com/tekezo/Seil/issues/68#issuecomment-230131664
    Having tried several of these solutions, I have some notes:

DoubleCommand will not allow you to swap esc and caps-lock.

PCKeyboardHack will allow you to map capslock to escape, but does not have the capability to map escape to capslock. Recent versions will allow you to perform a complete swap by editing both keys.

This may or may not be sufficient for your needs (I know it is for mine).
    In order to actually swap the escape key with the caps lock key (not just map one to the other) using both PCKeyboardHack and KeyRemap4MacBook, you have to follow the instructions in this thread, mapping the caps lock key to a keycode not used by the keyboard but accounted for by KeyRemap4MacBook (eg. 110). Then, in PCKeyboardHack, select the appropriate option that maps that keycode to escape (in the case of 110, it's ""Application Key to Escape""). Here's what your KeyRemap4MacBook preferences should look like (provided you've selected the ""show enabled only"" checkbox).



I originally attempted to post this information as an edit to cwd's excellent answer, but it was rejected. I encourage anyone who wants to go the route that I describe to first read his/her response.
    Seil doesn't work on macOS Sierra yet, so I'm using Karabiner Elements, download from https://pqrs.org/latest/karabiner-elements-latest.dmg.

Either use the GUI or put the following into ~/.karabiner.d/configuration/karabiner.json:

{
  ""profiles"" : [
    {
      ""name"" : ""Default profile"",
      ""selected"" : true,
      ""simple_modifications"" : {
        ""caps_lock"" : ""escape""
      }
    }
  ]
}

    You can also use DoubleCommand to remap this, and other keys.

IIRC, it will map Caps Lock to Esc.
    Karabiner-Elements
A powerful and stable keyboard customizer for macOS. (freeware)

https://pqrs.org/osx/karabiner/index.html

Worked for me for Mojave to change caps-lock to backspace
    ","[492, 342, 410, 60, 37, 10, 38, 3, 34, 14, 10, 4, 2, 1, 0]",137595,137,2008-09-24T14:42:21,2020-12-01 08:37:19Z,
How do I remove diacritics (accents) from a string in .NET?,"
                
I'm trying to convert some strings that are in French Canadian and basically, I'd like to be able to take out the French accent marks in the letters while keeping the letter. (E.g. convert é to e, so crème brûlée would become creme brulee)

What is the best method for achieving this?
    I've not used this method, but Michael Kaplan describes a method for doing so in his blog post (with a confusing title) that talks about stripping diacritics: Stripping is an interesting job (aka
On the meaning of meaningless, aka All
Mn characters are non-spacing, but
some are more non-spacing than
others)
static string RemoveDiacritics(string text) 
{
    var normalizedString = text.Normalize(NormalizationForm.FormD);
    var stringBuilder = new StringBuilder(capacity: normalizedString.Length);

    for (int i = 0; i < normalizedString.Length; i++)
    {
        char c = normalizedString[i];
        var unicodeCategory = CharUnicodeInfo.GetUnicodeCategory(c);
        if (unicodeCategory != UnicodeCategory.NonSpacingMark)
        {
            stringBuilder.Append(c);
        }
    }

    return stringBuilder
        .ToString()
        .Normalize(NormalizationForm.FormC);
}

Note that this is a followup to his earlier post: Stripping diacritics....
The approach uses String.Normalize to split the input string into constituent glyphs (basically separating the ""base"" characters from the diacritics) and then scans the result and retains only the base characters. It's just a little complicated, but really you're looking at a complicated problem.
Of course, if you're limiting yourself to French, you could probably get away with the simple table-based approach in How to remove accents and tilde in a C++ std::string, as recommended by @David Dibben.
    The accepted answer is totally correct, but nowadays, it should be updated to use Rune class instead of CharUnicodeInfo, as C# & .NET updated the way to analyse strings in latest versions (Rune class has been added in .NET Core 3.0).
The following code for .NET 5+ is now recommended, as it go further for non-latin chars :
static string RemoveDiacritics(string text) 
{
    var normalizedString = text.Normalize(NormalizationForm.FormD);
    var stringBuilder = new StringBuilder();

    foreach (var c in normalizedString.EnumerateRunes())
    {
        var unicodeCategory = Rune.GetUnicodeCategory(c);
        if (unicodeCategory != UnicodeCategory.NonSpacingMark)
        {
            stringBuilder.Append(c);
        }
    }

    return stringBuilder.ToString().Normalize(NormalizationForm.FormC);
}

    this did the trick for me...
string accentedStr;
byte[] tempBytes;
tempBytes = System.Text.Encoding.GetEncoding(""ISO-8859-8"").GetBytes(accentedStr);
string asciiStr = System.Text.Encoding.UTF8.GetString(tempBytes);

quick&short!
    Same as accepted answer but faster, using Span instead of StringBuilder.
Requires .NET Core 3.1 or newer .NET.
static string RemoveDiacritics(string text) 
{
    ReadOnlySpan<char> normalizedString = text.Normalize(NormalizationForm.FormD);
    int i = 0;
    Span<char> span = text.Length < 1000
        ? stackalloc char[text.Length]
        : new char[text.Length];

    foreach (char c in normalizedString)
    {
        if (CharUnicodeInfo.GetUnicodeCategory(c) != UnicodeCategory.NonSpacingMark)
            span[i++] = c;
    }

    return new string(span).Normalize(NormalizationForm.FormC);
}

Also this is extensible for additional character replacements e.g. for polish Ł.
span[i++] = c switch
{
    'Ł' => 'L',
    'ł' => 'l',
    _ => c
};

A small note: Stack allocation stackalloc is rather faster than Heap allocation new, and it makes less work for Garbage Collector. 1000 is a threshold to avoid allocating large structures on Stack which may cause StackOverflowException. While 1000 is a pretty safe value, in most cases 10000 or even 100000 would also work (100k allocates on Stack up to 200kB while default stack size is 1 MB). However 100k looks for me a bit dangerous.
    I needed something that converts all major unicode characters and the voted answer leaved a few out so I've created a version of CodeIgniter's convert_accented_characters($str) into C# that is easily customisable:

using System;
using System.Text;
using System.Collections.Generic;

public static class Strings
{
    static Dictionary<string, string> foreign_characters = new Dictionary<string, string>
    {
        { ""äæǽ"", ""ae"" },
        { ""öœ"", ""oe"" },
        { ""ü"", ""ue"" },
        { ""Ä"", ""Ae"" },
        { ""Ü"", ""Ue"" },
        { ""Ö"", ""Oe"" },
        { ""ÀÁÂÃÄÅǺĀĂĄǍΑΆẢẠẦẪẨẬẰẮẴẲẶА"", ""A"" },
        { ""àáâãåǻāăąǎªαάảạầấẫẩậằắẵẳặа"", ""a"" },
        { ""Б"", ""B"" },
        { ""б"", ""b"" },
        { ""ÇĆĈĊČ"", ""C"" },
        { ""çćĉċč"", ""c"" },
        { ""Д"", ""D"" },
        { ""д"", ""d"" },
        { ""ÐĎĐΔ"", ""Dj"" },
        { ""ðďđδ"", ""dj"" },
        { ""ÈÉÊËĒĔĖĘĚΕΈẼẺẸỀẾỄỂỆЕЭ"", ""E"" },
        { ""èéêëēĕėęěέεẽẻẹềếễểệеэ"", ""e"" },
        { ""Ф"", ""F"" },
        { ""ф"", ""f"" },
        { ""ĜĞĠĢΓГҐ"", ""G"" },
        { ""ĝğġģγгґ"", ""g"" },
        { ""ĤĦ"", ""H"" },
        { ""ĥħ"", ""h"" },
        { ""ÌÍÎÏĨĪĬǏĮİΗΉΊΙΪỈỊИЫ"", ""I"" },
        { ""ìíîïĩīĭǐįıηήίιϊỉịиыї"", ""i"" },
        { ""Ĵ"", ""J"" },
        { ""ĵ"", ""j"" },
        { ""ĶΚК"", ""K"" },
        { ""ķκк"", ""k"" },
        { ""ĹĻĽĿŁΛЛ"", ""L"" },
        { ""ĺļľŀłλл"", ""l"" },
        { ""М"", ""M"" },
        { ""м"", ""m"" },
        { ""ÑŃŅŇΝН"", ""N"" },
        { ""ñńņňŉνн"", ""n"" },
        { ""ÒÓÔÕŌŎǑŐƠØǾΟΌΩΏỎỌỒỐỖỔỘỜỚỠỞỢО"", ""O"" },
        { ""òóôõōŏǒőơøǿºοόωώỏọồốỗổộờớỡởợо"", ""o"" },
        { ""П"", ""P"" },
        { ""п"", ""p"" },
        { ""ŔŖŘΡР"", ""R"" },
        { ""ŕŗřρр"", ""r"" },
        { ""ŚŜŞȘŠΣС"", ""S"" },
        { ""śŝşșšſσςс"", ""s"" },
        { ""ȚŢŤŦτТ"", ""T"" },
        { ""țţťŧт"", ""t"" },
        { ""ÙÚÛŨŪŬŮŰŲƯǓǕǗǙǛŨỦỤỪỨỮỬỰУ"", ""U"" },
        { ""ùúûũūŭůűųưǔǖǘǚǜυύϋủụừứữửựу"", ""u"" },
        { ""ÝŸŶΥΎΫỲỸỶỴЙ"", ""Y"" },
        { ""ýÿŷỳỹỷỵй"", ""y"" },
        { ""В"", ""V"" },
        { ""в"", ""v"" },
        { ""Ŵ"", ""W"" },
        { ""ŵ"", ""w"" },
        { ""ŹŻŽΖЗ"", ""Z"" },
        { ""źżžζз"", ""z"" },
        { ""ÆǼ"", ""AE"" },
        { ""ß"", ""ss"" },
        { ""Ĳ"", ""IJ"" },
        { ""ĳ"", ""ij"" },
        { ""Œ"", ""OE"" },
        { ""ƒ"", ""f"" },
        { ""ξ"", ""ks"" },
        { ""π"", ""p"" },
        { ""β"", ""v"" },
        { ""μ"", ""m"" },
        { ""ψ"", ""ps"" },
        { ""Ё"", ""Yo"" },
        { ""ё"", ""yo"" },
        { ""Є"", ""Ye"" },
        { ""є"", ""ye"" },
        { ""Ї"", ""Yi"" },
        { ""Ж"", ""Zh"" },
        { ""ж"", ""zh"" },
        { ""Х"", ""Kh"" },
        { ""х"", ""kh"" },
        { ""Ц"", ""Ts"" },
        { ""ц"", ""ts"" },
        { ""Ч"", ""Ch"" },
        { ""ч"", ""ch"" },
        { ""Ш"", ""Sh"" },
        { ""ш"", ""sh"" },
        { ""Щ"", ""Shch"" },
        { ""щ"", ""shch"" },
        { ""ЪъЬь"", """" },
        { ""Ю"", ""Yu"" },
        { ""ю"", ""yu"" },
        { ""Я"", ""Ya"" },
        { ""я"", ""ya"" },
    };

    public static char RemoveDiacritics(this char c){
        foreach(KeyValuePair<string, string> entry in foreign_characters)
        {
            if(entry.Key.IndexOf (c) != -1)
            {
                return entry.Value[0];
            }
        }
        return c;
    }

    public static string RemoveDiacritics(this string s) 
    {
        //StringBuilder sb = new StringBuilder ();
        string text = """";


        foreach (char c in s)
        {
            int len = text.Length;

            foreach(KeyValuePair<string, string> entry in foreign_characters)
            {
                if(entry.Key.IndexOf (c) != -1)
                {
                    text += entry.Value;
                    break;
                }
            }

            if (len == text.Length) {
                text += c;  
            }
        }
        return text;
    }
}


Usage

// for strings
""crème brûlée"".RemoveDiacritics (); // creme brulee

// for chars
""Ã""[0].RemoveDiacritics (); // A

    Not having enough reputations, apparently I can not comment on Alexander's excellent link. - Lucene appears to be the only solution working in reasonably generic cases. 

For those wanting a simple copy-paste solution, here it is, leveraging code in Lucene:

string testbed = ""ÁÂÄÅÇÉÍÎÓÖØÚÜÞàáâãäåæçèéêëìíîïðñóôöøúüāăčĐęğıŁłńŌōřŞşšźžșțệủ"";

Console.WriteLine(Lucene.latinizeLucene(testbed));


  
    AAAACEIIOOOUUTHaaaaaaaeceeeeiiiidnoooouuaacDegiLlnOorSsszzsteu
  


//////////

public static class Lucene
{
    // source: https://raw.githubusercontent.com/apache/lucenenet/master/src/Lucene.Net.Analysis.Common/Analysis/Miscellaneous/ASCIIFoldingFilter.cs
    // idea: https://stackoverflow.com/questions/249087/how-do-i-remove-diacritics-accents-from-a-string-in-net (scroll down, search for lucene by Alexander)
    public static string latinizeLucene(string arg)
    {
        char[] argChar = arg.ToCharArray();

        // latinizeLuceneImpl can expand one char up to four chars - e.g. Þ to TH, or æ to ae, or in fact ⑽ to (10)
        char[] resultChar = new String(' ', arg.Length * 4).ToCharArray();

        int outputPos = Lucene.latinizeLuceneImpl(argChar, 0, ref resultChar, 0, arg.Length);

        string ret = new string(resultChar);
        ret = ret.Substring(0, outputPos);

        return ret;
    }

    /// <summary>
    /// Converts characters above ASCII to their ASCII equivalents.  For example,
    /// accents are removed from accented characters. 
    /// <para/>
    /// @lucene.internal
    /// </summary>
    /// <param name=""input"">     The characters to fold </param>
    /// <param name=""inputPos"">  Index of the first character to fold </param>
    /// <param name=""output"">    The result of the folding. Should be of size >= <c>length * 4</c>. </param>
    /// <param name=""outputPos""> Index of output where to put the result of the folding </param>
    /// <param name=""length"">    The number of characters to fold </param>
    /// <returns> length of output </returns>
    private static int latinizeLuceneImpl(char[] input, int inputPos, ref char[] output, int outputPos, int length)
    {
        int end = inputPos + length;
        for (int pos = inputPos; pos < end; ++pos)
        {
            char c = input[pos];

            // Quick test: if it's not in range then just keep current character
            if (c < '\u0080')
            {
                output[outputPos++] = c;
            }
            else
            {
                switch (c)
                {
                    case '\u00C0': // À  [LATIN CAPITAL LETTER A WITH GRAVE]
                    case '\u00C1': // Á  [LATIN CAPITAL LETTER A WITH ACUTE]
                    case '\u00C2': // Â  [LATIN CAPITAL LETTER A WITH CIRCUMFLEX]
                    case '\u00C3': // Ã  [LATIN CAPITAL LETTER A WITH TILDE]
                    case '\u00C4': // Ä  [LATIN CAPITAL LETTER A WITH DIAERESIS]
                    case '\u00C5': // Å  [LATIN CAPITAL LETTER A WITH RING ABOVE]
                    case '\u0100': // Ā  [LATIN CAPITAL LETTER A WITH MACRON]
                    case '\u0102': // Ă  [LATIN CAPITAL LETTER A WITH BREVE]
                    case '\u0104': // Ą  [LATIN CAPITAL LETTER A WITH OGONEK]
                    case '\u018F': // Ə  http://en.wikipedia.org/wiki/Schwa  [LATIN CAPITAL LETTER SCHWA]
                    case '\u01CD': // Ǎ  [LATIN CAPITAL LETTER A WITH CARON]
                    case '\u01DE': // Ǟ  [LATIN CAPITAL LETTER A WITH DIAERESIS AND MACRON]
                    case '\u01E0': // Ǡ  [LATIN CAPITAL LETTER A WITH DOT ABOVE AND MACRON]
                    case '\u01FA': // Ǻ  [LATIN CAPITAL LETTER A WITH RING ABOVE AND ACUTE]
                    case '\u0200': // Ȁ  [LATIN CAPITAL LETTER A WITH DOUBLE GRAVE]
                    case '\u0202': // Ȃ  [LATIN CAPITAL LETTER A WITH INVERTED BREVE]
                    case '\u0226': // Ȧ  [LATIN CAPITAL LETTER A WITH DOT ABOVE]
                    case '\u023A': // Ⱥ  [LATIN CAPITAL LETTER A WITH STROKE]
                    case '\u1D00': // ᴀ  [LATIN LETTER SMALL CAPITAL A]
                    case '\u1E00': // Ḁ  [LATIN CAPITAL LETTER A WITH RING BELOW]
                    case '\u1EA0': // Ạ  [LATIN CAPITAL LETTER A WITH DOT BELOW]
                    case '\u1EA2': // Ả  [LATIN CAPITAL LETTER A WITH HOOK ABOVE]
                    case '\u1EA4': // Ấ  [LATIN CAPITAL LETTER A WITH CIRCUMFLEX AND ACUTE]
                    case '\u1EA6': // Ầ  [LATIN CAPITAL LETTER A WITH CIRCUMFLEX AND GRAVE]
                    case '\u1EA8': // Ẩ  [LATIN CAPITAL LETTER A WITH CIRCUMFLEX AND HOOK ABOVE]
                    case '\u1EAA': // Ẫ  [LATIN CAPITAL LETTER A WITH CIRCUMFLEX AND TILDE]
                    case '\u1EAC': // Ậ  [LATIN CAPITAL LETTER A WITH CIRCUMFLEX AND DOT BELOW]
                    case '\u1EAE': // Ắ  [LATIN CAPITAL LETTER A WITH BREVE AND ACUTE]
                    case '\u1EB0': // Ằ  [LATIN CAPITAL LETTER A WITH BREVE AND GRAVE]
                    case '\u1EB2': // Ẳ  [LATIN CAPITAL LETTER A WITH BREVE AND HOOK ABOVE]
                    case '\u1EB4': // Ẵ  [LATIN CAPITAL LETTER A WITH BREVE AND TILDE]
                    case '\u1EB6': // Ặ  [LATIN CAPITAL LETTER A WITH BREVE AND DOT BELOW]
                    case '\u24B6': // Ⓐ  [CIRCLED LATIN CAPITAL LETTER A]
                    case '\uFF21': // Ａ  [FULLWIDTH LATIN CAPITAL LETTER A]
                        output[outputPos++] = 'A';
                        break;
                    case '\u00E0': // à  [LATIN SMALL LETTER A WITH GRAVE]
                    case '\u00E1': // á  [LATIN SMALL LETTER A WITH ACUTE]
                    case '\u00E2': // â  [LATIN SMALL LETTER A WITH CIRCUMFLEX]
                    case '\u00E3': // ã  [LATIN SMALL LETTER A WITH TILDE]
                    case '\u00E4': // ä  [LATIN SMALL LETTER A WITH DIAERESIS]
                    case '\u00E5': // å  [LATIN SMALL LETTER A WITH RING ABOVE]
                    case '\u0101': // ā  [LATIN SMALL LETTER A WITH MACRON]
                    case '\u0103': // ă  [LATIN SMALL LETTER A WITH BREVE]
                    case '\u0105': // ą  [LATIN SMALL LETTER A WITH OGONEK]
                    case '\u01CE': // ǎ  [LATIN SMALL LETTER A WITH CARON]
                    case '\u01DF': // ǟ  [LATIN SMALL LETTER A WITH DIAERESIS AND MACRON]
                    case '\u01E1': // ǡ  [LATIN SMALL LETTER A WITH DOT ABOVE AND MACRON]
                    case '\u01FB': // ǻ  [LATIN SMALL LETTER A WITH RING ABOVE AND ACUTE]
                    case '\u0201': // ȁ  [LATIN SMALL LETTER A WITH DOUBLE GRAVE]
                    case '\u0203': // ȃ  [LATIN SMALL LETTER A WITH INVERTED BREVE]
                    case '\u0227': // ȧ  [LATIN SMALL LETTER A WITH DOT ABOVE]
                    case '\u0250': // ɐ  [LATIN SMALL LETTER TURNED A]
                    case '\u0259': // ə  [LATIN SMALL LETTER SCHWA]
                    case '\u025A': // ɚ  [LATIN SMALL LETTER SCHWA WITH HOOK]
                    case '\u1D8F': // ᶏ  [LATIN SMALL LETTER A WITH RETROFLEX HOOK]
                    case '\u1D95': // ᶕ  [LATIN SMALL LETTER SCHWA WITH RETROFLEX HOOK]
                    case '\u1E01': // ạ  [LATIN SMALL LETTER A WITH RING BELOW]
                    case '\u1E9A': // ả  [LATIN SMALL LETTER A WITH RIGHT HALF RING]
                    case '\u1EA1': // ạ  [LATIN SMALL LETTER A WITH DOT BELOW]
                    case '\u1EA3': // ả  [LATIN SMALL LETTER A WITH HOOK ABOVE]
                    case '\u1EA5': // ấ  [LATIN SMALL LETTER A WITH CIRCUMFLEX AND ACUTE]
                    case '\u1EA7': // ầ  [LATIN SMALL LETTER A WITH CIRCUMFLEX AND GRAVE]
                    case '\u1EA9': // ẩ  [LATIN SMALL LETTER A WITH CIRCUMFLEX AND HOOK ABOVE]
                    case '\u1EAB': // ẫ  [LATIN SMALL LETTER A WITH CIRCUMFLEX AND TILDE]
                    case '\u1EAD': // ậ  [LATIN SMALL LETTER A WITH CIRCUMFLEX AND DOT BELOW]
                    case '\u1EAF': // ắ  [LATIN SMALL LETTER A WITH BREVE AND ACUTE]
                    case '\u1EB1': // ằ  [LATIN SMALL LETTER A WITH BREVE AND GRAVE]
                    case '\u1EB3': // ẳ  [LATIN SMALL LETTER A WITH BREVE AND HOOK ABOVE]
                    case '\u1EB5': // ẵ  [LATIN SMALL LETTER A WITH BREVE AND TILDE]
                    case '\u1EB7': // ặ  [LATIN SMALL LETTER A WITH BREVE AND DOT BELOW]
                    case '\u2090': // ₐ  [LATIN SUBSCRIPT SMALL LETTER A]
                    case '\u2094': // ₔ  [LATIN SUBSCRIPT SMALL LETTER SCHWA]
                    case '\u24D0': // ⓐ  [CIRCLED LATIN SMALL LETTER A]
                    case '\u2C65': // ⱥ  [LATIN SMALL LETTER A WITH STROKE]
                    case '\u2C6F': // Ɐ  [LATIN CAPITAL LETTER TURNED A]
                    case '\uFF41': // ａ  [FULLWIDTH LATIN SMALL LETTER A]
                        output[outputPos++] = 'a';
                        break;
                    case '\uA732': // Ꜳ  [LATIN CAPITAL LETTER AA]
                        output[outputPos++] = 'A';
                        output[outputPos++] = 'A';
                        break;
                    case '\u00C6': // Æ  [LATIN CAPITAL LETTER AE]
                    case '\u01E2': // Ǣ  [LATIN CAPITAL LETTER AE WITH MACRON]
                    case '\u01FC': // Ǽ  [LATIN CAPITAL LETTER AE WITH ACUTE]
                    case '\u1D01': // ᴁ  [LATIN LETTER SMALL CAPITAL AE]
                        output[outputPos++] = 'A';
                        output[outputPos++] = 'E';
                        break;
                    case '\uA734': // Ꜵ  [LATIN CAPITAL LETTER AO]
                        output[outputPos++] = 'A';
                        output[outputPos++] = 'O';
                        break;
                    case '\uA736': // Ꜷ  [LATIN CAPITAL LETTER AU]
                        output[outputPos++] = 'A';
                        output[outputPos++] = 'U';
                        break;

        // etc. etc. etc.
        // see link above for complete source code
        // 
        // unfortunately, postings are limited, as in
        // ""Body is limited to 30000 characters; you entered 136098.""

                    [...]

                    case '\u2053': // ⁓  [SWUNG DASH]
                    case '\uFF5E': // ～  [FULLWIDTH TILDE]
                        output[outputPos++] = '~';
                        break;
                    default:
                        output[outputPos++] = c;
                        break;
                }
            }
        }
        return outputPos;
    }
}

    TL;DR - C# string extension method

I think the best solution to preserve the meaning of the string is to convert the characters instead of stripping them, which is well illustrated in the example crème brûlée to crme brle vs. creme brulee.

I checked out Alexander's comment above and saw the Lucene.Net code is Apache 2.0 licensed, so I've modified the class into a simple string extension method. You can use it like this:

var originalString = ""crème brûlée"";
var maxLength = originalString.Length; // limit output length as necessary
var foldedString = originalString.FoldToASCII(maxLength); 
// ""creme brulee""


The function is too long to post in a StackOverflow answer (~139k characters of 30k allowed lol) so I made a gist and attributed the authors: 

/*
 * Licensed to the Apache Software Foundation (ASF) under one or more
 * contributor license agreements.  See the NOTICE file distributed with
 * this work for additional information regarding copyright ownership.
 * The ASF licenses this file to You under the Apache License, Version 2.0
 * (the ""License""); you may not use this file except in compliance with
 * the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

/// <summary>
/// This class converts alphabetic, numeric, and symbolic Unicode characters
/// which are not in the first 127 ASCII characters (the ""Basic Latin"" Unicode
/// block) into their ASCII equivalents, if one exists.
/// <para/>
/// Characters from the following Unicode blocks are converted; however, only
/// those characters with reasonable ASCII alternatives are converted:
/// 
/// <ul>
///   <item><description>C1 Controls and Latin-1 Supplement: <a href=""http://www.unicode.org/charts/PDF/U0080.pdf"">http://www.unicode.org/charts/PDF/U0080.pdf</a></description></item>
///   <item><description>Latin Extended-A: <a href=""http://www.unicode.org/charts/PDF/U0100.pdf"">http://www.unicode.org/charts/PDF/U0100.pdf</a></description></item>
///   <item><description>Latin Extended-B: <a href=""http://www.unicode.org/charts/PDF/U0180.pdf"">http://www.unicode.org/charts/PDF/U0180.pdf</a></description></item>
///   <item><description>Latin Extended Additional: <a href=""http://www.unicode.org/charts/PDF/U1E00.pdf"">http://www.unicode.org/charts/PDF/U1E00.pdf</a></description></item>
///   <item><description>Latin Extended-C: <a href=""http://www.unicode.org/charts/PDF/U2C60.pdf"">http://www.unicode.org/charts/PDF/U2C60.pdf</a></description></item>
///   <item><description>Latin Extended-D: <a href=""http://www.unicode.org/charts/PDF/UA720.pdf"">http://www.unicode.org/charts/PDF/UA720.pdf</a></description></item>
///   <item><description>IPA Extensions: <a href=""http://www.unicode.org/charts/PDF/U0250.pdf"">http://www.unicode.org/charts/PDF/U0250.pdf</a></description></item>
///   <item><description>Phonetic Extensions: <a href=""http://www.unicode.org/charts/PDF/U1D00.pdf"">http://www.unicode.org/charts/PDF/U1D00.pdf</a></description></item>
///   <item><description>Phonetic Extensions Supplement: <a href=""http://www.unicode.org/charts/PDF/U1D80.pdf"">http://www.unicode.org/charts/PDF/U1D80.pdf</a></description></item>
///   <item><description>General Punctuation: <a href=""http://www.unicode.org/charts/PDF/U2000.pdf"">http://www.unicode.org/charts/PDF/U2000.pdf</a></description></item>
///   <item><description>Superscripts and Subscripts: <a href=""http://www.unicode.org/charts/PDF/U2070.pdf"">http://www.unicode.org/charts/PDF/U2070.pdf</a></description></item>
///   <item><description>Enclosed Alphanumerics: <a href=""http://www.unicode.org/charts/PDF/U2460.pdf"">http://www.unicode.org/charts/PDF/U2460.pdf</a></description></item>
///   <item><description>Dingbats: <a href=""http://www.unicode.org/charts/PDF/U2700.pdf"">http://www.unicode.org/charts/PDF/U2700.pdf</a></description></item>
///   <item><description>Supplemental Punctuation: <a href=""http://www.unicode.org/charts/PDF/U2E00.pdf"">http://www.unicode.org/charts/PDF/U2E00.pdf</a></description></item>
///   <item><description>Alphabetic Presentation Forms: <a href=""http://www.unicode.org/charts/PDF/UFB00.pdf"">http://www.unicode.org/charts/PDF/UFB00.pdf</a></description></item>
///   <item><description>Halfwidth and Fullwidth Forms: <a href=""http://www.unicode.org/charts/PDF/UFF00.pdf"">http://www.unicode.org/charts/PDF/UFF00.pdf</a></description></item>
/// </ul>
/// <para/>
/// See: <a href=""http://en.wikipedia.org/wiki/Latin_characters_in_Unicode"">http://en.wikipedia.org/wiki/Latin_characters_in_Unicode</a>
/// <para/>
/// For example, '&amp;agrave;' will be replaced by 'a'.
/// </summary>
public static partial class StringExtensions
{
    /// <summary>
    /// Converts characters above ASCII to their ASCII equivalents.  For example,
    /// accents are removed from accented characters. 
    /// </summary>
    /// <param name=""input"">     The string of characters to fold </param>
    /// <param name=""length"">    The length of the folded return string </param>
    /// <returns> length of output </returns>
    public static string FoldToASCII(this string input, int? length = null)
    {
        // See https://gist.github.com/andyraddatz/e6a396fb91856174d4e3f1bf2e10951c
    }
}


Hope that helps someone else, this is the most robust solution I've found!
    The CodePage of Greek (ISO) can do it

The information about this codepage is into System.Text.Encoding.GetEncodings(). Learn about in: https://msdn.microsoft.com/pt-br/library/system.text.encodinginfo.getencoding(v=vs.110).aspx

Greek (ISO) has codepage 28597 and name iso-8859-7.

Go to the code... \o/

string text = ""Você está numa situação lamentável"";

string textEncode = System.Web.HttpUtility.UrlEncode(text, Encoding.GetEncoding(""iso-8859-7""));
//result: ""Voce+esta+numa+situacao+lamentavel""

string textDecode = System.Web.HttpUtility.UrlDecode(textEncode);
//result: ""Voce esta numa situacao lamentavel""


So, write this function...

public string RemoveAcentuation(string text)
{
    return
        System.Web.HttpUtility.UrlDecode(
            System.Web.HttpUtility.UrlEncode(
                text, Encoding.GetEncoding(""iso-8859-7"")));
}


Note that... Encoding.GetEncoding(""iso-8859-7"") is equivalent to Encoding.GetEncoding(28597) because first is the name, and second the codepage of Encoding.
    I often use an extenstion method based on another version I found here
(see Replacing characters in C# (ascii))
A quick explanation:


Normalizing to form D splits charactes like è to an e and a nonspacing `
From this, the nospacing characters are removed
The result is normalized back to form C (I'm not sure if this is neccesary)


Code:

using System.Linq;
using System.Text;
using System.Globalization;

// namespace here
public static class Utility
{
    public static string RemoveDiacritics(this string str)
    {
        if (null == str) return null;
        var chars =
            from c in str.Normalize(NormalizationForm.FormD).ToCharArray()
            let uc = CharUnicodeInfo.GetUnicodeCategory(c)
            where uc != UnicodeCategory.NonSpacingMark
            select c;

        var cleanStr = new string(chars.ToArray()).Normalize(NormalizationForm.FormC);

        return cleanStr;
    }

    // or, alternatively
    public static string RemoveDiacritics2(this string str)
    {
        if (null == str) return null;
        var chars = str
            .Normalize(NormalizationForm.FormD)
            .ToCharArray()
            .Where(c=> CharUnicodeInfo.GetUnicodeCategory(c) != UnicodeCategory.NonSpacingMark)
            .ToArray();

        return new string(chars).Normalize(NormalizationForm.FormC);
    }
}

    It's funny such a question can get so many answers, and yet none fit my requirements :) There are so many languages around, a full language agnostic solution is AFAIK not really possible, as others has mentionned that the FormC or FormD are giving issues.

Since the original question was related to French, the simplest working answer is indeed 

    public static string ConvertWesternEuropeanToASCII(this string str)
    {
        return Encoding.ASCII.GetString(Encoding.GetEncoding(1251).GetBytes(str));
    }


1251 should be replaced by the encoding code of the input language.

This however replace only one character by one character. Since I am also working with German as input, I did a manual convert

    public static string LatinizeGermanCharacters(this string str)
    {
        StringBuilder sb = new StringBuilder(str.Length);
        foreach (char c in str)
        {
            switch (c)
            {
                case 'ä':
                    sb.Append(""ae"");
                    break;
                case 'ö':
                    sb.Append(""oe"");
                    break;
                case 'ü':
                    sb.Append(""ue"");
                    break;
                case 'Ä':
                    sb.Append(""Ae"");
                    break;
                case 'Ö':
                    sb.Append(""Oe"");
                    break;
                case 'Ü':
                    sb.Append(""Ue"");
                    break;
                case 'ß':
                    sb.Append(""ss"");
                    break;
                default:
                    sb.Append(c);
                    break;
            }
        }
        return sb.ToString();
    }


It might not deliver the best performance, but at least it is very easy to read and extend.
Regex is a NO GO, much slower than any char/string stuff.

I also have a very simple method to remove space:

    public static string RemoveSpace(this string str)
    {
        return str.Replace("" "", string.Empty);
    }


Eventually, I am using a combination of all 3 above extensions:

    public static string LatinizeAndConvertToASCII(this string str, bool keepSpace = false)
    {
        str = str.LatinizeGermanCharacters().ConvertWesternEuropeanToASCII();            
        return keepSpace ? str : str.RemoveSpace();
    }


And a small unit test to that (not exhaustive) which pass successfully.

    [TestMethod()]
    public void LatinizeAndConvertToASCIITest()
    {
        string europeanStr = ""Bonjour ça va? C'est l'été! Ich möchte ä Ä á à â ê é è ë Ë É ï Ï î í ì ó ò ô ö Ö Ü ü ù ú û Û ý Ý ç Ç ñ Ñ"";
        string expected = ""Bonjourcava?C'estl'ete!IchmoechteaeAeaaaeeeeEEiIiiiooooeOeUeueuuuUyYcCnN"";
        string actual = europeanStr.LatinizeAndConvertToASCII();
        Assert.AreEqual(expected, actual);
    }

    Popping this Library here if you haven't already considered it. Looks like there are a full range of unit tests with it. 

https://github.com/thomasgalliker/Diacritics.NET
    This is how i replace diacritic characters to non-diacritic ones in all my .NET program

C#:

//Transforms the culture of a letter to its equivalent representation in the 0-127 ascii table, such as the letter 'é' is substituted by an 'e'
public string RemoveDiacritics(string s)
{
    string normalizedString = null;
    StringBuilder stringBuilder = new StringBuilder();
    normalizedString = s.Normalize(NormalizationForm.FormD);
    int i = 0;
    char c = '\0';

    for (i = 0; i <= normalizedString.Length - 1; i++)
    {
        c = normalizedString[i];
        if (CharUnicodeInfo.GetUnicodeCategory(c) != UnicodeCategory.NonSpacingMark)
        {
            stringBuilder.Append(c);
        }
    }

    return stringBuilder.ToString().ToLower();
}


VB .NET:

'Transforms the culture of a letter to its equivalent representation in the 0-127 ascii table, such as the letter ""é"" is substituted by an ""e""'
Public Function RemoveDiacritics(ByVal s As String) As String
    Dim normalizedString As String
    Dim stringBuilder As New StringBuilder
    normalizedString = s.Normalize(NormalizationForm.FormD)
    Dim i As Integer
    Dim c As Char

    For i = 0 To normalizedString.Length - 1
        c = normalizedString(i)
        If CharUnicodeInfo.GetUnicodeCategory(c) <> UnicodeCategory.NonSpacingMark Then
            stringBuilder.Append(c)
        End If
    Next
    Return stringBuilder.ToString().ToLower()
End Function

    THIS IS THE VB VERSION (Works with GREEK) :

Imports System.Text

Imports System.Globalization

Public Function RemoveDiacritics(ByVal s As String)
    Dim normalizedString As String
    Dim stringBuilder As New StringBuilder
    normalizedString = s.Normalize(NormalizationForm.FormD)
    Dim i As Integer
    Dim c As Char
    For i = 0 To normalizedString.Length - 1
        c = normalizedString(i)
        If CharUnicodeInfo.GetUnicodeCategory(c) <> UnicodeCategory.NonSpacingMark Then
            stringBuilder.Append(c)
        End If
    Next
    Return stringBuilder.ToString()
End Function

    I really like the concise and functional code provided by azrafe7.
So, I have changed it a little bit to convert it to an extension method:

public static class StringExtensions
{
    public static string RemoveDiacritics(this string text)
    {
        const string SINGLEBYTE_LATIN_ASCII_ENCODING = ""ISO-8859-8"";

        if (string.IsNullOrEmpty(text))
        {
            return string.Empty;
        }

        return Encoding.ASCII.GetString(
            Encoding.GetEncoding(SINGLEBYTE_LATIN_ASCII_ENCODING).GetBytes(text));
    }
}

    Imports System.Text
Imports System.Globalization

 Public Function DECODE(ByVal x As String) As String
        Dim sb As New StringBuilder
        For Each c As Char In x.Normalize(NormalizationForm.FormD).Where(Function(a) CharUnicodeInfo.GetUnicodeCategory(a) <> UnicodeCategory.NonSpacingMark)  
            sb.Append(c)
        Next
        Return sb.ToString()
    End Function

    you can use string extension from MMLib.Extensions nuget package:

using MMLib.RapidPrototyping.Generators;
public void ExtensionsExample()
{
  string target = ""aácčeéií"";
  Assert.AreEqual(""aacceeii"", target.RemoveDiacritics());
} 




Nuget page: https://www.nuget.org/packages/MMLib.Extensions/
Codeplex project site https://mmlib.codeplex.com/
    In case someone is interested, I was looking for something similar and ended writing the following:

public static string NormalizeStringForUrl(string name)
{
    String normalizedString = name.Normalize(NormalizationForm.FormD);
    StringBuilder stringBuilder = new StringBuilder();

    foreach (char c in normalizedString)
    {
        switch (CharUnicodeInfo.GetUnicodeCategory(c))
        {
            case UnicodeCategory.LowercaseLetter:
            case UnicodeCategory.UppercaseLetter:
            case UnicodeCategory.DecimalDigitNumber:
                stringBuilder.Append(c);
                break;
            case UnicodeCategory.SpaceSeparator:
            case UnicodeCategory.ConnectorPunctuation:
            case UnicodeCategory.DashPunctuation:
                stringBuilder.Append('_');
                break;
        }
    }
    string result = stringBuilder.ToString();
    return String.Join(""_"", result.Split(new char[] { '_' }
        , StringSplitOptions.RemoveEmptyEntries)); // remove duplicate underscores
}

    Try HelperSharp package.

There is a method RemoveAccents:

 public static string RemoveAccents(this string source)
 {
     //8 bit characters 
     byte[] b = Encoding.GetEncoding(1251).GetBytes(source);

     // 7 bit characters
     string t = Encoding.ASCII.GetString(b);
     Regex re = new Regex(""[^a-zA-Z0-9]=-_/"");
     string c = re.Replace(t, "" "");
     return c;
 }

    What this person said:

Encoding.ASCII.GetString(Encoding.GetEncoding(1251).GetBytes(text));

It actually splits the likes of å which is one character (which is character code 00E5, not 0061 plus the modifier 030A which would look the same) into a plus some kind of modifier, and then the ASCII conversion removes the modifier, leaving the only a.
    This code worked for me:
var updatedText = text.Normalize(NormalizationForm.FormD)
     .Where(c => CharUnicodeInfo.GetUnicodeCategory(c) != UnicodeCategory.NonSpacingMark)
     .ToArray();

However, please don't do this with names. It's not only an insult to people with umlauts/accents in their name, it can also be dangerously wrong in certain situations (see below). There are alternative writings instead of just removing the accent.
Furthermore, it's simply wrong and dangerous, e.g. if the user has to provide his name exactly how it occurs on the passport.
For example my name is written Zuberbühler and in the machine readable part of my passport you will find Zuberbuehler. By removing the umlaut, the name will not match with either part. This can lead to issues for the users.
You should rather disallow umlauts/accent in an input form for names so the user can write his name correctly without its umlaut or accent.
Practical example, if the web service to apply for ESTA (https://www.application-esta.co.uk/special-characters-and) would use above code instead of transforming umlauts correctly, the ESTA application would either be refused or the traveller will have problems with the American Border Control when entering the States.
Another example would be flight tickets. Assuming you have a flight ticket booking web application, the user provides his name with an accent and your implementation is just removing the accents and then using the airline's web service to book the ticket! Your customer may not be allowed to board since the name does not match to any part of his/her passport.
    ","[492, 602, 9, 205, 2, 39, -4, 9, 13, 16, 6, 3, 3, 3, 1, 1, 1, 35, 1, 1, 0]",262851,188,2008-10-30T02:07:46,2022-04-10 14:31:43Z,
MySQL Error 1153 - Got a packet bigger than 'max_allowed_packet' bytes,"
                
I'm importing a MySQL dump and getting the following error.

$ mysql foo < foo.sql 
ERROR 1153 (08S01) at line 96: Got a packet bigger than 'max_allowed_packet' bytes


Apparently there are attachments in the database, which makes for very large inserts.



This is on my local machine, a Mac with MySQL 5 installed from the MySQL package.

Where do I change max_allowed_packet to be able to import the dump?  

Is there anything else I should set?  

Just running mysql --max_allowed_packet=32M … resulted in the same error.
    You probably have to change it for both the client (you are running to do the import) AND the daemon mysqld that is running and accepting the import.
For the client, you can specify it on the command line:
mysql --max_allowed_packet=100M -u root -p database < dump.sql

Also, change the my.cnf or my.ini file (usually found in /etc/mysql/) under the mysqld section and set:
max_allowed_packet=100M

or you could run these commands in a MySQL console connected to that same server:
set global net_buffer_length=1000000; 
set global max_allowed_packet=1000000000;

(Use a very large value for the packet size.)
    As michaelpryor said, you have to change it for both the client and the daemon mysqld  server.

His solution for the client command-line is good, but the ini files don't always do the trick, depending on configuration. 

So, open a terminal, type mysql to get a mysql prompt, and issue these commands:

set global net_buffer_length=1000000; 
set global max_allowed_packet=1000000000; 


Keep the mysql prompt open, and run your command-line SQL execution on a second terminal..
    In etc/my.cnf try changing the max_allowed _packet and net_buffer_length to

max_allowed_packet=100000000
net_buffer_length=1000000 


if this is not working then try changing to

max_allowed_packet=100M
net_buffer_length=100K 

    The fix is to increase the MySQL daemon’s max_allowed_packet. You can do this to a running daemon by logging in as Super and running the following commands. 

# mysql -u admin -p

mysql> set global net_buffer_length=1000000;
Query OK, 0 rows affected (0.00 sec)

mysql> set global max_allowed_packet=1000000000;
Query OK, 0 rows affected (0.00 sec)


Then to import your dump:

gunzip < dump.sql.gz | mysql -u admin -p database

    This can be changed in your my.ini file (on Windows, located in \Program Files\MySQL\MySQL Server) under the server section, for example:

[mysqld]

max_allowed_packet = 10M

    Error:


  ERROR 1153 (08S01) at line 6772: Got a packet bigger than
  'max_allowed_packet' bytes Operation failed with exitcode 1


QUERY:

SET GLOBAL max_allowed_packet=1073741824;
SHOW VARIABLES LIKE 'max_allowed_packet'; 


Max value:

Default Value (MySQL >= 8.0.3)  67108864
Default Value (MySQL <= 8.0.2)  4194304
Minimum Value   1024
Maximum Value   1073741824

    Re my.cnf on Mac OS X when using MySQL from the mysql.com dmg package distribution

By default, my.cnf is nowhere to be found.

You need to copy one of /usr/local/mysql/support-files/my*.cnf to /etc/my.cnf and restart mysqld. (Which you can do in the MySQL preference pane if you installed it.)
    On CENTOS 6 /etc/my.cnf , under [mysqld] section the correct syntax is:

[mysqld]
# added to avoid err ""Got a packet bigger than 'max_allowed_packet' bytes""
#
net_buffer_length=1000000 
max_allowed_packet=1000000000
#

    Sometimes type setting:

max_allowed_packet = 16M


in my.ini is not working. 

Try to determine the my.ini as follows:

set-variable = max_allowed_packet = 32M


or

set-variable = max_allowed_packet = 1000000000


Then restart the server:

/etc/init.d/mysql restart

    Use a max_allowed_packet variable issuing a command like

mysql --max_allowed_packet=32M
 -u root -p database < dump.sql
    Set max_allowed_packet to the same (or more) than what it was when you dumped it with mysqldump. If you can't do that, make the dump again with a smaller value.

That is, assuming you dumped it with mysqldump. If you used some other tool, you're on your own.
    Slightly unrelated to your problem, so here's one for Google.

If you didn't mysqldump the SQL, it might be that your SQL is broken. 

I just got this error by accidentally having an unclosed string literal in my code. Sloppy fingers happen.

That's a fantastic error message to get for a runaway string, thanks for that MySQL!
    It is  a security risk to have max_allowed_packet at higher value, as an attacker can push bigger sized packets and crash the system. 

So, Optimum Value of max_allowed_packet to be tuned and tested.

It is to better to change when required (using set global max_allowed_packet = xxx) 
than to have it as part of my.ini or my.conf.
    I am working in a shared hosting environment and I have hosted a website based on Drupal. I cannot edit the my.ini file or my.conf file too.

So, I deleted all the tables which were related to Cache and hence I could resolve this issue. Still I am looking for a perfect solution / way to handle this problem.

Edit - Deleting the tables created problems for me, coz Drupal was expecting that these tables should be existing. So I emptied the contents of these tables which solved the problem.
    I have resolved my issue by this query
SET GLOBAL max_allowed_packet=1073741824;

and check max_allowed_packet with this query
SHOW VARIABLES LIKE 'max_allowed_packet';

    ","[492, 682, 135, 15, 15, 45, 2, 17, 6, 1, 4, -1, 4, 1, 0, 0]",512588,139,2008-09-18T14:38:14,2021-12-29 11:08:22Z,
"Multidimensional Array [][] vs [,] [duplicate]","
                    
            
        
            
                
                    
                        This question already has answers here:
                        
                    
                
            
                    
                        What are the differences between a multidimensional array and an array of arrays in C#?
                            
                                (12 answers)
                            
                    
                Closed 8 years ago.
        

    

double[][] ServicePoint = new double[10][9]; // <-- gives an error (1)
double[,] ServicePoint = new double[10,9]; // <-- ok (2)


What's their difference? (1) yields an error, what's the reason?

And

double d = new double[9]
ServicePoint[0] = d;


using (2) will prompt an error. Why?
    One is an array of arrays, and one is a 2d array.  The former can be jagged, the latter is uniform.

That is, a double[][] can validly be:

double[][] x = new double[5][];

x[0] = new double[10];
x[1] = new double[5];
x[2] = new double[3];
x[3] = new double[100];
x[4] = new double[1];


Because each entry in the array is a reference to an array of double. With a jagged array, you can do an assignment to an array like you want in your second example:

x[0] = new double[13];


On the second item, because it is a uniform 2d array, you can't assign a 1d array to a row or column, because you must index both the row and column, which gets you down to a single double:

double[,] ServicePoint = new double[10,9];

ServicePoint[0]... // <-- meaningless, a 2d array can't use just one index.


UPDATE:

To clarify based on your question, the reason your #1 had a syntax error is because you had this:

double[][] ServicePoint = new double[10][9];


And you can't specify the second index at the time of construction.  The key is that ServicePoint is not a 2d array, but an 1d array (of arrays) and thus since you are creating a 1d array (of arrays), you specify only one index:

double[][] ServicePoint = new double[10][];


Then, when you create each item in the array, each of those are also arrays, so then you can specify their dimensions (which can be different, hence the term jagged array):

ServicePoint[0] = new double[13];
ServicePoint[1] = new double[20];


Hope that helps!
    In the first instance you are trying to create what is called a jagged array.

double[][] ServicePoint = new double[10][9].


The above statement would have worked if it was defined like below. 

double[][] ServicePoint = new double[10][]


what this means is you are creating an array of size 10 ,that can store 10 differently sized arrays inside it.In simple terms an Array of arrays.see the below image,which signifies a jagged array.



http://msdn.microsoft.com/en-us/library/2s05feca(v=vs.80).aspx

The second one is basically a two dimensional array and the syntax is correct and acceptable.

  double[,] ServicePoint = new double[10,9];//<-ok (2)


And to access or modify a two dimensional array you have to pass both the dimensions,but in your case you are passing just a single dimension,thats why the error

Correct usage would be

ServicePoint[0][2] ,Refers to an item on the first row ,third column.

Pictorial rep of your two dimensional array


    double[,] is a 2d array (matrix) while double[][] is an array of arrays (jagged arrays) and the syntax is:

double[][] ServicePoint = new double[10][];

    double[][] are called jagged arrays , The inner dimensions aren’t specified in the declaration. Unlike a rectangular array, each inner array can be an arbitrary length. Each inner array is implicitly initialized to null rather than an empty array. Each inner array must be created manually: Reference [C# 4.0 in nutshell The definitive Reference]

for (int i = 0; i < matrix.Length; i++)
{
    matrix[i] = new int [3]; // Create inner array
    for (int j = 0; j < matrix[i].Length; j++)
        matrix[i][j] = i * 3 + j;
}


double[,] are called rectangular arrays, which are declared using commas to separate each dimension. The following piece of code declares a rectangular 3-by-3 two-dimensional array, initializing it with numbers from 0 to 8:

int [,] matrix = new int [3, 3];
for (int i = 0; i < matrix.GetLength(0); i++)
    for (int j = 0; j < matrix.GetLength(1); j++)
        matrix [i, j] = i * 3 + j;

    double[][] is an array of arrays and double[,] is a matrix. If you want to initialize an array of array, you will need to do this:

double[][] ServicePoint = new double[10][]
for(var i=0;i<ServicePoint.Length;i++)
    ServicePoint[i] = new double[9];


Take in account that using arrays of arrays will let you have arrays of different lengths:

ServicePoint[0] = new double[10];
ServicePoint[1] = new double[3];
ServicePoint[2] = new double[5];
//and so on...

    ","[492, 543, 236, 23, 68, 9]",707549,121,2012-09-24T14:41:41,2016-04-20 20:07:58Z,c 
How to convert a Kotlin source file to a Java source file,"
                
I have a Kotlin source file, but I want to translate it to Java.

How can I convert Kotlin to Java source?
    As @Vadzim said, in IntelliJ or Android Studio, you just have to do the following to get java code from kotlin:


Menu > Tools > Kotlin > Show Kotlin Bytecode
Click on the Decompile button
Copy the java code


Update:

With a recent version (1.2+) of the Kotlin plugin you also can directly do Menu > Tools > Kotlin -> Decompile Kotlin to Java.
    you can go to Tools > Kotlin > Show kotlin bytecode 






    
  To convert a Kotlin source file to a Java source file you need to (when you in Android Studio):



Press Cmd-Shift-A on a Mac,
or press Ctrl-Shift-A on a Windows machine.
Type the action you're looking for: Kotlin Bytecode and choose Show Kotlin Bytecode from menu.





Press Decompile button on the top of Kotlin Bytecode panel.





Now you get a Decompiled Java file along with Kotlin file in a adjacent tab:



    You can compile Kotlin to bytecode, then use a Java disassembler. 

The decompiling may be done inside IntelliJ Idea, or using FernFlower https://github.com/fesh0r/fernflower (thanks @Jire)

There was no automated tool as I checked a couple months ago (and no plans for one AFAIK)
    As @louis-cad mentioned ""Kotlin source -> Java's byte code -> Java source"" is the only solution so far.

But I would like to mention the way, which I prefer: using Jadx decompiler for Android.

It allows to see the generates code for closures and, as for me, resulting code is ""cleaner"" then one from IntelliJ IDEA decompiler.

Normally when I need to see Java source code of any Kotlin class I do: 


Generate apk: ./gradlew assembleDebug
Open apk using Jadx GUI: jadx-gui ./app/build/outputs/apk/debug/app-debug.apk


In this GUI basic IDE functionality works: class search, click to go declaration. etc.

Also all the source code could be saved and then viewed using other tools like IntelliJ IDEA.
    I compile Kotlin to byte code and then de-compile that to Java. I compile with the Kotlin compiler and de-compile with cfr.

My project is here.

This allows me to compile this:

package functionsiiiandiiilambdas.functions.p01tailiiirecursive

tailrec fun findFixPoint(x: Double = 1.0): Double =
        if (x == Math.cos(x)) x else findFixPoint(Math.cos(x))


To this:

package functionsiiiandiiilambdas.functions.p01tailiiirecursive;

public final class ExampleKt {
  public static final double findFixPoint(double x) {
    while (x != Math.cos(x)) {
      x = Math.cos(x);
    }
    return x;
  }

  public static /* bridge */ /* synthetic */ double findFixPoint$default(
      double d, int n, Object object) {
    if ((n & 1) != 0) {
      d = 1.0;
    }
    return ExampleKt.findFixPoint(d);
  }
}

    Java and Kotlin runs on Java Virtual Machine (JVM).

Converting a Kotlin file to Java file involves two steps i.e. compiling the Kotlin code to the JVM bytecode and then decompile the bytecode to the Java code.

Steps to convert your Kotlin source file to Java source file:


Open your Kotlin project in the Android Studio.
Then navigate to Tools -> Kotlin -> Show Kotlin Bytecode.





You will get the bytecode of your Kotin file.
Now click on the Decompile button to get your Java code from the bytecode

    
open kotlin file in android studio
go to tools -> kotlin ->kotlin bytecode 
in the new window that open beside your kotlin file , click the decompile button . it will create java equivalent of your kotlin file .

    ","[492, 502, 33, 17, 42, 6, 9, 3, 3]",332258,67,2016-01-22T23:07:14,2021-07-04 08:50:31Z,java kotlin 
How to determine the current iPhone/device model?,"
                
Is there a way to get the device model name (iPhone 4S, iPhone 5, iPhone 5S, etc) in Swift?

I know there is a property named UIDevice.currentDevice().model but it only returns device type (iPod touch, iPhone, iPad, iPhone Simulator, etc).

I also know it can be done easily in Objective-C with this method:

#import <sys/utsname.h>

struct utsname systemInfo;
uname(&systemInfo);

NSString* deviceModel = [NSString stringWithCString:systemInfo.machine
                          encoding:NSUTF8StringEncoding];


But I'm developing my iPhone app in Swift so could someone please help me with the equivalent way to solve this in Swift?
    I made this ""pure Swift"" extension on UIDevice.
If you are looking for a more elegant solution you can use my µ-framework DeviceKit published on GitHub (also available via CocoaPods, Carthage and Swift Package Manager).
Here's the code:
import UIKit

public extension UIDevice {

    static let modelName: String = {
        var systemInfo = utsname()
        uname(&systemInfo)
        let machineMirror = Mirror(reflecting: systemInfo.machine)
        let identifier = machineMirror.children.reduce("""") { identifier, element in
            guard let value = element.value as? Int8, value != 0 else { return identifier }
            return identifier + String(UnicodeScalar(UInt8(value)))
        }

        func mapToDevice(identifier: String) -> String { // swiftlint:disable:this cyclomatic_complexity
            #if os(iOS)
            switch identifier {
            case ""iPod5,1"":                                       return ""iPod touch (5th generation)""
            case ""iPod7,1"":                                       return ""iPod touch (6th generation)""
            case ""iPod9,1"":                                       return ""iPod touch (7th generation)""
            case ""iPhone3,1"", ""iPhone3,2"", ""iPhone3,3"":           return ""iPhone 4""
            case ""iPhone4,1"":                                     return ""iPhone 4s""
            case ""iPhone5,1"", ""iPhone5,2"":                        return ""iPhone 5""
            case ""iPhone5,3"", ""iPhone5,4"":                        return ""iPhone 5c""
            case ""iPhone6,1"", ""iPhone6,2"":                        return ""iPhone 5s""
            case ""iPhone7,2"":                                     return ""iPhone 6""
            case ""iPhone7,1"":                                     return ""iPhone 6 Plus""
            case ""iPhone8,1"":                                     return ""iPhone 6s""
            case ""iPhone8,2"":                                     return ""iPhone 6s Plus""
            case ""iPhone9,1"", ""iPhone9,3"":                        return ""iPhone 7""
            case ""iPhone9,2"", ""iPhone9,4"":                        return ""iPhone 7 Plus""
            case ""iPhone10,1"", ""iPhone10,4"":                      return ""iPhone 8""
            case ""iPhone10,2"", ""iPhone10,5"":                      return ""iPhone 8 Plus""
            case ""iPhone10,3"", ""iPhone10,6"":                      return ""iPhone X""
            case ""iPhone11,2"":                                    return ""iPhone XS""
            case ""iPhone11,4"", ""iPhone11,6"":                      return ""iPhone XS Max""
            case ""iPhone11,8"":                                    return ""iPhone XR""
            case ""iPhone12,1"":                                    return ""iPhone 11""
            case ""iPhone12,3"":                                    return ""iPhone 11 Pro""
            case ""iPhone12,5"":                                    return ""iPhone 11 Pro Max""
            case ""iPhone13,1"":                                    return ""iPhone 12 mini""
            case ""iPhone13,2"":                                    return ""iPhone 12""
            case ""iPhone13,3"":                                    return ""iPhone 12 Pro""
            case ""iPhone13,4"":                                    return ""iPhone 12 Pro Max""
            case ""iPhone14,4"":                                    return ""iPhone 13 mini""
            case ""iPhone14,5"":                                    return ""iPhone 13""
            case ""iPhone14,2"":                                    return ""iPhone 13 Pro""
            case ""iPhone14,3"":                                    return ""iPhone 13 Pro Max""
            case ""iPhone8,4"":                                     return ""iPhone SE""
            case ""iPhone12,8"":                                    return ""iPhone SE (2nd generation)""
            case ""iPhone14,6"":                                    return ""iPhone SE (3rd generation)""
            case ""iPad2,1"", ""iPad2,2"", ""iPad2,3"", ""iPad2,4"":      return ""iPad 2""
            case ""iPad3,1"", ""iPad3,2"", ""iPad3,3"":                 return ""iPad (3rd generation)""
            case ""iPad3,4"", ""iPad3,5"", ""iPad3,6"":                 return ""iPad (4th generation)""
            case ""iPad6,11"", ""iPad6,12"":                          return ""iPad (5th generation)""
            case ""iPad7,5"", ""iPad7,6"":                            return ""iPad (6th generation)""
            case ""iPad7,11"", ""iPad7,12"":                          return ""iPad (7th generation)""
            case ""iPad11,6"", ""iPad11,7"":                          return ""iPad (8th generation)""
            case ""iPad12,1"", ""iPad12,2"":                          return ""iPad (9th generation)""
            case ""iPad4,1"", ""iPad4,2"", ""iPad4,3"":                 return ""iPad Air""
            case ""iPad5,3"", ""iPad5,4"":                            return ""iPad Air 2""
            case ""iPad11,3"", ""iPad11,4"":                          return ""iPad Air (3rd generation)""
            case ""iPad13,1"", ""iPad13,2"":                          return ""iPad Air (4th generation)""
            case ""iPad13,16"", ""iPad13,17"":                        return ""iPad Air (5th generation)""
            case ""iPad2,5"", ""iPad2,6"", ""iPad2,7"":                 return ""iPad mini""
            case ""iPad4,4"", ""iPad4,5"", ""iPad4,6"":                 return ""iPad mini 2""
            case ""iPad4,7"", ""iPad4,8"", ""iPad4,9"":                 return ""iPad mini 3""
            case ""iPad5,1"", ""iPad5,2"":                            return ""iPad mini 4""
            case ""iPad11,1"", ""iPad11,2"":                          return ""iPad mini (5th generation)""
            case ""iPad14,1"", ""iPad14,2"":                          return ""iPad mini (6th generation)""
            case ""iPad6,3"", ""iPad6,4"":                            return ""iPad Pro (9.7-inch)""
            case ""iPad7,3"", ""iPad7,4"":                            return ""iPad Pro (10.5-inch)""
            case ""iPad8,1"", ""iPad8,2"", ""iPad8,3"", ""iPad8,4"":      return ""iPad Pro (11-inch) (1st generation)""
            case ""iPad8,9"", ""iPad8,10"":                           return ""iPad Pro (11-inch) (2nd generation)""
            case ""iPad13,4"", ""iPad13,5"", ""iPad13,6"", ""iPad13,7"":  return ""iPad Pro (11-inch) (3rd generation)""
            case ""iPad6,7"", ""iPad6,8"":                            return ""iPad Pro (12.9-inch) (1st generation)""
            case ""iPad7,1"", ""iPad7,2"":                            return ""iPad Pro (12.9-inch) (2nd generation)""
            case ""iPad8,5"", ""iPad8,6"", ""iPad8,7"", ""iPad8,8"":      return ""iPad Pro (12.9-inch) (3rd generation)""
            case ""iPad8,11"", ""iPad8,12"":                          return ""iPad Pro (12.9-inch) (4th generation)""
            case ""iPad13,8"", ""iPad13,9"", ""iPad13,10"", ""iPad13,11"":return ""iPad Pro (12.9-inch) (5th generation)""
            case ""AppleTV5,3"":                                    return ""Apple TV""
            case ""AppleTV6,2"":                                    return ""Apple TV 4K""
            case ""AudioAccessory1,1"":                             return ""HomePod""
            case ""AudioAccessory5,1"":                             return ""HomePod mini""
            case ""i386"", ""x86_64"", ""arm64"":                       return ""Simulator \(mapToDevice(identifier: ProcessInfo().environment[""SIMULATOR_MODEL_IDENTIFIER""] ?? ""iOS""))""
            default:                                              return identifier
            }
            #elseif os(tvOS)
            switch identifier {
            case ""AppleTV5,3"": return ""Apple TV 4""
            case ""AppleTV6,2"": return ""Apple TV 4K""
            case ""i386"", ""x86_64"": return ""Simulator \(mapToDevice(identifier: ProcessInfo().environment[""SIMULATOR_MODEL_IDENTIFIER""] ?? ""tvOS""))""
            default: return identifier
            }
            #endif
        }

        return mapToDevice(identifier: identifier)
    }()

}

You call it like this:
let modelName = UIDevice.modelName

For real devices it returns e.g. ""iPad Pro (12.9-inch) (5th generation)"", for simulators it returns e.g. ""Simulator iPad Pro (12.9-inch) (5th generation)""
Here's the model references:

https://theiphonewiki.com/wiki/Models
https://theiphonewiki.com/wiki/BORD

    Swift 5.x, both device & simulator updated to 2022
with the last: iPhone SE 3rd generation 2022, iPad Air 5th generation, iPhone 13 (all models), iPad 9th generation 2021, iPad mini 6th generation 2021, Apple Watch Series 7, iPad Pro (11-inch) (3rd generation), iPad Pro (12.9-inch) (5th generation) and Apple TV 4K (2nd generation) , (updates also for all iPods, Apple Watches and Apple TVs)
This method detects the correct model even if it's a simulator. (The exact name for the simulator device model running in your simulator)
With this answer you can check multiple device in few lines thanks to the  enums
example:
var myDefaultFontSize: CGFloat = 26.0
switch UIDevice().type {
    case .iPhoneSE, .iPhone5, .iPhone5S: print(""default value"")
    case .iPhone6, .iPhone7, .iPhone8, .iPhone6S, .iPhoneX: myDefaultFontSize += 4
    default: break
}

This is the code:
public enum Model : String {

//Simulator
case simulator     = ""simulator/sandbox"",

//iPod
iPod1              = ""iPod 1"",
iPod2              = ""iPod 2"",
iPod3              = ""iPod 3"",
iPod4              = ""iPod 4"",
iPod5              = ""iPod 5"",
iPod6              = ""iPod 6"",
iPod7              = ""iPod 7"",

//iPad
iPad2              = ""iPad 2"",
iPad3              = ""iPad 3"",
iPad4              = ""iPad 4"",
iPadAir            = ""iPad Air "",
iPadAir2           = ""iPad Air 2"",
iPadAir3           = ""iPad Air 3"",
iPadAir4           = ""iPad Air 4"",
iPadAir5           = ""iPad Air 5"",
iPad5              = ""iPad 5"", //iPad 2017
iPad6              = ""iPad 6"", //iPad 2018
iPad7              = ""iPad 7"", //iPad 2019
iPad8              = ""iPad 8"", //iPad 2020
iPad9              = ""iPad 9"", //iPad 2021

//iPad Mini
iPadMini           = ""iPad Mini"",
iPadMini2          = ""iPad Mini 2"",
iPadMini3          = ""iPad Mini 3"",
iPadMini4          = ""iPad Mini 4"",
iPadMini5          = ""iPad Mini 5"",
iPadMini6          = ""iPad Mini 6"",

//iPad Pro
iPadPro9_7         = ""iPad Pro 9.7\"""",
iPadPro10_5        = ""iPad Pro 10.5\"""",
iPadPro11          = ""iPad Pro 11\"""",
iPadPro2_11        = ""iPad Pro 11\"" 2nd gen"",
iPadPro3_11        = ""iPad Pro 11\"" 3rd gen"",
iPadPro12_9        = ""iPad Pro 12.9\"""",
iPadPro2_12_9      = ""iPad Pro 2 12.9\"""",
iPadPro3_12_9      = ""iPad Pro 3 12.9\"""",
iPadPro4_12_9      = ""iPad Pro 4 12.9\"""",
iPadPro5_12_9      = ""iPad Pro 5 12.9\"""",

//iPhone
iPhone4            = ""iPhone 4"",
iPhone4S           = ""iPhone 4S"",
iPhone5            = ""iPhone 5"",
iPhone5S           = ""iPhone 5S"",
iPhone5C           = ""iPhone 5C"",
iPhone6            = ""iPhone 6"",
iPhone6Plus        = ""iPhone 6 Plus"",
iPhone6S           = ""iPhone 6S"",
iPhone6SPlus       = ""iPhone 6S Plus"",
iPhoneSE           = ""iPhone SE"",
iPhone7            = ""iPhone 7"",
iPhone7Plus        = ""iPhone 7 Plus"",
iPhone8            = ""iPhone 8"",
iPhone8Plus        = ""iPhone 8 Plus"",
iPhoneX            = ""iPhone X"",
iPhoneXS           = ""iPhone XS"",
iPhoneXSMax        = ""iPhone XS Max"",
iPhoneXR           = ""iPhone XR"",
iPhone11           = ""iPhone 11"",
iPhone11Pro        = ""iPhone 11 Pro"",
iPhone11ProMax     = ""iPhone 11 Pro Max"",
iPhoneSE2          = ""iPhone SE 2nd gen"",
iPhone12Mini       = ""iPhone 12 Mini"",
iPhone12           = ""iPhone 12"",
iPhone12Pro        = ""iPhone 12 Pro"",
iPhone12ProMax     = ""iPhone 12 Pro Max"",
iPhone13Mini       = ""iPhone 13 Mini"",
iPhone13           = ""iPhone 13"",
iPhone13Pro        = ""iPhone 13 Pro"",
iPhone13ProMax     = ""iPhone 13 Pro Max"",
iPhoneSE3          = ""iPhone SE 3nd gen"",

// Apple Watch
AppleWatch1         = ""Apple Watch 1gen"",
AppleWatchS1        = ""Apple Watch Series 1"",
AppleWatchS2        = ""Apple Watch Series 2"",
AppleWatchS3        = ""Apple Watch Series 3"",
AppleWatchS4        = ""Apple Watch Series 4"",
AppleWatchS5        = ""Apple Watch Series 5"",
AppleWatchSE        = ""Apple Watch Special Edition"",
AppleWatchS6        = ""Apple Watch Series 6"",
AppleWatchS7        = ""Apple Watch Series 7"",

//Apple TV
AppleTV1           = ""Apple TV 1gen"",
AppleTV2           = ""Apple TV 2gen"",
AppleTV3           = ""Apple TV 3gen"",
AppleTV4           = ""Apple TV 4gen"",
AppleTV_4K         = ""Apple TV 4K"",
AppleTV2_4K        = ""Apple TV 4K 2gen"",

unrecognized       = ""?unrecognized?""
}

// #-#-#-#-#-#-#-#-#-#-#-#-#
// MARK: UIDevice extensions
// #-#-#-#-#-#-#-#-#-#-#-#-#

    public extension UIDevice {
    
    var type: Model {
        var systemInfo = utsname()
        uname(&systemInfo)
        let modelCode = withUnsafePointer(to: &systemInfo.machine) {
            $0.withMemoryRebound(to: CChar.self, capacity: 1) {
                ptr in String.init(validatingUTF8: ptr)
            }
        }
    
        let modelMap : [String: Model] = [
    
            //Simulator
            ""i386""      : .simulator,
            ""x86_64""    : .simulator,
    
            //iPod
            ""iPod1,1""   : .iPod1,
            ""iPod2,1""   : .iPod2,
            ""iPod3,1""   : .iPod3,
            ""iPod4,1""   : .iPod4,
            ""iPod5,1""   : .iPod5,
            ""iPod7,1""   : .iPod6,
            ""iPod9,1""   : .iPod7,
    
            //iPad
            ""iPad2,1""   : .iPad2,
            ""iPad2,2""   : .iPad2,
            ""iPad2,3""   : .iPad2,
            ""iPad2,4""   : .iPad2,
            ""iPad3,1""   : .iPad3,
            ""iPad3,2""   : .iPad3,
            ""iPad3,3""   : .iPad3,
            ""iPad3,4""   : .iPad4,
            ""iPad3,5""   : .iPad4,
            ""iPad3,6""   : .iPad4,
            ""iPad6,11""  : .iPad5, //iPad 2017
            ""iPad6,12""  : .iPad5,
            ""iPad7,5""   : .iPad6, //iPad 2018
            ""iPad7,6""   : .iPad6,
            ""iPad7,11""  : .iPad7, //iPad 2019
            ""iPad7,12""  : .iPad7,
            ""iPad11,6""  : .iPad8, //iPad 2020
            ""iPad11,7""  : .iPad8,
            ""iPad12,1""  : .iPad9, //iPad 2021
            ""iPad12,2""  : .iPad9,
    
            //iPad Mini
            ""iPad2,5""   : .iPadMini,
            ""iPad2,6""   : .iPadMini,
            ""iPad2,7""   : .iPadMini,
            ""iPad4,4""   : .iPadMini2,
            ""iPad4,5""   : .iPadMini2,
            ""iPad4,6""   : .iPadMini2,
            ""iPad4,7""   : .iPadMini3,
            ""iPad4,8""   : .iPadMini3,
            ""iPad4,9""   : .iPadMini3,
            ""iPad5,1""   : .iPadMini4,
            ""iPad5,2""   : .iPadMini4,
            ""iPad11,1""  : .iPadMini5,
            ""iPad11,2""  : .iPadMini5,
            ""iPad14,1""  : .iPadMini6,
            ""iPad14,2""  : .iPadMini6,
    
            //iPad Pro
            ""iPad6,3""   : .iPadPro9_7,
            ""iPad6,4""   : .iPadPro9_7,
            ""iPad7,3""   : .iPadPro10_5,
            ""iPad7,4""   : .iPadPro10_5,
            ""iPad6,7""   : .iPadPro12_9,
            ""iPad6,8""   : .iPadPro12_9,
            ""iPad7,1""   : .iPadPro2_12_9,
            ""iPad7,2""   : .iPadPro2_12_9,
            ""iPad8,1""   : .iPadPro11,
            ""iPad8,2""   : .iPadPro11,
            ""iPad8,3""   : .iPadPro11,
            ""iPad8,4""   : .iPadPro11,
            ""iPad8,9""   : .iPadPro2_11,
            ""iPad8,10""  : .iPadPro2_11,
            ""iPad13,4""  : .iPadPro3_11,
            ""iPad13,5""  : .iPadPro3_11,
            ""iPad13,6""  : .iPadPro3_11,
            ""iPad13,7""  : .iPadPro3_11,
            ""iPad8,5""   : .iPadPro3_12_9,
            ""iPad8,6""   : .iPadPro3_12_9,
            ""iPad8,7""   : .iPadPro3_12_9,
            ""iPad8,8""   : .iPadPro3_12_9,
            ""iPad8,11""  : .iPadPro4_12_9,
            ""iPad8,12""  : .iPadPro4_12_9,
            ""iPad13,8""  : .iPadPro5_12_9,
            ""iPad13,9""  : .iPadPro5_12_9,
            ""iPad13,10"" : .iPadPro5_12_9,
            ""iPad13,11"" : .iPadPro5_12_9,
    
            //iPad Air
            ""iPad4,1""   : .iPadAir,
            ""iPad4,2""   : .iPadAir,
            ""iPad4,3""   : .iPadAir,
            ""iPad5,3""   : .iPadAir2,
            ""iPad5,4""   : .iPadAir2,
            ""iPad11,3""  : .iPadAir3,
            ""iPad11,4""  : .iPadAir3,
            ""iPad13,1""  : .iPadAir4,
            ""iPad13,2""  : .iPadAir4,
            ""iPad13,16"" : .iPadAir5,
            ""iPad13,17"" : .iPadAir5,
    
            //iPhone
            ""iPhone3,1"" : .iPhone4,
            ""iPhone3,2"" : .iPhone4,
            ""iPhone3,3"" : .iPhone4,
            ""iPhone4,1"" : .iPhone4S,
            ""iPhone5,1"" : .iPhone5,
            ""iPhone5,2"" : .iPhone5,
            ""iPhone5,3"" : .iPhone5C,
            ""iPhone5,4"" : .iPhone5C,
            ""iPhone6,1"" : .iPhone5S,
            ""iPhone6,2"" : .iPhone5S,
            ""iPhone7,1"" : .iPhone6Plus,
            ""iPhone7,2"" : .iPhone6,
            ""iPhone8,1"" : .iPhone6S,
            ""iPhone8,2"" : .iPhone6SPlus,
            ""iPhone8,4"" : .iPhoneSE,
            ""iPhone9,1"" : .iPhone7,
            ""iPhone9,3"" : .iPhone7,
            ""iPhone9,2"" : .iPhone7Plus,
            ""iPhone9,4"" : .iPhone7Plus,
            ""iPhone10,1"" : .iPhone8,
            ""iPhone10,4"" : .iPhone8,
            ""iPhone10,2"" : .iPhone8Plus,
            ""iPhone10,5"" : .iPhone8Plus,
            ""iPhone10,3"" : .iPhoneX,
            ""iPhone10,6"" : .iPhoneX,
            ""iPhone11,2"" : .iPhoneXS,
            ""iPhone11,4"" : .iPhoneXSMax,
            ""iPhone11,6"" : .iPhoneXSMax,
            ""iPhone11,8"" : .iPhoneXR,
            ""iPhone12,1"" : .iPhone11,
            ""iPhone12,3"" : .iPhone11Pro,
            ""iPhone12,5"" : .iPhone11ProMax,
            ""iPhone12,8"" : .iPhoneSE2,
            ""iPhone13,1"" : .iPhone12Mini,
            ""iPhone13,2"" : .iPhone12,
            ""iPhone13,3"" : .iPhone12Pro,
            ""iPhone13,4"" : .iPhone12ProMax,
            ""iPhone14,4"" : .iPhone13Mini,
            ""iPhone14,5"" : .iPhone13,
            ""iPhone14,2"" : .iPhone13Pro,
            ""iPhone14,3"" : .iPhone13ProMax,
            ""iPhone14,6"" : .iPhoneSE3,
            
            // Apple Watch
            ""Watch1,1"" : .AppleWatch1,
            ""Watch1,2"" : .AppleWatch1,
            ""Watch2,6"" : .AppleWatchS1,
            ""Watch2,7"" : .AppleWatchS1,
            ""Watch2,3"" : .AppleWatchS2,
            ""Watch2,4"" : .AppleWatchS2,
            ""Watch3,1"" : .AppleWatchS3,
            ""Watch3,2"" : .AppleWatchS3,
            ""Watch3,3"" : .AppleWatchS3,
            ""Watch3,4"" : .AppleWatchS3,
            ""Watch4,1"" : .AppleWatchS4,
            ""Watch4,2"" : .AppleWatchS4,
            ""Watch4,3"" : .AppleWatchS4,
            ""Watch4,4"" : .AppleWatchS4,
            ""Watch5,1"" : .AppleWatchS5,
            ""Watch5,2"" : .AppleWatchS5,
            ""Watch5,3"" : .AppleWatchS5,
            ""Watch5,4"" : .AppleWatchS5,
            ""Watch5,9"" : .AppleWatchSE,
            ""Watch5,10"" : .AppleWatchSE,
            ""Watch5,11"" : .AppleWatchSE,
            ""Watch5,12"" : .AppleWatchSE,
            ""Watch6,1"" : .AppleWatchS6,
            ""Watch6,2"" : .AppleWatchS6,
            ""Watch6,3"" : .AppleWatchS6,
            ""Watch6,4"" : .AppleWatchS6,
            ""Watch6,6"" : .AppleWatchS7,
            ""Watch6,7"" : .AppleWatchS7,
            ""Watch6,8"" : .AppleWatchS7,
            ""Watch6,9"" : .AppleWatchS7,
    
            //Apple TV
            ""AppleTV1,1"" : .AppleTV1,
            ""AppleTV2,1"" : .AppleTV2,
            ""AppleTV3,1"" : .AppleTV3,
            ""AppleTV3,2"" : .AppleTV3,
            ""AppleTV5,3"" : .AppleTV4,
            ""AppleTV6,2"" : .AppleTV_4K,
            ""AppleTV11,1"" : .AppleTV2_4K
        ]
    
        guard let mcode = modelCode, let map = String(validatingUTF8: mcode), let model = modelMap[map] else { return Model.unrecognized }
        if model == .simulator {
            if let simModelCode = ProcessInfo().environment[""SIMULATOR_MODEL_IDENTIFIER""] {
                if let simMap = String(validatingUTF8: simModelCode), let simModel = modelMap[simMap] {
                    return simModel
                }
            }
        }
        return model
        }
    }

Usage:
You can simply get the device model with:
let deviceType = UIDevice().type

or print the exact string with:
print(""Running on: \(UIDevice().type)"")
Output -> ""iPhone X""

Another example with cases:
var myDefaultHeight: CGFloat = 30.0
switch UIDevice().type {
    case .iPhoneSE, .iPhone5, .iPhone5S: print(""default value"")
    case .iPhone6, .iPhone7, .iPhone8, .iPhone6S, .iPhoneX: myDefaultHeight+= 5
    case .iPhone11, .iPhone12, .iPhone13: myDefaultHeight+= 10
    default: break
}

For Apple devices models visit:
https://www.theiphonewiki.com/wiki/Models
P.S.: I've made a little new asyncronous experiment here (direct connection with THEIPHONEWIKI site, without long static device list in source code.
    Swift 5

/// Obtain the machine hardware platform from the `uname()` unix command
///
/// Example of return values
///  - `""iPhone8,1""` = iPhone 6s
///  - `""iPad6,7""` = iPad Pro (12.9-inch)
static var unameMachine: String {
    var utsnameInstance = utsname()
    uname(&utsnameInstance)
    let optionalString: String? = withUnsafePointer(to: &utsnameInstance.machine) {
        $0.withMemoryRebound(to: CChar.self, capacity: 1) {
            ptr in String.init(validatingUTF8: ptr)
        }
    }
    return optionalString ?? ""N/A""
}

    Yet another/simple alternative (model identifier reference found at https://www.theiphonewiki.com/wiki/Models):

Updated answer for Swift 3/4/5 including string trimming and simulator support:

func modelIdentifier() -> String {
    if let simulatorModelIdentifier = ProcessInfo().environment[""SIMULATOR_MODEL_IDENTIFIER""] { return simulatorModelIdentifier }
    var sysinfo = utsname()
    uname(&sysinfo) // ignore return value
    return String(bytes: Data(bytes: &sysinfo.machine, count: Int(_SYS_NAMELEN)), encoding: .ascii)!.trimmingCharacters(in: .controlCharacters)
}

    Using Swift 3 (Xcode 8.3)
    func deviceName() -> String {
        var systemInfo = utsname()
        uname(&systemInfo)
        let str = withUnsafePointer(to: &systemInfo.machine.0) { ptr in
            return String(cString: ptr)
        }
        return str
    }

Note: According to official dev forum answer, it is safe to use tuples in this way. Memory alignment for the big Int8 tuple will be the same as if it were a big Int8 array. ie: contiguous and not-padded.
    WikiDevice
the asynchronous library that gives you the answer from theiphonewiki
A crazy little experiment for automation fans like me. I made this algorithm that reads the identification code of the device, physical or simulated, and load the theiphonewiki page to extrapolate the model name based on the identification code (example iPhone11,2 -> iPhone XS). The algorithm interfaces with the WIKI page using the internal Wiki API Sandbox tool that allows you to have a JSON response, however the content is not obtainable in JSON (just the part that was needed, that is the wikitables) so I parsed the HTML content to get to the device name, without using third parts HTML parsing libraries.
PROS: always updated, you don't need to add new devices
CONS: asyncronous answer using the wiki page from web
P.S. Feel free to improve my code to get an even more precise result and a more elegant syntax
P.S.S. If you need a more immediate answer use my previous answer here in this page
public extension UIDevice {
    var identifier: String {
        var systemInfo = utsname()
        uname(&systemInfo)
        let modelCode = withUnsafePointer(to: &systemInfo.machine) {
            $0.withMemoryRebound(to: CChar.self, capacity: 1) {
                ptr in String.init(validatingUTF8: ptr)
            }
        }
        if modelCode == ""x86_64"" {
            if let simModelCode = ProcessInfo().environment[""SIMULATOR_MODEL_IDENTIFIER""] {
                if let simMap = String(validatingUTF8: simModelCode) {
                    return simMap
                }
            }
        }
        return modelCode ?? ""?unrecognized?""
    }
}
class WikiDevice {
    static func model(_ completion: @escaping ((String) -> ())){
        let unrecognized = ""?unrecognized?""
        guard let wikiUrl=URL(string:""https://www.theiphonewiki.com//w/api.php?action=parse&format=json&page=Models"") else { return completion(unrecognized) }
        var identifier: String {
            var systemInfo = utsname()
            uname(&systemInfo)
            let modelCode = withUnsafePointer(to: &systemInfo.machine) {
                $0.withMemoryRebound(to: CChar.self, capacity: 1) {
                    ptr in String.init(validatingUTF8: ptr)
                }
            }
            if modelCode == ""x86_64"" {
                if let simModelCode = ProcessInfo().environment[""SIMULATOR_MODEL_IDENTIFIER""] {
                    if let simMap = String(validatingUTF8: simModelCode) {
                        return simMap
                    }
                }
            }
            return modelCode ?? unrecognized
        }
        guard identifier != unrecognized else { return completion(unrecognized)}
        let request = URLRequest(url: wikiUrl)
        URLSession.shared.dataTask(with: request) { (data, response, error) in
            do {
                guard let data = data,
                    let response = response as? HTTPURLResponse, (200 ..< 300) ~= response.statusCode,
                    error == nil else { return completion(unrecognized) }
                guard let convertedString = String(data: data, encoding: String.Encoding.utf8) else { return completion(unrecognized) }
                var wikiTables = convertedString.components(separatedBy: ""wikitable"")
                wikiTables.removeFirst()
                var tables = [[String]]()
                wikiTables.enumerated().forEach{ index,table in
                    let rawRows = table.components(separatedBy: #""<tr>\n<td""#)
                    var counter = 0
                    var rows = [String]()
                    while counter < rawRows.count {
                        let rawRow = rawRows[counter]
                        if let subRowsNum = rawRow.components(separatedBy: #""rowspan=\""""#).dropFirst().compactMap({ sub in
                            (sub.range(of: #""\"">""#)?.lowerBound).flatMap { endRange in
                                String(sub[sub.startIndex ..< endRange])
                            }
                        }).first {
                            if let subRowsTot = Int(subRowsNum) {
                                var otherRows = """"
                                for i in counter..<counter+subRowsTot {
                                    otherRows += rawRows[i]
                                }
                                let row = rawRow + otherRows
                                rows.append(row)
                                counter += subRowsTot-1
                            }
                        } else {
                            rows.append(rawRows[counter])
                        }
                        counter += 1
                    }
                    tables.append(rows)
                }
                for table in tables {
                    if let rowIndex = table.firstIndex(where: {$0.lowercased().contains(identifier.lowercased())}) {
                        let rows = table[rowIndex].components(separatedBy: ""<td>"")
                        if rows.count>0 {
                            if rows[0].contains(""title"") { //hyperlink
                                if let (cleanedGen) = rows[0].components(separatedBy: #"">""#).dropFirst().compactMap({ sub in
                                    (sub.range(of: ""</"")?.lowerBound).flatMap { endRange in
                                        String(sub[sub.startIndex ..< endRange]).replacingOccurrences(of: #""\n""#, with: """")
                                    }
                                }).first {
                                    completion(cleanedGen)
                                }
                            } else {
                                let raw = rows[0].replacingOccurrences(of: ""<td>"", with: """")
                                let cleanedGen = raw.replacingOccurrences(of: #""\n""#, with: """")
                                completion(cleanedGen)
                            }
                            return
                        }
                    }
                }
                completion(unrecognized)
            }
        }.resume()
    }
}

Usage:
var deviceModel:String = """"
WikiDevice.model { (model) in
     print(""Using WikiDevice, running on: \(model)"")
     deviceModel = model
}

Output:
Using WikiDevice, running on: iPhone 11 Pro Max

GitHUB:
If you need to test this library you can download the test project from here
    For swift4.0 and above used below code:
let udid = UIDevice.current.identifierForVendor?.uuidString
let name = UIDevice.current.name
let version = UIDevice.current.systemVersion
let modelName = UIDevice.current.model
let osName = UIDevice.current.systemName
let localized = UIDevice.current.localizedModel

print(udid ?? """")
print(name)
print(version)
print(modelName)
print(osName)
print(localized)

    I've made another sample extension on UIDevice to include simulator model identifier base on @HAS's answer . It's working fine with Swift3.2 above(include Swift 4.x, Swift 5):
let modelName = UIDevice.current.modelName

New add Models: iPod touch (7th generation), iPhone SE (2nd generation), iPhone 12 mini, iPhone 12, iPhone 12 Pro, iPhone 12 Pro Max, iPad Pro (12.9-inch) (4th generation)
import UIKit

public extension UIDevice {

    /// pares the deveice name as the standard name
    var modelName: String {

        #if targetEnvironment(simulator)
            let identifier = ProcessInfo().environment[""SIMULATOR_MODEL_IDENTIFIER""]!
        #else
            var systemInfo = utsname()
            uname(&systemInfo)
            let machineMirror = Mirror(reflecting: systemInfo.machine)
            let identifier = machineMirror.children.reduce("""") { identifier, element in
                guard let value = element.value as? Int8, value != 0 else { return identifier }
                return identifier + String(UnicodeScalar(UInt8(value)))
            }
        #endif

        switch identifier {
        case ""iPod5,1"":                                 return ""iPod Touch 5""
        case ""iPod7,1"":                                 return ""iPod Touch 6""
        case ""iPod9,1"":                                 return ""iPod touch (7th generation)""
        case ""iPhone3,1"", ""iPhone3,2"", ""iPhone3,3"":     return ""iPhone 4""
        case ""iPhone4,1"":                               return ""iPhone 4s""
        case ""iPhone5,1"", ""iPhone5,2"":                  return ""iPhone 5""
        case ""iPhone5,3"", ""iPhone5,4"":                  return ""iPhone 5c""
        case ""iPhone6,1"", ""iPhone6,2"":                  return ""iPhone 5s""
        case ""iPhone7,2"":                               return ""iPhone 6""
        case ""iPhone7,1"":                               return ""iPhone 6 Plus""
        case ""iPhone8,1"":                               return ""iPhone 6s""
        case ""iPhone8,2"":                               return ""iPhone 6s Plus""
        case ""iPhone9,1"", ""iPhone9,3"":                  return ""iPhone 7""
        case ""iPhone9,2"", ""iPhone9,4"":                  return ""iPhone 7 Plus""
        case ""iPhone8,4"":                               return ""iPhone SE""
        case ""iPhone10,1"", ""iPhone10,4"":                return ""iPhone 8""
        case ""iPhone10,2"", ""iPhone10,5"":                return ""iPhone 8 Plus""
        case ""iPhone10,3"", ""iPhone10,6"":                return ""iPhone X""
        case ""iPhone11,2"":                              return ""iPhone XS""
        case ""iPhone11,4"", ""iPhone11,6"":                return ""iPhone XS Max""
        case ""iPhone11,8"":                              return ""iPhone XR""
        case ""iPhone12,1"":                              return ""iPhone 11""
        case ""iPhone12,3"":                              return ""iPhone 11 Pro""
        case ""iPhone12,5"":                              return ""iPhone 11 Pro Max""
        case ""iPhone12,8"":                              return ""iPhone SE (2nd generation)""
        case ""iPhone13,1"":                              return ""iPhone 12 mini""
        case ""iPhone13,2"":                              return ""iPhone 12""
        case ""iPhone13,3"":                              return ""iPhone 12 Pro""
        case ""iPhone13,4"":                              return ""iPhone 12 Pro Max""
        case ""iPad2,1"", ""iPad2,2"", ""iPad2,3"", ""iPad2,4"":return ""iPad 2""
        case ""iPad3,1"", ""iPad3,2"", ""iPad3,3"":           return ""iPad 3""
        case ""iPad3,4"", ""iPad3,5"", ""iPad3,6"":           return ""iPad 4""
        case ""iPad4,1"", ""iPad4,2"", ""iPad4,3"":           return ""iPad Air""
        case ""iPad5,3"", ""iPad5,4"":                      return ""iPad Air 2""
        case ""iPad6,11"", ""iPad6,12"":                    return ""iPad 5""
        case ""iPad7,5"", ""iPad7,6"":                      return ""iPad 6""
        case ""iPad2,5"", ""iPad2,6"", ""iPad2,7"":           return ""iPad Mini""
        case ""iPad4,4"", ""iPad4,5"", ""iPad4,6"":           return ""iPad Mini 2""
        case ""iPad4,7"", ""iPad4,8"", ""iPad4,9"":           return ""iPad Mini 3""
        case ""iPad5,1"", ""iPad5,2"":                      return ""iPad Mini 4""
        case ""iPad6,3"", ""iPad6,4"":                      return ""iPad Pro 9.7 Inch""
        case ""iPad6,7"", ""iPad6,8"":                      return ""iPad Pro 12.9 Inch""
        case ""iPad7,1"", ""iPad7,2"":                      return ""iPad Pro (12.9-inch) (2nd generation)""
        case ""iPad7,3"", ""iPad7,4"":                      return ""iPad Pro (10.5-inch)""
        case ""iPad8,1"", ""iPad8,2"", ""iPad8,3"", ""iPad8,4"":return ""iPad Pro (11-inch)""
        case ""iPad8,5"", ""iPad8,6"", ""iPad8,7"", ""iPad8,8"":return ""iPad Pro (12.9-inch) (3rd generation)""
        case ""iPad8,11"", ""iPad8,12"":                    return ""iPad Pro (12.9-inch) (4th generation)""
        case ""AppleTV5,3"":                              return ""Apple TV""
        case ""AppleTV6,2"":                              return ""Apple TV 4K""
        case ""AudioAccessory1,1"":                       return ""HomePod""
        default:                                        return identifier
        }
    }
}

    I found that a lot all these answers use strings. I decided to change @HAS answer to use an enum:

public enum Devices: String {
    case IPodTouch5
    case IPodTouch6
    case IPhone4
    case IPhone4S
    case IPhone5
    case IPhone5C
    case IPhone5S
    case IPhone6
    case IPhone6Plus
    case IPhone6S
    case IPhone6SPlus
    case IPhone7
    case IPhone7Plus
    case IPhoneSE
    case IPad2
    case IPad3
    case IPad4
    case IPadAir
    case IPadAir2
    case IPadMini
    case IPadMini2
    case IPadMini3
    case IPadMini4
    case IPadPro
    case AppleTV
    case Simulator
    case Other
}

public extension UIDevice {

    public var modelName: Devices {
        var systemInfo = utsname()
        uname(&systemInfo)
        let machineMirror = Mirror(reflecting: systemInfo.machine)
        let identifier = machineMirror.children.reduce("""") { identifier, element in
            guard let value = element.value as? Int8 , value != 0 else { return identifier }
            return identifier + String(UnicodeScalar(UInt8(value)))
        }

        switch identifier {
        case ""iPod5,1"":                                 return Devices.IPodTouch5
        case ""iPod7,1"":                                 return Devices.IPodTouch6
        case ""iPhone3,1"", ""iPhone3,2"", ""iPhone3,3"":     return Devices.IPhone4
        case ""iPhone4,1"":                               return Devices.IPhone4S
        case ""iPhone5,1"", ""iPhone5,2"":                  return Devices.IPhone5
        case ""iPhone5,3"", ""iPhone5,4"":                  return Devices.IPhone5C
        case ""iPhone6,1"", ""iPhone6,2"":                  return Devices.IPhone5S
        case ""iPhone7,2"":                               return Devices.IPhone6
        case ""iPhone7,1"":                               return Devices.IPhone6Plus
        case ""iPhone8,1"":                               return Devices.IPhone6S
        case ""iPhone8,2"":                               return Devices.IPhone6SPlus
        case ""iPhone9,1"", ""iPhone9,3"":                  return Devices.IPhone7
        case ""iPhone9,2"", ""iPhone9,4"":                  return Devices.IPhone7Plus
        case ""iPhone8,4"":                               return Devices.IPhoneSE
        case ""iPad2,1"", ""iPad2,2"", ""iPad2,3"", ""iPad2,4"":return Devices.IPad2
        case ""iPad3,1"", ""iPad3,2"", ""iPad3,3"":           return Devices.IPad3
        case ""iPad3,4"", ""iPad3,5"", ""iPad3,6"":           return Devices.IPad4
        case ""iPad4,1"", ""iPad4,2"", ""iPad4,3"":           return Devices.IPadAir
        case ""iPad5,3"", ""iPad5,4"":                      return Devices.IPadAir2
        case ""iPad2,5"", ""iPad2,6"", ""iPad2,7"":           return Devices.IPadMini
        case ""iPad4,4"", ""iPad4,5"", ""iPad4,6"":           return Devices.IPadMini2
        case ""iPad4,7"", ""iPad4,8"", ""iPad4,9"":           return Devices.IPadMini3
        case ""iPad5,1"", ""iPad5,2"":                      return Devices.IPadMini4
        case ""iPad6,3"", ""iPad6,4"", ""iPad6,7"", ""iPad6,8"":return Devices.IPadPro
        case ""AppleTV5,3"":                              return Devices.AppleTV
        case ""i386"", ""x86_64"":                          return Devices.Simulator
        default:                                        return Devices.Other
        }
    }

}

    There is a helper library for this.

Swift 5


  pod 'DeviceKit', '~> 2.0'


Swift 4.0 - Swift 4.2


  pod 'DeviceKit', '~> 1.3'


if you just want to determine the model and make something accordingly.

You can use like that : 

let isIphoneX = Device().isOneOf([.iPhoneX, .simulator(.iPhoneX)])


In a function : 

func isItIPhoneX() -> Bool {
    let device = Device()
    let check = device.isOneOf([.iPhoneX, .iPhoneXr , .iPhoneXs , .iPhoneXsMax ,
                                .simulator(.iPhoneX), .simulator(.iPhoneXr) , .simulator(.iPhoneXs) , .simulator(.iPhoneXsMax) ])
    return check
}

    If you do not want to keep updating your code everytime Apple adds a new model to a device family, use the method below returning you the model code only.

func platform() -> String {
        var systemInfo = utsname()
        uname(&systemInfo)
        let modelCode = withUnsafeMutablePointer(&systemInfo.machine) {
            ptr in String.fromCString(UnsafePointer<CChar>(ptr))
        }

        return String.fromCString(modelCode!)!
}

    Here an modification without force unwrap and Swift 3.0:

import Foundation
import UIKit


public enum Model : String {
    case simulator = ""simulator/sandbox"",
    iPod1          = ""iPod 1"",
    iPod2          = ""iPod 2"",
    iPod3          = ""iPod 3"",
    iPod4          = ""iPod 4"",
    iPod5          = ""iPod 5"",
    iPad2          = ""iPad 2"",
    iPad3          = ""iPad 3"",
    iPad4          = ""iPad 4"",
    iPhone4        = ""iPhone 4"",
    iPhone4S       = ""iPhone 4S"",
    iPhone5        = ""iPhone 5"",
    iPhone5S       = ""iPhone 5S"",
    iPhone5C       = ""iPhone 5C"",
    iPadMini1      = ""iPad Mini 1"",
    iPadMini2      = ""iPad Mini 2"",
    iPadMini3      = ""iPad Mini 3"",
    iPadAir1       = ""iPad Air 1"",
    iPadAir2       = ""iPad Air 2"",
    iPhone6        = ""iPhone 6"",
    iPhone6plus    = ""iPhone 6 Plus"",
    iPhone6S       = ""iPhone 6S"",
    iPhone6Splus   = ""iPhone 6S Plus"",
    iPhoneSE       = ""iPhone SE"",
    iPhone7        = ""iPhone 7"",
    iPhone7plus    = ""iPhone 7 Plus"",
    unrecognized   = ""?unrecognized?""
}

public extension UIDevice {
    public var type: Model {
        var systemInfo = utsname()
        uname(&systemInfo)
        let modelCode = withUnsafePointer(to: &systemInfo.machine) {
            $0.withMemoryRebound(to: CChar.self, capacity: 1) {
                ptr in String.init(validatingUTF8: ptr)

            }
        }
        var modelMap : [ String : Model ] = [
            ""i386""      : .simulator,
            ""x86_64""    : .simulator,
            ""iPod1,1""   : .iPod1,
            ""iPod2,1""   : .iPod2,
            ""iPod3,1""   : .iPod3,
            ""iPod4,1""   : .iPod4,
            ""iPod5,1""   : .iPod5,
            ""iPad2,1""   : .iPad2,
            ""iPad2,2""   : .iPad2,
            ""iPad2,3""   : .iPad2,
            ""iPad2,4""   : .iPad2,
            ""iPad2,5""   : .iPadMini1,
            ""iPad2,6""   : .iPadMini1,
            ""iPad2,7""   : .iPadMini1,
            ""iPhone3,1"" : .iPhone4,
            ""iPhone3,2"" : .iPhone4,
            ""iPhone3,3"" : .iPhone4,
            ""iPhone4,1"" : .iPhone4S,
            ""iPhone5,1"" : .iPhone5,
            ""iPhone5,2"" : .iPhone5,
            ""iPhone5,3"" : .iPhone5C,
            ""iPhone5,4"" : .iPhone5C,
            ""iPad3,1""   : .iPad3,
            ""iPad3,2""   : .iPad3,
            ""iPad3,3""   : .iPad3,
            ""iPad3,4""   : .iPad4,
            ""iPad3,5""   : .iPad4,
            ""iPad3,6""   : .iPad4,
            ""iPhone6,1"" : .iPhone5S,
            ""iPhone6,2"" : .iPhone5S,
            ""iPad4,1""   : .iPadAir1,
            ""iPad4,2""   : .iPadAir2,
            ""iPad4,4""   : .iPadMini2,
            ""iPad4,5""   : .iPadMini2,
            ""iPad4,6""   : .iPadMini2,
            ""iPad4,7""   : .iPadMini3,
            ""iPad4,8""   : .iPadMini3,
            ""iPad4,9""   : .iPadMini3,
            ""iPhone7,1"" : .iPhone6plus,
            ""iPhone7,2"" : .iPhone6,
            ""iPhone8,1"" : .iPhone6S,
            ""iPhone8,2"" : .iPhone6Splus,
            ""iPhone8,4"" : .iPhoneSE,
            ""iPhone9,1"" : .iPhone7,
            ""iPhone9,2"" : .iPhone7plus,
            ""iPhone9,3"" : .iPhone7,
            ""iPhone9,4"" : .iPhone7plus,
            ]

        guard let safeModelCode = modelCode else {
            return Model.unrecognized
        }

        guard let modelString = String.init(validatingUTF8: safeModelCode) else {
            return Model.unrecognized
        }

        guard let model = modelMap[modelString] else {
            return Model.unrecognized
        }

        return model
    }
}

    Swift 3.0 or higher

import UIKit

class ViewController: UIViewController {

    let device = UIDevice.current

    override func viewDidLoad() {
        super.viewDidLoad()

        let model = device.model
        print(model) // e.g. ""iPhone""

        let modelName = device.modelName
        print(modelName) // e.g. ""iPhone 6""  /* see the extension */

        let deviceName = device.name
        print(deviceName) // e.g. ""My iPhone""

        let systemName = device.systemName
        print(systemName) // e.g. ""iOS""

        let systemVersion = device.systemVersion
        print(systemVersion) // e.g. ""10.3.2""

        if let identifierForVendor = device.identifierForVendor {

            print(identifierForVendor) // e.g. ""E1X2XX34-5X6X-7890-123X-XXX456C78901""
        }
    }
}


and add the following extension

extension UIDevice {

    var modelName: String {

        var systemInfo = utsname()
        uname(&systemInfo)

        let machineMirror = Mirror(reflecting: systemInfo.machine)

        let identifier = machineMirror.children.reduce("""") { identifier, element in
            guard let value = element.value as? Int8, value != 0 else { return identifier }
            return identifier + String(UnicodeScalar(UInt8(value)))
        }

        switch identifier {

        case ""iPod5,1"":                                 return ""iPod Touch 5""
        case ""iPod7,1"":                                 return ""iPod Touch 6""
        case ""iPhone3,1"", ""iPhone3,2"", ""iPhone3,3"":     return ""iPhone 4""
        case ""iPhone4,1"":                               return ""iPhone 4s""
        case ""iPhone5,1"", ""iPhone5,2"":                  return ""iPhone 5""
        case ""iPhone5,3"", ""iPhone5,4"":                  return ""iPhone 5c""
        case ""iPhone6,1"", ""iPhone6,2"":                  return ""iPhone 5s""
        case ""iPhone7,2"":                               return ""iPhone 6""
        case ""iPhone7,1"":                               return ""iPhone 6 Plus""
        case ""iPhone8,1"":                               return ""iPhone 6s""
        case ""iPhone8,2"":                               return ""iPhone 6s Plus""
        case ""iPhone9,1"", ""iPhone9,3"":                  return ""iPhone 7""
        case ""iPhone9,2"", ""iPhone9,4"":                  return ""iPhone 7 Plus""
        case ""iPhone8,4"":                               return ""iPhone SE""
        case ""iPad2,1"", ""iPad2,2"", ""iPad2,3"", ""iPad2,4"":return ""iPad 2""
        case ""iPad3,1"", ""iPad3,2"", ""iPad3,3"":           return ""iPad 3""
        case ""iPad3,4"", ""iPad3,5"", ""iPad3,6"":           return ""iPad 4""
        case ""iPad4,1"", ""iPad4,2"", ""iPad4,3"":           return ""iPad Air""
        case ""iPad5,3"", ""iPad5,4"":                      return ""iPad Air 2""
        case ""iPad6,11"", ""iPad6,12"":                    return ""iPad 5""
        case ""iPad2,5"", ""iPad2,6"", ""iPad2,7"":           return ""iPad Mini""
        case ""iPad4,4"", ""iPad4,5"", ""iPad4,6"":           return ""iPad Mini 2""
        case ""iPad4,7"", ""iPad4,8"", ""iPad4,9"":           return ""iPad Mini 3""
        case ""iPad5,1"", ""iPad5,2"":                      return ""iPad Mini 4""
        case ""iPad6,3"", ""iPad6,4"":                      return ""iPad Pro 9.7 Inch""
        case ""iPad6,7"", ""iPad6,8"":                      return ""iPad Pro 12.9 Inch""
        case ""iPad7,1"", ""iPad7,2"":                      return ""iPad Pro 12.9 Inch 2. Generation""
        case ""iPad7,3"", ""iPad7,4"":                      return ""iPad Pro 10.5 Inch""
        case ""AppleTV5,3"":                              return ""Apple TV""
        case ""i386"", ""x86_64"":                          return ""Simulator""
        default:                                        return identifier
        }
    }
}

    Based on this answer and this answer. I've created a public gist

How it can be used

let boolean: Bool = UIDevice.isDevice(ofType: .iPhoneX)
// true or false

let specificDevice: DeviceModel.Model = UIDevice.modelType
// iPhone6s, iPhoneX, iPad etc...

let model: DeviceModel = UIDevice.model
// .simulator(let specificDevice), .real(let specificDevice),
// .unrecognizedSimulator(let string), .unrecognized(let string)

let modelName: String = UIDevice.model.name
// iPhone 6, iPhone X, etc...


This is the code inside the gist

public extension UIDevice {
    public static var modelCode: String {
        if let simulatorModelIdentifier = ProcessInfo().environment[""SIMULATOR_MODEL_IDENTIFIER""] { return simulatorModelIdentifier }
        var systemInfo = utsname()
        uname(&systemInfo)
        return withUnsafeMutablePointer(to: &systemInfo.machine) {
            ptr in String(cString: UnsafeRawPointer(ptr).assumingMemoryBound(to: CChar.self))
        }
    }

    public static var model: DeviceModel {
        // Thanks https://stackoverflow.com/a/26962452/5928180
        var systemInfo = utsname()
        uname(&systemInfo)
        let modelCode = withUnsafeMutablePointer(to: &systemInfo.machine) {
            ptr in String(cString: UnsafeRawPointer(ptr).assumingMemoryBound(to: CChar.self))
        }

        // Thanks https://stackoverflow.com/a/33495869/5928180
        if modelCode == ""i386"" || modelCode == ""x86_64"" {
            if let simulatorModelCode = ProcessInfo().environment[""SIMULATOR_MODEL_IDENTIFIER""], let model = DeviceModel.Model(modelCode: simulatorModelCode) {
                return DeviceModel.simulator(model)
            } else if let simulatorModelCode = ProcessInfo().environment[""SIMULATOR_MODEL_IDENTIFIER""] {
                return DeviceModel.unrecognizedSimulator(simulatorModelCode)
            } else {
                return DeviceModel.unrecognized(modelCode)
            }
        } else if let model = DeviceModel.Model(modelCode: modelCode) {
            return DeviceModel.real(model)
        } else {
            return DeviceModel.unrecognized(modelCode)
        }
    }

    public static var modelType: DeviceModel.Model? {
        return UIDevice.model.model
    }

    public static func isDevice(ofType model: DeviceModel.Model) -> Bool {
        return UIDevice.modelType == model
    }
}


public enum DeviceModel {
    case simulator(Model)
    case unrecognizedSimulator(String)
    case real(Model)
    case unrecognized(String)

    public enum Model: String {
        case iPod1            = ""iPod 1""
        case iPod2            = ""iPod 2""
        case iPod3            = ""iPod 3""
        case iPod4            = ""iPod 4""
        case iPod5            = ""iPod 5""
        case iPad2            = ""iPad 2""
        case iPad3            = ""iPad 3""
        case iPad4            = ""iPad 4""
        case iPhone4          = ""iPhone 4""
        case iPhone4S         = ""iPhone 4S""
        case iPhone5          = ""iPhone 5""
        case iPhone5S         = ""iPhone 5S""
        case iPhone5C         = ""iPhone 5C""
        case iPadMini1        = ""iPad Mini 1""
        case iPadMini2        = ""iPad Mini 2""
        case iPadMini3        = ""iPad Mini 3""
        case iPadAir1         = ""iPad Air 1""
        case iPadAir2         = ""iPad Air 2""
        case iPadPro9_7       = ""iPad Pro 9.7\""""
        case iPadPro9_7_cell  = ""iPad Pro 9.7\"" cellular""
        case iPadPro10_5      = ""iPad Pro 10.5\""""
        case iPadPro10_5_cell = ""iPad Pro 10.5\"" cellular""
        case iPadPro12_9      = ""iPad Pro 12.9\""""
        case iPadPro12_9_cell = ""iPad Pro 12.9\"" cellular""
        case iPhone6          = ""iPhone 6""
        case iPhone6plus      = ""iPhone 6 Plus""
        case iPhone6S         = ""iPhone 6S""
        case iPhone6Splus     = ""iPhone 6S Plus""
        case iPhoneSE         = ""iPhone SE""
        case iPhone7          = ""iPhone 7""
        case iPhone7plus      = ""iPhone 7 Plus""
        case iPhone8          = ""iPhone 8""
        case iPhone8plus      = ""iPhone 8 Plus""
        case iPhoneX          = ""iPhone X""

        init?(modelCode: String) {
            switch modelCode {
            case ""iPod1,1"":    self = .iPod1
            case ""iPod2,1"":    self = .iPod2
            case ""iPod3,1"":    self = .iPod3
            case ""iPod4,1"":    self = .iPod4
            case ""iPod5,1"":    self = .iPod5
            case ""iPad2,1"":    self = .iPad2
            case ""iPad2,2"":    self = .iPad2
            case ""iPad2,3"":    self = .iPad2
            case ""iPad2,4"":    self = .iPad2
            case ""iPad2,5"":    self = .iPadMini1
            case ""iPad2,6"":    self = .iPadMini1
            case ""iPad2,7"":    self = .iPadMini1
            case ""iPhone3,1"":  self = .iPhone4
            case ""iPhone3,2"":  self = .iPhone4
            case ""iPhone3,3"":  self = .iPhone4
            case ""iPhone4,1"":  self = .iPhone4S
            case ""iPhone5,1"":  self = .iPhone5
            case ""iPhone5,2"":  self = .iPhone5
            case ""iPhone5,3"":  self = .iPhone5C
            case ""iPhone5,4"":  self = .iPhone5C
            case ""iPad3,1"":    self = .iPad3
            case ""iPad3,2"":    self = .iPad3
            case ""iPad3,3"":    self = .iPad3
            case ""iPad3,4"":    self = .iPad4
            case ""iPad3,5"":    self = .iPad4
            case ""iPad3,6"":    self = .iPad4
            case ""iPhone6,1"":  self = .iPhone5S
            case ""iPhone6,2"":  self = .iPhone5S
            case ""iPad4,1"":    self = .iPadAir1
            case ""iPad4,2"":    self = .iPadAir2
            case ""iPad4,4"":    self = .iPadMini2
            case ""iPad4,5"":    self = .iPadMini2
            case ""iPad4,6"":    self = .iPadMini2
            case ""iPad4,7"":    self = .iPadMini3
            case ""iPad4,8"":    self = .iPadMini3
            case ""iPad4,9"":    self = .iPadMini3
            case ""iPad6,3"":    self = .iPadPro9_7
            case ""iPad6,11"":   self = .iPadPro9_7
            case ""iPad6,4"":    self = .iPadPro9_7_cell
            case ""iPad6,12"":   self = .iPadPro9_7_cell
            case ""iPad6,7"":    self = .iPadPro12_9
            case ""iPad6,8"":    self = .iPadPro12_9_cell
            case ""iPad7,3"":    self = .iPadPro10_5
            case ""iPad7,4"":    self = .iPadPro10_5_cell
            case ""iPhone7,1"":  self = .iPhone6plus
            case ""iPhone7,2"":  self = .iPhone6
            case ""iPhone8,1"":  self = .iPhone6S
            case ""iPhone8,2"":  self = .iPhone6Splus
            case ""iPhone8,4"":  self = .iPhoneSE
            case ""iPhone9,1"":  self = .iPhone7
            case ""iPhone9,2"":  self = .iPhone7plus
            case ""iPhone9,3"":  self = .iPhone7
            case ""iPhone9,4"":  self = .iPhone7plus
            case ""iPhone10,1"": self = .iPhone8
            case ""iPhone10,2"": self = .iPhone8plus
            case ""iPhone10,3"": self = .iPhoneX
            case ""iPhone10,6"": self = .iPhoneX
            default:           return nil
            }
        }
    }

    public var name: String {
        switch self {
        case .simulator(let model):         return ""Simulator[\(model.rawValue)]""
        case .unrecognizedSimulator(let s): return ""UnrecognizedSimulator[\(s)]""
        case .real(let model):              return model.rawValue
        case .unrecognized(let s):          return ""Unrecognized[\(s)]""
        }
    }

    public var model: DeviceModel.Model? {
        switch self {
        case .simulator(let model):         return model
        case .real(let model):              return model
        case .unrecognizedSimulator(_):     return nil
        case .unrecognized(_):              return nil
        }
    }
}

    You can use BDLocalizedDevicesModels framework to parse device info and get the name.

Then just call UIDevice.currentDevice.productName in your code.
    My simple solution grouped by device and support new devices iPhone 8 and iPhone X in Swift 3:

public extension UIDevice {
    var modelName: String {
        var systemInfo = utsname()
        uname(&systemInfo)
        let machineMirror = Mirror(reflecting: systemInfo.machine)
        let identifier = machineMirror.children.reduce("""") { identifier, element in
            guard let value = element.value as? Int8, value != 0 else { return identifier }
            return identifier + String(UnicodeScalar(UInt8(value)))
        }

        switch identifier {
        case ""iPhone3,1"", ""iPhone3,2"", ""iPhone3,3"", ""iPhone4,1"":
            return ""iPhone 4""

        case ""iPhone5,1"", ""iPhone5,2"", ""iPhone5,3"", ""iPhone5,4"", ""iPhone6,1"", ""iPhone6,2"", ""iPhone8,4"":
            return ""iPhone 5""

        case ""iPhone7,2"", ""iPhone8,1"", ""iPhone9,1"", ""iPhone9,3"", ""iPhone10,1"", ""iPhone10,4"":
            return ""iPhone 6,7,8""

        case ""iPhone7,1"", ""iPhone8,2"", ""iPhone9,2"", ""iPhone9,4"", ""iPhone10,2"", ""iPhone10,5"":
            return ""iPhone Plus""

        case ""iPhone10,3"", ""iPhone10,6"":
            return ""iPhone X""

        case ""i386"", ""x86_64"":
            return ""Simulator""
        default:
            return identifier
        }
    }
}


And use: 

switch UIDevice.current.modelName {
  case ""iPhone 4"":
  case ""iPhone 5"":
  case ""iPhone 6,7,8"":
  case ""iPhone Plus"":
  case ""iPhone X"":
  case ""Simulator"":
  default:
}

    There are some problems with the accepted answer when you're using Swift 3!
This answer (inspired from NAZIK) works with Swift 3 and the new iPhone models:

import UIKit


public extension UIDevice {
var modelName: String {
    #if (arch(i386) || arch(x86_64)) && os(iOS)
        let DEVICE_IS_SIMULATOR = true
    #else
        let DEVICE_IS_SIMULATOR = false
    #endif

    var machineString = String()

    if DEVICE_IS_SIMULATOR == true
    {
        if let dir = ProcessInfo().environment[""SIMULATOR_MODEL_IDENTIFIER""] {
            machineString = dir
        }
    }
    else {
        var systemInfo = utsname()
        uname(&systemInfo)
        let machineMirror = Mirror(reflecting: systemInfo.machine)
        machineString = machineMirror.children.reduce("""") { identifier, element in
            guard let value = element.value as? Int8 , value != 0 else { return identifier }
            return identifier + String(UnicodeScalar(UInt8(value)))
        }
    }
    switch machineString {
    case ""iPod4,1"":                                 return ""iPod Touch 4G""
    case ""iPod5,1"":                                 return ""iPod Touch 5G""
    case ""iPod7,1"":                                 return ""iPod Touch 6G""
    case ""iPhone3,1"", ""iPhone3,2"", ""iPhone3,3"":     return ""iPhone 4""
    case ""iPhone4,1"":                               return ""iPhone 4s""
    case ""iPhone5,1"", ""iPhone5,2"":                  return ""iPhone 5""
    case ""iPhone5,3"", ""iPhone5,4"":                  return ""iPhone 5c""
    case ""iPhone6,1"", ""iPhone6,2"":                  return ""iPhone 5s""
    case ""iPhone7,2"":                               return ""iPhone 6""
    case ""iPhone7,1"":                               return ""iPhone 6 Plus""
    case ""iPhone8,1"":                               return ""iPhone 6s""
    case ""iPhone8,2"":                               return ""iPhone 6s Plus""
    case ""iPhone8,4"":                               return ""iPhone SE""
    case ""iPhone9,1"", ""iPhone9,3"":                  return ""iPhone 7""
    case ""iPhone9,2"", ""iPhone 9,4"":                 return ""iPhone 7 Plus""
    case ""iPad2,1"", ""iPad2,2"", ""iPad2,3"", ""iPad2,4"":return ""iPad 2""
    case ""iPad3,1"", ""iPad3,2"", ""iPad3,3"":           return ""iPad 3""
    case ""iPad3,4"", ""iPad3,5"", ""iPad3,6"":           return ""iPad 4""
    case ""iPad4,1"", ""iPad4,2"", ""iPad4,3"":           return ""iPad Air""
    case ""iPad5,3"", ""iPad5,4"":                      return ""iPad Air 2""
    case ""iPad2,5"", ""iPad2,6"", ""iPad2,7"":           return ""iPad Mini""
    case ""iPad4,4"", ""iPad4,5"", ""iPad4,6"":           return ""iPad Mini 2""
    case ""iPad4,7"", ""iPad4,8"", ""iPad4,9"":           return ""iPad Mini 3""
    case ""iPad5,1"", ""iPad5,2"":                      return ""iPad Mini 4""
    case ""iPad6,3"", ""iPad6,4"":                      return ""iPad Pro (9.7 inch)""
    case ""iPad6,7"", ""iPad6,8"":                      return ""iPad Pro (12.9 inch)""
    case ""AppleTV5,3"":                              return ""Apple TV""
    default:                                        return machineString
    }
}
}

    SWIFT 3.1

my two cents for simply calling utsname:

    func platform() -> String {
    var systemInfo = utsname()
    uname(&systemInfo)
    let size = Int(_SYS_NAMELEN) // is 32, but posix AND its init is 256....

    let s = withUnsafeMutablePointer(to: &systemInfo.machine) {p in

        p.withMemoryRebound(to: CChar.self, capacity: size, {p2 in
            return String(cString: p2)
        })

    }
    return s
}


as other did, but a bit cleaner about all the intricacy of C/Swift and back.
):

Returns values such as ""x86_64""
    Below is the code for getting the hardware string, but you need to compare these hardware string to know which device it is. I have created a class for that contains almost all the device strings(we're keeping string upto date with new devices). It's easy to use please check

Swift : GitHub/DeviceGuru

Objective-C : GitHub/DeviceUtil

public func hardwareString() -> String {
  var name: [Int32] = [CTL_HW, HW_MACHINE]
  var size: Int = 2
  sysctl(&name, 2, nil, &size, &name, 0)
  var hw_machine = [CChar](count: Int(size), repeatedValue: 0)
  sysctl(&name, 2, &hw_machine, &size, &name, 0)

  let hardware: String = String.fromCString(hw_machine)!
  return hardware
}

    struct utsname systemInfo;
uname(&systemInfo);

NSString* deviceModel = [NSString stringWithCString:systemInfo.machine
                          encoding:NSUTF8StringEncoding];

    Dealing with c structs is painful in swift. Especially if they have some kind of c arrays in it. Here is my solution: Continue to use objective-c. Just create a wrapper objective-c class that does this job and then use that class in swift. Here is a sample class that does exactly this:

@interface DeviceInfo : NSObject

+ (NSString *)model;

@end

#import ""DeviceInfo.h""
#import <sys/utsname.h>

@implementation DeviceInfo

+ (NSString *)model
{
    struct utsname systemInfo;
    uname(&systemInfo);

    return [NSString stringWithCString: systemInfo.machine encoding: NSUTF8StringEncoding];
}

@end


In swift side:

let deviceModel = DeviceInfo.model()

    Simplest way to get model name (marketing name)
Use private API -[UIDevice _deviceInfoForKey:] carefully, you won't be rejected by Apple,
// works on both simulators and real devices, iOS 8 to iOS 12
NSString *deviceModelName(void) {
    // For Simulator
    NSString *modelName = NSProcessInfo.processInfo.environment[@""SIMULATOR_DEVICE_NAME""];
    if (modelName.length > 0) {
        return modelName;
    }

    // For real devices and simulators, except simulators running on iOS 8.x
    UIDevice *device = [UIDevice currentDevice];
    NSString *selName = [NSString stringWithFormat:@""_%@ForKey:"", @""deviceInfo""];
    SEL selector = NSSelectorFromString(selName);
    if ([device respondsToSelector:selector]) {
#pragma clang diagnostic push
#pragma clang diagnostic ignored ""-Warc-performSelector-leaks""
        modelName = [device performSelector:selector withObject:@""marketing-name""];
#pragma clang diagnostic pop
    }
    return modelName;
}

How did I get the key ""marketing-name""?
Running on a simulator, NSProcessInfo.processInfo.environment contains a key named ""SIMULATOR_CAPABILITIES"", the value of which is a plist file. Then you open the plist file, you will get the model name's key ""marketing-name"".
    extension UIDevice {

    public static let hardwareModel: String = {
        var path = [CTL_HW, HW_MACHINE]
        var n = 0
        sysctl(&path, 2, nil, &n, nil, 0)
        var a: [UInt8] = .init(repeating: 0, count: n)
        sysctl(&path, 2, &a, &n, nil, 0)
        return .init(cString: a)
    }()
}

UIDevice.hardwareModel // → iPhone9,3

    struct DeviceType {
        static let IS_IPHONE_4_OR_LESS = UIDevice.current.userInterfaceIdiom == .phone && Constants.SCREEN_MAX_LENGTH < 568
        static let IS_IPHONE_5 = UIDevice.current.userInterfaceIdiom == .phone && Constants.SCREEN_MAX_LENGTH == 568
        static let IS_IPHONE_6 = UIDevice.current.userInterfaceIdiom == .phone && Constants.SCREEN_MAX_LENGTH == 667
        static let IS_IPHONE_6P = UIDevice.current.userInterfaceIdiom == .phone && Constants.SCREEN_MAX_LENGTH == 736
        static let IS_IPAD = UIDevice.current.userInterfaceIdiom == .pad && Constants.SCREEN_MAX_LENGTH == 1024
    }

    In Swift 3 it'd be

 UIDevice.current.model

    This Swift 3.0 example returns the current device model as an enum constant (to avoid direct comparisons to string literals). The enum's raw value is a String containing the human-readable iOS device name. Since it is Swift, the list of recognized devices only includes models recent enough to support iOS releases that include Swift. The following usage example utilizes the implementation at the end of this answer:

    switch UIDevice().type {
    case .iPhone5:
              print(""No TouchID sensor"")
    case .iPhone5S:
              fallthrough
    case .iPhone6:
              fallthrough
    case .iPhone6plus:
              fallthrough
    case .iPad_Pro9_7:
              fallthrough
    case .iPad_Pro12_9:
              fallthrough
    case .iPhone7:
              fallthrough
    case .iPhone7plus:
              print(""Put your thumb on the "" + 
                     UIDevice().type.rawValue + "" TouchID sensor"")
    case .unrecognized:
              print(""Device model unrecognized"");
    default:
              print(UIDevice().type.rawValue + "" not supported by this app"");
    }


Your app should be kept up-to-date for new device releases and also when Apple adds new models for the same device family.  For example, iPhone3,1 iPhone3,2 iPhone3,4 are all ""iPhone 4"". Avoid writing code that doesn't account for new models, so your algorithms don't unexpectedly fail to configure or respond to a new device.  You can refer to this maintained list of iOS Device Model #'s  to update your app at strategic times.

iOS includes device-independent interfaces to detect hardware capabilities and parameters such as screen size. The generalized interfaces Apple provides are usually the safest, best supported mechanisms to dynamically adapt an app's behavior to different hardware. Nevertheless, the following code can be useful for prototyping, debugging, testing, or any time code needs to target a specific device family. This technique can also be useful to describe the current device  by its common/publicly recognized name.

Swift 3

// 1. Declare outside class definition (or in its own file).
// 2. UIKit must be included in file where this code is added.
// 3. Extends UIDevice class, thus is available anywhere in app.
//
// Usage example:
//
//    if UIDevice().type == .simulator {
//       print(""You're running on the simulator... boring!"")
//    } else {
//       print(""Wow! Running on a \(UIDevice().type.rawValue)"")
//    }
import UIKit

public enum Model : String {
    case simulator   = ""simulator/sandbox"",
    iPod1            = ""iPod 1"",
    iPod2            = ""iPod 2"",
    iPod3            = ""iPod 3"",
    iPod4            = ""iPod 4"",
    iPod5            = ""iPod 5"",
    iPad2            = ""iPad 2"",
    iPad3            = ""iPad 3"",
    iPad4            = ""iPad 4"",
    iPhone4          = ""iPhone 4"",
    iPhone4S         = ""iPhone 4S"",
    iPhone5          = ""iPhone 5"",
    iPhone5S         = ""iPhone 5S"",
    iPhone5C         = ""iPhone 5C"",
    iPadMini1        = ""iPad Mini 1"",
    iPadMini2        = ""iPad Mini 2"",
    iPadMini3        = ""iPad Mini 3"",
    iPadAir1         = ""iPad Air 1"",
    iPadAir2         = ""iPad Air 2"",
    iPadPro9_7       = ""iPad Pro 9.7\"""",
    iPadPro9_7_cell  = ""iPad Pro 9.7\"" cellular"",
    iPadPro10_5      = ""iPad Pro 10.5\"""",
    iPadPro10_5_cell = ""iPad Pro 10.5\"" cellular"",
    iPadPro12_9      = ""iPad Pro 12.9\"""",
    iPadPro12_9_cell = ""iPad Pro 12.9\"" cellular"",
    iPhone6          = ""iPhone 6"",
    iPhone6plus      = ""iPhone 6 Plus"",
    iPhone6S         = ""iPhone 6S"",
    iPhone6Splus     = ""iPhone 6S Plus"",
    iPhoneSE         = ""iPhone SE"",
    iPhone7          = ""iPhone 7"",
    iPhone7plus      = ""iPhone 7 Plus"",
    iPhone8          = ""iPhone 8"",
    iPhone8plus      = ""iPhone 8 Plus"",
    iPhoneX          = ""iPhone X"",
    iPhoneXS         = ""iPhone XS"",
    iPhoneXSmax      = ""iPhone XS Max"",
    iPhoneXR         = ""iPhone XR"",
    iPhone11         = ""iPhone 11"",
    iPhone11Pro      = ""iPhone 11 Pro"",
    iPhone11ProMax   = ""iPhone 11 Pro Max"",
    unrecognized     = ""?unrecognized?""
}

public extension UIDevice {
    public var type: Model {
        var systemInfo = utsname()
        uname(&systemInfo)
        let modelCode = withUnsafePointer(to: &systemInfo.machine) {
            $0.withMemoryRebound(to: CChar.self, capacity: 1) {
                ptr in String.init(validatingUTF8: ptr)

            }
        }
        var modelMap : [ String : Model ] = [
            ""i386""       : .simulator,
            ""x86_64""     : .simulator,
            ""iPod1,1""    : .iPod1,
            ""iPod2,1""    : .iPod2,
            ""iPod3,1""    : .iPod3,
            ""iPod4,1""    : .iPod4,
            ""iPod5,1""    : .iPod5,
            ""iPad2,1""    : .iPad2,
            ""iPad2,2""    : .iPad2,
            ""iPad2,3""    : .iPad2,
            ""iPad2,4""    : .iPad2,
            ""iPad2,5""    : .iPadMini1,
            ""iPad2,6""    : .iPadMini1,
            ""iPad2,7""    : .iPadMini1,
            ""iPhone3,1""  : .iPhone4,
            ""iPhone3,2""  : .iPhone4,
            ""iPhone3,3""  : .iPhone4,
            ""iPhone4,1""  : .iPhone4S,
            ""iPhone5,1""  : .iPhone5,
            ""iPhone5,2""  : .iPhone5,
            ""iPhone5,3""  : .iPhone5C,
            ""iPhone5,4""  : .iPhone5C,
            ""iPad3,1""    : .iPad3,
            ""iPad3,2""    : .iPad3,
            ""iPad3,3""    : .iPad3,
            ""iPad3,4""    : .iPad4,
            ""iPad3,5""    : .iPad4,
            ""iPad3,6""    : .iPad4,
            ""iPhone6,1""  : .iPhone5S,
            ""iPhone6,2""  : .iPhone5S,
            ""iPad4,1""    : .iPadAir1,
            ""iPad4,2""    : .iPadAir2,
            ""iPad4,4""    : .iPadMini2,
            ""iPad4,5""    : .iPadMini2,
            ""iPad4,6""    : .iPadMini2,
            ""iPad4,7""    : .iPadMini3,
            ""iPad4,8""    : .iPadMini3,
            ""iPad4,9""    : .iPadMini3,
            ""iPad6,3""    : .iPadPro9_7,
            ""iPad6,11""   : .iPadPro9_7,
            ""iPad6,4""    : .iPadPro9_7_cell,
            ""iPad6,12""   : .iPadPro9_7_cell,
            ""iPad6,7""    : .iPadPro12_9,
            ""iPad6,8""    : .iPadPro12_9_cell,
            ""iPad7,3""    : .iPadPro10_5,
            ""iPad7,4""    : .iPadPro10_5_cell,
            ""iPhone7,1""  : .iPhone6plus,
            ""iPhone7,2""  : .iPhone6,
            ""iPhone8,1""  : .iPhone6S,
            ""iPhone8,2""  : .iPhone6Splus,
            ""iPhone8,4""  : .iPhoneSE,
            ""iPhone9,1""  : .iPhone7,
            ""iPhone9,2""  : .iPhone7plus,
            ""iPhone9,3""  : .iPhone7,
            ""iPhone9,4""  : .iPhone7plus,
            ""iPhone10,1"" : .iPhone8,
            ""iPhone10,2"" : .iPhone8plus,
            ""iPhone10,3"" : .iPhoneX,
            ""iPhone10,6"" : .iPhoneX,
            ""iPhone11,2"" : .iPhoneXS,
            ""iPhone11,4"" : .iPhoneXSmax,
            ""iPhone11,6"" : .iPhoneXSmax,
            ""iPhone11,8"" : .iPhoneXR,
            ""iPhone12,1"" : .iPhone11,
            ""iPhone12,3"" : .iPhone11Pro,
            ""iPhone12,5"" : .iPhone11ProMax
        ]

    if let model = modelMap[String.init(validatingUTF8: modelCode!)!] {
            return model
        }
        return Model.unrecognized
    }
}

    I've implemented a super-lightweight library to detect the used device based on some of the given answers: https://github.com/schickling/Device.swift

It can be installed via Carthage and be used like this:

import Device

let deviceType = UIDevice.currentDevice().deviceType

switch deviceType {
case .IPhone6: print(""Do stuff for iPhone6"")
case .IPadMini: print(""Do stuff for iPad mini"")
default: print(""Check other available cases of DeviceType"")
}

    For both device as well as simulators,
Create a new swift file with name UIDevice.swift

Add the below code

import UIKit


public extension UIDevice {

var modelName: String {
    #if (arch(i386) || arch(x86_64)) && os(iOS)
        let DEVICE_IS_SIMULATOR = true
    #else
        let DEVICE_IS_SIMULATOR = false
    #endif

    var machineString : String = """"

    if DEVICE_IS_SIMULATOR == true
    {

        if let dir = NSProcessInfo().environment[""SIMULATOR_MODEL_IDENTIFIER""] {
            machineString = dir
        }
    }
    else {
        var systemInfo = utsname()
        uname(&systemInfo)
        let machineMirror = Mirror(reflecting: systemInfo.machine)
        machineString = machineMirror.children.reduce("""") { identifier, element in
            guard let value = element.value as? Int8 where value != 0 else { return identifier }
            return identifier + String(UnicodeScalar(UInt8(value)))
        }
    }
    switch machineString {
    case ""iPod5,1"":                                 return ""iPod Touch 5""
    case ""iPod7,1"":                                 return ""iPod Touch 6""
    case ""iPhone3,1"", ""iPhone3,2"", ""iPhone3,3"":     return ""iPhone 4""
    case ""iPhone4,1"":                               return ""iPhone 4s""
    case ""iPhone5,1"", ""iPhone5,2"":                  return ""iPhone 5""
    case ""iPhone5,3"", ""iPhone5,4"":                  return ""iPhone 5c""
    case ""iPhone6,1"", ""iPhone6,2"":                  return ""iPhone 5s""
    case ""iPhone7,2"":                               return ""iPhone 6""
    case ""iPhone7,1"":                               return ""iPhone 6 Plus""
    case ""iPhone8,1"":                               return ""iPhone 6s""
    case ""iPhone8,2"":                               return ""iPhone 6s Plus""
    case ""iPad2,1"", ""iPad2,2"", ""iPad2,3"", ""iPad2,4"":return ""iPad 2""
    case ""iPad3,1"", ""iPad3,2"", ""iPad3,3"":           return ""iPad 3""
    case ""iPad3,4"", ""iPad3,5"", ""iPad3,6"":           return ""iPad 4""
    case ""iPad4,1"", ""iPad4,2"", ""iPad4,3"":           return ""iPad Air""
    case ""iPad5,3"", ""iPad5,4"":                      return ""iPad Air 2""
    case ""iPad2,5"", ""iPad2,6"", ""iPad2,7"":           return ""iPad Mini""
    case ""iPad4,4"", ""iPad4,5"", ""iPad4,6"":           return ""iPad Mini 2""
    case ""iPad4,7"", ""iPad4,8"", ""iPad4,9"":           return ""iPad Mini 3""
    case ""iPad5,1"", ""iPad5,2"":                      return ""iPad Mini 4""
    case ""iPad6,7"", ""iPad6,8"":                      return ""iPad Pro""
    case ""AppleTV5,3"":                              return ""Apple TV""
    default:                                        return machineString
    }
}
}


Then in your viewcontroller,

 let deviceType = UIDevice.currentDevice().modelName

    if deviceType.lowercaseString.rangeOfString(""iphone 4"") != nil {
       print(""iPhone 4 or iphone 4s"")
    }
    else if deviceType.lowercaseString.rangeOfString(""iphone 5"") != nil {
        print(""iPhone 5 or iphone 5s or iphone 5c"")
    }
   else if deviceType.lowercaseString.rangeOfString(""iphone 6"") != nil {
        print(""iPhone 6 Series"")
    }

    ","[491, 1128, 218, 22, 127, 14, 3, -1, 39, 9, 5, 3, 4, 6, 2, 3, 2, 6, 2, 2, 0, 13, 1, 0, -2, -2, 162, 8, 16]",341076,269,2014-09-25T01:08:01,2022-04-26 05:28:41Z,swift 
How to change spinner text size and text color?,"
                
In my Android application, I am using spinner, and I have loaded data from the SQLite database into the spinner, and it's working properly. Here is the code for that.

Spinner spinner = (Spinner) this.findViewById(R.id.spinner1);
List<String> list = new ArrayList<String>();
ArrayAdapter<String> dataAdapter = new ArrayAdapter<String>  (this,android.R.layout.simple_spinner_item, list);
cursor.moveToFirst();

list.add(""All Lists"");

if (cursor.getCount() > 0) {
    for (int i = 0; i < cursor.getCount(); i++) {
        keyList[i] = cursor.getString(cursor.getColumnIndex(AndroidOpenDbHelper.KEYWORD));
        list.add(keyList[i]);
        cursor.moveToNext();
    }
}
Database.close();
cursor.close();
dataAdapter.setDropDownViewResource(android.R.layout.simple_spinner_dropdown_item);
spinner.setAdapter(dataAdapter);


Now I want to change the text color and text size of spinner data. I have used following XML lines to my spinner tag on my XML file, but it is not working.

android:textColor=""@android:color/white""
android:textSize=""11dp""


How can I change the text color and text size of my spinner?
    Make a custom XML file for your spinner item.

spinner_item.xml:

Give your customized color and size to text in this file.

<?xml version=""1.0"" encoding=""utf-8""?>

<TextView  
    xmlns:android=""http://schemas.android.com/apk/res/android""
    android:layout_width=""match_parent"" 
    android:layout_height=""wrap_content""
    android:textSize=""20sp""
    android:gravity=""left""  
    android:textColor=""#FF0000""         
    android:padding=""5dip""
    />


Now use this file to show your spinner items like:

ArrayAdapter<String> adapter = new ArrayAdapter<String>(this, R.layout.spinner_item,list);


You don't need to set the drop down resource. It will take spinner_item.xml only to show your items in spinner.
    Just wanted to make a small change on the correct answer at the top.
Make a custom XML file for your spinner item inside the layout directory.
spinner_style.xml:
Give your customized color and size to text in this file.
 <?xml version=""1.0"" encoding=""utf-8""?>

     <TextView  
            xmlns:android=""http://schemas.android.com/apk/res/android""
            android:layout_width=""match_parent"" 
            android:layout_height=""wrap_content""
            style=""?android:attr/spinnerItemStyle""
            android:singleLine=""true""
            android:ellipsize=""marquee""
            android:textAlignment=""inherit""
            android:textSize=""15sp""
            android:textColor=""#FF0000""         
            android:padding=""5dp""
            />

Now use this file to show your spinner items inside your java file:
ArrayAdapter<String> adapter = new ArrayAdapter<>(this,R.layout.spinner_style,list);
adapter.setDropDownViewResource(R.layout.spinner_style);

    we can change style of spinner textview set theme for spinner like this:
styles.xml:
<style name=""mySpinnerItemStyle"" parent=""@android:style/Widget.Holo.DropDownItem.Spinner"">
    <item name=""android:textSize"">@dimen/_11ssp</item>
    <item name=""android:textColor"">@color/blue</item>
    <item name=...</item>
</style>

then
<Spinner
                    android:theme=""@style/mySpinnerItemStyle""
                    android:layout_width=""match_parent""
                    android:layout_height=""wrap_content""/>

if you want to change spinner textview attribute programtically:
Programatically:
val textView = (view.getChildAt(0) as TextView)
textView.setTextColor(resources.getColor(R.color.dark_mode))

    Simple and crisp...:

private OnItemSelectedListener OnCatSpinnerCL = new AdapterView.OnItemSelectedListener() {
    public void onItemSelected(AdapterView<?> parent, View view, int pos, long id) {

       ((TextView) parent.getChildAt(0)).setTextColor(Color.BLUE);
       ((TextView) parent.getChildAt(0)).setTextSize(5);

    }

    public void onNothingSelected(AdapterView<?> parent) {

    }
};

    If all the spinners may have the same text color for their TextView items, another approach is to use a custom style for spinner dropdown items:

In res/values/styles.xml:

<resources>
    <style name=""AppBaseTheme"" parent=""android:Theme.Light"">
    </style>

    <style name=""AppTheme"" parent=""AppBaseTheme"">
        <item name=""android:spinnerDropDownItemStyle"">@style/mySpinnerItemStyle</item>
    </style>

    <style name=""mySpinnerItemStyle"" parent=""@android:style/Widget.Holo.DropDownItem.Spinner"">
        <item name=""android:textColor"">@color/my_spinner_text_color</item>
    </style>
</resources>


And define your custom color in res/values/colors.xml:

<color name=""my_spinner_text_color"">#808080</color>

    If you work with android.support.v7.widget.AppCompatSpinner here is the simplest tested solution using styles:

 <android.support.v7.widget.AppCompatSpinner
                    android:id=""@+id/spefcialFx""
                    style=""@style/Widget.AppCompat.Spinner.Underlined""
                    android:layout_width=""200dp""
                    android:layout_height=""wrap_content""
                    android:layout_marginLeft=""4dp""
                    android:theme=""@style/Spinner""
                    android:entries=""@array/special_fx_arrays""
                    android:textSize=""@dimen/text_size_normal""></android.support.v7.widget.AppCompatSpinner>


And the style:

<style name=""Spinner"" parent=""Widget.AppCompat.Light.DropDownItem.Spinner"">
        <item name=""android:paddingStart"">0dp</item>
        <item name=""android:paddingEnd"">0dp</item>
        <item name=""android:textColor"">@color/white</item>
        <item name=""android:backgroundTint"">@color/red</item>
        <item name=""android:textSize"">14sp</item>
    </style>


The only downside is the android:backgroundTint sets color for both the dropdown arrow and the dropdown background.
    If you want a simple method, in order to add items to a dropdown, you usually add them to the strings.xml. Here is an example on how to add colour by using the strings.xml file:

SELECT AGE RANGE

<string-array name=""age_array"">

   <item> 0-6 </item>                               //No custom colour

  <item><font fgcolor='#FF4CD964'> 12+ </font></item> //With custom colour

</string-array>

    To prevent lagging, you need to not only set the text properties in the onItemSelected listener, but also in the Activity's onCreate method (but it's a little tricky).

Specifically, you need to put this in onCreate after setting the adapter:

spinner.setSelection(0, true);
View v = spinner.getSelectedView();
((TextView)v).setTextColor(backgroundColor);


And then put this in onItemSelected:

((TextView) view).setTextColor(backgroundColor);


Here is a full example:

@Override  
protected void onCreate(Bundle savedInstanceState)
{  
    Spinner spinner = (Spinner) findViewById(R.id.spinner); 

    //Set the choices on the spinner by setting the adapter.  
    spinner.setAdapter(new SpinnerAdapter(toolbar.getContext(), new String[]{""Overview"", ""Story"", ""Specifications"", ""Poll"", ""Video""}, accentColor, backgroundColor));

    //Set the text color of the Spinner's selected view (not a drop down list view) 
    spinner.setSelection(0, true);
    View v = spinner.getSelectedView();
    ((TextView)v).setTextColor(backgroundColor);

    //Set the listener for when each option is clicked.  
    spinner.setOnItemSelectedListener(new AdapterView.OnItemSelectedListener()
    {  

        @Override  
        public void onItemSelected(AdapterView<?> parent, View view, int position, long id)
        {  
           //Change the selected item's text color  
           ((TextView) view).setTextColor(backgroundColor);
        }  

        @Override  
        public void onNothingSelected(AdapterView<?> parent)
        {  
        }  
    });  

}  


For more details, see my question.
    For those who want to change DrowDownIcon color
you can use like this

spinner.getBackground().setColorFilter(Color.parseColor(""#ffffff""), PorterDuff.Mode.SRC_ATOP);

    Here is a link that can help you to change the color of the Spinner:

Click here

<Spinner
    android:layout_width=""fill_parent""
    android:layout_height=""wrap_content""
    android:id=""@+id/spinner""
    android:textSize=""20sp""
    android:entries=""@array/planets""/>


You need to create your own layout file with a custom definition for the spinner item spinner_item.xml:

<TextView xmlns:android=""http://schemas.android.com/apk/res/android""
    android:id=""@android:id/text1""
    android:layout_width=""match_parent""
    android:layout_height=""wrap_content""
    android:textSize=""20sp""
    android:textColor=""#ff0000"" />


If you want to customize the dropdown list items, you will need to create a new layout file. spinner_dropdown_item.xml:

<?xml version=""1.0"" encoding=""utf-8""?>
<CheckedTextView xmlns:android=""http://schemas.android.com/apk/res/android""
    android:id=""@android:id/text1""
    style=""?android:attr/spinnerDropDownItemStyle""
    android:maxLines=""1""
    android:layout_width=""match_parent""
    android:layout_height=""?android:attr/listPreferredItemHeight""
    android:ellipsize=""marquee""
    android:textColor=""#aa66cc""/>


And finally another change in the declaration of the spinner:

ArrayAdapter adapter = ArrayAdapter.createFromResource(this,
R.array.planets_array, R.layout.spinner_item);

adapter.setDropDownViewResource(R.layout.spinner_dropdown_item);
spinner.setAdapter(adapter);


That's it.
    If you want the text color to change in the selected item only, then this can be a possible workaround. It worked for me and should work for you as well.

spinner.getViewTreeObserver().addOnGlobalLayoutListener(new ViewTreeObserver.OnGlobalLayoutListener() {
            @Override
            public void onGlobalLayout() {
                ((TextView) spinner.getSelectedView()).setTextColor(Color.WHITE);
            }
        });

    For someone who needs only Style way for AppCompat.

Result



styles.xml  

<resources>
    ... 
    <style name=""Spinner"" parent=""Widget.AppCompat.Light.DropDownItem.Spinner"">
        <item name=""android:paddingStart"">0dp</item>
        <item name=""android:paddingEnd"">0dp</item>
        <item name=""android:textColor"">@color/material_grey_700</item>
        <item name=""android:textSize"">12sp</item>
    </style>
</resources>


your_spinner_layout.xml

<?xml version=""1.0"" encoding=""utf-8""?>
<LinearLayout xmlns:android=""http://schemas.android.com/apk/res/android""
    xmlns:app=""http://schemas.android.com/apk/res-auto""
    xmlns:tools=""http://schemas.android.com/tools""
    android:layout_width=""match_parent""
    android:layout_height=""match_parent"" />
    ...

    <android.support.v7.widget.AppCompatSpinner
        android:id=""@+id/content_spinner""
        style=""@style/Widget.AppCompat.Spinner.Underlined""
        android:layout_width=""140dp""
        android:layout_height=""wrap_content""
        android:entries=""@array/shipping_tracking_carrier_names""
        android:spinnerMode=""dropdown""
        android:theme=""@style/Spinner"" />

    <EditText
        android:id=""@+id/content_input""
        android:layout_width=""140dp""
        android:layout_height=""wrap_content""
        android:inputType=""text""
        android:maxLines=""1""
        android:paddingEnd=""8dp""
        android:paddingStart=""8dp""
        android:textColor=""@color/material_grey_700""
        android:textSize=""12sp"" />

    ...
</LinearLayout>    


Plus
And if you want to set android:entries programmatically with defined style.
Try this. 

AppCompatSpinner spinner = findViewById(R.id.content_spinner);
CharSequence[] entries = getResources().getTextArray(R.array.shipping_tracking_carrier_names);
ArrayAdapter<CharSequence> adapter = new ArrayAdapter<>(spinner.getContext(), android.R.layout.simple_spinner_item, entries);
adapter.setDropDownViewResource(android.support.v7.appcompat.R.layout.support_simple_spinner_dropdown_item);
spinner.setAdapter(adapter);


As in the code, using same Context with the Spinner is most important thing.  

spinner.getContext()

    To change the color of spinner text :

 public void onItemSelected(AdapterView<?> parent, View view, int position, long id) {
            ((TextView) parent.getChildAt(0)).setTextColor(Color.WHITE);}

    Can change the text colour by overriding the getView method as follows:

 new ArrayAdapter<String>(getContext(), android.R.layout.simple_spinner_dropdown_item, list()){
                @Override
                public View getView(int position, View convertView, @NonNull ViewGroup parent) {
                    View view = super.getView(position, convertView, parent);
                    //change the color to which ever you want                    
                    ((CheckedTextView) view).setTextColor(Color.RED);
                    //change the size to which ever you want                    
                    ((CheckedTextView) view).setTextSize(5);
                    //for using sp values use setTextSize(TypedValue.COMPLEX_UNIT_SP, 16);
                    return view;
                }
    }

        String typeroutes[] = {""Select"",""Direct"",""Non Stop""};
    Spinner typeroute;

    typeroute = view.findViewById(R.id.typeroute);

    final ArrayAdapter<String> arrayAdapter5 = new ArrayAdapter<String>(
                getActivity(), android.R.layout.simple_spinner_item, typeroutes) {
            @Override
            public boolean isEnabled(int position) {
                if (position == 0) {
                    // Disable the first item from Spinner
                    // First item will be use for hint
                    return false;
                } else {
                    return true;
                }
            }

            public View getView(int position, View convertView, ViewGroup parent) {
                View v = super.getView(position, convertView, parent);
                ((TextView) v).setTextSize(TypedValue.COMPLEX_UNIT_DIP, 16);
                ((TextView) v).setTextColor(Color.parseColor(""#ffffff""));
                return v;
            }         ---->in this line very important so add this

            @Override
            public View getDropDownView(int position, View convertView,
                                        ViewGroup parent) {
                View view = super.getDropDownView(position, convertView, parent);
                TextView tv = (TextView) view;
                if (position == 0) {
                    // Set the hint text color gray
                    tv.setTextColor(Color.GRAY);
                } else {
                    tv.setTextColor(Color.BLACK);
                }
                return view;
            }
        };

        arrayAdapter5.setDropDownViewResource(android.R.layout.simple_spinner_dropdown_item);

        typeroute.setAdapter(arrayAdapter5);


that's all enjoy your coding...
    Try this method. It is working for me. 

@Override
public void onItemSelected(AdapterView<?> adapterView, View view, int i, long l) {
    TextView textView = (TextView) view;
    ((TextView) adapterView.getChildAt(0)).setTextColor(Color.RED);
    ((TextView) adapterView.getChildAt(0)).setTextSize(20);
    Toast.makeText(this, textView.getText()+"" Selected"", Toast.LENGTH_SHORT).show();
}

    The easiest way to re-use/change the android.R.layout resources is just go the definition. In Android Studio, do Ctrl + B on android.R.layout.simple_spinner_item.xml.

It will take you to the resource file. Just copy the resource file and add a new layout in your Package.R.layout folder and change the textColor of textview as you like and then just call it in adapter like this:

ArrayAdapter<String> adapter = new ArrayAdapter<String(Context,R.layout.spinner_item, spinnerlist);

    you can have this type of adapter for spinner, totally customized:

 ArrayAdapter<String> genderAdapter = new ArrayAdapter<String>(getActivity(), R.layout.spinner_text, genderList) {

        public View getView(int position, View convertView, ViewGroup parent) {
            View v = super.getView(position, convertView, parent);
            ((TextView) v).setTextSize(TypedValue.COMPLEX_UNIT_DIP, 16);
            ((TextView) v).setTextColor(Color.parseColor(""#676767""));
            ((TextView) v).setTypeface(vrFont);
            return v;
        }

        public View getDropDownView(int position, View convertView, ViewGroup parent) {
            View v = super.getDropDownView(position, convertView, parent);
            ((TextView) v).setTextSize(TypedValue.COMPLEX_UNIT_DIP, 16);
            ((TextView) v).setTypeface(vrFont);
            ((TextView) v).setTextColor(Color.parseColor(""#676767""));

            if (position == 0) {
                ((TextView) v).setTextColor(Color.parseColor(""#979797""));
            }

            return v;
        }


while R.layout.spinner_text is:

<TextView xmlns:android=""http://schemas.android.com/apk/res/android""
android:id=""@+id/text1""
style=""?android:attr/spinnerItemStyle""
android:layout_width=""fill_parent""
android:layout_height=""40dp""
android:gravity=""center_vertical|left""
android:ellipsize=""marquee""
android:maxLines=""1""
android:textColor=""@color/whiteThree"" />

    Simplest: Works for me

TextView spinnerText = (TextView) spinner.getChildAt(0);

spinnerText.setTextColor(Color.RED);

    <?xml version=""1.0"" encoding=""utf-8""?>
<TextView xmlns:android=""http://schemas.android.com/apk/res/android"" 
    android:id=""@android:id/text1""
    style=""?android:attr/spinnerItemStyle""
    android:singleLine=""true""
    android:layout_width=""match_parent""
    android:layout_height=""wrap_content""
    android:textColor=""#fff""
    android:ellipsize=""marquee""
    android:textAlignment=""inherit""/>


just use this:

ArrayAdapter<String> adapter_category = new ArrayAdapter<String>(this,
    R.layout.spinner_list_item, categories);
adapter_category
    .setDropDownViewResource(android.R.layout.simple_spinner_dropdown_item);

    Another variation of Ashraf's solution would be to make sure you're taking into account screen sizes.  You'll need to get the spinner in onCreate and set the listener after you set the adapter:

//set your adapter with default or custom spinner cell, then://
serverSpinner.setOnItemSelectedListener(spinnerSelector);
serverSpinner.setSelection(defaultServer);


Then you can start changing the text size of the view that's showing before the spinner is clicked:

private AdapterView.OnItemSelectedListener spinnerSelector = new AdapterView.OnItemSelectedListener() {
    public void onItemSelected(AdapterView<?> parent, View view, int pos, long id) {
        boolean tabletSize = getResources().getBoolean(R.bool.isTablet);
        boolean largeTablet = getResources().getBoolean(R.bool.isLargeTablet);
        if (tabletSize) { ((TextView)parent.getChildAt(0)).setTextSize(16); }
        else if (largeTablet) { ((TextView)parent.getChildAt(0)).setTextSize(18); }
        else { ((TextView)parent.getChildAt(0)).setTextSize(12); }
    }
    public void onNothingSelected(AdapterView<?> parent) {

    }
};


All you need to do is create layout specific folders like this:


  values-sw360dp
  
  values-sw600dp
  
  values-sw800dp


an then add an xml file named ""bool.xml"" into each of those folders:

<?xml version=""1.0"" encoding=""utf-8""?>
<resources>
    <bool name=""isTablet"">false</bool>
    <bool name=""isLargeTablet"">false</bool>
</resources>

    First we have to create the simple xml resource file for the textview like as below:    

<?xml version=""1.0"" encoding=""utf-8""?>

 <TextView  
    xmlns:android=""http://schemas.android.com/apk/res/android""
    android:layout_width=""match_parent"" 
    android:layout_height=""wrap_content""
    android:textSize=""20sp""
    android:gravity=""left""  
    android:textColor=""#FF0000""         
    android:padding=""5dip""
    />   


and save it. after set on your adapterlist.
    Rather than making a custom layout to get a small size and if you want to use Android's internal small size LAYOUT for the spinner, you should use:

""android.R.layout.simple_gallery_item"" instead of ""android.R.layout.simple_spinner_item"".

ArrayAdapter<CharSequence> madaptor = ArrayAdapter
            .createFromResource(rootView.getContext(),
                                R.array.String_visitor,
                                android.R.layout.simple_gallery_item);


It can reduce the size of spinner's layout. It's just a simple trick.

If you want to reduce the size of a drop down list use this:

madaptor.setDropDownViewResource(android.R.layout.simple_gallery_item);

    just add new style like this:

<style name=""mySpinnerItemStyle"" parent=""ThemeOverlay.AppCompat.Dark"">
    <item name=""android:textColor"">#000</item>
    <item name=""android:color"">#000</item>
</style>


and use it:

<Spinner
      android:id=""@+id/spinnerCategories""
      android:layout_width=""match_parent""
      android:layout_height=""wrap_content""
      style=""@style/mySpinnerItemStyle""
      android:layout_margin=""5dp"" />

    I have done this as following.I have use getDropDownView() and getView() methods.

Use getDropDownView() for opened Spinner.

@Override
public View getDropDownView(int position, View convertView, ViewGroup parent) {
  View view = convertView;
  if (view == null) {
    LayoutInflater vi = (LayoutInflater) activity.getSystemService(Context.LAYOUT_INFLATER_SERVICE);
    view = vi.inflate(R.layout.context_row_icon, null);
  }
  TextView mTitle = (TextView) view.findViewById(R.id.context_label);
  ImageView flag = (ImageView) view.findViewById(R.id.context_icon);                

  mTitle.setText(values[position].getLabel(activity));

  if (!((LabelItem) getItem(position)).isEnabled()) {
    mTitle.setTextColor(activity.getResources().getColor(R.color.context_item_disabled));
  } else {
    mTitle.setTextColor(activity.getResources().getColor(R.color.context_item));
  }
  return view;
}


And Use getView() for closed Spinner.

@Override
public View getView(int position, View convertView, ViewGroup parent) {
  View view = convertView;
  if (view == null) {
    LayoutInflater vi = (LayoutInflater) activity.getSystemService(Context.LAYOUT_INFLATER_SERVICE);
    view = vi.inflate(R.layout.context_row_icon, null);
  }
  TextView mTitle = (TextView) view.findViewById(R.id.context_label);
  ImageView flag = (ImageView) view.findViewById(R.id.context_icon);

  mTitle.setText(values[position].getLabel(activity));
  mTitle.setTextColor(activity.getResources().getColor(R.color.context_item_disabled));

  return view;
}

    ","[491, 866, 5, 8, 202, 154, 30, 3, 21, 6, 80, 17, 8, 7, 5, 1, 1, 4, 1, 3, 2, 1, 1, 4, -2, 0]",678683,111,2012-02-28T05:02:24,2021-11-16 07:02:19Z,
Determine if variable is defined in Python [duplicate],"
                    
            
        
            
                
                    
                        This question already has answers here:
                        
                    
                
            
                    
                        Easy way to check that a variable is defined in python? [duplicate]
                            
                                (5 answers)
                            
                    
                Closed 2 years ago.
        

    

How do you know whether a variable has been set at a particular place in the code at runtime? This is not always obvious because (1) the variable could be conditionally set, and (2) the variable could be conditionally deleted. I'm looking for something like defined() in Perl or isset() in PHP or defined? in Ruby.

if condition:
    a = 42

# is ""a"" defined here?

if other_condition:
    del a

# is ""a"" defined here?

    try:
    thevariable
except NameError:
    print(""well, it WASN'T defined after all!"")
else:
    print(""sure, it was defined."")

    'a' in vars() or 'a' in globals()

if you want to be pedantic, you can check the builtins too
'a' in vars(__builtins__)
    For this particular case it's better to do a = None instead of del a. This will decrement reference count to object a was (if any) assigned to and won't fail when a is not defined. Note, that del statement doesn't call destructor of an object directly, but unbind it from variable. Destructor of object is called when reference count became zero.
    try:
    a # does a exist in the current namespace
except NameError:
    a = 10 # nope

    I think it's better to avoid the situation.  It's cleaner and clearer to write:

a = None
if condition:
    a = 42

    One possible situation where this might be needed:

If you are using finally block to close connections but in the try block, the program exits with sys.exit() before the connection is defined. In this case, the finally block will be called and the connection closing statement will fail since no connection was created.
    ","[491, 731, 424, 6, 22, 150, 5]",805894,81,2009-10-20T05:03:36,2020-01-31 06:45:21Z,python 
Error: More than one module matches. Use skip-import option to skip importing the component into the closest module,"
                
When I try to create a component in the angular cli, it's showing me this error. How do I get rid of it ?


  Error: More than one module matches. Use skip-import option to skip importing the component into the closest module.


I'm using angular cli version: 1.4.1 
    Specify the module using the --module parameter. 
For example, if the main module is app.module.ts, run this:

ng g c new-component --module app


Or if you are in an other directory then

ng g c component-name --module ../

    Try This: It is working for me

ng generate component componentName --module=app.module
    for me this command working:
ng g c new-component --module app

    It is working for me

ng g component component-name --skip-import

    In my case, it seems ng is not registered into my environment path. I have been using npm run command to run the ng commands. Be aware in order to pass arguments you need an extra -- as per the npm run specification.
Example:
npm run ng g c components/scheduling **--** --module=app

Or:
npm run ng g c components/scheduling **--** --skip-import

    There are two ways to solve this issue.

1) Skip (using --skip-import in command) default import and create component and once component is created import it manually wherever you want to use it.

ng generate component my-component --skip-import


2) Provide module name explicitly where you want it to be imported

ng generate  component  my-component --module=my-module.module

    Just to add another piece of info to this for anyone like me who happens along that just has a single application.  

I had my application set up with the main app.module.ts and I had routing with the routing module in it's own folder under the main application.  I went through and did some 'cleaning up' since I had a few other things that needed to be organized better.  One thing I did was move the routing.module.ts to the root folder; since it was the only file in the folder I figured it didn't need it's own folder.

This worked fine at first but next time I tried to generate a new component (some time later, through the WebStorm IDE) it failed with this message.  After reading through this I tried putting the routing module back into a separate folder and it worked again.

So note of warning to others, don't move the routing module into your root folder!  I'm sure there are other ways to deal with this too but I'm happy with it in it's own folder for now and using the IDE generator like I was previously.
    This is caused since the generation tried to add your component to a module, i.e. to add this line

import { MyComponent } from './Components/my-component/my-component.component';


but it found 2 modules.

As stated here, they fixed it to a situation where as long as in the root src/app folder you have only 1 module, you're fine, so just move the secondaries modules to a sub-folder.

Otherwise you have to use --module 
    I was getting below error when trying to create a new component under a folder.

error: More than one module matches. Use skip-import option to skip importing the component into the closest module.

I have used below command and new component got created successfully under a folder.

 ng g c folderName/my_newComponent ---module ../app

    You have to give the specify module name like

ng g c your-component --module module-name


Where module-name should be that you want to update with newly created component.
    
  When app or lib have multiple nested modules


myApp
  > src
    > app
      app.module.ts
      > routes
        > login
          > auth
          login.module.ts



  Angular CLI


ng g component routes/login/auth/my-auth --module=routes/login/login.module.ts 



  NRWL NX Angular CLI


ng g component routes/login/auth/my-auth --project=myApp --module=routes/login/login.module.ts



  Result


myApp
  > src
    > app
      app.module.ts
      > routes
        > login
          > auth
            > my-auth
              my-auth.component.ts etc...
          login.module.ts

    When there is more than one module under app folder, generating a component with below command will fail:

ng generate component New-Component-Name


The reason is angular CLI detects multiple module, and does't know in which module to add the component. So, you need to explicitly mention which module component will be added:

ng generate component New-Component-Name --module=ModuleName

    
  Angular CLI: 8.3.1


when you have multiple module.ts files inside a module, you need to specify for which module file you are generating component.

ng g c modulefolder/componentname --module=modulename.module


for e.g. i have shared module folder inside which i have shared.module.ts and material.module.ts like this

shared
  > shared.module.ts
  > material.module.ts


and i want to generate sidebar component for shared.module.ts
then i will run following command

ng g c shared/sidebar --module=shared.module


if you want to export the component then run following command

ng g c shared/sidebar --module=shared.module --export

    My project was created using Visual Studio Community 2017 and it creates 3 separated modules: app.browser.module, app.server.module and app.shared.module

In order to create my components I checked above answers and found my module to be app.shared.module.

So, I run:

ng g c componentName --module=app.shared.module

    Angular CLI: 8.3.4
Node : 10.16.3
Angualr : 4.2.5

I used ""dotnet new angular"" command to generate the project, and it has generated 3 different modules in app folder (Although a simple test with ng new project-name just generates a single module. 

see the modules in your project and decide wich module you want - then specify the name

ng g c componentName --module=[name-of-your-module]


You can read more about modules here:
https://angular.io/guide/architecture-modules
    Angular CLI: 6.0.8
Node: 10.4.0
OS: linux x64
Angular: 6.0.4

In case there is a feature module (e.g. manager.module.ts inside the e.g. ""/manager"" sub-folder) with the routing module externalized into the separate NgModule (e.g. manager-routing.module.ts) the error message:

More than one module matches. Use skip-import option to skip importing the component into the closest module.

does not appear and the component is properly generated and added to the manager.module.ts module.

BUT BE CAREFUL the naming convention! the name of the routing module must terminate with ""-routing""!

If the routing module is given a name like e.g. manager-router.module.ts, CLI will complain with the error message and expect you to provide --module option to automatically add the component import:

ng generate component some-name --module=manager.module.ts


or

ng generate component some-name --skip-import


if you prefer to add the import of the component manually
    Just a small update to Zisha's answer. 

In my project all the modules were placed in a folder called ""modules"" and all the components are placed in ""components"" folder under ""src/app""



so to create a component under a specific path, I used the following syntax : 


  ng g c components_path/component_name --module modules_path/module_name


example : 


  ng g c components/login --module modules/app

    if you are creating in specific module go to that path and run 
ng g c componentname

else create module first
ng g module modulename

cd arc/app/modulename
go to modulename path and create the component
    try ng g component header --module app
it is work for me
    As a hack, below steps, worked for me.

1) Move *.module.ts files from src/app to a location out of the project.

2) Execute command to create component [ng g c component-name]

3) Move back the *.module.ts files to src/app/
    when you have more than one module, you need to specify module name 

 ng g c componentName --module=modulename.module 

    I had this warning when had this in angular.json config:

""prefix"": ""app_ng""


When changed to ""app"" all worked perfectly fine.
    ","[491, 1019, 130, 14, 50, 3, 12, 1, 63, 4, 3, 6, 3, 1, 3, 1, 9, 11, 1, 0, -1, 0, 0]",482687,72,2017-09-12T11:08:27,2021-03-23 19:34:10Z,
How do I force git to use LF instead of CR+LF under windows?,"
                
I want to force git to checkout files under Windows using just LF not CR+LF. I checked the two configuration options but I was not able to find the right combination of settings.

I want it to convert all files to LF and keep the LF on the files.

Remark: I used autocrlf = input but this just repairs the files when you commit them. I want to force it to get them using LF.

Probably I wasn't so clear: the repository is already using LF but the files checked out using msysgit are using CR+LF and I want to force msysgit to get them with LF: forcing Unix line endings.

>git config --list | grep crlf
core.autocrlf=input

    The proper way to get LF endings in Windows is to first set core.autocrlf to false:

git config --global core.autocrlf false


You need to do this if you are using msysgit, because it sets it to true in its system settings.

Now git won’t do any line ending normalization. If you want files you check in to be normalized, do this: Set text=auto in your .gitattributes for all files:

* text=auto


And set core.eol to lf:

git config --global core.eol lf


Now you can also switch single repos to crlf (in the working directory!) by running

git config core.eol crlf


After you have done the configuration, you might want git to normalize all the files in the repo. To do this, go to to the root of your repo and run these commands:

git rm --cached -rf .
git diff --cached --name-only -z | xargs -n 50 -0 git add -f


If you now want git to also normalize the files in your working directory, run these commands:

git ls-files -z | xargs -0 rm
git checkout .

    I come back to this answer fairly often, though none of these are quite right for me. That said, the right answer for me is a mixture of the others.

What I find works is the following:

 git config --global core.eol lf
 git config --global core.autocrlf input


For repos that were checked out after those global settings were set, everything will be checked out as whatever it is in the repo – hopefully LF (\n). Any CRLF will be converted to just LF on checkin.

With an existing repo that you have already checked out – that has the correct line endings in the repo but not your working copy – you can run the following commands to fix it:

git rm -rf --cached .
git reset --hard HEAD


This will delete (rm) recursively (r) without prompt (-f), all files except those that you have edited (--cached), from the current directory (.). The reset then returns all of those files to a state where they have their true line endings (matching what's in the repo).

If you need to fix the line endings of files in a repo, I recommend grabbing an editor that will let you do that in bulk like IntelliJ or Sublime Text, but I'm sure any good one will likely support this.
    Context
If you

want to force all users to have LF line endings for text files and
you cannot ensure that all users change their git config,

you can do that starting with git 2.10. 2.10 or later is required, because 2.10 fixed the behavior of text=auto together with eol=lf. Source.
Solution
Put a .gitattributes file in the root of your git repository having following contents:
* text=auto eol=lf

Commit it.
Optional tweaks
You can also add an .editorconfig in the root of your repository to ensure that modern tooling creates new files with the desired line endings.
# EditorConfig is awesome: http://EditorConfig.org

# top-most EditorConfig file
root = true

# Unix-style newlines with a newline ending every file
[*]
end_of_line = lf
insert_final_newline = true

    The OP added in his question:


  the files checked out using msysgit are using CR+LF and I want to force msysgit to get them with LF


A first simple step would still be in a .gitattributes file:

# 2010
*.txt -crlf

# 2020
*.txt text eol=lf 


(as noted in the comments by grandchild, referring to .gitattributes End-of-line conversion), to avoid any CRLF conversion for files with correct eol.

And I have always recommended git config --global core.autocrlf false to disable any conversion (which would apply to all versioned files)

See Best practices for cross platform git config?

Since Git 2.16 (Q1 2018), you can use git add --renormalize . to apply those .gitattributes settings immediately.



But a second more powerful step involves a gitattribute filter driver and add a smudge step



Whenever you would update your working tree, a script could, only for the files you have specified in the .gitattributes, force the LF eol and any other formatting option you want to enforce.
If the ""clear"" script doesn't do anything, you will have (after commit) transformed your files, applying exactly the format you need them to follow.
    core.autocrlf=input is the right setting for what you want, but you might have to do a git update-index --refresh and/or a git reset --hard for the change to take effect.

With core.autocrlf set to input, git will not apply newline-conversion on check-out (so if you have LF in the repo, you'll get LF), but it will make sure that in case you mess up and introduce some CRLFs in the working copy somehow, they won't make their way into the repo.
    You can find the solution to this problem at:
https://help.github.com/en/github/using-git/configuring-git-to-handle-line-endings

Simplified description of how you can solve this problem on windows:

Global settings for line endings
The git config core.autocrlf command is used to change how Git handles line endings. It takes a single argument.

On Windows, you simply pass true to the configuration. For example:
C:>git config --global core.autocrlf true

Good luck, I hope I helped.
    ","[491, 594, 339, 104, 173, 28, 0]",318291,266,2010-03-25T16:07:33,2020-08-17 04:52:48Z,
HashSet vs. List performance,"
                
It's clear that a search performance of the generic HashSet<T> class is higher than of the generic List<T> class. Just compare the hash-based key with the linear approach in the List<T> class.

However calculating a hash key may itself take some CPU cycles, so for a small amount of items the linear search can be a real alternative to the HashSet<T>.

My question: where is the break-even?

To simplify the scenario (and to be fair) let's assume that the List<T> class uses the element's Equals() method to identify an item.
    A lot of people are saying that once you get to the size where speed is actually a concern that HashSet<T> will always beat List<T>, but that depends on what you are doing.
Let's say you have a List<T> that will only ever have on average 5 items in it.  Over a large number of cycles, if a single item is added or removed each cycle, you may well be better off using a List<T>.
I did a test for this on my machine, and, well, it has to be very very small to get an advantage from List<T>. For a list of short strings, the advantage went away after size 5, for objects after size 20.
1 item LIST strs time: 617ms
1 item HASHSET strs time: 1332ms

2 item LIST strs time: 781ms
2 item HASHSET strs time: 1354ms

3 item LIST strs time: 950ms
3 item HASHSET strs time: 1405ms

4 item LIST strs time: 1126ms
4 item HASHSET strs time: 1441ms

5 item LIST strs time: 1370ms
5 item HASHSET strs time: 1452ms

6 item LIST strs time: 1481ms
6 item HASHSET strs time: 1418ms

7 item LIST strs time: 1581ms
7 item HASHSET strs time: 1464ms

8 item LIST strs time: 1726ms
8 item HASHSET strs time: 1398ms

9 item LIST strs time: 1901ms
9 item HASHSET strs time: 1433ms

1 item LIST objs time: 614ms
1 item HASHSET objs time: 1993ms

4 item LIST objs time: 837ms
4 item HASHSET objs time: 1914ms

7 item LIST objs time: 1070ms
7 item HASHSET objs time: 1900ms

10 item LIST objs time: 1267ms
10 item HASHSET objs time: 1904ms

13 item LIST objs time: 1494ms
13 item HASHSET objs time: 1893ms

16 item LIST objs time: 1695ms
16 item HASHSET objs time: 1879ms

19 item LIST objs time: 1902ms
19 item HASHSET objs time: 1950ms

22 item LIST objs time: 2136ms
22 item HASHSET objs time: 1893ms

25 item LIST objs time: 2357ms
25 item HASHSET objs time: 1826ms

28 item LIST objs time: 2555ms
28 item HASHSET objs time: 1865ms

31 item LIST objs time: 2755ms
31 item HASHSET objs time: 1963ms

34 item LIST objs time: 3025ms
34 item HASHSET objs time: 1874ms

37 item LIST objs time: 3195ms
37 item HASHSET objs time: 1958ms

40 item LIST objs time: 3401ms
40 item HASHSET objs time: 1855ms

43 item LIST objs time: 3618ms
43 item HASHSET objs time: 1869ms

46 item LIST objs time: 3883ms
46 item HASHSET objs time: 2046ms

49 item LIST objs time: 4218ms
49 item HASHSET objs time: 1873ms

Here is that data displayed as a graph:

Here's the code:
static void Main(string[] args)
{
    int times = 10000000;

    for (int listSize = 1; listSize < 10; listSize++)
    {
        List<string> list = new List<string>();
        HashSet<string> hashset = new HashSet<string>();

        for (int i = 0; i < listSize; i++)
        {
            list.Add(""string"" + i.ToString());
            hashset.Add(""string"" + i.ToString());
        }

        Stopwatch timer = new Stopwatch();
        timer.Start();
        for (int i = 0; i < times; i++)
        {
            list.Remove(""string0"");
            list.Add(""string0"");
        }
        timer.Stop();
        Console.WriteLine(listSize.ToString() + "" item LIST strs time: "" + timer.ElapsedMilliseconds.ToString() + ""ms"");

        timer = new Stopwatch();
        timer.Start();
        for (int i = 0; i < times; i++)
        {
            hashset.Remove(""string0"");
            hashset.Add(""string0"");
        }
        timer.Stop();
        Console.WriteLine(listSize.ToString() + "" item HASHSET strs time: "" + timer.ElapsedMilliseconds.ToString() + ""ms"");
        Console.WriteLine();
    }

    for (int listSize = 1; listSize < 50; listSize+=3)
    {
        List<object> list = new List<object>();
        HashSet<object> hashset = new HashSet<object>();

        for (int i = 0; i < listSize; i++)
        {
            list.Add(new object());
            hashset.Add(new object());
        }

        object objToAddRem = list[0];
        
        Stopwatch timer = new Stopwatch();
        timer.Start();
        for (int i = 0; i < times; i++)
        {
            list.Remove(objToAddRem);
            list.Add(objToAddRem);
        }
        timer.Stop();
        Console.WriteLine(listSize.ToString() + "" item LIST objs time: "" + timer.ElapsedMilliseconds.ToString() + ""ms"");

        timer = new Stopwatch();
        timer.Start();
        for (int i = 0; i < times; i++)
        {
            hashset.Remove(objToAddRem);
            hashset.Add(objToAddRem);
        }
        timer.Stop();
        Console.WriteLine(listSize.ToString() + "" item HASHSET objs time: "" + timer.ElapsedMilliseconds.ToString() + ""ms"");
        Console.WriteLine();
    }

    Console.ReadLine();
}

    It's essentially pointless to compare two structures for performance that behave differently. Use the structure that conveys the intent. Even if you say your List<T> wouldn't have duplicates and iteration order doesn't matter making it comparable to a HashSet<T>, its still a poor choice to use List<T> because its relatively less fault tolerant. 

That said, I will inspect some other aspects of performance, 

+------------+--------+-------------+-----------+----------+----------+-----------+
| Collection | Random | Containment | Insertion | Addition |  Removal | Memory    |
|            | access |             |           |          |          |           |
+------------+--------+-------------+-----------+----------+----------+-----------+
| List<T>    | O(1)   | O(n)        | O(n)      | O(1)*    | O(n)     | Lesser    |
| HashSet<T> | O(n)   | O(1)        | n/a       | O(1)     | O(1)     | Greater** |
+------------+--------+-------------+-----------+----------+----------+-----------+



Even though addition is O(1) in both cases, it will be relatively slower in HashSet since it involves cost of precomputing hash code before storing it.
The superior scalability of HashSet has a memory cost. Every entry is stored as a new object along with its hash code. This article might give you an idea.

    Just thought I'd chime in with some benchmarks for different scenarios to illustrate the previous answers:


A few (12 - 20) small strings (length between 5 and 10 characters)
Many (~10K) small strings
A few long strings (length between 200 and 1000 characters)
Many (~5K) long strings
A few integers
Many (~10K) integers


And for each scenario, looking up values which appear:


In the beginning of the list (""start"", index 0)
Near the beginning of the list (""early"", index 1)
In the middle of the list (""middle"", index count/2)
Near the end of the list (""late"", index count-2)
At the end of the list (""end"", index count-1)


Before each scenario I generated randomly sized lists of random strings, and then fed each list to a hashset.  Each scenario ran 10,000 times, essentially:

(test pseudocode)

stopwatch.start
for X times
    exists = list.Contains(lookup);
stopwatch.stop

stopwatch.start
for X times
    exists = hashset.Contains(lookup);
stopwatch.stop


Sample Output

Tested on Windows 7, 12GB Ram, 64 bit, Xeon 2.8GHz

---------- Testing few small strings ------------
Sample items: (16 total)
vgnwaloqf diwfpxbv tdcdc grfch icsjwk
...

Benchmarks:
1: hashset: late -- 100.00 % -- [Elapsed: 0.0018398 sec]
2: hashset: middle -- 104.19 % -- [Elapsed: 0.0019169 sec]
3: hashset: end -- 108.21 % -- [Elapsed: 0.0019908 sec]
4: list: early -- 144.62 % -- [Elapsed: 0.0026607 sec]
5: hashset: start -- 174.32 % -- [Elapsed: 0.0032071 sec]
6: list: middle -- 187.72 % -- [Elapsed: 0.0034536 sec]
7: list: late -- 192.66 % -- [Elapsed: 0.0035446 sec]
8: list: end -- 215.42 % -- [Elapsed: 0.0039633 sec]
9: hashset: early -- 217.95 % -- [Elapsed: 0.0040098 sec]
10: list: start -- 576.55 % -- [Elapsed: 0.0106073 sec]


---------- Testing many small strings ------------
Sample items: (10346 total)
dmnowa yshtrxorj vthjk okrxegip vwpoltck
...

Benchmarks:
1: hashset: end -- 100.00 % -- [Elapsed: 0.0017443 sec]
2: hashset: late -- 102.91 % -- [Elapsed: 0.0017951 sec]
3: hashset: middle -- 106.23 % -- [Elapsed: 0.0018529 sec]
4: list: early -- 107.49 % -- [Elapsed: 0.0018749 sec]
5: list: start -- 126.23 % -- [Elapsed: 0.0022018 sec]
6: hashset: early -- 134.11 % -- [Elapsed: 0.0023393 sec]
7: hashset: start -- 372.09 % -- [Elapsed: 0.0064903 sec]
8: list: middle -- 48,593.79 % -- [Elapsed: 0.8476214 sec]
9: list: end -- 99,020.73 % -- [Elapsed: 1.7272186 sec]
10: list: late -- 99,089.36 % -- [Elapsed: 1.7284155 sec]


---------- Testing few long strings ------------
Sample items: (19 total)
hidfymjyjtffcjmlcaoivbylakmqgoiowbgxpyhnrreodxyleehkhsofjqenyrrtlphbcnvdrbqdvji...
...

Benchmarks:
1: list: early -- 100.00 % -- [Elapsed: 0.0018266 sec]
2: list: start -- 115.76 % -- [Elapsed: 0.0021144 sec]
3: list: middle -- 143.44 % -- [Elapsed: 0.0026201 sec]
4: list: late -- 190.05 % -- [Elapsed: 0.0034715 sec]
5: list: end -- 193.78 % -- [Elapsed: 0.0035395 sec]
6: hashset: early -- 215.00 % -- [Elapsed: 0.0039271 sec]
7: hashset: end -- 248.47 % -- [Elapsed: 0.0045386 sec]
8: hashset: start -- 298.04 % -- [Elapsed: 0.005444 sec]
9: hashset: middle -- 325.63 % -- [Elapsed: 0.005948 sec]
10: hashset: late -- 431.62 % -- [Elapsed: 0.0078839 sec]


---------- Testing many long strings ------------
Sample items: (5000 total)
yrpjccgxjbketcpmnvyqvghhlnjblhgimybdygumtijtrwaromwrajlsjhxoselbucqualmhbmwnvnpnm
...

Benchmarks:
1: list: early -- 100.00 % -- [Elapsed: 0.0016211 sec]
2: list: start -- 132.73 % -- [Elapsed: 0.0021517 sec]
3: hashset: start -- 231.26 % -- [Elapsed: 0.003749 sec]
4: hashset: end -- 368.74 % -- [Elapsed: 0.0059776 sec]
5: hashset: middle -- 385.50 % -- [Elapsed: 0.0062493 sec]
6: hashset: late -- 406.23 % -- [Elapsed: 0.0065854 sec]
7: hashset: early -- 421.34 % -- [Elapsed: 0.0068304 sec]
8: list: middle -- 18,619.12 % -- [Elapsed: 0.3018345 sec]
9: list: end -- 40,942.82 % -- [Elapsed: 0.663724 sec]
10: list: late -- 41,188.19 % -- [Elapsed: 0.6677017 sec]


---------- Testing few ints ------------
Sample items: (16 total)
7266092 60668895 159021363 216428460 28007724
...

Benchmarks:
1: hashset: early -- 100.00 % -- [Elapsed: 0.0016211 sec]
2: hashset: end -- 100.45 % -- [Elapsed: 0.0016284 sec]
3: list: early -- 101.83 % -- [Elapsed: 0.0016507 sec]
4: hashset: late -- 108.95 % -- [Elapsed: 0.0017662 sec]
5: hashset: middle -- 112.29 % -- [Elapsed: 0.0018204 sec]
6: hashset: start -- 120.33 % -- [Elapsed: 0.0019506 sec]
7: list: late -- 134.45 % -- [Elapsed: 0.0021795 sec]
8: list: start -- 136.43 % -- [Elapsed: 0.0022117 sec]
9: list: end -- 169.77 % -- [Elapsed: 0.0027522 sec]
10: list: middle -- 237.94 % -- [Elapsed: 0.0038573 sec]


---------- Testing many ints ------------
Sample items: (10357 total)
370826556 569127161 101235820 792075135 270823009
...

Benchmarks:
1: list: early -- 100.00 % -- [Elapsed: 0.0015132 sec]
2: hashset: end -- 101.79 % -- [Elapsed: 0.0015403 sec]
3: hashset: early -- 102.08 % -- [Elapsed: 0.0015446 sec]
4: hashset: middle -- 103.21 % -- [Elapsed: 0.0015618 sec]
5: hashset: late -- 104.26 % -- [Elapsed: 0.0015776 sec]
6: list: start -- 126.78 % -- [Elapsed: 0.0019184 sec]
7: hashset: start -- 130.91 % -- [Elapsed: 0.0019809 sec]
8: list: middle -- 16,497.89 % -- [Elapsed: 0.2496461 sec]
9: list: end -- 32,715.52 % -- [Elapsed: 0.4950512 sec]
10: list: late -- 33,698.87 % -- [Elapsed: 0.5099313 sec]

    You're looking at this wrong. Yes a linear search of a List will beat a HashSet for a small number of items. But the performance difference usually doesn't matter for collections that small. It's generally the large collections you have to worry about, and that's where you think in terms of Big-O. However, if you've measured a real bottleneck on HashSet performance, then you can try to create a hybrid List/HashSet, but you'll do that by conducting lots of empirical performance tests - not asking questions on SO.
    Whether to use a HashSet<> or List<> comes down to how you need to access your collection. If you need to guarantee the order of items, use a List. If you don't, use a HashSet. Let Microsoft worry about the implementation of their hashing algorithms and objects.

A HashSet will access items without having to enumerate the collection (complexity of O(1) or near it), and because a List guarantees order, unlike a HashSet, some items will have to be enumerated (complexity of O(n)).
    You can use a HybridDictionary which automaticly detects the breaking point, and accepts null-values, making it essentialy the same as a HashSet.
    Depends on a lot of factors... List implementation, CPU architecture, JVM, loop semantics, complexity of equals method, etc... By the time the list gets big enough to effectively benchmark (1000+ elements), Hash-based binary lookups beat linear searches hands-down, and the difference only scales up from there. 

Hope this helps!
    The breakeven will depend on the cost of computing the hash. Hash computations can be trivial, or not... :-) There is always the System.Collections.Specialized.HybridDictionary class to help you not have to worry about the breakeven point.
    The answer, as always, is ""It depends"".  I assume from the tags you're talking about C#.

Your best bet is to determine


A Set of data
Usage requirements


and write some test cases.

It also depends on how you sort the list (if it's sorted at all), what kind of comparisons need to be made, how long the ""Compare"" operation takes for the particular object in the list, or even how you intend to use the collection.

Generally, the best one to choose isn't so much based on the size of data you're working with, but rather how you intend to access it.  Do you have each piece of data associated with a particular string, or other data?  A hash based collection would probably be best.  Is the order of the data you're storing important, or are you going to need to access all of the data at the same time?  A regular list may be better then.

Additional:

Of course, my above comments assume 'performance' means data access.  Something else to consider: what are you looking for when you say ""performance""?  Is performance individual value look up?  Is it management of large (10000, 100000 or more) value sets?  Is it the performance of filling the data structure with data?  Removing data?  Accessing individual bits of data?  Replacing values?  Iterating over the values?  Memory usage?  Data copying speed?  For example, If you access data by a string value, but your main performance requirement is minimal memory usage, you might have conflicting design issues.
    It depends.  If the exact answer really matters, do some profiling and find out.  If you're sure you'll never have more than a certain number of elements in the set, go with a List.  If the number is unbounded, use a HashSet.
    Depends on what you're hashing. If your keys are integers you probably don't need very many items before the HashSet is faster. If you're keying it on a string then it will be slower, and depends on the input string.

Surely you could whip up a benchmark pretty easily?
    One factor your not taking into account is the robustness of the GetHashcode() function.  With a perfect hash function the HashSet will clearly have better searching performance.  But as the hash function diminishes so will the HashSet search time.  
    ","[491, 935, 95, 35, 77, 56, 8, 1, 11, 6, 4, 3, 3]",276543,162,2008-09-29T21:24:15,2022-04-13 08:08:01Z,
Flexbox not giving equal width to elements,"
                
Attempting a flexbox nav that has up to 5 items and as little as 3, but it's not dividing the width equally between all the elements.

Fiddle

The tutorial I'm modeling this after is http://www.sitepoint.com/responsive-fluid-width-variable-item-navigation-css/

SASS

* {
  font-size: 16px;
}

.tabs {
  max-width: 1010px;
  width: 100%;
  height: 5rem;
  border-bottom: solid 1px grey;
  margin: 0 0 0 6.5rem;
  display: table;
  table-layout: fixed;
}
.tabs ul {
  margin: 0;
  display: flex;
  flex-direction: row;
}
.tabs ul li {
  flex-grow: 1;
  list-style: none;
  text-align: center;
  font-size: 1.313rem;
  background: blue;
  color: white;
  height: inherit;
  left: auto;
  vertical-align: top;
  text-align: left;
  padding: 20px 20px 20px 70px;
  border-top-left-radius: 20px;
  border: solid 1px blue;
  cursor: pointer;
}
.tabs ul li.active {
  background: white;
  color: blue;
}
.tabs ul li:before {
  content: """";
}<div class=""tabs"">
  <ul>
    <li class=""active"" data-tab=""1"">Pizza</li>
    <li data-tab=""2"">Chicken Noodle Soup</li>
    <li data-tab=""3"">Peanut Butter</li>
    <li data-tab=""4"">Fish</li>
  </ul>
</div>

    There is an important bit that is not mentioned in the article to which you linked and that is flex-basis.  By default flex-basis is auto.  

From the spec:


  If the specified flex-basis is auto, the used flex basis is the value of the flex item’s main size property. (This can itself be the keyword auto, which sizes the flex item based on its contents.) 


Each flex item has a flex-basis which is sort of like its initial size.  Then from there, any remaining free space is distributed proportionally (based on flex-grow) among the items.  With auto, that basis is the contents size (or defined size with width, etc.).  As a result, items with bigger text within are being given more space overall in your example.

If you want your elements to be completely even, you can set flex-basis: 0.  This will set the flex basis to 0 and then any remaining space (which will be all space since all basises are 0) will be proportionally distributed based on flex-grow.

li {
    flex-grow: 1;
    flex-basis: 0;
    /* ... */
}


This diagram from the spec does a pretty good job of illustrating the point.

And here is a working example with your fiddle.
    As explained in @James Montagne answer flex-basis: 0 will ensure the flexbox columns are distributed evenly which works in this case since the column content can wrap and isn't forcing the width. However, in cases where the width of the column content is forced (for example with image width or white-space: nowrap), the solution is to set min-width: 0...
li {
  flex-grow: 1;
  flex-basis: 0;
  min-width: 0;
}

https://codeply.com/p/sLZxZRFduI
    To create elements with equal width using Flex, you should set to your's child (flex elements):

flex-basis: 25%;
flex-grow: 0;


It will give to all elements in row 25% width. They will not grow and go one by one.
    Solution:
flex: 1;

OR
.flex-child-items{
   flex-grow: 1;
} 

Explanation:
If you only put display: flex it just horizontally align all the item and the width is going to be sum of child's width (depend on the content or sometimes width property).
For example:
// A normal flex
++++++++++   ++++++++++   ++++++++++
+        +   +        +   +        +
+   A    +   +   B    +   +   C    +
+  10px  +   +  10px  +   +  10px  +
+        +   +        +   +        +
++++++++++   ++++++++++   ++++++++++

Now suppose you want to divide space equally to all of them.
To do this add flex-grow: 1 to all children of flex. (In this example A,B and C)
.A, .B, .C {
    flex-grow: 1;
}

After this it looks like this:
++++++++++                              ++++++++++                              ++++++++++
+        +                              +        +                              +        +
+   A    +                              +   B    +                              +   C    +
+  10px  +                              +  10px  +                              +  10px  +
+        +                              +        +                              +        +
++++++++++                              ++++++++++                              ++++++++++

*BTW, if the above example box does not look like center, sorry for that but code work try it on the project.
    Flex may not give equal widths to children in all cases.

use css grid for equal width elements.

.el{
 display: grid;
 grid-auto-flow: column;
 grid-auto-columns: 1fr
}

Reference https://css-tricks.com/equal-columns-with-flexbox-its-more-complicated-than-you-might-think/
If you wish to use CSS flex only, then there are few options

flex-basis: 100% to all the childs, this will be a close match.
OR
flex-basis: 0 this is less useful than first option

    ","[491, 1188, 15, 21, 3, -4]",401559,89,2014-07-31T18:19:59,2021-10-28 14:16:58Z,html css 
Unresolved reference issue in PyCharm,"
                
I have a directory structure

├── simulate.py
├── src
│   ├── networkAlgorithm.py
│   ├── ...


And I can access the network module with sys.path.insert().    

import sys
import os.path
sys.path.insert(0, ""./src"")
from networkAlgorithm import *


However, pycharm complains that it cannot access the module. How can I teach pycham to resolve the reference?


    Manually adding it as you have done is indeed one way of doing this, but there is a simpler method, and that is by simply telling pycharm that you want to add the src folder as a source root, and then adding the sources root to your python path.
This way, you don't have to hard code things into your interpreter's settings:

Add src as a source content root:

                           


Then make sure to add add sources to your PYTHONPATH under:
Preferences ~ Build, Execution, Deployment ~ Console ~ Python Console





Now imports will be resolved:

                     

This way, you can add whatever you want as a source root, and things will simply work. If you unmarked it as a source root however, you will get an error:
                                 

After all this don't forget to restart. In PyCharm menu select: File --> Invalidate Caches / Restart
    There are several reasons why this could be happening. Below are several steps that fixes the majority of those cases:
.idea caching issue
Some .idea issue causing the IDE to show error while the code still runs correctly. Solution:

close the project and quick PyCharm
delete the .idea folder where the project is. note that it is a hidden folder and you might not be aware of its existence in your project directory.
start PyCharm and recreate the project

imports relative not to project folder
Relative imports while code root folder is not the same as the project folder. Solution:

Find the folder that relative imports require in the project explorer
right click and mark it as ""Source Root""

Editor not marking init.py as Python but as Text
Which is the most illusive of all the cases. Here, for some reason, PyCharm considers all __init__.py files not to be python files, and thus ignores them during code analysis. To fix this:

Open PyCharm settings
Navigate to Editor -> File Types
Find Python and add __init__.py to the list of python files

or

Find Text and delete __init__.py from the list of text files

    The project I cloned had a directory called modules and was successfully using files from there in the code with import this as that, but Pycharm was unable to jump to those code fragments because it did not recognise the imports.
Marking the module folder in the following settings section as source solved the issue.

    If anyone is still looking at this, the accepted answer still works for PyCharm 2016.3 when I tried it. The UI might have changed, but the options are still the same. 

ie. Right click on your root folder --> 'Mark Directory As' --> Source Root
    For my case :
Directory0
    ├── Directory1
    │     └── file1.py  
    ├── Directory2
    │     ├── file2.py  

Into file1, I have :
from Directory2 import file2

which trows an ""unresolved reference Directory2"".
I resolved it by:

marking the parent directory Directory0 as ""Source Root"" like said above

AND

putting my cursor on another line on the file where I had the error so that it takes my modification into account

It is silly but if I don't do the second action, the error still appears and can make you think that you didn't resolve the issue by marking the parent directory as Source Root.
    
--> Right-click on the directory where your files are located in PyCharm
Go to the --> Mark Directory as
Select the --> Source Root

your problem will be solved
    I was also using a virtual environment like Dan above, however I was able to add an interpreter in the existing environment, therefore not needing to inherit global site packages and therefore undo what a virtual environment is trying to achieve.
    Although all the answers are really helpful, there's one tiny piece of information that should be explained explicitly:


Essentially, a project with multiple hierarchical directories work as a package with some attributes.
To import custom local created Classes, we need to navigate to the directory containing .py file and create an __init__.py (empty) file there.


Why this helps is because this file is required to make Python treat the directory as containing packages. Cheers!
    This worked for me: Top Menu -> File -> Invalidate Caches/Restart
    Done in PyCharm 2019.3.1
Right-click on your src folder -> ""Mark Directory as"" -> Click-on ""Excluded"" and your src folder should be blue.  
    Many a times what happens is that the plugin is not installed. e.g. 

If you are developing a django project and you do not have django plugin installed in pyCharm, it says error 'unresolved reference'. 
Refer:
https://www.jetbrains.com/pycharm/help/resolving-references.html
    Please check if you are using the right interpreter that you are supposed to. I was getting error ""unresolved reference 'django' "" to solve this I changed Project Interpreter (Changed Python 3 to Python 2.7) from project settings:
Select Project, go to File -> Settings -> Project: -> Project Interpreter -> Brows and Select correct version or Interpreter (e.g /usr/bin/python2.7).
    In my case the problem was I was using Virtual environment which didn't have access to global site-packages. Thus, the interpreter was not aware of the newly installed packages.

To resolve the issue, just edit or recreate your virtual interpreter and tick the Inherit global site-packages option.


    Pycharm uses venv. In the venv's console you should install the packages explicitly or go in settings -> project interpreter -> add interpreter -> inherit global site-packages.
    The easiest way to fix it is by doing the following in your pyCharm software:

Click on: File > Settings > (Project: your project name) > Project Interpreter >

then click on the ""+"" icon on the right side to search for the package you want and install it.

Enjoy coding !!!
    In newer versions of pycharm u can do simply by right clicking on the directory or python package from which you want to import a file, then click on 'Mark Directory As' -> 'Sources Root'
    
check for __init__.py file in src folder 
add the src folder as a source root
Then make sure to add add sources to your PYTHONPATH (see above)
in PyCharm menu select: File --> Invalidate Caches / Restart 

    After testing all workarounds, i suggest you to take a look at Settings -> Project -> project dependencies and re-arrange them.


    Generally, this is a missing package problem, just place the caret at the unresolved reference and press Alt+Enter to reveal the options, then you should know how to solve it.
    Install via PyCharm (works with Community Edition). Open up Settings > Project > Project Interpreter then click the green + icon in the screenshot below. In the 2nd dialogue that opens, enter the package name and click the 'Install Package' button.


    After following the accepted answer, doing the following solved it for me:

File → Settings → Project <your directory/project> → Project Dependencies

Chose the directory/project where your file that has unresolved imports resides and check the box to tell Pycharm that that project depends on your other project.

My folder hierarcy is slightly different from the one in the question. Mine is like this

├── MyDirectory  
│     └── simulate.py  
├── src  
│     ├── networkAlgorithm.py  
│     ├── ...


Telling Pycharm that src depends on MyDirectory solved the issue for me!
    Normally, $PYTHONPATH is used to teach python interpreter to find necessary modules. PyCharm needs to add the path in Preference.


    For me, adding virtualenv (venv)'s site-packages path to the paths of the interpreter works.
Finally!


    I tried everything here twice and even more. I finally solved it doing something I hadn't seen anywhere online.  If you go to Settings>Editor>File Types there is an 'Ignore Files and folders' line at the bottom.  In my case, I was ignoring 'venv', which is what I always name my virtual environments.  So I removed venv; from the list of directories to ignore and VOILA!!  I was FINALLY able to fix this problem.  Literally all of my import problems were fixed for the project.
BTW, I had installed each and every package using PyCharm, and not through a terminal. (Meaning, by going to Settings>Interpreter...). I had invalidated cache, changed 'Source Root', restarted PyCharm, refreshed my interpreters paths, changed interpreters, deleted my venv...  I tried everything.  This finally worked. Obviously there are multiple problems going on here with different people, so this may not work for you, but it's definitely worth a shot if nothing else has worked, and easy to reverse if it doesn't.
    I had the same problem and also try so many suggestions but none of them worked, until I find this post (https://stackoverflow.com/a/62632870/16863617). Regardless his solution didn't work for me, it helped me to came up with the idea to add _init.py_ into the --> Settings | Editor | File Types | Python | Registered patterns
ScreenShot
And the unresolved reference error is now solved.
    ","[491, 1009, 7, 5, 29, 1, 3, 2, 4, 3, 1, 2, 1, 1, -1, -1, -2, 59, 18, 5, 3, 3, 14, 0, 0, 0]",505220,166,2014-01-20T14:44:29,2021-12-13 22:05:24Z,python 
Easy way to turn JavaScript array into comma-separated list?,"
                
I have a one-dimensional array of strings in JavaScript that I'd like to turn into a comma-separated list. Is there a simple way in garden-variety JavaScript (or jQuery) to turn that into a comma-separated list? (I know how to iterate through the array and build the string myself by concatenation if that's the only way.)
    The Array.prototype.join() method:

var arr = [""Zero"", ""One"", ""Two""];

document.write(arr.join("", ""));

    Simple Array
let simpleArray = [1,2,3,4]
let commaSeperated = simpleArray.join("","");
console.log(commaSeperated);

Array of Objects with a particular attributes as comma separated.
let arrayOfObjects = [
{
id : 1,
name : ""Name 1"",
address : ""Address 1""
},
{
id : 2,
name : ""Name 2"",
address : ""Address 2""
},
{
id : 3,
name : ""Name 3"",
address : ""Address 3""
}]
let names = arrayOfObjects.map(x => x.name).join("", "");
console.log(names);

Result
Name 1, Name 2, Name 3

    Actually, the toString() implementation does a join with commas by default:

var arr = [ 42, 55 ];
var str1 = arr.toString(); // Gives you ""42,55""
var str2 = String(arr); // Ditto


I don't know if this is mandated by the JS spec but this is what most pretty much all browsers seem to be doing.
    As of Chrome 72, it's possible to use Intl.ListFormat:

const vehicles = ['Motorcycle', 'Bus', 'Car'];

const formatter = new Intl.ListFormat('en', { style: 'long', type: 'conjunction' });
console.log(formatter.format(vehicles));
// expected output: ""Motorcycle, Bus, and Car""

const formatter2 = new Intl.ListFormat('de', { style: 'short', type: 'disjunction' });
console.log(formatter2.format(vehicles));
// expected output: ""Motorcycle, Bus oder Car""

const formatter3 = new Intl.ListFormat('en', { style: 'narrow', type: 'unit' });
console.log(formatter3.format(vehicles));
// expected output: ""Motorcycle Bus Car""


Please note that this way is in its very earlier stage, so as of the date of posting this answer, expect incompatibility with older versions of Chrome and other browsers.
    If you need to use "" and "" instead of "", "" between the last two items you can do this:

function arrayToList(array){
  return array
    .join("", "")
    .replace(/, ((?:.(?!, ))+)$/, ' and $1');
}

    Use the built-in Array.toString method 

var arr = ['one', 'two', 'three'];
arr.toString();  // 'one,two,three'


MDN on Array.toString()
    const arr = [1, 2, 3];
console.log(`${arr}`)

    
here you can separate with any char and can take any property list with just foreach

let taskIds: string = '';    
this.checkedTaskList.forEach(res => {
  taskIds = taskIds + res.taskId.toString() + ','
});
if (taskIds) {
    taskIds.substring(0, taskIds.length - 1),**
}

    Or (more efficiently):


var arr = new Array(3);
arr[0] = ""Zero"";
arr[1] = ""One"";
arr[2] = ""Two"";

document.write(arr); // same as document.write(arr.toString()) in this context


The toString method of an array when called returns exactly what you need - comma-separated list.
    Here's an implementation that converts a two-dimensional array or an array of columns into a properly escaped CSV string. The functions do not check for valid string/number input or column counts (ensure your array is valid to begin with). The cells can contain commas and quotes! 

Here's a script for decoding CSV strings.

Here's my script for encoding CSV strings:

// Example
var csv = new csvWriter();
csv.del = '\t';
csv.enc = ""'"";

var nullVar;
var testStr = ""The comma (,) pipe (|) single quote (') double quote (\"") and tab (\t) are commonly used to tabulate data in plain-text formats."";
var testArr = [
    false,
    0,
    nullVar,
    // undefinedVar,
    '',
    {key:'value'},
];

console.log(csv.escapeCol(testStr));
console.log(csv.arrayToRow(testArr));
console.log(csv.arrayToCSV([testArr, testArr, testArr]));

/**
 * Class for creating csv strings
 * Handles multiple data types
 * Objects are cast to Strings
 **/

function csvWriter(del, enc) {
    this.del = del || ','; // CSV Delimiter
    this.enc = enc || '""'; // CSV Enclosure

    // Convert Object to CSV column
    this.escapeCol = function (col) {
        if(isNaN(col)) {
            // is not boolean or numeric
            if (!col) {
                // is null or undefined
                col = '';
            } else {
                // is string or object
                col = String(col);
                if (col.length > 0) {
                    // use regex to test for del, enc, \r or \n
                    // if(new RegExp( '[' + this.del + this.enc + '\r\n]' ).test(col)) {

                    // escape inline enclosure
                    col = col.split( this.enc ).join( this.enc + this.enc );

                    // wrap with enclosure
                    col = this.enc + col + this.enc;
                }
            }
        }
        return col;
    };

    // Convert an Array of columns into an escaped CSV row
    this.arrayToRow = function (arr) {
        var arr2 = arr.slice(0);

        var i, ii = arr2.length;
        for(i = 0; i < ii; i++) {
            arr2[i] = this.escapeCol(arr2[i]);
        }
        return arr2.join(this.del);
    };

    // Convert a two-dimensional Array into an escaped multi-row CSV 
    this.arrayToCSV = function (arr) {
        var arr2 = arr.slice(0);

        var i, ii = arr2.length;
        for(i = 0; i < ii; i++) {
            arr2[i] = this.arrayToRow(arr2[i]);
        }
        return arr2.join(""\r\n"");
    };
}

    There are many methods to convert an array to comma separated list

1. Using array#join

From MDN


  The join() method joins all elements of an array (or an array-like object) into a string.


The code

var arr = [""this"",""is"",""a"",""comma"",""separated"",""list""];
arr = arr.join("","");


Snippet

var arr = [""this"", ""is"", ""a"", ""comma"", ""separated"", ""list""];
arr = arr.join("","");
console.log(arr);


2. Using array#toString

From MDN


  The toString() method returns a string representing the specified array and its elements.


The code

var arr = [""this"",""is"",""a"",""comma"",""separated"",""list""];
arr = arr.toString();


Snippet

var arr = [""this"", ""is"", ""a"", ""comma"", ""separated"", ""list""];
arr = arr.toString();
console.log(arr);


3. Add []+ before array or +[] after an array

The []+ or +[] will convert it into a string

Proof

([]+[] === [].toString())


will output true

console.log([]+[] === [].toString());


var arr = [""this"",""is"",""a"",""comma"",""separated"",""list""];
arr = []+arr;


Snippet

var arr = [""this"", ""is"", ""a"", ""comma"", ""separated"", ""list""];
arr = []+arr;
console.log(arr);


Also

var arr = [""this"",""is"",""a"",""comma"",""separated"",""list""];
arr = arr+[];


var arr = [""this"", ""is"", ""a"", ""comma"", ""separated"", ""list""];
arr = arr + [];
console.log(arr);

    I liked the solution at https://jsfiddle.net/rwone/qJUh2/ because it adds spaces after commas:

array = [""test"",""test2"",""test3""]
array = array.toString();
array = array.replace(/,/g, "", "");
alert(array);


Or, as suggested by @StackOverflaw in the comments:

array.join(', ');

    Papa Parse  handles commas in values and other edge cases.

(Baby Parse for Node has been deprecated - you can now use Papa Parse in the Browser and in Node.)

Eg. (node)

const csvParser = require('papaparse'); // previously you might have used babyparse
var arr = [1,null,""a,b""] ;
var csv = csvParser.unparse([arr]) ;
console.log(csv) ;


1,,""a,b""
    I think this should do it:

var arr = ['contains,comma', 3.14, 'contains""quote', ""more'quotes""]
var item, i;
var line = [];

for (i = 0; i < arr.length; ++i) {
    item = arr[i];
    if (item.indexOf && (item.indexOf(',') !== -1 || item.indexOf('""') !== -1)) {
        item = '""' + item.replace(/""/g, '""""') + '""';
    }
    line.push(item);
}

document.getElementById('out').innerHTML = line.join(',');


fiddle

Basically all it does is check if the string contains a comma or quote. If it does, then it doubles all the quotes, and puts quotes on the ends. Then it joins each of the parts with a comma.
    var array = [""Zero"", ""One"", ""Two""];
var s = array + [];
console.log(s); // => Zero,One,Two

    I usually find myself needing something that also skips the value if that value is null or undefined, etc.

So here is the solution that works for me:

// Example 1
const arr1 = ['apple', null, 'banana', '', undefined, 'pear'];
const commaSeparated1 = arr1.filter(item => item).join(', ');
console.log(commaSeparated1); // 'apple, banana, pear'

// Example 2
const arr2 = [null, 'apple'];
const commaSeparated2 = arr2.filter(item => item).join(', ');
console.log(commaSeparated2); // 'apple'


Most of the solutions here would return ', apple' if my array would look like the one in my second example. That's why I prefer this solution.
    Taking the initial code:

var arr = new Array(3);
arr[0] = ""Zero"";
arr[1] = ""One"";
arr[2] = ""Two"";


The initial answer of using the join function is ideal. One thing to consider would be the ultimate use of the string. 

For using in some end textual display:

arr.join("","")
=> ""Zero,One,Two""


For using in a URL for passing multiple values through in a (somewhat) RESTful manner:

arr.join(""|"")
=> ""Zero|One|Two""

var url = 'http://www.yoursitehere.com/do/something/to/' + arr.join(""|"");
=> ""http://www.yoursitehere.com/do/something/to/Zero|One|Two""


Of course, it all depends on the final use. Just keep the data source and use in mind and all will be right with the world.
    Do you want to end it with an ""and""?

For this situation, I created an npm module.

Try arrford:



Usage

const arrford = require('arrford');

arrford(['run', 'climb', 'jump!']);
//=> 'run, climb, and jump!'

arrford(['run', 'climb', 'jump!'], false);
//=> 'run, climb and jump!'

arrford(['run', 'climb!']);
//=> 'run and climb!'

arrford(['run!']);
//=> 'run!'




Install

npm install --save arrford




Read More

https://github.com/dawsonbotsford/arrford



Try it yourself

Tonic link
    var arr = [""Pro1"", ""Pro2"", ""Pro3""];
console.log(arr.join());// Pro1,Pro2,Pro3
console.log(arr.join(', '));// Pro1, Pro2, Pro3

    This solution also removes values such as ""   "":

const result = ['', null, 'foo', '  ', undefined, 'bar'].filter(el => {
  return Boolean(el) && el.trim() !== '';
}).join(', ');

console.log(result); // => foo, bar

    ","[491, 919, 18, 109, 2, 20, 9, 2, 2, 30, 14, 10, 2, 2, 11, 0, 3, 1, 1, 0, 0]",534375,62,2008-10-14T15:47:17,2021-10-21 07:12:31Z,javascript 
Changing case in Vim,"
                
Is there a command in Vim that changes the case of the selected text?
    Visual select the text, then U for uppercase or u for lowercase. To swap all casing in a visual selection, press ~ (tilde).

Without using a visual selection, gU<motion> will make the characters in motion uppercase, or use gu<motion> for lowercase.

For more of these, see Section 3 in Vim's change.txt help file.
    See the following methods:
 ~    : Changes the case of current character

 guu  : Change current line from upper to lower.

 gUU  : Change current LINE from lower to upper.

 guw  : Change to end of current WORD from upper to lower.

 guaw : Change all of current WORD to lower.

 gUw  : Change to end of current WORD from lower to upper.

 gUaw : Change all of current WORD to upper.

 g~~  : Invert case to entire line

 g~w  : Invert case to current WORD

 guG  : Change to lowercase until the end of document.

 gU)  : Change until end of sentence to upper case

 gu}  : Change to end of paragraph to lower case

 gU5j : Change 5 lines below to upper case

 gu3k : Change 3 lines above to lower case

    
gUaw : Change all of current WORD to upper.

doesn't work for vim 8.2.0834
    ","[491, 659, 449, 0]",187651,103,2010-05-31T21:33:18,2022-03-03 16:29:07Z,
How to tell which commit a tag points to in Git?,"
                
I have a bunch of unannotated tags in the repository and I want to work out which commit they point to. Is there a command that that will just list the tags and their commit SHAs? Checking out the tag and looking at the HEAD seems a bit too laborious to me.

Update

I realized after I went through the responses that what I actually wanted was to simply look at the history leading up to the tag, for which git log <tagname> is sufficient. 

The answer that is marked as answer is useful for getting a list of tags and their commits, which is what I asked. With a bit of shell hackery I'm sure it's possible to transform those into SHA+Commit message.
    One way to do this would be with git rev-list. The following will output the commit to which a tag points:
$ git rev-list -n 1 $TAG

NOTE This works for both Annotated and Unannotated tags
You could add it as an alias in ~/.gitconfig if you use it a lot:
[alias]
  tagcommit = rev-list -n 1

And then call it with:
$ git tagcommit $TAG

Possible pitfall: if you have a local checkout or a branch of the same tag name, this solution might get you ""warning: refname 'myTag' is ambiguous"". In that case, try increasing specificity, e.g.:
$ git rev-list -n 1 tags/$TAG

    The --format option can be used to show both tag hash and the commit hash, and to distinguish between lightweight and annotated tags.
git tag --format=""%(color:bold cyan)== %(refname:short) ==%(if)%(object)%(then)%0aTag Hash: %(objectname)%0aTag Date: %(taggerdate:iso-local)%0a  Commit: %(object) %0a%0a%(contents)%(else)%0a(lightweight tag)%0a  Commit: %(objectname)%(end)%0a""

Gives output similar to:
== b2lightweight ==
(lightweight tag)
  Commit: 0450fae4352dbbbf088419757eda32711316a02e

== c3_annotated ==
Tag Hash: 19961d8678a09a319a9d6c398c79f27cc23d610c
Tag Date: 2021-08-06 15:18:48 -0600
  Commit: 85be6e80c109ce44d78f0ca0da8e1ec53817b24c

This is my tag message.

It has multiple lines.

Another line.

To define as a git alias, you can edit the global git config with git config --global -e and add the following:
[alias]
    tag-verbose = tag --format='%(color:bold cyan)== %(refname:short) ==%(if)%(object)%(then)%0aTag Hash: %(objectname)%0aTag Date: %(taggerdate:iso-local)%0a  Commit: %(object) %0a%0a%(contents)%(else)%0a(lightweight tag)%0a  Commit: %(objectname)%(end)%0a'

The alias still allows filtering, e.g.
C:\playground>git tag-verbose -l *b2*
== b2lightweight ==
(lightweight tag)
  Commit: 0450fae4352dbbbf088419757eda32711316a02e

For additional information on the --format options see the ""Field Names"" section under git help for-each-ref. (git help tag states ""The format is the same as that of git-for-each-ref"")
    For annotated tags, git show-ref TAG shows the tag's hash, not the hash of the commit it points to.
git show-ref --dereference TAG shows, additionally, the commit being pointed at with an added ^{}.
    WARNING This only works for Unannotated tags Therefore it is safer to use the accepted answer which works in the general case https://stackoverflow.com/a/1862542/1586965
git show-ref --tags

For example, git show-ref --abbrev=7 --tags will show you something like the following:
f727215 refs/tags/v2.16.0
56072ac refs/tags/v2.17.0
b670805 refs/tags/v2.17.1
250ed01 refs/tags/v2.17.2

    From Igor Zevaka:

Summary

Since there are about 4 almost equally acceptable yet different answers I will summarise all the different ways to skin a tag.


git rev-list -1 $TAG (answer). git rev-list outputs the commits that lead up to the $TAG similar to git log but only showing the SHA1 of the commit. The -1 limits the output to the commit it points at.
git show-ref --tags (answer) will show all tags (local and fetched from remote) and their SHA1s.
git show-ref $TAG (answer) will show the tag and its path along with the SHA1.
git rev-parse $TAG (answer) will show the SHA1 of an unannotated tag.
git rev-parse --verify $TAG^{commit} (answer) will show a SHA1 of both annotated and unannotated tags. On Windows use git rev-parse --verify %TAG%^^^^{commit} (four hats).
cat .git/refs/tags/* or cat .git/packed-refs (answer) depending on whether or not the tag is local or fetched from remote.

    Just use git show <tag>

However, it also dumps commit diffs. To omit those diffs, use git log -1 <tag>. (Thanks to @DolphinDream and @demisx !)
    In order to get the sha/hash of the commit that a tag refers to (not the sha of the tag):

git rev-list -1 <tag>
    Use

git rev-parse --verify <tag>^{commit}


(which would return SHA-1 of a commit even for annotated tag).



git show-ref <tag> would also work if <tag> is not annotated.  And there is always git for-each-ref (see documentation for details).
    I'd also like to know the ""right"" way, but in the meantime, you can do this:

git show mytag | head -1    

    This doesn't show the filenames, but at least you get a feel of the repository.

cat .git/refs/tags/*


Each file in that directory contains a commit SHA pointing to a commit.
    You could as well get more easy-to-interpret picture of where tags point to using

git log --graph |git name-rev --stdin --tags |less


and then scroll to the tag you're looking for via /.

More compact view (--pretty=oneline) plus all heads (-a) could also help:

git log -a --pretty=oneline --graph |git name-rev --stdin --tags |less


Looks a bit terrifying, but could also be aliased in ~/.gitconfig if necessary.

~/.gitconfig

[alias]
ls-tags = !git log -a --pretty=oneline --graph |git name-rev --stdin --tags |less

    From git mailing list, here is the way to get the list of commit hashes for tags with automatic dereferencing for annotated tags:

git for-each-ref --format='%(if)%(*objectname)%(then)%(*objectname)%(else)%(objectname)%(end) %(refname)' refs/tags

    Even though this is pretty old, I thought I would point out a cool feature I just found for listing tags with commits:

git log --decorate=full


It will show the branches which end/start at a commit, and the tags for commits.
    This will get you the current SHA1 hash 

Abbreviated Commit Hash

git show <tag> --format=""%h"" --> 42e646e


Commit Hash 

git show <tag> --format=""%H"" --> 42e646ea3483e156c58cf68925545fffaf4fb280

    Short post-Git-2 answer

I know this question has been out here for quite a while. And the answer from CB Bailey is 100% correct: git show-ref --tags --abbrev

I like this one better since it uses git tag:

git tag --list --format '%(refname:short) %(objectname:short)'


Simple. Short.

PS alias it as git taglist with this command:

git config --global alias.taglist ""tag --list --format '%(refname:short) %(objectname:short)'""

    How about this:

git log -1 $TAGNAME


OR 

git log -1 origin/$TAGNAME

    i'd also like to know the right way, but you can always peek either into:

$ cat .git/packed-refs 


or:

$ cat .git/refs/tags/*

    If you would like to see the details of the tag SOMETAG (tagger, date, etc), the hash of the commit it points to and a bit of info about the commit but without the full diff, try

git show --name-status SOMETAG


Example output:

tag SOMETAG
Tagger: ....
Date:   Thu Jan 26 17:40:53 2017 +0100

 .... tag message .......

commit 9f00ce27c924c7e972e96be7392918b826a3fad9
Author: .............
Date:   Thu Jan 26 17:38:35 2017 +0100

 .... commit message .......

..... list of changed files with their change-status (like git log --name-status) .....

    So I have a load of release folders, where those folders may be checked out from one of a few different repos, and may be dev, qa or master branches or may be production releases, checked out from a tag, and the tag may be annotated or not.  I have a script that will look at the target folder and get be back an answer in the form -.  The problem is different versions of git return different status' for a tag checkout.  

So I found git show-ref --tags worked initially, except for the annotated tags.  However adding -d added a separate entry to the list of tags, one for the tag, the other for the annotation (the annotation commit was identified as ^{} which I stripped out with sed).  

So this is the core of my script, for anyone that wants it:-

REPO=`git --git-dir=${TARGET} remote show origin -n | \
         grep ""Fetch URL:"" | \
         sed -E ""s/^.*\/(.*)$/\1/"" | \
         sed ""s/.git$//""`

TAG=`git --git-dir=${TARGET} show-ref -d --tags | \
         grep \`git --git-dir=${TARGET} show --quiet --format=format:%H HEAD\` | \
         cut -d\  -f2 | \
         cut -d/ -f3 | \
         sed ""s/\^{}$//""`

if [ ""${TAG}"" == """" ] ; then 
  BRANCH=`git --git-dir=${TARGET} show-ref --heads | \
         grep \`git --git-dir=${TARGET} show --quiet --format=format:%H HEAD\` | \
         cut -d\  -f2 | \
         cut -d/ -f3`
  TAG=${BRANCH}
fi

    Can use below, It will give the commit hash
git show -s --format=%H <tag>^{commit}

If abbreviated commit hash required, git show -s --format=%h <tag>^{commit}
    Hacky solution
Parse the .git/packed-refs and format it as {tag}\t{sha}
sed -n '/ refs\/tags/ { s@\([^ ]*\) refs/tags/\(.*\)@\2\t\1@; p}' .git/packed-refs

    ","[491, 439, 4, 44, 271, 50, 117, 12, 35, 9, 3, 5, 3, 7, 2, 10, 15, 2, 2, 0, 0, 0]",243627,124,2009-12-07T19:45:17,2022-01-04 15:08:46Z,
How do I (or can I) SELECT DISTINCT on multiple columns?,"
                
I need to retrieve all rows from a table where 2 columns combined are all different. So I want all the sales that do not have any other sales that happened on the same day for the same price. The sales that are unique based on day and price will get updated to an active status.

So I'm thinking:

UPDATE sales
SET status = 'ACTIVE'
WHERE id IN (SELECT DISTINCT (saleprice, saledate), id, count(id)
             FROM sales
             HAVING count = 1)


But my brain hurts going any farther than that.
    SELECT DISTINCT a,b,c FROM t


is roughly equivalent to:  

SELECT a,b,c FROM t GROUP BY a,b,c


It's a good idea to get used to the GROUP BY syntax, as it's more powerful.  

For your query, I'd do it like this:

UPDATE sales
SET status='ACTIVE'
WHERE id IN
(
    SELECT id
    FROM sales S
    INNER JOIN
    (
        SELECT saleprice, saledate
        FROM sales
        GROUP BY saleprice, saledate
        HAVING COUNT(*) = 1 
    ) T
    ON S.saleprice=T.saleprice AND s.saledate=T.saledate
 )

    If you put together the answers so far, clean up and improve, you would arrive at this superior query:

UPDATE sales
SET    status = 'ACTIVE'
WHERE  (saleprice, saledate) IN (
    SELECT saleprice, saledate
    FROM   sales
    GROUP  BY saleprice, saledate
    HAVING count(*) = 1 
    );


Which is much faster than either of them. Nukes the performance of the currently accepted answer by factor 10 - 15 (in my tests on PostgreSQL 8.4 and 9.1).

But this is still far from optimal. Use a NOT EXISTS (anti-)semi-join for even better performance. EXISTS is standard SQL, has been around forever (at least since PostgreSQL 7.2, long before this question was asked) and fits the presented requirements perfectly:

UPDATE sales s
SET    status = 'ACTIVE'
WHERE  NOT EXISTS (
   SELECT FROM sales s1                     -- SELECT list can be empty for EXISTS
   WHERE  s.saleprice = s1.saleprice
   AND    s.saledate  = s1.saledate
   AND    s.id <> s1.id                     -- except for row itself
   )
AND    s.status IS DISTINCT FROM 'ACTIVE';  -- avoid empty updates. see below


db<>fiddle here
Old SQL Fiddle

Unique key to identify row

If you don't have a primary or unique key for the table (id in the example), you can substitute with the system column ctid for the purpose of this query (but not for some other purposes):

   AND    s1.ctid <> s.ctid


Every table should have a primary key. Add one if you didn't have one, yet. I suggest a serial or an IDENTITY column in Postgres 10+.

Related:


In-order sequence generation
Auto increment table column


How is this faster?

The subquery in the EXISTS anti-semi-join can stop evaluating as soon as the first dupe is found (no point in looking further). For a base table with few duplicates this is only mildly more efficient. With lots of duplicates this becomes way more efficient.

Exclude empty updates

For rows that already have status = 'ACTIVE' this update would not change anything, but still insert a new row version at full cost (minor exceptions apply). Normally, you do not want this. Add another WHERE condition like demonstrated above to avoid this and make it even faster:

If status is defined NOT NULL, you can simplify to:

AND status <> 'ACTIVE';


The data type of the column must support the <> operator. Some types like json don't. See:


How to query a json column for empty objects?


Subtle difference in NULL handling

This query (unlike the currently accepted answer by Joel) does not treat NULL values as equal. The following two rows for (saleprice, saledate) would qualify as ""distinct"" (though looking identical to the human eye):

(123, NULL)
(123, NULL)


Also passes in a unique index and almost anywhere else, since NULL values do not compare equal according to the SQL standard. See:


Create unique constraint with null columns


OTOH, GROUP BY, DISTINCT or DISTINCT ON () treat NULL values as equal. Use an appropriate query style depending on what you want to achieve. You can still use this faster query with IS NOT DISTINCT FROM instead of = for any or all comparisons to make NULL compare equal. More:


How to delete duplicate rows without unique identifier


If all columns being compared are defined NOT NULL, there is no room for disagreement.
    The problem with your query is that when using a GROUP BY clause (which you essentially do by using distinct) you can only use columns that you group by or aggregate functions. You cannot use the column id because there are potentially different values. In your case there is always only one value because of the HAVING clause, but most RDBMS are not smart enough to recognize that.

This should work however (and doesn't need a join):

UPDATE sales
SET status='ACTIVE'
WHERE id IN (
  SELECT MIN(id) FROM sales
  GROUP BY saleprice, saledate
  HAVING COUNT(id) = 1
)


You could also use MAX or AVG instead of MIN, it is only important to use a function that returns the value of the column if there is only one matching row.
    If your DBMS doesn't support distinct with multiple columns like this:

select distinct(col1, col2) from table


Multi select in general can be executed safely as follows:

select distinct * from (select col1, col2 from table ) as x


As this can work on most of the DBMS and this is expected to be faster than group by solution as you are avoiding the grouping functionality.
    I want to select the distinct values from one column 'GrondOfLucht' but they should be sorted in the order as given in the column 'sortering'. I cannot get the distinct values of just one column using

Select distinct GrondOfLucht,sortering
from CorWijzeVanAanleg
order by sortering


It will also give the column 'sortering' and because 'GrondOfLucht' AND 'sortering' is not unique, the result will be ALL rows.

use the GROUP to select the records of 'GrondOfLucht' in the order given by 'sortering

SELECT        GrondOfLucht
FROM            dbo.CorWijzeVanAanleg
GROUP BY GrondOfLucht, sortering
ORDER BY MIN(sortering)

    ","[491, 521, 380, 28, 4, 2]",1057733,142,2008-09-10T15:33:10,2020-06-11 23:34:39Z,sql 
How to revert initial git commit?,"
                
I commit to a git repository for the first time; I then regret the commit and want to revert it.  I try

# git reset --hard HEAD~1


I get this message:

fatal: ambiguous argument 'HEAD~1': unknown revision or path not in the working tree.


This commit is the first commit of the repository. Any idea how to undo git's initial commit?
    You just need to delete the branch you are on. You can't use git branch -D as this has a safety check against doing this. You can use update-ref to do this.

git update-ref -d HEAD


Do not use rm -rf .git or anything like this as this will completely wipe your entire repository including all other branches as well as the branch that you are trying to reset.
    You can delete the HEAD and restore your repository to a new state, where you can create a new initial commit:

git update-ref -d HEAD


After you create a new commit, if you have already pushed to remote, you will need to force it to the remote in order to overwrite the previous initial commit:

git push --force origin

    I will throw in what worked for me in the end.
I needed to remove the initial commit on a repository as quarantined data had been misplaced, the commit had already been pushed.

Make sure you are are currently on the right branch.

git checkout master

git update-ref -d HEAD

git commit -m ""Initial commit

git push -u origin master

This was able to resolve the problem.

Important

This was on an internal repository which was not publicly accessible, if your repository was publicly accessible please assume anything you need to revert has already been pulled down by someone else.
    Under the conditions stipulated in the question:


The commit is the first commit in the repository.
Which means there have been very few commands executed:


a git init,
presumably some git add operations,
and a git commit,
and that's all!



If those preconditions are met, then the simplest way to undo the initial commit would be:

rm -fr .git


from the directory where you did git init.  You can then redo the git init to recreate the Git repository, and redo the additions with whatever changes are sensible that you regretted not making the first time, and redo the initial commit.

DANGER! This removes the Git repository directory.

It removes the Git repository directory permanently and irrecoverably, unless you've got backups somewhere.  Under the preconditions, you've nothing you want to keep in the repository, so you're not losing anything.
All the files you added are still available in the working directories, assuming you have not modified them yet and have not deleted them, etc.  However, doing this is safe only if you have nothing else in your repository at all.  Under the circumstances described in the question 'commit repository first time — then regret it', it is safe.  Very often, though, it is not safe.

It's also safe to do this to remove an unwanted cloned repository; it does no damage to the repository that it was cloned from.  It throws away anything you've done in your copy, but doesn't affect the original repository otherwise.

Be careful, but it is safe and effective when the preconditions are met.

If you've done other things with your repository that you want preserved, then this is not the appropriate technique — your repository no longer meets the preconditions for this to be appropriate.
    For me:
git update-ref -d HEAD
git rm --cached . -r

First line was as suggested by CB Bailey (not sure why the second line was necessary, but git didn't uncommit the files until I did that - I could tell by running git status before and after the second line above)
    One option is to delete the repository and create a new one:
rm -rf .git
git init

    I wonder why ""amend"" is not suggest and have been crossed out by @damkrat, as amend appears to me as just the right way to resolve the most efficiently the underlying problem of fixing the wrong commit since there is no purpose of having no initial commit. As some stressed out you should only modify ""public"" branch like master if no one has clone your repo...

git add <your different stuff>
git commit --amend --author=""author name <author.name@email.com>""-m ""new message""

    This question was linked from this blog post and an alternative solution was proposed for the newer versions of Git:

git branch -m master old_master
git checkout --orphan master
git branch -D old_master


This solution assumes that:


You have only one commit on your master branch
There is no branch called old_master so I'm free to use that name


It will rename the existing branch to old_master and create a new, orphaned, branch master (like it is created for new repositories) after which you can freely delete old_master... or not. Up to you.

Note: Moving or copying a git branch preserves its reflog (see this code) while deleting and then creating a new branch destroys it. Since you want to get back to the original state with no history you probably want to delete the branch, but others may want to consider this small note.
    Technically, to revert the initial commit, you'd do:
git revert HEAD

But since that records a new commit that reverses the effects of the last commit, you might as well just make a new commit yourself that fixes the issues introduced by your initial commit. That way, you'd keep your initial commit (Ie, you'd keep your history unchanged.) which you might want to do (especially if, eg, you've already pushed to a shared repository). Otherwise, you might prefer to just start over. Ie, delete the repository and create a new one.
        git reset --hard  
make changes, then do

git add -A
git commit --amend --no-edit 


or

git add -A
git commit --amend -m ""commit_message""


and then

git push origin master --force


--force will rewrite that commit you've reseted to in the first step.

Don't do this, because you're about to go against the whole idea of VCS systems and git in particular. The only good method is to create new and delete unneeded branch. See git help branch for info.
    ","[491, 775, 93, 6, 20, 1, 4, 4, 29, 0, 0]",147074,130,2011-07-09T01:49:42,2022-03-10 21:44:41Z,
How is the default max Java heap size determined?,"
                
If I omit the -Xmxn option from the Java command line then a default value will be used. According to Java documentation

""the default value is chosen at runtime based on system configuration""

What system configuration settings influence the default value?
    On Windows, you can use the following command to find out the defaults on the system where your applications runs.
java -XX:+PrintFlagsFinal -version | findstr HeapSize

Look for the options MaxHeapSize (for -Xmx) and InitialHeapSize for -Xms.
On a Unix/Linux system, you can do
java -XX:+PrintFlagsFinal -version | grep HeapSize

I believe the resulting output is in bytes.
    Java 8 takes more than 1/64th of your physical memory for your Xmssize (Minimum HeapSize) and less than 1/4th of your physical memory for your -Xmxsize (Maximum HeapSize).

You can check the default Java heap size by:

In Windows:

java -XX:+PrintFlagsFinal -version | findstr /i ""HeapSize PermSize ThreadStackSize""


In Linux:

java -XX:+PrintFlagsFinal -version | grep -iE 'HeapSize|PermSize|ThreadStackSize'



  What system configuration settings influence the default value?


The machine's physical memory & Java version.
    For Java SE 5: According to Garbage Collector Ergonomics [Oracle]:


  initial heap size:
  
  Larger of 1/64th of the machine's physical memory on the machine or some
  reasonable minimum. Before J2SE 5.0,
  the default initial heap size was a
  reasonable minimum, which varies by
  platform. You can override this
  default using the -Xms command-line
  option.
  
  maximum heap size:
  
  Smaller of 1/4th of the physical memory or 1GB. Before J2SE 5.0, the
  default maximum heap size was 64MB.
  You can override this default using
  the -Xmx command-line option.


UPDATE:

As pointed out by Tom Anderson in his comment, the above is for server-class machines. From Ergonomics in the 5.0 JavaTM Virtual Machine:


  In the J2SE platform version 5.0 a
  class of machine referred to as a
  server-class machine has been defined
  as a machine with
  
  
  2 or more physical processors
  2 or more Gbytes of physical memory
  
  
  with the exception of 32 bit platforms
  running a version of the Windows
  operating system. On all other
  platforms the default values are the
  same as the default values for version
  1.4.2. 
  
  In the J2SE platform version 1.4.2 by
  default the following selections were
  made
  
  
  initial heap size of 4 Mbyte
  maximum heap size of 64 Mbyte
  

    Finally!

As of Java 8u191 you now have the options:

-XX:InitialRAMPercentage
-XX:MaxRAMPercentage
-XX:MinRAMPercentage


that can be used to size the heap as a percentage of the usable physical RAM. (which is same as the RAM installed less what the kernel uses).

See Release Notes for Java8 u191 for more information. Note that the options are mentioned under a Docker heading but in fact they apply whether you are in Docker environment or in a traditional environment.

The default value for MaxRAMPercentage is 25%. This is extremely conservative. 

My own rule: If your host is more or less dedicated to running the given java application, then you can without problems increase dramatically. If you are on Linux,  only running standard daemons and have installed RAM from somewhere around 1 Gb and up then I wouldn't hesitate to use 75% for the JVM's heap. Again, remember that this is 75% of the RAM available, not the RAM installed. What is left is the other user land processes that may be running on the host and the other types of memory that the JVM needs (eg for stack). All together, this will typically fit nicely in the 25% that is left. Obviously, with even more installed RAM the 75% is a safer and safer bet. (I wish the JDK folks had implemented an option where you could specify a ladder)

Setting the MaxRAMPercentage option look like this:

java -XX:MaxRAMPercentage=75.0  ....


Note that these percentage values are of 'double' type and therefore you must specify them with a decimal dot. You get a somewhat odd error if you use ""75"" instead of ""75.0"".
    This is changed in Java 6 update 18.

Assuming that we have more than 1 GB of physical memory (quite common these days), it's always 1/4th of your physical memory for the server vm.
    The Xms and Xmx are flag of Java virtual machine (JVM):

Xms: initial and minimum JVM heap size

Format: -Xms<size>[g|G|m|M|k|K]
Default Size:

-server mode: 25% of free physical memory, >=8MB and <= 64MB
-client mode: 25% of free physical memory, >=8MB and <= 16MB


Typical Size:

-Xms128M
-Xms256M
-Xms512M


Function/Effect:

-> JVM start with allocate Xms size memory




Xmx: maximum JVM heap size

Format: -Xmx<size>[g|G|m|M|k|K]
Default Size:

<= R27.2

Windows: 75% of total physical memory up to 1GB
Linux/Solaris: 50% of available physical memory up to 1GB


>= R27.3

Windows X64: 75% of total physical memory up to 2GB
Linux/Solaris X64: 50% of available physical memory up to 2GB
Windows x86: 75% of total physical memory up to 1GB
Linux/Solaris X86: 50% of available physical memory up to 1GB




Typical Size:

-Xmx1g
-Xmx2084M
-Xmx4g
-Xmx6g
-Xmx8g


Function/Effect:

-> JVM allow use maxium of Xmx size memory

when exceed Xmx, will java.lang.OutOfMemoryError

How to fix OutOfMemoryError ?

exceed Xmx value

eg: from -Xmx4g to -Xmx8g













More detail
see  official doc: -X Command-line Options
    A number of parameters affect generation size. The following diagram illustrates the difference between committed space and virtual space in the heap. At initialization of the virtual machine, the entire space for the heap is reserved. The size of the space reserved can be specified with the -Xmx option. If the value of the -Xms parameter is smaller than the value of the -Xmx parameter, not all of the space that is reserved is immediately committed to the virtual machine. The uncommitted space is labeled ""virtual"" in this figure. The different parts of the heap (permanent generation, tenured generation and young generation) can grow to the limit of the virtual space as needed.



By default, the virtual machine grows or shrinks the heap at each collection to try to keep the proportion of free space to live objects at each collection within a specific range. This target range is set as a percentage by the parameters -XX:MinHeapFreeRatio=<minimum> and -XX:MaxHeapFreeRatio=<maximum>, and the total size is bounded below by -Xms<min> and above by -Xmx<max>.

Parameter           Default Value

MinHeapFreeRatio    40

MaxHeapFreeRatio    70

-Xms    3670k

-Xmx    64m

Default values of heap size parameters on 64-bit systems have been scaled up by approximately 30%. This increase is meant to compensate for the larger size of objects on a 64-bit system.

With these parameters, if the percent of free space in a generation falls below 40%, the generation will be expanded to maintain 40% free space, up to the maximum allowed size of the generation. Similarly, if the free space exceeds 70%, the generation will be contracted so that only 70% of the space is free, subject to the minimum size of the generation.

Large server applications often experience two problems with these defaults. One is slow startup, because the initial heap is small and must be resized over many major collections. A more pressing problem is that the default maximum heap size is unreasonably small for most server applications. The rules of thumb for server applications are:


Unless you have problems with pauses, try granting as much memory as
possible to the virtual machine. The default size (64MB) is often too
small.
Setting -Xms and -Xmx to the same value increases predictability by
removing the most important sizing decision from the virtual machine.
However, the virtual machine is then unable to compensate if you make
a poor choice.
In general, increase the memory as you increase the number of
processors, since allocation can be parallelized.

There is the full article

    
default value is chosen at runtime based on system configuration

Have a look at the documentation page

Default Heap Size
Unless the initial and maximum heap sizes are specified on the command line, they are calculated based on the amount of memory on the machine.


Client JVM Default Initial and Maximum Heap Sizes:
The default maximum heap size is half of the physical memory up to a physical memory size of 192 megabytes (MB) and otherwise one fourth of the physical memory up to a physical memory size of 1 gigabyte (GB).

Server JVM Default Initial and Maximum Heap Sizes:
On 32-bit JVMs, the default maximum heap size can be up to 1 GB if there is 4 GB or more of physical memory. On 64-bit JVMs, the default maximum heap size can be up to 32 GB if there is 128 GB or more of physical memory



What system configuration settings influence the default value?

You can specify the initial and maximum heap sizes using the flags -Xms (initial heap size) and -Xmx (maximum heap size). If you know how much heap your application needs to work well, you can set -Xms and -Xmx to the same value
    For the IBM JVM, the command is the following:

java -verbose:sizes -version


For more information about the IBM SDK for Java 8: http://www-01.ibm.com/support/knowledgecenter/SSYKE2_8.0.0/com.ibm.java.lnx.80.doc/diag/appendixes/defaults.html?lang=en
    Ernesto is right.  According to the link he posted [1]:


  Updated Client JVM heap configuration 
  
  In the Client JVM...
  
  
  The default maximum heap size is half of the physical memory up to a physical memory size of 192 megabytes and otherwise one fourth of the physical memory up to a physical memory size of 1 gigabyte. 
  
  For example, if your machine has 128 megabytes of physical memory, then the maximum heap size is 64 megabytes, and greater than or equal to 1 gigabyte of physical memory results in a maximum heap size of 256 megabytes.
  The maximum heap size is not actually used by the JVM unless your program creates enough objects to require it. A much smaller amount, termed the initial heap size, is allocated during JVM initialization. ...
  ...
  Server JVM heap configuration ergonomics are now the same as the Client, except that the default maximum heap size for 32-bit JVMs is 1 gigabyte, corresponding to a physical memory size of 4 gigabytes, and for 64-bit JVMs is 32 gigabytes, corresponding to a physical memory size of 128 gigabytes.
  


[1] http://www.oracle.com/technetwork/java/javase/6u18-142093.html
    ","[491, 585, 67, 125, 20, 41, 15, 6, 8, 10, 16]",410173,142,2011-01-12T10:06:38,2021-10-21 14:19:38Z,java 
What's the Hi/Lo algorithm?,"
                
What's the Hi/Lo algorithm?

I've found this in the NHibernate documentation (it's one method to generate unique keys, section 5.1.4.2), but I haven't found a good explanation of how it works.

I know that Nhibernate handles it, and I don't need to know the inside, but I'm just curious.
    In addition to Jon's answer: 

It is used to be able to work disconnected. A client can then ask the server for a hi number and create objects increasing the lo number itself. It does not need to contact the server until the lo range is used up. 
    The basic idea is that you have two numbers to make up a primary key- a ""high"" number and a ""low"" number. A client can basically increment the ""high"" sequence, knowing that it can then safely generate keys from the entire range of the previous ""high"" value with the variety of ""low"" values.

For instance, supposing you have a ""high"" sequence with a current value of 35, and the ""low"" number is in the range 0-1023. Then the client can increment the sequence to 36 (for other clients to be able to generate keys while it's using 35) and know that keys 35/0, 35/1, 35/2, 35/3... 35/1023 are all available.

It can be very useful (particularly with ORMs) to be able to set the primary keys on the client side, instead of inserting values without primary keys and then fetching them back onto the client. Aside from anything else, it means you can easily make parent/child relationships and have the keys all in place before you do any inserts, which makes batching them simpler.
    The hi/lo algorithm splits the sequences domain into hi groups. A hi value is assigned synchronously. Every hi group is given a maximum number of lo entries, that can be assigned off-line without worrying about concurrent duplicate entries.

The hi token is assigned by the database, and two concurrent calls are guaranteed to see unique consecutive values

Once a hi token is retrieved we only need the incrementSize (the number of lo entries)

The identifiers range is given by the following formula:
 [(hi -1) * incrementSize) + 1, (hi * incrementSize) + 1)

and the “lo” value will be in the range:
 [0, incrementSize)

being applied from the start value of:
 [(hi -1) * incrementSize) + 1)


When all lo values are used, a new hi value is fetched and the cycle continues


And this visual presentation is easy to follow as well:

While hi/lo optimizer is fine for optimizing identifier generation, it doesn't play well with other systems inserting rows into our database, without knowing anything about our identifier strategy.
Hibernate offers the pooled-lo optimizer, which offers the advantages of the hi/lo generator strategy while also providing interoperability with other 3rd-party clients that are not aware of this sequence allocation strategy.
Being both efficient and interoperable with other systems, the pooled-lo optimizer is a much better candidate than the legacy hi/lo identifier strategy.
    Lo is a cached allocator that splits the keyspace into large chunks, typically based on some machine word size, rather than the meaningfully-sized ranges (eg obtaining 200 keys at a time) which a human might sensibly choose.

Hi-Lo usage tends to waste large numbers of keys on server restart, and generate large human-unfriendly key values.

Better than the Hi-Lo allocator, is the ""Linear Chunk"" allocator. This uses a similar table-based principle but allocates small, conveniently-sized chunks & generates nice human-friendly values.

create table KEY_ALLOC (
    SEQ varchar(32) not null,
    NEXT bigint not null,
    primary key (SEQ)
);


To allocate the next, say, 200 keys (which are then held as a range in the server & used as needed):

select NEXT from KEY_ALLOC where SEQ=?;
update KEY_ALLOC set NEXT=(old value+200) where SEQ=? and NEXT=(old value);


Providing you can commit this transaction (use retries to handle contention), you have allocated 200 keys & can dispense them as needed.

With a chunk-size of just 20, this scheme is 10x faster than allocating from an Oracle sequence, and is 100% portable amongst all databases. Allocation performance is equivalent to hi-lo.

Unlike Ambler's idea, it treats the keyspace as a contiguous linear numberline.

This avoids the impetus for composite keys (which were never really a good idea) and avoids wasting entire lo-words when the server restarts. It generates ""friendly"", human-scale key values.

Mr Ambler's idea, by comparison, allocates the high 16- or 32-bits, and generates large human-unfriendly key values as the hi-words increment.

Comparison of allocated keys:  

Linear_Chunk       Hi_Lo
100                65536
101                65537
102                65538
.. server restart
120                131072
121                131073
122                131073
.. server restart
140                196608


Design-wise, his solution is fundamentally more complex on the number-line (composite keys, large hi_word products) than Linear_Chunk while achieving no comparative benefit. 

The Hi-Lo design arose early in OO mapping and persistence. These days persistence frameworks such as Hibernate offer simpler and better allocators as their default.
    I found the Hi/Lo algorithm is perfect for multiple databases with replication scenarios based in my experience. Imagine this. you have a server in New York (alias 01) and another server in Los Angeles (alias 02) then you have a PERSON table...
so in New York when a person is create... you always use 01 as the HI value and the LO value is the next secuential. por example.


010000010 Jason
010000011 David
010000012 Theo


in Los Angeles you always use the HI 02. for example:


020000045 Rupert
020000046 Oswald
020000047 Mario


So, when you use the database replication (no matter what brand) all the primary keys and data combine easily and naturally without to worry about duplicate primary keys, collissions, etc.

This is the best way to go in this scenario.
    ","[491, 169, 576, 41, 27, 1]",101549,172,2008-11-11T20:53:00,2021-01-10 06:08:55Z,
Seeding the random number generator in Javascript,"
                
Is it possible to seed the random number generator (Math.random) in JavaScript?
    No, it is not possible to seed Math.random().
I've implemented a number of good, short and fast Pseudorandom number generator (PRNG) functions in plain JavaScript. All of them can be seeded and provide high quality numbers.
First of all, take care to initialize your PRNGs properly. To keep things simple, the generators below have no built-in seed generating procedure, but accept one or more 32-bit values as the initial seed state of the PRNG. Similar or sparse seeds (e.g. a simple seed of 1 and 2) have low entropy, and can cause correlations or other randomness quality issues, sometimes resulting in the output having similar properties (such as randomly generated levels being similar). To avoid this, it is best practice to initialize PRNGs with a well-distributed, high entropy seed.
There are many ways to do this, but here are two methods. Firstly, hash functions are very good at generating seeds from short strings. A good hash function will generate very different results even when two strings are similar, so you don't have to put much thought into the string. Here's an example seed generator based on MurmurHash3's mixing function:
function xmur3(str) {
    for(var i = 0, h = 1779033703 ^ str.length; i < str.length; i++) {
        h = Math.imul(h ^ str.charCodeAt(i), 3432918353);
        h = h << 13 | h >>> 19;
    } return function() {
        h = Math.imul(h ^ (h >>> 16), 2246822507);
        h = Math.imul(h ^ (h >>> 13), 3266489909);
        return (h ^= h >>> 16) >>> 0;
    }
}

Each subsequent call to the return function of xmur3 produces a new 32-bit hash value to be used as a seed in a PRNG. Here's how you might use it:
// Create xmur3 state:
var seed = xmur3(""apples"");
// Output four 32-bit hashes to provide the seed for sfc32.
var rand = sfc32(seed(), seed(), seed(), seed());

// Output one 32-bit hash to provide the seed for mulberry32.
var rand = mulberry32(seed());

// Obtain sequential random numbers like so:
rand();
rand();

Alternatively, simply choose some dummy data to pad the seed with, and advance the generator beforehand a few times (12-20 iterations) to mix the initial state thoroughly. This has the benefit of being simpler, and is often used in reference implementations of PRNGs, but it does limit the number of initial states:
var seed = 1337 ^ 0xDEADBEEF; // 32-bit seed with optional XOR value
// Pad seed with Phi, Pi and E.
// https://en.wikipedia.org/wiki/Nothing-up-my-sleeve_number
var rand = sfc32(0x9E3779B9, 0x243F6A88, 0xB7E15162, seed);
for (var i = 0; i < 15; i++) rand();

Note: the output of these PRNG functions produce a positive 32-bit number (0 to 232-1) which is then converted to a floating-point number between 0-1 (0 inclusive, 1 exclusive) equivalent to Math.random(), if you want random numbers of a specific range, read this article on MDN. If you only want the raw bits, simply remove the final division operation.
JavaScript numbers can only represent whole integers up to 53-bit resolution. And when using bitwise operations, this is reduced to 32. Modern PRNGs in other languages often use 64-bit operations, which require shims when porting to JS that can drastically reduce performance. The algorithms here only use 32-bit operations, as it is directly compatible with JS.

Now, onward to the the generators. (I maintain the full list with references and license info here)


sfc32 (Simple Fast Counter)
sfc32 is part of the PractRand random number testing suite (which it passes of course). sfc32 has a 128-bit state and is very fast in JS.
function sfc32(a, b, c, d) {
    return function() {
      a >>>= 0; b >>>= 0; c >>>= 0; d >>>= 0; 
      var t = (a + b) | 0;
      a = b ^ b >>> 9;
      b = c + (c << 3) | 0;
      c = (c << 21 | c >>> 11);
      d = d + 1 | 0;
      t = t + d | 0;
      c = c + t | 0;
      return (t >>> 0) / 4294967296;
    }
}

You may wonder what the | 0 and >>>= 0 are for. These are essentially 32-bit integer casts, used for performance optimizations. Number in JS are basically floats, but during bitwise operations, they switch into a 32-bit integer mode. This mode is processed faster by JS interpreters, but any multiplication or addition will cause it to switch back to a float, resulting in a performance hit.
Mulberry32
Mulberry32 is a simple generator with a 32-bit state, but is extremely fast and has good quality randomness (author states it passes all tests of gjrand testing suite and has a full 232 period, but I haven't verified).
function mulberry32(a) {
    return function() {
      var t = a += 0x6D2B79F5;
      t = Math.imul(t ^ t >>> 15, t | 1);
      t ^= t + Math.imul(t ^ t >>> 7, t | 61);
      return ((t ^ t >>> 14) >>> 0) / 4294967296;
    }
}

I would recommend this if you just need a simple but decent PRNG and don't need billions of random numbers (see Birthday problem).
xoshiro128**
As of May 2018, xoshiro128** is the new member of the Xorshift family, by Vigna & Blackman (professor Vigna was also responsible for the Xorshift128+ algorithm powering most Math.random implementations under the hood). It is the fastest generator that offers a 128-bit state.
function xoshiro128ss(a, b, c, d) {
    return function() {
        var t = b << 9, r = a * 5; r = (r << 7 | r >>> 25) * 9;
        c ^= a; d ^= b;
        b ^= c; a ^= d; c ^= t;
        d = d << 11 | d >>> 21;
        return (r >>> 0) / 4294967296;
    }
}

The authors claim it passes randomness tests well (albeit with caveats). Other researchers have pointed out that it fails some tests in TestU01 (particularly LinearComp and BinaryRank). In practice, it should not cause issues when floats are used (such as these implementations), but may cause issues if relying on the raw lowest order bit.
JSF (Jenkins' Small Fast)
This is JSF or 'smallprng' by Bob Jenkins (2007), who also made ISAAC and SpookyHash. It passes PractRand tests and should be quite fast, although not as fast as sfc32.
function jsf32(a, b, c, d) {
    return function() {
        a |= 0; b |= 0; c |= 0; d |= 0;
        var t = a - (b << 27 | b >>> 5) | 0;
        a = b ^ (c << 17 | c >>> 15);
        b = c + d | 0;
        c = d + t | 0;
        d = a + t | 0;
        return (d >>> 0) / 4294967296;
    }
}

    No, it is not possible to seed Math.random(), but it's fairly easy to write your own generator, or better yet, use an existing one.
Check out: this related question.
Also, see David Bau's blog for more information on seeding.
    NOTE: Despite (or rather, because of) succinctness and apparent elegance, this algorithm is by no means a high-quality one in terms of randomness. Look for e.g. those listed in this answer for better results.

(Originally adapted from a clever idea presented in a comment to another answer.)

var seed = 1;
function random() {
    var x = Math.sin(seed++) * 10000;
    return x - Math.floor(x);
}


You can set seed to be any number, just avoid zero (or any multiple of Math.PI).

The elegance of this solution, in my opinion, comes from the lack of any ""magic"" numbers (besides 10000, which represents about the minimum amount of digits you must throw away to avoid odd patterns - see results with values 10, 100, 1000).  Brevity is also nice.

It's a bit slower than Math.random() (by a factor of 2 or 3), but I believe it's about as fast as any other solution written in JavaScript.
    No, but here's a simple pseudorandom generator, an implementation of Multiply-with-carry I adapted from Wikipedia (has been removed since):
var m_w = 123456789;
var m_z = 987654321;
var mask = 0xffffffff;

// Takes any integer
function seed(i) {
    m_w = (123456789 + i) & mask;
    m_z = (987654321 - i) & mask;
}

// Returns number between 0 (inclusive) and 1.0 (exclusive),
// just like Math.random().
function random()
{
    m_z = (36969 * (m_z & 65535) + (m_z >> 16)) & mask;
    m_w = (18000 * (m_w & 65535) + (m_w >> 16)) & mask;
    var result = ((m_z << 16) + (m_w & 65535)) >>> 0;
    result /= 4294967296;
    return result;
}

    Math.random no, but the ran library solves this. It has almost all distributions you can imagine and supports seeded random number generation. Example:

ran.core.seed(0)
myDist = new ran.Dist.Uniform(0, 1)
samples = myDist.sample(1000)

    To write your own pseudo random generator is quite simple.

The suggestion of Dave Scotese is useful but, as pointed out by others, it is not quite uniformly distributed.

However, it is not because of the integer arguments of sin. It's simply because of the range of sin, which happens to be a one dimensional projection of a circle. If you would take the angle of the circle instead it would be uniform.

So instead of sin(x) use arg(exp(i * x)) / (2 * PI).

If you don't like the linear order, mix it a bit up with xor. The actual factor doesn't matter that much either.

To generate n pseudo random numbers one could use the code:

function psora(k, n) {
  var r = Math.PI * (k ^ n)
  return r - Math.floor(r)
}
n = 42; for(k = 0; k < n; k++) console.log(psora(k, n))


Please also note that you cannot use pseudo random sequences when real entropy is needed.
    Most of the answers here produce biased results. So here's a tested function based on seedrandom library from github:
!function(f,a,c){var s,l=256,p=""random"",d=c.pow(l,6),g=c.pow(2,52),y=2*g,h=l-1;function n(n,t,r){function e(){for(var n=u.g(6),t=d,r=0;n<g;)n=(n+r)*l,t*=l,r=u.g(1);for(;y<=n;)n/=2,t/=2,r>>>=1;return(n+r)/t}var o=[],i=j(function n(t,r){var e,o=[],i=typeof t;if(r&&""object""==i)for(e in t)try{o.push(n(t[e],r-1))}catch(n){}return o.length?o:""string""==i?t:t+""\0""}((t=1==t?{entropy:!0}:t||{}).entropy?[n,S(a)]:null==n?function(){try{var n;return s&&(n=s.randomBytes)?n=n(l):(n=new Uint8Array(l),(f.crypto||f.msCrypto).getRandomValues(n)),S(n)}catch(n){var t=f.navigator,r=t&&t.plugins;return[+new Date,f,r,f.screen,S(a)]}}():n,3),o),u=new m(o);return e.int32=function(){return 0|u.g(4)},e.quick=function(){return u.g(4)/4294967296},e.double=e,j(S(u.S),a),(t.pass||r||function(n,t,r,e){return e&&(e.S&&v(e,u),n.state=function(){return v(u,{})}),r?(c[p]=n,t):n})(e,i,""global""in t?t.global:this==c,t.state)}function m(n){var t,r=n.length,u=this,e=0,o=u.i=u.j=0,i=u.S=[];for(r||(n=[r++]);e<l;)i[e]=e++;for(e=0;e<l;e++)i[e]=i[o=h&o+n[e%r]+(t=i[e])],i[o]=t;(u.g=function(n){for(var t,r=0,e=u.i,o=u.j,i=u.S;n--;)t=i[e=h&e+1],r=r*l+i[h&(i[e]=i[o=h&o+t])+(i[o]=t)];return u.i=e,u.j=o,r})(l)}function v(n,t){return t.i=n.i,t.j=n.j,t.S=n.S.slice(),t}function j(n,t){for(var r,e=n+"""",o=0;o<e.length;)t[h&o]=h&(r^=19*t[h&o])+e.charCodeAt(o++);return S(t)}function S(n){return String.fromCharCode.apply(0,n)}if(j(c.random(),a),""object""==typeof module&&module.exports){module.exports=n;try{s=require(""crypto"")}catch(n){}}else""function""==typeof define&&define.amd?define(function(){return n}):c[""seed""+p]=n}(""undefined""!=typeof self?self:this,[],Math);

function randIntWithSeed(seed, max=1) {
  /* returns a random number between [0,max] including zero and max
  seed can be either string or integer */
  return Math.round(new Math.seedrandom('seed' + seed)()) * max
}

test for true randomness of this code: https://es6console.com/kkjkgur2/
    Here's the adopted version of Jenkins hash, borrowed from here
export function createDeterministicRandom(): () => number {
  let seed = 0x2F6E2B1;
  return function() {
    // Robert Jenkins’ 32 bit integer hash function
    seed = ((seed + 0x7ED55D16) + (seed << 12))  & 0xFFFFFFFF;
    seed = ((seed ^ 0xC761C23C) ^ (seed >>> 19)) & 0xFFFFFFFF;
    seed = ((seed + 0x165667B1) + (seed << 5))   & 0xFFFFFFFF;
    seed = ((seed + 0xD3A2646C) ^ (seed << 9))   & 0xFFFFFFFF;
    seed = ((seed + 0xFD7046C5) + (seed << 3))   & 0xFFFFFFFF;
    seed = ((seed ^ 0xB55A4F09) ^ (seed >>> 16)) & 0xFFFFFFFF;
    return (seed & 0xFFFFFFF) / 0x10000000;
  };
}

You can use it like this:
const deterministicRandom = createDeterministicRandom()
deterministicRandom()
// => 0.9872818551957607

deterministicRandom()
// => 0.34880331158638

    Combining some of the previous answers, this is the seedable random function you are looking for:

Math.seed = function(s) {
    var mask = 0xffffffff;
    var m_w  = (123456789 + s) & mask;
    var m_z  = (987654321 - s) & mask;

    return function() {
      m_z = (36969 * (m_z & 65535) + (m_z >>> 16)) & mask;
      m_w = (18000 * (m_w & 65535) + (m_w >>> 16)) & mask;

      var result = ((m_z << 16) + (m_w & 65535)) >>> 0;
      result /= 4294967296;
      return result;
    }
}

var myRandomFunction = Math.seed(1234);
var randomNumber = myRandomFunction();

    Many people who need a seedable random-number generator in Javascript these days are using David Bau's seedrandom module.
    A simple approach for a fixed seed:

function fixedrandom(p){
    const seed = 43758.5453123;
    return (Math.abs(Math.sin(p)) * seed)%1;
}

    I have written a function that returns a seeded random number, it uses Math.sin to have a long random number and uses the seed to pick numbers from that.

Use :

seedRandom(""k9]:2@"", 15)


it will return your seeded number
the first parameter is any string value ; your seed.
the second parameter is how many digits will return.

     function seedRandom(inputSeed, lengthOfNumber){

           var output = """";
           var seed = inputSeed.toString();
           var newSeed = 0;
           var characterArray = ['0','1','2','3','4','5','6','7','8','9','a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','y','x','z','A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','U','R','S','T','U','V','W','X','Y','Z','!','@','#','$','%','^','&','*','(',')',' ','[','{',']','}','|',';',':',""'"",',','<','.','>','/','?','`','~','-','_','=','+'];
           var longNum = """";
           var counter = 0;
           var accumulator = 0;

           for(var i = 0; i < seed.length; i++){
                var a = seed.length - (i+1);
                for(var x = 0; x < characterArray.length; x++){
                     var tempX = x.toString();
                     var lastDigit = tempX.charAt(tempX.length-1);
                     var xOutput = parseInt(lastDigit);
                     addToSeed(characterArray[x], xOutput, a, i); 
                }                  
           }

                function addToSeed(character, value, a, i){
                     if(seed.charAt(i) === character){newSeed = newSeed + value * Math.pow(10, a)}
                }
                newSeed = newSeed.toString();

                var copy = newSeed;
           for(var i=0; i<lengthOfNumber*9; i++){
                newSeed = newSeed + copy;
                var x = Math.sin(20982+(i)) * 10000;
                var y = Math.floor((x - Math.floor(x))*10);
                longNum = longNum + y.toString()
           }

           for(var i=0; i<lengthOfNumber; i++){
                output = output + longNum.charAt(accumulator);
                counter++;
                accumulator = accumulator + parseInt(newSeed.charAt(counter));
           }
           return(output)
      }

    Please see Pierre L'Ecuyer's work going back to the late 1980s and early 1990s.  There are others as well.  Creating a (pseudo) random number generator on your own, if you are not an expert, is pretty dangerous, because there is a high likelihood of either the results not being statistically random or in having a small period.  Pierre (and others) have put together some good (pseudo) random number generators that are easy to implement.  I use one of his LFSR generators.

https://www.iro.umontreal.ca/~lecuyer/myftp/papers/handstat.pdf

Phil Troy
    Antti Sykäri's algorithm is nice and short. I initially made a variation that replaced JavaScript's Math.random when you call Math.seed(s), but then Jason commented that returning the function would be better:
Math.seed = function(s) {
    return function() {
        s = Math.sin(s) * 10000; return s - Math.floor(s);
    };
};

// usage:
var random1 = Math.seed(42);
var random2 = Math.seed(random1());
Math.random = Math.seed(random2());

This gives you another functionality that JavaScript doesn't have: multiple independent random generators. That is especially important if you want to have multiple repeatable simulations running at the same time.
    In PHP, there is function srand(seed) which generate fixed random value for particular seed.
But, in JS, there is no such inbuilt function.
However, we can write simple and short function.
Step 1: Choose some Seed (Fix Number). 
var seed = 100; 
Number should be Positive Integer and greater than 1, further explanation in Step 2.
Step 2: Perform Math.sin() function on Seed, it will give sin value of that number. Store this value in variable x.
var x; 
x = Math.sin(seed); // Will Return Fractional Value between -1 & 1 (ex. 0.4059..)

sin() method returns a Fractional value between -1 and 1.And we don't need Negative value, therefore, in first step choose number greater than 1.
Step 3: Returned Value is a Fractional value between -1 and 1. So mulitply this value with 10 for making it more than 1.
x = x * 10; // 10 for Single Digit Number

Step 4: Multiply the value with 10 for additional digits
x = x * 10; // Will Give value between 10 and 99 OR
x = x * 100; // Will Give value between 100 and 999

Multiply as per requirement of digits.
The result will be in decimal.
Step 5: Remove value after Decimal Point by Math's Round (Math.round()) Method.
x = Math.round(x); // This will give Integer Value.

Step 6: Turn Negative Values into Positive (if any) by Math.abs method
x = Math.abs(x); // Convert Negative Values into Positive(if any)

Explanation End.Final Code
var seed = 111; // Any Number greater than 1
var digit = 10 // 1 => single digit, 10 => 2 Digits, 100 => 3 Digits and so. (Multiple of 10) 

var x; // Initialize the Value to store the result
x = Math.sin(seed); // Perform Mathematical Sin Method on Seed.
x = x * 10; // Convert that number into integer
x = x * digit; // Number of Digits to be included
x = Math.round(x); // Remove Decimals
x = Math.abs(x); // Convert Negative Number into Positive

Clean and Optimized Functional Code
function random_seed(seed, digit = 1) {
    var x = Math.abs(Math.round(Math.sin(seed++) * 10 * digit));
    return x;
}

Then Call this function using
random_seed(any_number, number_of_digits)any_number is must and should be greater than 1.number_of_digits is optional parameter and if nothing passed, 1 Digit will return.
random_seed(555); // 1 Digit
random_seed(234, 1); // 1 Digit
random_seed(7895656, 1000); // 4 Digit

    For a number between 0 and 100.

Number.parseInt(Math.floor(Math.random() * 100))

    ","[491, 299, 233, 190, 49, 2, 5, 2, 1, 6, 2, -3, -2, 12, 31, -5, -11]",286751,98,2009-02-06T17:37:39,2022-02-27 17:16:52Z,javascript 
How to pass a function as a parameter in Java? [duplicate],"
                    
            
        
            
                
                    
                        This question already has answers here:
                        
                    
                
            
                    
                        Java Pass Method as Parameter
                            
                                (17 answers)
                            
                    
                Closed 7 years ago.
        

    

In Java, how can one pass a function as an argument of another function?
    Java 8 and above

Using Java 8+ lambda expressions, if you have a class or interface with only a single abstract method (sometimes called a SAM type), for example:

public interface MyInterface {
    String doSomething(int param1, String param2);
}


then anywhere where MyInterface is used, you can substitute a lambda expression:

class MyClass {
    public MyInterface myInterface = (p1, p2) -> { return p2 + p1; };
}


For example, you can create a new thread very quickly:

new Thread(() -> someMethod()).start();


And use the method reference syntax to make it even cleaner:

new Thread(this::someMethod).start();


Without lambda expressions, these last two examples would look like:

new Thread(new Runnable() { someMethod(); }).start();


Before Java 8

A common pattern would be to 'wrap' it within an interface, like Callable, for example, then you pass in a Callable:

public T myMethod(Callable<T> func) {
    return func.call();
}


This pattern is known as the Command Pattern.

Keep in mind you would be best off creating an interface for your particular usage. If you chose to go with callable, then you'd replace T above with whatever type of return value you expect, such as String.

In response to your comment below you could say:

public int methodToPass() { 
        // do something
}

public void dansMethod(int i, Callable<Integer> myFunc) {
       // do something
}


then call it, perhaps using an anonymous inner class:

dansMethod(100, new Callable<Integer>() {
   public Integer call() {
        return methodToPass();
   }
});


Keep in mind this is not a 'trick'. It's just java's basic conceptual equivalent to function pointers.
    You could use Java reflection to do this.  The method would be represented as an instance of java.lang.reflect.Method.

import java.lang.reflect.Method;

public class Demo {

    public static void main(String[] args) throws Exception{
        Class[] parameterTypes = new Class[1];
        parameterTypes[0] = String.class;
        Method method1 = Demo.class.getMethod(""method1"", parameterTypes);

        Demo demo = new Demo();
        demo.method2(demo, method1, ""Hello World"");
    }

    public void method1(String message) {
        System.out.println(message);
    }

    public void method2(Object object, Method method, String message) throws Exception {
        Object[] parameters = new Object[1];
        parameters[0] = message;
        method.invoke(object, parameters);
    }

}

    Lambda Expressions

To add on to jk.'s excellent answer, you can now pass a method more easily using Lambda Expressions (in Java 8). First, some background. A functional interface is an interface that has one and only one abstract method, although it can contain any number of default methods (new in Java 8) and static methods. A lambda expression can quickly implement the abstract method, without all the unnecessary syntax needed if you don't use a lambda expression.

Without lambda expressions:

obj.aMethod(new AFunctionalInterface() {
    @Override
    public boolean anotherMethod(int i)
    {
        return i == 982
    }
});


With lambda expressions:

obj.aMethod(i -> i == 982);




Here is an excerpt from the Java tutorial on Lambda Expressions:


  Syntax of Lambda Expressions
  
  A lambda expression consists of the following:
  
  
  A comma-separated list of formal parameters enclosed in parentheses. The CheckPerson.test method contains one parameter, p,
  which represents an instance of the Person class.Note: You
  can omit the data type of the parameters in a lambda expression. In
  addition, you can omit the parentheses if there is only one parameter.
  For example, the following lambda expression is also valid:

p -> p.getGender() == Person.Sex.MALE 
    && p.getAge() >= 18
    && p.getAge() <= 25

  The arrow token, ->
  A body, which consists of a single expression or a statement block. This example uses the following expression:

p.getGender() == Person.Sex.MALE 
    && p.getAge() >= 18
    && p.getAge() <= 25

  
  If you specify a single expression, then the Java runtime evaluates the expression and then returns its value. Alternatively,
  you can use a return statement:

p -> {
    return p.getGender() == Person.Sex.MALE
        && p.getAge() >= 18
        && p.getAge() <= 25;
}

  
  A return statement is not an expression; in a lambda expression, you must enclose statements in braces ({}). However, you do not have
  to enclose a void method invocation in braces. For example, the
  following is a valid lambda expression:

email -> System.out.println(email)

  
  
  Note that a lambda expression looks a lot like a method declaration;
  you can consider lambda expressions as anonymous methods—methods
  without a name.




Here is how you can ""pass a method"" using a lambda expression:

Note: this uses a new standard functional interface, java.util.function.IntConsumer.

class A {
    public static void methodToPass(int i) { 
        // do stuff
    }
}




import java.util.function.IntConsumer;

class B {
    public void dansMethod(int i, IntConsumer aMethod) {
        /* you can now call the passed method by saying aMethod.accept(i), and it
        will be the equivalent of saying A.methodToPass(i) */
    }
}




class C {
    B b = new B();

    public C() {
        b.dansMethod(100, j -> A.methodToPass(j));   //Lambda Expression here
    }
}




The above example can be shortened even more using the :: operator.

public C() {
    b.dansMethod(100, A::methodToPass);
}

    Thanks to Java 8 you don't need to do the steps below to pass a function to a method, that's what lambdas are for, see Oracle's Lambda Expression tutorial. The rest of this post describes what we used to have to do in the bad old days in order to implement this functionality.

Typically you declare your method as taking some interface with a single method, then you pass in an object that implements that interface. An example is in commons-collections, where you have interfaces for Closure, Transformer, and Predicate, and methods that you pass implementations of those into. Guava is the new improved commons-collections, you can find equivalent interfaces there.

So for instance, commons-collections has org.apache.commons.collections.CollectionUtils, which has lots of static methods that take objects passed in, to pick one at random, there's one called exists with this signature:

static boolean exists(java.util.Collection collection, Predicate predicate) 


It takes an object that implements the interface Predicate, which means it has to have a method on it that takes some Object and returns a boolean.

So I can call it like this:

CollectionUtils.exists(someCollection, new Predicate() {
    public boolean evaluate(Object object) { 
        return (""a"".equals(object.toString());
    }
});


and it returns true or false depending on whether someCollection contains an object that the predicate returns true for.

Anyway, this is just an example, and commons-collections is outdated. I just forget the equivalent in Guava.
    Java supports closures just fine. It just doesn't support functions, so the syntax you're used to for closures is much more awkward and bulky: you have to wrap everything up in a class with a method. For example,

public Runnable foo(final int x) {
  return new Runnable() {
    public void run() {
      System.out.println(x);
    }
  };
}


Will return a Runnable object whose run() method ""closes over"" the x passed in, just like in any language that supports first-class functions and closures.
    I used the command pattern that @jk. mentioned, adding a return type:

public interface Callable<I, O> {

    public O call(I input);   
}

    I know this is a rather old post but I have another slightly simpler solution.
You could create another class within and make it abstract. Next make an Abstract method name it whatever you like. In the original class make a method that takes the new class as a parameter, in this method call the abstract method. It will look something like this.

public class Demo {

    public Demo(/.../){

    }

    public void view(Action a){
        a.preform();
    }

    /**
     * The Action Class is for making the Demo
     * View Custom Code
     */
    public abstract class Action {

        public Action(/.../){

        }

        abstract void preform();
    }
}


Now you can do something like this to call a method from within the class.

/...
Demo d = new Demo;
Action a = new Action() {

    @Override
    void preform() {
        //Custom Method Code Goes Here
    }
};

/.../
d.view(a)


Like I said I know its old but this way I think is a little easier. Hope it helps.
    Java does not (yet) support closures. But there are other languages like Scala and Groovy which run in the JVM and do support closures.
    ","[491, 561, 129, 101, 17, 6, 5, 4, -14]",745278,176,2011-01-13T21:37:32,2020-01-28 15:39:22Z,java 
Why are there no ++ and --​ operators in Python?,"
                
Why are there no ++ and -- operators in Python?
    It's not because it doesn't make sense; it makes perfect sense to define ""x++"" as ""x += 1, evaluating to the previous binding of x"".

If you want to know the original reason, you'll have to either wade through old Python mailing lists or ask somebody who was there (eg. Guido), but it's easy enough to justify after the fact:

Simple increment and decrement aren't needed as much as in other languages.  You don't write things like for(int i = 0; i < 10; ++i) in Python very often; instead you do things like for i in range(0, 10).

Since it's not needed nearly as often, there's much less reason to give it its own special syntax; when you do need to increment, += is usually just fine.

It's not a decision of whether it makes sense, or whether it can be done--it does, and it can.  It's a question of whether the benefit is worth adding to the core syntax of the language.  Remember, this is four operators--postinc, postdec, preinc, predec, and each of these would need to have its own class overloads; they all need to be specified, and tested; it would add opcodes to the language (implying a larger, and therefore slower, VM engine); every class that supports a logical increment would need to implement them (on top of += and -=).

This is all redundant with += and -=, so it would become a net loss.
    Of course, we could say ""Guido just decided that way"", but I think the question is really about the reasons for that decision. I think there are several reasons:


It mixes together statements and expressions, which is not good practice. See http://norvig.com/python-iaq.html
It generally encourages people to write less readable code
Extra complexity in the language implementation, which is unnecessary in Python, as already mentioned

    Because, in Python, integers are immutable (int's += actually returns a different object).

Also, with ++/-- you need to worry about pre- versus post- increment/decrement, and it takes only one more keystroke to write x+=1.  In other words, it avoids potential confusion at the expense of very little gain.
    This original answer I wrote is a myth from the folklore of computing: debunked by Dennis Ritchie as ""historically impossible"" as noted in the letters to the editors of Communications of the ACM July 2012 doi:10.1145/2209249.2209251



The C increment/decrement operators were invented at a time when the C compiler wasn't very smart and the authors wanted to be able to specify the direct intent that a machine language operator should be used which saved a handful of cycles for a compiler which might do a 

load memory
load 1
add
store memory


instead of 

inc memory 


and the PDP-11 even supported ""autoincrement"" and ""autoincrement deferred"" instructions corresponding to *++p and *p++, respectively. See section 5.3 of the manual if horribly curious.

As compilers are smart enough to handle the high-level optimization tricks built into the syntax of C, they are just a syntactic convenience now. 

Python doesn't have tricks to convey intentions to the assembler because it doesn't use one.
    My understanding of why python does not have ++ operator is following: When you write this in python a=b=c=1 you will get three variables (labels) pointing at same object (which value is 1). You can verify this by using id function which will return an object memory address:

In [19]: id(a)
Out[19]: 34019256

In [20]: id(b)
Out[20]: 34019256

In [21]: id(c)
Out[21]: 34019256


All three variables (labels) point to the same object. Now increment one of variable and see how it affects memory addresses:

In [22] a = a + 1

In [23]: id(a)
Out[23]: 34019232

In [24]: id(b)
Out[24]: 34019256

In [25]: id(c)
Out[25]: 34019256


You can see that variable a now points to another object as variables b and c. Because you've used a = a + 1 it is explicitly clear. In other words you assign completely another object to label a. Imagine that you can write a++ it would suggest that you did not assign to variable a new object but ratter increment the old one. All this stuff is IMHO for minimization of confusion. For better understanding see how python variables works:

In Python, why can a function modify some arguments as perceived by the caller, but not others?

Is Python call-by-value or call-by-reference? Neither.

Does Python pass by value, or by reference?

Is Python pass-by-reference or pass-by-value?

Python: How do I pass a variable by reference?

Understanding Python variables and Memory Management

Emulating pass-by-value behaviour in python

Python functions call by reference

Code Like a Pythonista: Idiomatic Python
    To complete already good answers on that page:
Let's suppose we decide to do this, prefix (++i) that would break the unary + and - operators.
Today, prefixing by ++ or -- does nothing, because it enables unary plus operator twice (does nothing) or unary minus twice (twice: cancels itself)
>>> i=12
>>> ++i
12
>>> --i
12

So that would potentially break that logic.
now if one needs it for list comprehensions or lambdas, from python 3.8 it's possible with the new := assignment operator (PEP572)
pre-incrementing a and assign it to b:
>>> a = 1
>>> b = (a:=a+1)
>>> b
2
>>> a
2

post-incrementing just needs to make up the premature add by subtracting 1:
>>> a = 1
>>> b = (a:=a+1)-1
>>> b
1
>>> a
2

    Other answers have described why it's not needed for iterators, but sometimes it is useful when assigning to increase a variable in-line, you can achieve the same effect using tuples and multiple assignment:

b = ++a becomes:

a,b = (a+1,)*2


and b = a++ becomes:

a,b = a+1, a


Python 3.8 introduces the assignment := operator, allowing us to achievefoo(++a) with 

foo(a:=a+1)


foo(a++) is still elusive though.
    Clarity!

Python is a lot about clarity and no programmer is likely to correctly guess the meaning of --a unless s/he's learned a language having that construct.

Python is also a lot about avoiding constructs that invite mistakes and the ++ operators are known to be rich sources of defects.
These two reasons are enough not to have those operators in Python.

The decision that Python uses indentation to mark blocks rather
than syntactical means such as some form of begin/end bracketing 
or mandatory end marking is based largely on the same considerations.

For illustration, have a look at the discussion around introducing a conditional operator (in C: cond ? resultif : resultelse) into Python in 2005.
Read at least the first message and the decision message of that discussion (which had several precursors on the same topic previously).

Trivia:
The PEP frequently mentioned therein is the ""Python Extension Proposal"" PEP 308. LC means list comprehension, GE means generator expression (and don't worry if those confuse you, they are none of the few complicated spots of Python).
    First, Python is only indirectly influenced by C; it is heavily influenced by ABC, which apparently does not have these operators, so it should not be any great surprise not to find them in Python either.

Secondly, as others have said, increment and decrement are supported by += and -= already.

Third, full support for a ++ and -- operator set usually includes supporting both the prefix and postfix versions of them.  In C and C++, this can lead to all kinds of ""lovely"" constructs that seem (to me) to be against the spirit of simplicity and straight-forwardness that Python embraces.

For example, while the C statement while(*t++ = *s++); may seem simple and elegant to an experienced programmer, to someone learning it, it is anything but simple.  Throw in a mixture of prefix and postfix increments and decrements, and even many pros will have to stop and think a bit.
    I believe it stems from the Python creed that ""explicit is better than implicit"".
    as i understood it so you won't think the value in memory is changed.
in c when you do x++ the value of x in memory changes.
but in python all numbers are immutable hence the address that x pointed as still has x not x+1. when you write x++ you would think that x change what really happens is that x refrence is changed to a location in memory where x+1 is stored or recreate this location if doe's not exists.  
    This may be because @GlennMaynard is looking at the matter as in comparison with other languages, but in Python, you do things the python way. It's not a 'why' question. It's there and you can do things to the same effect with x+=. In The Zen of Python, it is given: ""there should only be one way to solve a problem."" Multiple choices are great in art (freedom of expression) but lousy in engineering.
    I always assumed it had to do with this line of the zen of python:


  There should be one — and preferably only one — obvious way to do it.


x++ and x+=1 do the exact same thing, so there is no reason to have both. 
    It was just designed that way.  Increment and decrement operators are just shortcuts for x = x + 1.  Python has typically adopted a design strategy which reduces the number of alternative means of performing an operation.  Augmented assignment is the closest thing to increment/decrement operators in Python, and they weren't even added until Python 2.0.
    In addition to the other excellent answers here, ++ and -- are also notorious for undefined behavior. For example, what happens in this code?
foo[bar] = bar++;

It's so innocent-looking, but it's wrong C (and C++), because you don't know whether the first bar will have been incremented or not. One compiler might do it one way, another might do it another way, and a third might make demons fly out of your nose. All would be perfectly conformant with the C and C++ standards.
Undefined behavior is seen as a necessary evil in C and C++, but in Python, it's just evil, and avoided as much as possible.
    I'm very new to python but I suspect the reason is because of the emphasis between mutable and immutable objects within the language.  Now, I know that x++ can easily be interpreted as x = x + 1, but it LOOKS like you're incrementing in-place an object which could be immutable.

Just my guess/feeling/hunch.
    The ++ class of operators are expressions with side effects. This is something generally not found in Python.

For the same reason an assignment is not an expression in Python, thus preventing the common if (a = f(...)) { /* using a here */ } idiom.

Lastly I suspect that there operator are not very consistent with Pythons reference semantics. Remember, Python does not have variables (or pointers) with the semantics known from C/C++.
    Maybe a better question would be to ask why do these operators exist in C. K&R calls increment and decrement operators 'unusual' (Section 2.8page 46). The Introduction calls them 'more concise and often more efficient'. I suspect that the fact that these operations always come up in pointer manipulation also has played a part in their introduction.
In Python it has been probably decided that it made no sense to try to optimise increments (in fact I just did a test in C, and it seems that the gcc-generated assembly uses addl instead of incl in both cases) and there is no pointer arithmetic; so it would have been just One More Way to Do It and we know Python loathes that.
    I think this relates to the concepts of mutability and immutability of objects. 2,3,4,5 are immutable in python. Refer to the image below. 2 has fixed id until this python process. 



x++ would essentially mean an in-place increment like C. In C, x++ performs in-place increments. So, x=3, and x++ would increment 3 in the memory to 4, unlike python where 3 would still exist in memory. 

Thus in python, you don't need to recreate a value in memory. This may lead to performance optimizations. 

This is a hunch based answer.
    I know this is an old thread, but the most common use case for ++i is not covered, that being manually indexing sets when there are no provided indices. This situation is why python provides enumerate()

Example : In any given language, when you use a construct like foreach to iterate over a set - for the sake of the example we'll even say it's an unordered set and you need a unique index for everything to tell them apart, say

i = 0
stuff = {'a': 'b', 'c': 'd', 'e': 'f'}
uniquestuff = {}
for key, val in stuff.items() :
  uniquestuff[key] = '{0}{1}'.format(val, i)
  i += 1


In cases like this, python provides an enumerate method, e.g.

for i, (key, val) in enumerate(stuff.items()) :

    This is not the answer, (just a log from me) but I believe: it should be there.
It is true that there is a python way of doing things and it is not needed for loop counters, However: there are few cases where one needs to manipulate other variable besides the one which is looping.
Looking at views for this thread.. there definitely is a use case.
We need lobbying to get this feature in... although I don't see that fructifying for a long long time. In the mean time: is there a way to do operator overloading to imitate ++?
    ","[491, 492, 41, 17, 88, 11, 2, 1, 12, 4, 3, 1, 2, 68, 7, -2, 6, 2, 1, 0, 0, 0]",317505,87,2010-09-06T23:29:24,2022-04-13 02:40:17Z,python 
How to convert java.util.Date to java.sql.Date?,"
                
I am trying to use a java.util.Date as input and then creating a query with it - so I need a java.sql.Date.  

I was surprised to find that it couldn't do the conversion implicitly or explicitly - but I don't even know how I would do this, as the Java API is still fairly new to me.
    tl;dr

How to convert java.util.Date to java.sql.Date?

Don’t.
Both Date classes are outmoded. Sun, Oracle, and the JCP community gave up on those legacy date-time classes years ago with the unanimous adoption of JSR 310 defining the java.time classes.

Use java.time classes instead of legacy java.util.Date & java.sql.Date with JDBC 4.2 or later.
Convert to/from java.time if inter-operating with code not yet updated to java.time.





Legacy
Modern
Conversion




java.util.Date
java.time.Instant
java.util.Date.toInstant()java.util.Date.from( Instant )


java.sql.Date
java.time.Date
java.sql.Date.toLocalDate()java.sql.Date.valueOf( LocalDate )




Example query with PreparedStatement.
myPreparedStatement.setObject( 
    … ,                                         // Specify the ordinal number of which argument in SQL statement.
    myJavaUtilDate.toInstant()                  // Convert from legacy class `java.util.Date` (a moment in UTC) to a modern `java.time.Instant` (a moment in UTC).
        .atZone( ZoneId.of( ""Africa/Tunis"" ) )  // Adjust from UTC to a particular time zone, to determine a date. Instantiating a `ZonedDateTime`.
        .toLocalDate()                          // Extract a date-only `java.time.LocalDate` object from the date-time `ZonedDateTime` object.
)

Replacements:

Instant instead of java.util.DateBoth represent a moment in UTC. but now with nanoseconds instead of milliseconds.
LocalDate instead of java.sql.DateBoth represent a date-only value without a time of day and without a time zone.

Details
If you are trying to work with date-only values (no time-of-day, no time zone), use the LocalDate class rather than java.util.Date.

java.time
In Java 8 and later, the troublesome old date-time classes bundled with early versions of Java have been supplanted by the new java.time package. See Oracle Tutorial. Much of the functionality has been back-ported to Java 6 & 7 in ThreeTen-Backport and further adapted to Android in ThreeTenABP.
A SQL data type DATE is meant to be date-only, with no time-of-day and no time zone. Java never had precisely such a class† until java.time.LocalDate in Java 8. Let's create such a value by getting today's date according to a particular time zone (time zone is important in determining a date as a new day dawns earlier in Paris than in Montréal, for example).
LocalDate todayLocalDate = LocalDate.now( ZoneId.of( ""America/Montreal"" ) );  // Use proper ""continent/region"" time zone names; never use 3-4 letter codes like ""EST"" or ""IST"".

At this point, we may be done. If your JDBC driver complies with JDBC 4.2 spec, you should be able to pass a LocalDate via setObject on a PreparedStatement to store into a SQL DATE field.
myPreparedStatement.setObject( 1 , localDate );

Likewise, use ResultSet::getObject to fetch from a SQL DATE column to a Java LocalDate object. Specifying the class in the second argument makes your code type-safe.
LocalDate localDate = ResultSet.getObject( 1 , LocalDate.class );

In other words, this entire Question is irrelevant under JDBC 4.2 or later.
If your JDBC driver does not perform in this manner, you need to fall back to converting to the java.sql types.
Convert to java.sql.Date
To convert, use new methods added to the old date-time classes. We can call java.sql.Date.valueOf(…) to convert a LocalDate.
java.sql.Date sqlDate = java.sql.Date.valueOf( todayLocalDate );

And going the other direction.
LocalDate localDate = sqlDate.toLocalDate();

Converting from java.util.Date
While you should avoid using the old date-time classes, you may be forced to when working with existing code. If so, you can convert to/from java.time.
Go through the Instant class, which represents a moment on the timeline in UTC. An Instant is similar in idea to a java.util.Date. But note that Instant has a resolution up to nanoseconds while java.util.Date has only milliseconds resolution.
To convert, use new methods added to the old classes. For example, java.util.Date.from( Instant ) and java.util.Date::toInstant.
Instant instant = myUtilDate.toInstant();

To determine a date, we need the context of a time zone. For any given moment, the date varies around the globe by time zone. Apply a ZoneId to get a ZonedDateTime.
ZoneId zoneId = ZoneId.of ( ""America/Montreal"" );
ZonedDateTime zdt = ZonedDateTime.ofInstant ( instant , zoneId );
LocalDate localDate = zdt.toLocalDate();


† The java.sql.Date class pretends to be date-only without a time-of-day but actually does a time-of-day, adjusted to a midnight time. Confusing? Yes, the old date-time classes are a mess.

About java.time
The java.time framework is built into Java 8 and later. These classes supplant the troublesome old legacy date-time classes such as java.util.Date, Calendar, & SimpleDateFormat.
To learn more, see the Oracle Tutorial. And search Stack Overflow for many examples and explanations. Specification is JSR 310.
The Joda-Time project, now in maintenance mode, advises migration to the java.time classes.
You may exchange java.time objects directly with your database. Use a JDBC driver compliant with JDBC 4.2 or later. No need for strings, no need for java.sql.* classes. Hibernate 5 & JPA 2.2 support java.time.
Where to obtain the java.time classes?

Java SE 8, Java SE 9, Java SE 10, Java SE 11, and later  - Part of the standard Java API with a bundled implementation.

Java 9 brought some minor features and fixes.


Java SE 6 and Java SE 7

Most of the java.time functionality is back-ported to Java 6 & 7 in ThreeTen-Backport.


Android

Later versions of Android (26+) bundle implementations of the java.time classes.
For earlier Android (<26), a process known as API desugaring brings a subset of the java.time functionality not originally built into Android.

If the desugaring does not offer what you need, the ThreeTenABP project adapts ThreeTen-Backport (mentioned above) to Android. See How to use ThreeTenABP….






The ThreeTen-Extra project extends java.time with additional classes. This project is a proving ground for possible future additions to java.time. You may find some useful classes here such as Interval, YearWeek, YearQuarter, and more.
    Nevermind....

public class MainClass {

  public static void main(String[] args) {
    java.util.Date utilDate = new java.util.Date();
    java.sql.Date sqlDate = new java.sql.Date(utilDate.getTime());
    System.out.println(""utilDate:"" + utilDate);
    System.out.println(""sqlDate:"" + sqlDate);

  }

}


explains it.  The link is http://www.java2s.com/Tutorial/Java/0040__Data-Type/ConvertfromajavautilDateObjecttoajavasqlDateObject.htm
    This function will return a converted SQL date from java date object.

public java.sql.Date convertJavaDateToSqlDate(java.util.Date date) {
    return new java.sql.Date(date.getTime());
}

    Converting java.util.Date to java.sql.Date will lose hours, minutes and seconds. So if it is possible, I suggest you to use java.sql.Timestamp like this:
prepareStatement.setTimestamp(1, new Timestamp(utilDate.getTime()));

For more info, you can check this question.
    This function will return a converted SQL date from java date object.

public static java.sql.Date convertFromJAVADateToSQLDate(
            java.util.Date javaDate) {
        java.sql.Date sqlDate = null;
        if (javaDate != null) {
            sqlDate = new Date(javaDate.getTime());
        }
        return sqlDate;
    }

    Format your java.util.Date first. Then use the formatted date to get the date in java.sql.Date

java.util.Date utilDate = ""Your date""
SimpleDateFormat dateFormat = new SimpleDateFormat(""yyyy-MM-dd"");
final String stringDate= dateFormat.format(utilDate);
final java.sql.Date sqlDate=  java.sql.Date.valueOf(stringDate);

    With the other answer you may have troubles with the time info (compare the dates with unexpected results!)

I suggest:

java.util.Calendar cal = Calendar.getInstance();
java.util.Date utilDate = new java.util.Date(); // your util date
cal.setTime(utilDate);
cal.set(Calendar.HOUR_OF_DAY, 0);
cal.set(Calendar.MINUTE, 0);
cal.set(Calendar.SECOND, 0);
cal.set(Calendar.MILLISECOND, 0);    
java.sql.Date sqlDate = new java.sql.Date(cal.getTime().getTime()); // your sql date
System.out.println(""utilDate:"" + utilDate);
System.out.println(""sqlDate:"" + sqlDate);

    In my case of picking date from JXDatePicker (java calender) and getting it stored in database as SQL Date type, below works fine ..

java.sql.Date date = new java.sql.Date(pickedDate.getDate().getTime());

where pickedDate is object of JXDatePicker
    I am a novice: after much running around this worked.  Thought might be useful

     String bufDt =  bDOB.getText();  //data from form
     DateFormat dF = new SimpleDateFormat(""dd-MM-yyyy""); //data in form is in this format
     Date bbdt = (Date)dF.parse(bufDt);  // string data is converted into java util date
     DateFormat dsF = new SimpleDateFormat(""yyyy-MM-dd""); //converted date is reformatted for conversion to sql.date
     String ndt = dsF.format(bbdt); // java util date is converted to compatible java sql date
     java.sql.Date sqlDate=  java.sql.Date.valueOf(ndt);  // finally data from the form is convered to java sql. date for placing in database

    I think the best way to convert is:

static java.sql.Timestamp SQLDateTime(Long utilDate) {
    return new java.sql.Timestamp(utilDate);
}

Date date = new Date();
java.sql.Timestamp dt = SQLDateTime(date.getTime());


If you want to insert the dt variable into an SQL table you can do:

insert into table (expireAt) values ('""+dt+""');

    I was trying the following coding that worked fine.


  java.util.Date utilDate = new java.util.Date(); java.sql.Date
  sqlDate = new java.sql.Date(utilDate);

    You can use this method to convert util date to sql date,

DateUtilities.convertUtilDateToSql(java.util.Date)

    Here the example of converting Util Date to Sql date and ya this is one example what i am using in my project might be helpful to you too.

java.util.Date utilStartDate = table_Login.getDob();(orwhat ever date your give form obj)
java.sql.Date sqlStartDate = new java.sql.Date(utilStartDate.getTime());(converting date)

    Method for comparing 2 dates (util.date or sql.date)  

 public static boolean isSameDay(Date a, Date b) {
    Calendar calA = new GregorianCalendar();
    calA.setTime(a);

    Calendar calB = new GregorianCalendar();
    calB.setTime(b);

    final int yearA = calA.get(Calendar.YEAR);
    final int monthA = calA.get(Calendar.MONTH);
    final int dayA = calA.get(Calendar.DAY_OF_YEAR);

    final int yearB = calB.get(Calendar.YEAR);
    final int monthB = calB.get(Calendar.MONTH);
    final int dayB = calB.get(Calendar.DAY_OF_YEAR);

    return yearA == yearB && monthA == monthB && dayA == dayB;
}

    try with this 

public static String toMysqlDateStr(Date date) {
    String dateForMySql = """";
    if (date == null) {
        dateForMySql = null;
    } else {
        SimpleDateFormat sdf = new SimpleDateFormat(""yyyy-MM-dd HH:mm:ss"");
        dateForMySql = sdf.format(date);
    }

    return dateForMySql;
}

    i am using the following code please try it out

DateFormat fm= new SimpleDateFormatter();


specify the format of the date you want
for example ""DD-MM_YYYY"" or 'YYYY-mm-dd'  then use the java Date datatype as

fm.format(""object of java.util.date"");


then it will parse your date
    If you are usgin Mysql a date column can be passed a String representation of this date

so i using the DateFormatter Class to format it and then set it as a String in the sql statement or prepared statement

here is the code illustration:

private String converUtilDateToSqlDate(java.util.Date utilDate) {
    SimpleDateFormat sdf = new SimpleDateFormat(""yyyy-MM-dd"");
    String sqlDate = sdf.format(utilDate);
    return sqlDate;
}


String date = converUtilDateToSqlDate(otherTransaction.getTransDate());

//then pass this date in you sql statement
    ","[491, 119, 511, 30, 21, 6, 6, 40, 16, 2, -1, -4, -4, 2, 1, 0, -3, -8]",711608,89,2009-02-09T21:16:18,2021-08-04 21:38:14Z,java sql 
Using Application context everywhere?,"
                
In an Android app, is there anything wrong with the following approach:

public class MyApp extends android.app.Application {

    private static MyApp instance;

    public MyApp() {
        instance = this;
    }

    public static Context getContext() {
        return instance;
    }

}


and pass it everywhere (e.g. SQLiteOpenHelper) where context is required (and not leaking of course)?
    There are a couple of potential problems with this approach, though in a lot of circumstances (such as your example) it will work well.

In particular you should be careful when dealing with anything that deals with the GUI that requires a Context. For example, if you pass the application Context into the LayoutInflater you will get an Exception. Generally speaking, your approach is excellent: it's good practice to use an Activity's Context within that Activity, and the Application Context when passing a context beyond the scope of an Activity to avoid memory leaks.

Also, as an alternative to your pattern you can use the shortcut of calling getApplicationContext() on a Context object (such as an Activity) to get the Application Context.
    Some people have asked: how can the singleton return a null pointer?
I'm answering that question. (I cannot answer in a comment because I need to post code.)

It may return null in between two events: (1) the class is loaded, and (2) the object of this class is created. Here's an example:

class X {
    static X xinstance;
    static Y yinstance = Y.yinstance;
    X() {xinstance=this;}
}
class Y {
    static X xinstance = X.xinstance;
    static Y yinstance;
    Y() {yinstance=this;}
}

public class A {
    public static void main(String[] p) {
    X x = new X();
    Y y = new Y();
    System.out.println(""x:""+X.xinstance+"" y:""+Y.yinstance);
    System.out.println(""x:""+Y.xinstance+"" y:""+X.yinstance);
    }
}


Let's run the code:

$ javac A.java 
$ java A
x:X@a63599 y:Y@9036e
x:null y:null


The second line shows that Y.xinstance and X.yinstance are null; they are null because the variables X.xinstance ans Y.yinstance were read when they were null.

Can this be fixed? Yes,

class X {
    static Y y = Y.getInstance();
    static X theinstance;
    static X getInstance() {if(theinstance==null) {theinstance = new X();} return theinstance;}
}
class Y {
    static X x = X.getInstance();
    static Y theinstance;
    static Y getInstance() {if(theinstance==null) {theinstance = new Y();} return theinstance;}
}

public class A {
    public static void main(String[] p) {
    System.out.println(""x:""+X.getInstance()+"" y:""+Y.getInstance());
    System.out.println(""x:""+Y.x+"" y:""+X.y);
    }
}


and this code shows no anomaly:

$ javac A.java 
$ java A
x:X@1c059f6 y:Y@152506e
x:X@1c059f6 y:Y@152506e


BUT this is not an option for the Android Application object: the programmer does not control the time when it is created.

Once again: the difference between the first example and the second one is that the second example creates an instance if the static pointer is null. But a programmer cannot create the Android application object before the system decides to do it.

UPDATE

One more puzzling example where initialized static fields happen to be null.

Main.java:

enum MyEnum {
    FIRST,SECOND;
    private static String prefix=""<"", suffix="">"";
    String myName;
    MyEnum() {
        myName = makeMyName();
    }
    String makeMyName() {
        return prefix + name() + suffix;
    }
    String getMyName() {
        return myName;
    }
}
public class Main {
    public static void main(String args[]) {
        System.out.println(""first: ""+MyEnum.FIRST+"" second: ""+MyEnum.SECOND);
        System.out.println(""first: ""+MyEnum.FIRST.makeMyName()+"" second: ""+MyEnum.SECOND.makeMyName());
        System.out.println(""first: ""+MyEnum.FIRST.getMyName()+"" second: ""+MyEnum.SECOND.getMyName());
    }
}


And you get:

$ javac Main.java
$ java Main
first: FIRST second: SECOND
first: <FIRST> second: <SECOND>
first: nullFIRSTnull second: nullSECONDnull


Note that you cannot move the static variable declaration one line upper, the code will not compile.
    In my experience this approach shouldn't be necessary.  If you need the context for anything you can usually get it via a call to View.getContext() and using the Context obtained there you can call Context.getApplicationContext() to get the Application context.  If you are trying to get the Application context this from an Activity you can always call Activity.getApplication() which should be able to be passed as the Context needed for a call to SQLiteOpenHelper().

Overall there doesn't seem to be a problem with your approach for this situation, but when dealing with Context just make sure you are not leaking memory anywhere as described on the official Google Android Developers blog.
    Application Class:

import android.app.Application;
import android.content.Context;

public class MyApplication extends Application {

    private static Context mContext;

    public void onCreate() {
        super.onCreate();
        mContext = getApplicationContext();
    }

    public static Context getAppContext() {
        return mContext;
    }

}


Declare the Application in the AndroidManifest:

<application android:name="".MyApplication""
    ...
/>


Usage:

MyApplication.getAppContext()

    It is a good approach. I use it myself as well. I would only suggest to override onCreate to set the singleton instead of using a constructor.

And since you mentioned SQLiteOpenHelper: In onCreate () you can open the database as well.

Personally I think the documentation got it wrong in saying that There is normally no need to subclass Application. I think the opposite is true: You should always subclass Application.
    You are trying to create a wrapper to get Application Context and there is a possibility that it might return ""null"" pointer.

As per my understanding, I guess its better approach to call- any of the 2
Context.getApplicationContext()  or Activity.getApplication().
    I like it, but I would suggest a singleton instead:

package com.mobidrone;

import android.app.Application;
import android.content.Context;

public class ApplicationContext extends Application
{
    private static ApplicationContext instance = null;

    private ApplicationContext()
    {
        instance = this;
    }

    public static Context getInstance()
    {
        if (null == instance)
        {
            instance = new ApplicationContext();
        }

        return instance;
    }
}

    I'm using the same approach, I suggest to write the singleton a little better:

public static MyApp getInstance() {

    if (instance == null) {
        synchronized (MyApp.class) {
            if (instance == null) {
                instance = new MyApp ();
            }
        }
    }

    return instance;
}


but I'm not using everywhere, I use getContext() and getApplicationContext() where I can do it!
    I would use Application Context to get a System Service in the constructor. This eases testing & benefits from composition

public class MyActivity extends Activity {

    private final NotificationManager notificationManager;

    public MyActivity() {
       this(MyApp.getContext().getSystemService(NOTIFICATION_SERVICE));
    }

    public MyActivity(NotificationManager notificationManager) {
       this.notificationManager = notificationManager;
    }

    // onCreate etc

}


Test class would then use the overloaded constructor.

Android would use the default constructor.
    ","[491, 427, 14, 30, 12, 5, 8, 1, 0, 3]",315502,197,2009-06-12T14:54:10,2019-06-14 10:28:34Z,
iOS - Dismiss keyboard when touching outside of UITextField,"
                
I'm wondering how to make the keyboard disappear when the user touches outside of a UITextField.
    You'll need to add an UITapGestureRecogniser and assign it to the view, and then call resign first responder on the UITextField on it's selector.

The code:

In viewDidLoad

UITapGestureRecognizer *tap = [[UITapGestureRecognizer alloc] initWithTarget:self action:@selector(dismissKeyboard)];

[self.view addGestureRecognizer:tap];


In dismissKeyboard:

-(void)dismissKeyboard 
{
    [aTextField resignFirstResponder];
}


(Where aTextField is the textfield that is responsible for the keyboard)

Swift 3 version looks like that

let tapGesture = UITapGestureRecognizer(target: self, action: #selector(self.dismissKeyboard (_:)))
self.view.addGestureRecognizer(tapGesture)


For dismissKeyboard

@objc func dismissKeyboard (_ sender: UITapGestureRecognizer) {
    aTextField.resignFirstResponder()
}

    Swift 4

Setup your UIViewController with this extension method once e.g in viewDidLoad:

override func viewDidLoad() {
    super.viewDidLoad()
    self.setupHideKeyboardOnTap()
}


and the keyboard will be dismissed even by tapping on the NavigationBar.

import UIKit
extension UIViewController {
    /// Call this once to dismiss open keyboards by tapping anywhere in the view controller
    func setupHideKeyboardOnTap() {
        self.view.addGestureRecognizer(self.endEditingRecognizer())
        self.navigationController?.navigationBar.addGestureRecognizer(self.endEditingRecognizer())
    }

    /// Dismisses the keyboard from self.view
    private func endEditingRecognizer() -> UIGestureRecognizer {
        let tap = UITapGestureRecognizer(target: self.view, action: #selector(self.view.endEditing(_:)))
        tap.cancelsTouchesInView = false
        return tap
    }
}

    I see that some people are having issues using the UITapGestureRecognizer method. The easiest way that I've accomplished this functionality while still leaving my existing button's tap behavior intact is adding only one line to @Jensen2k 's answer:

[tap setCancelsTouchesInView:NO];


This allowed my existing buttons to still work without using @Dmitry Sitnikov 's method. 

Read about that property here (search for CancelsTouchesInView): UIGestureRecognizer Class Reference

I'm not sure how it would work with scrollbars, as I see some had issues with, but hopefully someone else might run into the same scenario I had.
    This is a good generic solution:

Objective-C:

- (void)touchesBegan:(NSSet *)touches withEvent:(UIEvent *)event {
    [self.view endEditing:YES];    
}


Swift:

override func touchesBegan(touches: NSSet, withEvent event: UIEvent) {
    self.view.endEditing(true)
}


Based on @icodebuster solution: https://stackoverflow.com/a/18756253/417652
    I mashed up a few answers.

Use an ivar that gets initialized during viewDidLoad:

UIGestureRecognizer *tapper;

- (void)viewDidLoad
{
    [super viewDidLoad];
    tapper = [[UITapGestureRecognizer alloc]
                initWithTarget:self action:@selector(handleSingleTap:)];
    tapper.cancelsTouchesInView = NO;
    [self.view addGestureRecognizer:tapper];
}


Dismiss what ever is currently editing:

- (void)handleSingleTap:(UITapGestureRecognizer *) sender
{
    [self.view endEditing:YES];
}

    Check this, this would be the easiest way to do that,

-(void)touchesBegan:(NSSet *)touches withEvent:(UIEvent *)event{
      [self.view endEditing:YES];// this will do the trick
}


Or

This library will handle including scrollbar auto scrolling, tap space to hide the keyboard, etc...

https://github.com/michaeltyson/TPKeyboardAvoiding
    Objective-C:
Add this code in your ViewController.m file :
-(void)touchesBegan:(NSSet *)touches withEvent:(UIEvent *)event
{
    [self.view endEditing:YES];
}

Swift:
override func touchesBegan(_ touches: Set<UITouch>, with event: UIEvent?) {
    view.endEditing(true)
}

    In swift 5 You can use following code to dismiss keyboard  outside textfield

override func viewDidLoad() {
    // ... code

    let tapGesture = UITapGestureRecognizer(target: self, action: #selector(self.dismissKeyboard(_:)))
    self.view.addGestureRecognizer(tapGesture)  
}

@objc func dismissKeyboard(_ sender: UITapGestureRecognizer) {
    self.view.endEditing(true)
}

    If the view is embedded at all in a UIScrollView then you can use the following:

tableView.keyboardDismissMode = UIScrollViewKeyboardDismissModeOnDrag;
tableView.keyboardDismissMode = UIScrollViewKeyboardDismissModeInteractive;


The former will animate the keyboard off screen when the table view is scrolled and the later will hide the keyboard like the stock Messages app.


  Note that these are are available on iOS 7.0 or above.

    Just to add to the list here my version of how to dismiss a keyboard on outside touch.

viewDidLoad:

UITapGestureRecognizer *singleTap = [[UITapGestureRecognizer alloc] initWithTarget:self action:@selector(handleSingleTap:)];
[self.view addGestureRecognizer:singleTap];


Anywhere:

-(void)handleSingleTap:(UITapGestureRecognizer *)sender{
    [textFieldName resignFirstResponder];
    puts(""Dismissed the keyboard"");
}

    Swift 4 oneliner

view.addGestureRecognizer(UITapGestureRecognizer(target: view, action: #selector(UIView.endEditing(_:))))

    This must be the easiest way to hide your keyboard by touching outside :

- (void)touchesBegan:(NSSet *)touches withEvent:(UIEvent *)event {
    [self.view endEditing:YES];    
}


(from How to dismiss keyboard when user tap other area outside textfield?)
    It is better to make your UIView an instance of UIControl (in interface builder) and then connect their TouchUpInside event to dismissKeyboard method. This IBAction method will look like:

- (IBAction)dismissKeyboard:(id)sender {
    [aTextBox resignFirstResponder];
}

    override func touchesBegan(touches: Set<UITouch>, withEvent event: UIEvent?) {

    if let touch = touches.first{
     view.endEditing(true)

     }
}

    How about this: I know this is an old post. It might help someone :)

- (void)touchesEnded:(NSSet *)touches withEvent:(UIEvent *)event {  
    NSArray *subviews = [self.view subviews];
    for (id objects in subviews) {
        if ([objects isKindOfClass:[UITextField class]]) {
            UITextField *theTextField = objects;
            if ([objects isFirstResponder]) {
                [theTextField resignFirstResponder];
            }
        } 
    }
}

    Swift version, this works in combination with other elements (like a UIButton or another UITextField):

override func viewDidLoad() {
    super.viewDidLoad()

    let tapper = UITapGestureRecognizer(target: self, action:#selector(endEditing))
    tapper.cancelsTouchesInView = false
    view.addGestureRecognizer(tapper)
}

    I tried many of the responses here and had no luck.  My tap gesture recognizer was always causing my UIButtons to not respond when tapped, even when I set the cancelsTouchesInView property of the gesture recognizer to NO.

This is what eventually solved the issue:

Have an ivar:

UITapGestureRecognizer *_keyboardDismissGestureRecognizer;


When a text field begins editing, set the gesture recognizer:

- (void) textFieldDidBeginEditing:(UITextField *)textField
{
    if(_keyboardDismissGestureRecognizer == nil)
    {
        _keyboardDismissGestureRecognizer = [[[UITapGestureRecognizer alloc]
                                       initWithTarget:self
                                       action:@selector(dismissKeyboard)] autorelease];
        _keyboardDismissGestureRecognizer.cancelsTouchesInView = NO;

        [self.view addGestureRecognizer:_keyboardDismissGestureRecognizer];
    }
}


Then the trick is in how you set up the dismissKeyboard method:

- (void) dismissKeyboard
{
    [self performSelector:@selector(dismissKeyboardSelector) withObject:nil afterDelay:0.01];
}

- (void) dismissKeyboardSelector
{
    [self.view endEditing:YES];

    [self.view removeGestureRecognizer:_keyboardDismissGestureRecognizer];
    _keyboardDismissGestureRecognizer = nil;
}


I guess there's just something about getting the dismissKeyboardSelector execution out of the touch handling execution stack...
    You can do this using the Storyboard in XCode 6 and above:



Create the action to hide the keyboard

Add this to the header file of the class used by your ViewController:

@interface TimeDelayViewController : UIViewController <UITextFieldDelegate>

- (IBAction)dissmissKeyboardOnTap:(id)sender;

@end


Then add this to the implementation file of the same ViewController:

- (IBAction)dissmissKeyboardOnTap:(id)sender{
    [[self view]endEditing:YES];
}


This will now be one of the 'Received Actions' for your storyboard scene (i.e. ViewController):





Hook up the action to the user event

Now you need to hook up this action to the user gesture of touching off the keyboard.

Important - You need to convert the 'UIView' that's contained in your storyboard to a UIControl, so it can receive events. Select the view from your View Controller Scene hierarchy:



...and change its class:



Now drag from the small circle next to the 'received action' for your scene, onto an 'empty' part of your scene (actually you're dragging the 'Received Action' to the UIControl). You'll be shown a selection of events that you can hook up your action to:



Select the 'touch up inside' option. You've now hooked the IBAction you created to a user action of touching off the keyboard. When the user taps off the keyboard, it will now be hidden.

(NOTE: To hook the action to the event, you can also drag from the received action directly onto the UIControl in your View Controllers hierarchy. It's displayed as 'Control' in the hierarchy.)
    I think the easiest (and best) way to do this is to subclass your global view and use hitTest:withEvent method to listen to any touch. Touches on keyboard aren't registered, so hitTest:withEvent is only called when you touch/scroll/swipe/pinch... somewhere else, then call [self endEditing:YES].

This is better than using touchesBegan because touchesBegan are not called if you click on a button on top of the view. It is better than UITapGestureRecognizer which can't recognize a scrolling gesture for example. It is also better than using a dim screen because in a complexe and dynamic user interface, you can't put dim screen everywhere. Moreover, it doesn't block other actions, you don't need to tap twice to select a button outside (like in the case of a UIPopover).

Also, it's better than calling [textField resignFirstResponder], because you may have many text fields on screen, so this works for all of them.
    If I got you right you want to resign keyboard wile tapping on outSide of textfield but you don't have reference of your textfield.

Try this;


Take global textField, lets call it reftextField
Now in textFieldDidBeginEditing set referenced text field to 

- (void) textFieldDidBeginEditing:(UITextField *)textField{
    reftextField = textField;
}

Now you can happily use on any button clock, (adding a transparent button on begin editing recomended)

- (void)dismissKeyboard {
      [reftextField resignFirstResponder];
}

Or for resigning done button try this.

//for resigning on done button    
- (BOOL) textFieldShouldReturn:(UITextField *)textField{
    [textField resignFirstResponder];
    return YES;
}


    Swift version of @Jensen2k's answer:

let gestureRecognizer : UITapGestureRecognizer = UITapGestureRecognizer.init(target: self, action: ""dismissKeyboard"")
self.view.addGestureRecognizer(gestureRecognizer)

func dismissKeyboard() {
    aTextField.resignFirstResponder()
}


One liner

self.view.addTapGesture(UITapGestureRecognizer.init(target: self, action: ""endEditing:""))

    Plenty of great answers here about using UITapGestureRecognizer--all of which break UITextField's clear (X) button. The solution is to suppress the gesture recognizer via its delegate:

- (BOOL)gestureRecognizer:(UIGestureRecognizer *)gestureRecognizer shouldReceiveTouch:(UITouch *)touch {
    BOOL touchViewIsButton = [touch.view isKindOfClass:[UIButton class]];
    BOOL touchSuperviewIsTextField = [[touch.view superview] isKindOfClass:[UITextField class]];
    return !(touchViewIsButton && touchSuperviewIsTextField);
}


It's not the most robust solution but it works for me.
    You can create category for the UiView and override the touchesBegan meathod as follows.

It is working fine for me.And it is centralize solution for this problem.

#import ""UIView+Keyboard.h""
@implementation UIView(Keyboard)

- (void)touchesBegan:(NSSet *)touches withEvent:(UIEvent *)event
{
    [self.window endEditing:true];
    [super touchesBegan:touches withEvent:event];
}
@end

    I used Barry example for my new development. It worked great! but i had to include a slightly change, required to dismiss the keyboard only for the textfield being edited.

So, I added to Barry example the following:

- (void) textFieldDidBeginEditing:(UITextField *)textField
{
    _textBeingEdited = textField;
}
-(void) textFieldDidEndEditing:(UITextField *)textField
{
    _textBeingEdited = nil;
}


Also, I changed hideKeyboard method as follows:

- (IBAction)hideKeyboard:(id)sender
{
    // Just call resignFirstResponder on all UITextFields and UITextViews in this VC
    // Why? Because it works and checking which one was last active gets messy.
    //UITextField * tf = (UITextField *) sender;
    [_textBeingEdited resignFirstResponder];
}

    One of the most easiest and shortest way is to add this code to your viewDidLoad

[self.view addGestureRecognizer:[[UITapGestureRecognizer alloc]
                                     initWithTarget:self.view
                                     action:@selector(endEditing:)]];

    Send message resignFirstResponder to the textfiled that put it there. Please see this post for more information.
    This works

In this example, aTextField is the only UITextField.... If there are others or UITextViews, there's a tiny bit more to do.

// YourViewController.h
// ...
@interface YourViewController : UIViewController /* some subclass of UIViewController */ <UITextFieldDelegate> // <-- add this protocol
// ...
@end

// YourViewController.m

@interface YourViewController ()
@property (nonatomic, strong, readonly) UITapGestureRecognizer *singleTapRecognizer;
@end
// ...

@implementation
@synthesize singleTapRecognizer = _singleTapRecognizer;
// ...

- (void)viewDidLoad
{
    [super viewDidLoad];
    // your other init code here
    [self.view addGestureRecognizer:self.singleTapRecognizer];

{

- (UITapGestureRecognizer *)singleTapRecognizer
{
    if (nil == _singleTapRecognizer) {
        _singleTapRecognizer = [[UITapGestureRecognizer alloc] initWithTarget:self action:@selector(singleTapToDismissKeyboard:)];
        _singleTapRecognizer.cancelsTouchesInView = NO; // absolutely required, otherwise ""tap"" eats events.
    }
    return _singleTapRecognizer;
}

// Something inside this VC's view was tapped (except the navbar/toolbar)
- (void)singleTapToDismissKeyboard:(UITapGestureRecognizer *)sender
{
    NSLog(@""singleTap"");
    [self hideKeyboard:sender];
}

// When the ""Return"" key is pressed on the on-screen keyboard, hide the keyboard.
// for protocol UITextFieldDelegate
- (BOOL)textFieldShouldReturn:(UITextField*)textField
{
    NSLog(@""Return pressed"");
    [self hideKeyboard:textField];
    return YES;
}

- (IBAction)hideKeyboard:(id)sender
{
    // Just call resignFirstResponder on all UITextFields and UITextViews in this VC
    // Why? Because it works and checking which one was last active gets messy.
    [aTextField resignFirstResponder];
    NSLog(@""keyboard hidden"");
}

    - (void)viewDidLoad
{
    [super viewDidLoad]; 

UITapGestureRecognizer *singleTapGestureRecognizer = [[UITapGestureRecognizer alloc]
                                                          initWithTarget:self
                                                          action:@selector(handleSingleTap:)];
    [singleTapGestureRecognizer setNumberOfTapsRequired:1];
    [singleTapGestureRecognizer requireGestureRecognizerToFail:singleTapGestureRecognizer];

    [self.view addGestureRecognizer:singleTapGestureRecognizer];
}

- (void)handleSingleTap:(UITapGestureRecognizer *)recognizer
{
    [self.view endEditing:YES];
    [textField resignFirstResponder];
    [scrollView setContentOffset:CGPointMake(0, -40) animated:YES];

}

    In this case, there can be use ScrollView and added to TextField in ScrollView and I want Tap the ScrollView and View then Dismiss the Keyboard. I tried to create sample code just in case. Like this,

import UIKit

class ViewController: UIViewController {

    @IBOutlet weak var scrollView: UIScrollView!
    @IBOutlet weak var textField: UITextField!

    override func viewDidLoad() {
        super.viewDidLoad()

        let tapGesture = UITapGestureRecognizer(target: self, action: #selector(ViewController.tap(_:)))
        view.addGestureRecognizer(tapGesture)
        // Do any additional setup after loading the view, typically from a nib.
    }
    func tap(gesture: UITapGestureRecognizer) {
        textField.resignFirstResponder()
    }
    override func didReceiveMemoryWarning() {
        super.didReceiveMemoryWarning()
        // Dispose of any resources that can be recreated.
    }
}


Your Storyboard Look at that Just Like.


    You can use UITapGestureRecongnizer method for dismissing keyboard  by clicking outside of UITextField. By using this method whenever user will click outside of UITextField then keyboard will get dismiss. Below is the code snippet for using it.

 UITapGestureRecognizer *tap = [[UITapGestureRecognizer alloc]
                                   initWithTarget:self
                                   action:@selector(dismissk)];

    [self.view addGestureRecognizer:tap];


//Method
- (void) dismissk
{
    [abctextfield resignFirstResponder];
    [deftextfield resignFirstResponder];

}

    ","[490, 788, 45, 90, 17, 181, 106, 3, 3, 7, 4, 15, 9, 56, 2, 17, 28, 2, 6, 10, 5, 3, 3, 3, 2, 2, 1, 1, 1, 1, 1]",272281,163,2011-03-15T00:31:21,2021-05-07 10:46:26Z,
How to round to 2 decimals with Python?,"
                
I am getting a lot of decimals in the output of this code (Fahrenheit to Celsius converter).

My code currently looks like this:

def main():
    printC(formeln(typeHere()))

def typeHere():
    global Fahrenheit
    try:
        Fahrenheit = int(raw_input(""Hi! Enter Fahrenheit value, and get it in Celsius!\n""))
    except ValueError:
        print ""\nYour insertion was not a digit!""
        print ""We've put your Fahrenheit value to 50!""
        Fahrenheit = 50
    return Fahrenheit

def formeln(c):
    Celsius = (Fahrenheit - 32.00) * 5.00/9.00
    return Celsius

def printC(answer):
    answer = str(answer)
    print ""\nYour Celsius value is "" + answer + "" C.\n""



main()


So my question is, how do I make the program round every answer to the 2nd decimal place?
    You can use the round function, which takes as its first argument the number and the second argument is the precision after the decimal point.

In your case, it would be:

answer = str(round(answer, 2))

    Using str.format()'s syntax to display answer with two decimal places (without altering the underlying value of answer):

def printC(answer):
    print(""\nYour Celsius value is {:0.2f}ºC.\n"".format(answer))


Where:


: introduces the format spec
0 enables sign-aware zero-padding for numeric types
.2 sets the precision to 2
f displays the number as a fixed-point number

    Most answers suggested round or format. round sometimes rounds up, and in my case I needed the value of my variable to be rounded down and not just displayed as such.

round(2.357, 2)  # -> 2.36


I found the answer here: How do I round a floating point number up to a certain decimal place?

import math
v = 2.357
print(math.ceil(v*100)/100)  # -> 2.36
print(math.floor(v*100)/100)  # -> 2.35


or:

from math import floor, ceil

def roundDown(n, d=8):
    d = int('1' + ('0' * d))
    return floor(n * d) / d

def roundUp(n, d=8):
    d = int('1' + ('0' * d))
    return ceil(n * d) / d

    If you just want to print the rounded result out, you can use the f-strings introduced since Python 3.6. The syntax is the same as str.format()'s format string syntax, except you put a f in front of the literal string, and you put the variables directly in the string, within the curly braces.
.2f indicates rounding to two decimal places:
number = 3.1415926
print(f""The number rounded to two decimal places is {number:.2f}"")

Output:
The number rounded to two decimal places is 3.14

    You can use the round function.
round(80.23456, 3)

will give you an answer of 80.234
In your case, use
answer = str(round(answer, 2))

    from decimal import Decimal, ROUND_HALF_UP

# Here are all your options for rounding:
# This one offers the most out of the box control
# ROUND_05UP       ROUND_DOWN       ROUND_HALF_DOWN  ROUND_HALF_UP
# ROUND_CEILING    ROUND_FLOOR      ROUND_HALF_EVEN  ROUND_UP

our_value = Decimal(16.0/7)
output = Decimal(our_value.quantize(Decimal('.01'), 
rounding=ROUND_HALF_UP))
print output

    If you need not only round result but elso do math operations with round result, then you can use decimal.Decimal https://docs.python.org/2/library/decimal.html
from decimal import Decimal, ROUND_DOWN

Decimal('7.325').quantize(Decimal('.01'), rounding=ROUND_DOWN)
Decimal('7.32') 

    You want to round your answer.

round(value,significantDigit) is the ordinary solution to do this, however this sometimes does not operate as one would expect from a math perspective when the digit immediately inferior (to the left of) the digit you're rounding to has a 5.

Here's some examples of this unpredictable behavior:

>>> round(1.0005,3)
1.0
>>> round(2.0005,3)
2.001
>>> round(3.0005,3)
3.001
>>> round(4.0005,3)
4.0
>>> round(1.005,2)
1.0
>>> round(5.005,2)
5.0
>>> round(6.005,2)
6.0
>>> round(7.005,2)
7.0
>>> round(3.005,2)
3.0
>>> round(8.005,2)
8.01


Assuming your intent is to do the traditional rounding for statistics in the sciences, this is a handy wrapper to get the round function working as expected needing to import extra stuff like Decimal.

>>> round(0.075,2)

0.07

>>> round(0.075+10**(-2*6),2)

0.08


Aha! So based on this we can make a function...

def roundTraditional(val,digits):
   return round(val+10**(-len(str(val))-1), digits)


Basically this adds a really small value to the string to force it to round up properly on the unpredictable instances where it doesn't ordinarily with the round function when you expect it to.  A convenient value to add is 1e-X where X is the length of the number string you're trying to use round on plus 1. 

The approach of using 10**(-len(val)-1) was deliberate, as it the largest small number you can add to force the shift, while also ensuring that the value you add never changes the rounding even if the decimal . is missing.  I could use just 10**(-len(val)) with a condiditional if (val>1) to subtract 1 more... but it's simpler to just always subtract the 1 as that won't change much the applicable range of decimal numbers this workaround can properly handle.  This approach will fail if your values reaches the limits of the type, this will fail, but for nearly the entire range of valid decimal values it should work.

So the finished code will be something like:

def main():
    printC(formeln(typeHere()))

def roundTraditional(val,digits):
    return round(val+10**(-len(str(val))-1))

def typeHere():
    global Fahrenheit
    try:
        Fahrenheit = int(raw_input(""Hi! Enter Fahrenheit value, and get it in Celsius!\n""))
    except ValueError:
        print ""\nYour insertion was not a digit!""
        print ""We've put your Fahrenheit value to 50!""
        Fahrenheit = 50
    return Fahrenheit

def formeln(c):
    Celsius = (Fahrenheit - 32.00) * 5.00/9.00
    return Celsius

def printC(answer):
    answer = str(roundTraditional(answer,2))
    print ""\nYour Celsius value is "" + answer + "" C.\n""

main()


...should give you the results you expect.

You can also use the decimal library to accomplish this, but the wrapper I propose is simpler and may be preferred in some cases.



Edit: Thanks Blckknght for pointing out that the 5 fringe case occurs only for certain values here.
    You can use the string formatting operator of python ""%"".
""%.2f"" means 2 digits after the decimal point.

def typeHere():
    try:
        Fahrenheit = int(raw_input(""Hi! Enter Fahrenheit value, and get it in Celsius!\n""))
    except ValueError:
        print ""\nYour insertion was not a digit!""
        print ""We've put your Fahrenheit value to 50!""
        Fahrenheit = 50
    return Fahrenheit

def formeln(Fahrenheit):
    Celsius = (Fahrenheit - 32.0) * 5.0/9.0
    return Celsius

def printC(answer):
    print ""\nYour Celsius value is %.2f C.\n"" % answer

def main():
    printC(formeln(typeHere()))

main()


http://docs.python.org/2/library/stdtypes.html#string-formatting
    To avoid surprising value from round() this is my approche:
Round = lambda x, n: eval('""%.'+str(int(n))+'f"" % '+repr(int(x)+round(float('.'+str(float(x)).split('.')[1]),n)))

print(Round(2, 2))       # 2.00
print(Round(2.675, 2))   # 2.68

    If you need avoid floating point problem on rounding numbers for accounting, you can use numpy round.

You need install numpy : 

pip install numpy


and the code : 

import numpy as np

print(round(2.675, 2))
print(float(np.round(2.675, 2)))


prints

2.67
2.68


You should use that if you manage money with legal rounding.
    Here is an example that I used:

def volume(self):
    return round(pi * self.radius ** 2 * self.height, 2)

def surface_area(self):
    return round((2 * pi * self.radius * self.height) + (2 * pi * self.radius ** 2), 2)

    You can use round operator for up to 2 decimal 

num = round(343.5544, 2)
print(num) // output is 343.55

    float(str(round(answer, 2)))
float(str(round(0.0556781255, 2)))

    Just use the formatting with %.2f which gives you rounding down to 2 decimals.

def printC(answer):
    print ""\nYour Celsius value is %.2f C.\n"" % answer

    round(12.3956 - 0.005, 2)  # minus 0.005, then round.


The answer is from: https://stackoverflow.com/a/29651462/8025086
    Not sure why, but '{:0.2f}'.format(0.5357706) gives me '0.54'.
The only solution that works for me (python 3.6) is the following:

def ceil_floor(x):
    import math
    return math.ceil(x) if x < 0 else math.floor(x)

def round_n_digits(x, n):
    import math
    return ceil_floor(x * math.pow(10, n)) / math.pow(10, n)

round_n_digits(-0.5357706, 2) -> -0.53 
round_n_digits(0.5357706, 2) -> 0.53

    As you want your answer in decimal number so you dont need to typecast your answer variable to str in printC() function. 

and then use printf-style String Formatting
    Truncating to 2 digitis:
somefloat = 2.23134133
truncated = int( somefloat * 100 ) / 100  # 2.23

    ","[490, 815, 161, 79, 37, 29, 5, 8, 18, 5, 2, 16, 2, 9, 13, 8, 1, 0, 0, 0]",1417685,62,2013-12-08T18:13:41,2022-04-16 19:20:52Z,python 
Changing one character in a string,"
                
What is the easiest way in Python to replace a character in a string?

For example:

text = ""abcdefg"";
text[1] = ""Z"";
           ^

    Don't modify strings.

Work with them as lists; turn them into strings only when needed.

>>> s = list(""Hello zorld"")
>>> s
['H', 'e', 'l', 'l', 'o', ' ', 'z', 'o', 'r', 'l', 'd']
>>> s[6] = 'W'
>>> s
['H', 'e', 'l', 'l', 'o', ' ', 'W', 'o', 'r', 'l', 'd']
>>> """".join(s)
'Hello World'


Python strings are immutable (i.e. they can't be modified).  There are a lot of reasons for this.  Use lists until you have no choice, only then turn them into strings.
    Fastest method?

There are three ways. For the speed seekers I recommend 'Method 2' 

Method 1

Given by this answer

text = 'abcdefg'
new = list(text)
new[6] = 'W'
''.join(new)


Which is pretty slow compared to 'Method 2'

timeit.timeit(""text = 'abcdefg'; s = list(text); s[6] = 'W'; ''.join(s)"", number=1000000)
1.0411581993103027


Method 2 (FAST METHOD)

Given by this answer

text = 'abcdefg'
text = text[:1] + 'Z' + text[2:]


Which is much faster:

timeit.timeit(""text = 'abcdefg'; text = text[:1] + 'Z' + text[2:]"", number=1000000)
0.34651994705200195


Method 3:

Byte array:

timeit.timeit(""text = 'abcdefg'; s = bytearray(text); s[1] = 'Z'; str(s)"", number=1000000)
1.0387420654296875

    Python strings are immutable, you change them by making a copy.
The easiest way to do what you want is probably:

text = ""Z"" + text[1:]


The text[1:] returns the string in text from position 1 to the end, positions count from 0 so '1' is the second character.

edit:
You can use the same string slicing technique for any part of the string

text = text[:1] + ""Z"" + text[2:]


Or if the letter only appears once you can use the search and replace technique suggested 
below
    new = text[:1] + 'Z' + text[2:]

    I like f-strings:
text = f'{text[:1]}Z{text[2:]}'

In my machine this method is 10% faster than the ""fast method"" of using + to concatenate strings:
>>> timeit.timeit(""text = 'abcdefg'; text = text[:1] + 'Z' + text[2:]"", number=1000000)
1.1691178000000093
>>> timeit.timeit(""text = 'abcdefg'; text = f'{text[:1]}Z{text[2:]}'"", number =1000000)
0.9047831999999971
>>>

    try this :
old_string = ""mba""
string_list = list(old_string)
string_list[2] = ""e""
//Replace 3rd element

new_string = """".join(string_list)

print(new_string)


    This code is not mine. I couldn't recall the site form where, I took it. Interestingly, you can use this to replace one character or more with one or more charectors.
Though this reply is very late, novices like me (anytime) might find it useful.
Change Text function.
mytext = 'Hello Zorld'
mytext = mytext.replace('Z', 'W')
print mytext,

    Strings are immutable in Python, which means you cannot change the existing string.
But if you want to change any character in it, you could create a new string out it as follows,
def replace(s, position, character):
    return s[:position] + character + s[position+1:]

replace('King', 1, 'o') 
// result: Kong
Note: If you give the position value greater than the length of the string, it will append the character at the end.
replace('Dog', 10, 's') 
// result: Dogs
    Starting with python 2.6 and python 3 you can use bytearrays which are mutable (can be changed element-wise unlike strings):

s = ""abcdefg""
b_s = bytearray(s)
b_s[1] = ""Z""
s = str(b_s)
print s
aZcdefg


edit: Changed str to s

edit2: As Two-Bit Alchemist mentioned in the comments, this code does not work with unicode.
    Like other people have said, generally Python strings are supposed to be immutable.

However, if you are using CPython, the implementation at python.org, it is possible to use ctypes to modify the string structure in memory.

Here is an example where I use the technique to clear a string.

Mark data as sensitive in python

I mention this for the sake of completeness, and this should be your last resort as it is hackish.
    Actually, with strings, you can do something like this:

oldStr = 'Hello World!'    
newStr = ''

for i in oldStr:  
    if 'a' < i < 'z':    
        newStr += chr(ord(i)-32)     
    else:      
        newStr += i
print(newStr)

'HELLO WORLD!'


Basically, I'm ""adding""+""strings"" together into a new string :).
    if your world is 100% ascii/utf-8(a lot of use cases fit in that box):

b = bytearray(s, 'utf-8')
# process - e.g., lowercasing: 
#    b[0] = b[i+1] - 32
s = str(b, 'utf-8')


python 3.7.3
    I would like to add another way of changing a character in a string.

>>> text = '~~~~~~~~~~~'
>>> text = text[:1] + (text[1:].replace(text[0], '+', 1))
'~+~~~~~~~~~'


How faster it is when compared to turning the string into list and replacing the ith value then joining again?.

List approach

>>> timeit.timeit(""text = '~~~~~~~~~~~'; s = list(text); s[1] = '+'; ''.join(s)"", number=1000000)
0.8268570480013295


My solution

>>> timeit.timeit(""text = '~~~~~~~~~~~'; text=text[:1] + (text[1:].replace(text[0], '+', 1))"", number=1000000)
0.588400217000526

    A solution combining find and replace methods in a single line if statement could be:
```python
my_var = ""stackoverflaw""
my_new_var = my_var.replace('a', 'o', 1) if my_var.find('s') != -1 else my_var
print(f""my_var = {my_var}"")           # my_var = stackoverflaw
print(f""my_new_var = {my_new_var}"")   # my_new_var = stackoverflow
```

    To replace a character in a string
You can use either of the method:
Method 1
In general,
string = f'{string[:index]}{replacing_character}{string[index+1:]}'

Here
text = f'{text[:1]}Z{text[2:]}'

Method 2
In general,
string = string[:index] + replacing_character + string[index+1:]

Here,
text = text[:1] + 'Z' + text[2:]

    you can use .replace() function:
text.replace('b','Z')
    ","[490, 685, 266, 50, 143, 3, 0, 9, 8, 14, 8, 2, 0, 0, 0, 0, 0]",1016490,123,2009-08-04T15:48:39,2022-04-29 03:08:13Z,python 
Java - Convert integer to string [duplicate],"
                    
            
        
            
                
                    
                        This question already has answers here:
                        
                    
                
            
                    
                        Java int to String - Integer.toString(i) vs new Integer(i).toString()
                            
                                (11 answers)
                            
                    
                    
                        How do I convert from int to String?
                            
                                (20 answers)
                            
                    
                Closed 7 years ago.
        

    

Given a number:

int number = 1234;


Which would be the ""best"" way to convert this to a string:

String stringNumber = ""1234"";





I have tried searching (googling) for an answer but no many seemed ""trustworthy"".

    There are multiple ways:


String.valueOf(number) (my preference)
"""" + number (I don't know how the compiler handles it, perhaps it is as efficient as the above)
Integer.toString(number)

    This will do. Pretty trustworthy. : )

    """"+number;


Just to clarify, this works and acceptable to use unless you are looking for micro optimization.
    One that I use often:

 Integer.parseInt(""1234"");


Point is, there are plenty of ways to do this, all equally valid. As to which is most optimum/efficient, you'd have to ask someone else.
    The way I know how to convert an integer into a string is by using the following code:

Integer.toString(int);


and 

String.valueOf(int);


If you had an integer i, and a string s, then the following would apply:

int i;
String s = Integer.toString(i); or
String s = String.valueOf(i);


If you wanted to convert a string ""s"" into an integer ""i"", then the following would work:

i = Integer.valueOf(s).intValue();

    Always use either String.valueOf(number) or Integer.toString(number).

Using """" + number is an overhead and does the following:

StringBuilder sb = new StringBuilder();
sb.append("""");
sb.append(number);
return sb.toString();

    Integer class has static method toString() - you can use it:

int i = 1234;
String str = Integer.toString(i);



  Returns a String object representing the specified integer. The argument is converted to signed decimal representation and returned as a string, exactly as if the argument and radix 10 were given as arguments to the toString(int, int) method.

    This is the method which i used to convert the integer to string.Correct me if i did wrong.

/**
 * @param a
 * @return
 */
private String convertToString(int a) {

    int c;
    char m;
    StringBuilder ans = new StringBuilder();
    // convert the String to int
    while (a > 0) {
        c = a % 10;
        a = a / 10;
        m = (char) ('0' + c);
        ans.append(m);
    }
    return ans.reverse().toString();
}

    ","[490, 951, 42, -4, 19, 46, 63, 2]",1739524,98,2011-02-21T20:43:03,2018-01-24 09:07:02Z,java 
How to assign string to bytes array,"
                
I want to assign string to bytes array:

var arr [20]byte
str := ""abc""
for k, v := range []byte(str) {
  arr[k] = byte(v)
}


Have another method?
    Safe and simple:
[]byte(""Here is a string...."")

    
                
For converting from a string to a byte slice, string -> []byte:
[]byte(str)

For converting an array to a slice, [20]byte -> []byte:
arr[:]

For copying a string to an array, string -> [20]byte:
copy(arr[:], str)

Same as above, but explicitly converting the string to a slice first:
copy(arr[:], []byte(str))



The built-in copy function only copies to a slice, from a slice.
Arrays are ""the underlying data"", while slices are ""a viewport into underlying data"".
Using [:] makes an array qualify as a slice.
A string does not qualify as a slice that can be copied to, but it qualifies as a slice that can be copied from (strings are immutable).
If the string is too long, copy will only copy the part of the string that fits (and multi-byte runes may then be copied only partly, which will corrupt the last rune of the resulting string).


This code:
var arr [20]byte
copy(arr[:], ""abc"")
fmt.Printf(""array: %v (%T)\n"", arr, arr)

...gives the following output:
array: [97 98 99 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] ([20]uint8)

I also made it available at the Go Playground
    I think it's better..

package main

import ""fmt""

func main() {
    str := ""abc""
    mySlice := []byte(str)
    fmt.Printf(""%v -> '%s'"",mySlice,mySlice )
}


Check here: http://play.golang.org/p/vpnAWHZZk7
    Go, convert a string to a bytes slice

You need a fast way to convert a []string to []byte type. To use in situations such as storing text data into a random access file or other type of data manipulation that requires the input data to be in []byte type.

package main

func main() {

    var s string

    //...

    b := []byte(s)

    //...
}


which is useful when using ioutil.WriteFile, which accepts a bytes slice as its data parameter:

WriteFile func(filename string, data []byte, perm os.FileMode) error


Another example

package main

import (
    ""fmt""
    ""strings""
)

func main() {

    stringSlice := []string{""hello"", ""world""}

    stringByte := strings.Join(stringSlice, "" "")

    // Byte array value
    fmt.Println([]byte(stringByte))

    // Corresponding string value
    fmt.Println(string([]byte(stringByte)))
}


Output:


  [104 101 108 108 111 32 119 111 114 108 100] hello world


Please check the link playground
    For example,

package main

import ""fmt""

func main() {
    s := ""abc""
    var a [20]byte
    copy(a[:], s)
    fmt.Println(""s:"", []byte(s), ""a:"", a)
}


Output:

s: [97 98 99] a: [97 98 99 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]

    Piece of cake:

arr := []byte(""That's all folks!!"")

    Besides the methods mentioned above, you can also do a trick as

s := ""hello""
b := *(*[]byte)(unsafe.Pointer((*reflect.SliceHeader)(unsafe.Pointer(&s))))


Go Play: http://play.golang.org/p/xASsiSpQmC

You should never use this :-)
    Arrays are values... slices are more like pointers. That is [n]type is not compatible with []type as they are fundamentally two different things. You can get a slice that points to an array by using arr[:] which returns a slice that has arr as it's backing storage. 

One way to convert a slice of for example []byte to [20]byte is to actually allocate a [20]byte which you can do by using var [20]byte (as it's a value... no make needed) and then copy data into it:

buf := make([]byte, 10)
var arr [10]byte
copy(arr[:], buf)


Essentially what a lot of other answers get wrong is that []type is NOT an array. 

[n]T and []T are completely different things!

When using reflect []T is not of kind Array but of kind Slice and [n]T is of kind Array. 

You also can't use map[[]byte]T but you can use map[[n]byte]T. 

This can sometimes be cumbersome because a lot of functions operate for example on []byte whereas some functions return [n]byte (most notably the hash functions in crypto/*). 
A sha256 hash for example is [32]byte and not []byte so when beginners try to write it to a file for example:

sum := sha256.Sum256(data)
w.Write(sum)


they will get an error. The correct way of is to use

w.Write(sum[:])


However, what is it that you want? Just accessing the string bytewise? You can easily convert a string to []byte using:

bytes := []byte(str)


but this isn't an array, it's a slice. Also, byte != rune. In case you want to operate on ""characters"" you need to use rune... not byte. 
    Ended up creating array specific methods to do this. Much like the encoding/binary package with specific methods for each int type. For example binary.BigEndian.PutUint16([]byte, uint16).

func byte16PutString(s string) [16]byte {
    var a [16]byte
    if len(s) > 16 {
        copy(a[:], s)
    } else {
        copy(a[16-len(s):], s)
    }
    return a
}

var b [16]byte
b = byte16PutString(""abc"")
fmt.Printf(""%v\n"", b)


Output:

[0 0 0 0 0 0 0 0 0 0 0 0 0 97 98 99]


Notice how I wanted padding on the left, not the right.

http://play.golang.org/p/7tNumnJaiN
    ","[490, 672, 236, 29, 15, 118, 45, 0, 0, 1]",509413,77,2011-11-07T02:29:57,2022-03-27 00:40:39Z,go 
What is the difference between instanceof and Class.isAssignableFrom(...)?,"
                
Which of the following is better?

a instanceof B


or

B.class.isAssignableFrom(a.getClass())


The only difference that I know of is, when 'a' is null, the first returns false, while the second throws an exception. Other than that, do they always give the same result?
    When using instanceof, you need to know the class of B at compile time.  When using isAssignableFrom() it can be dynamic and change during runtime.
    instanceof can only be used with reference types, not primitive types.  isAssignableFrom() can be used with any class objects:

a instanceof int  // syntax error
3 instanceof Foo  // syntax error
int.class.isAssignableFrom(int.class)  // true


See http://java.sun.com/javase/6/docs/api/java/lang/Class.html#isAssignableFrom(java.lang.Class).
    Talking in terms of performance :

TL;DR

Use isInstance or instanceof which have similar performance. isAssignableFrom is slightly slower.

Sorted by performance:


isInstance
instanceof (+ 0.5%)
isAssignableFrom (+ 2.7%)


Based on a benchmark of 2000 iterations on JAVA 8 Windows x64, with 20 warmup iterations.

In theory

Using a soft like bytecode viewer we can translate each operator into bytecode.

In the context of:

package foo;

public class Benchmark
{
  public static final Object a = new A();
  public static final Object b = new B();

  ...

}


JAVA:

b instanceof A;


Bytecode:

getstatic foo/Benchmark.b:java.lang.Object
instanceof foo/A


JAVA:

A.class.isInstance(b);


Bytecode:

ldc Lfoo/A; (org.objectweb.asm.Type)
getstatic foo/Benchmark.b:java.lang.Object
invokevirtual java/lang/Class isInstance((Ljava/lang/Object;)Z);


JAVA:

A.class.isAssignableFrom(b.getClass());


Bytecode:

ldc Lfoo/A; (org.objectweb.asm.Type)
getstatic foo/Benchmark.b:java.lang.Object
invokevirtual java/lang/Object getClass(()Ljava/lang/Class;);
invokevirtual java/lang/Class isAssignableFrom((Ljava/lang/Class;)Z);


Measuring how many bytecode instructions are used by each operator, we could expect instanceof and isInstance to be faster than isAssignableFrom. However, the actual performance is NOT determined by the bytecode but by the machine code (which is platform dependent). Let's do a micro benchmark for each of the operators.

The benchmark

Credit: As advised by @aleksandr-dubinsky, and thanks to @yura for providing the base code, here is a JMH benchmark (see this tuning guide):

class A {}
class B extends A {}

public class Benchmark {

    public static final Object a = new A();
    public static final Object b = new B();

    @Benchmark
    @BenchmarkMode(Mode.Throughput)
    @OutputTimeUnit(TimeUnit.MICROSECONDS)
    public boolean testInstanceOf()
    {
        return b instanceof A;
    }

    @Benchmark
    @BenchmarkMode(Mode.Throughput)
    @OutputTimeUnit(TimeUnit.MICROSECONDS)
    public boolean testIsInstance()
    {
        return A.class.isInstance(b);
    }

    @Benchmark
    @BenchmarkMode(Mode.Throughput)
    @OutputTimeUnit(TimeUnit.MICROSECONDS)
    public boolean testIsAssignableFrom()
    {
        return A.class.isAssignableFrom(b.getClass());
    }

    public static void main(String[] args) throws RunnerException {
        Options opt = new OptionsBuilder()
                .include(TestPerf2.class.getSimpleName())
                .warmupIterations(20)
                .measurementIterations(2000)
                .forks(1)
                .build();

        new Runner(opt).run();
    }
}


Gave the following results (score is a number of operations in a time unit, so the higher the score the better):

Benchmark                       Mode   Cnt    Score   Error   Units
Benchmark.testIsInstance        thrpt  2000  373,061 ± 0,115  ops/us
Benchmark.testInstanceOf        thrpt  2000  371,047 ± 0,131  ops/us
Benchmark.testIsAssignableFrom  thrpt  2000  363,648 ± 0,289  ops/us


Warning


the benchmark is JVM and platform dependent. Since there are no significant differences between each operation, it might be possible to get a different result (and maybe different order!) on a different JAVA version and/or platforms like Solaris, Mac or Linux.
the benchmark compares the performance of ""is B an instance of A"" when ""B extends A"" directly. If the class hierarchy is deeper and more complex (like B extends X which extends Y which extends Z which extends A), results might be different.
it is usually advised to write the code first picking one of the operators (the most convenient) and then profile your code to check if there are a performance bottleneck. Maybe this operator is negligible in the context of your code, or maybe...
in relation to the previous point, instanceof in the context of your code might get optimized more easily than an isInstance for example... 


To give you an example, take the following loop:

class A{}
class B extends A{}

A b = new B();

boolean execute(){
  return A.class.isAssignableFrom(b.getClass());
  // return A.class.isInstance(b);
  // return b instanceof A;
}

// Warmup the code
for (int i = 0; i < 100; ++i)
  execute();

// Time it
int count = 100000;
final long start = System.nanoTime();
for(int i=0; i<count; i++){
   execute();
}
final long elapsed = System.nanoTime() - start;


Thanks to the JIT, the code is optimized at some point and we get:


instanceof: 6ms 
isInstance: 12ms
isAssignableFrom : 15ms


Note

Originally this post was doing its own benchmark using a for loop in raw JAVA, which gave unreliable results as some optimization like Just In Time can eliminate the loop. So it was mostly measuring how long did the JIT compiler take to optimize the loop: see Performance test independent of the number of iterations for more details

Related questions


Does instanceof operator generate a lot of overhead ? Why?
How instanceof is implemented inside JAVA?
The performance impact of using instanceof in Java

    Apart from basic differences mentioned above, there is a core subtle difference between instanceof operator and isAssignableFrom method in Class.

Read instanceof as “is this (the left part) the instance of this or any subclass of this (the right part)” and read x.getClass().isAssignableFrom(Y.class) as “Can I write X x = new Y()”. In other words, instanceof operator checks if the left object is same or subclass of right class, while isAssignableFrom checks if we can assign object of the parameter class (from) to the reference of the class on which the method is called.
Note that both of these consider the actual instance not the reference type.

Consider an example of 3 classes A, B and C where C extends B and B extends A.

B b = new C();

System.out.println(b instanceof A); //is b (which is actually class C object) instance of A, yes. This will return true.  
System.out.println(b instanceof B); // is b (which is actually class C object) instance of B, yes. This will return true.  
System.out.println(b instanceof C); // is b (which is actually class C object) instance of C, yes. This will return true. If the first statement would be B b = new B(), this would have been false.
System.out.println(b.getClass().isAssignableFrom(A.class));//Can I write C c = new A(), no. So this is false.
System.out.println(b.getClass().isAssignableFrom(B.class)); //Can I write C c = new B(), no. So this is false.
System.out.println(b.getClass().isAssignableFrom(C.class)); //Can I write C c = new C(), Yes. So this is true.

    instanceof cannot be used with primitive types or generic types either.  As in the following code:

//Define Class< T > type ... 

Object e = new Object();

if(e instanceof T) {
  // Do something.
}


The error is: Cannot perform instanceof check against type parameter T.  Use it's erasure Object instead since further generic type information will be erased at runtime.

Does not compile due to type erasure removing the runtime reference.  However, the code below will compile:

if( type.isAssignableFrom(e.getClass())){
  // Do something.
}

    There is yet another difference. If the type (Class) to test against is dynamic, e.g. passed as a method parameter, then instanceof won't cut it for you.

boolean test(Class clazz) {
   return (this instanceof clazz); // clazz cannot be resolved to a type.
}


but you can do:

boolean test(Class clazz) {
   return (clazz.isAssignableFrom(this.getClass())); // okidoki
}


Oops, I see this answer is already covered. Maybe this example is helpful to someone.
    A more direct equivalent to a instanceof B is

B.class.isInstance(a)


This works (returns false) when a is null too.
    There is also another difference:

null instanceof X is false no matter what X is

null.getClass().isAssignableFrom(X) will throw a NullPointerException
    Consider following situation. Suppose you want to check whether type A is a super class of the type of obj, you can go either

...
A.class.isAssignableFrom(obj.getClass())
...

OR

...
obj instanceof A
...

But the isAssignableFrom solution requires that the type of obj be visible here. If this is not the case (e.g., the type of obj might be of a private inner class), this option is out. However, the instanceof solution would always work.
    This thread provided me some insight into how instanceof differed from isAssignableFrom, so I thought I'd share something of my own.

I have found that using isAssignableFrom to be the only (probably not the only, but possibly the easiest) way to ask one's self if a reference of one class can take instances of another, when one has instances of neither class to do the comparison.

Hence, I didn't find using the instanceof operator to compare assignability to be a good idea when all I had were classes, unless I contemplated creating an instance from one of the classes; I thought this would be sloppy.
    isAssignableFrom(A, B) =

if (A == B) return true
else if (B == java.lang.Object) return false
else return isAssignableFrom(A, getSuperClass(B))


The pseudo code above is a definition of, if references of type/class A is assignable from references of type/class B. It is a recursive definition. To some it may be helpful, for others it may be confusing. I add it in case somebody should find it useful. This is just an attempt to capture my understanding, it is not the official definition. It is used in a certain Java VM implementation and works for many example programs, so while I cannot guarentee that it captures all aspects of isAssignableFrom, it is not completely off.
    Talking in terms of performance ""2"" (with JMH):

class A{}
class B extends A{}

public class InstanceOfTest {

public static final Object a = new A();
public static final Object b = new B();

@Benchmark
@BenchmarkMode(Mode.AverageTime)
@OutputTimeUnit(TimeUnit.NANOSECONDS)
public boolean testInstanceOf()
{
    return b instanceof A;
}

@Benchmark
@BenchmarkMode(Mode.AverageTime)
@OutputTimeUnit(TimeUnit.NANOSECONDS)
public boolean testIsInstance()
{
    return A.class.isInstance(b);
}

@Benchmark
@BenchmarkMode(Mode.AverageTime)
@OutputTimeUnit(TimeUnit.NANOSECONDS)
public boolean testIsAssignableFrom()
{
    return A.class.isAssignableFrom(b.getClass());
}

public static void main(String[] args) throws RunnerException {
    Options opt = new OptionsBuilder()
            .include(InstanceOfTest.class.getSimpleName())
            .warmupIterations(5)
            .measurementIterations(5)
            .forks(1)
            .build();

    new Runner(opt).run();
}
}


It gives:

Benchmark                            Mode  Cnt  Score   Error  Units
InstanceOfTest.testInstanceOf        avgt    5  1,972 ? 0,002  ns/op
InstanceOfTest.testIsAssignableFrom  avgt    5  1,991 ? 0,004  ns/op
InstanceOfTest.testIsInstance        avgt    5  1,972 ? 0,003  ns/op


So that we can conclude: instanceof as fast as isInstance() and isAssignableFrom() not far away (+0.9% executon time). So no real difference whatever you choose
    How about some examples to show it in action...

@Test
public void isInstanceOf() {
    Exception anEx1 = new Exception(""ex"");
    Exception anEx2 = new RuntimeException(""ex"");
    RuntimeException anEx3 = new RuntimeException(""ex"");

    //Base case, handles inheritance
    Assert.assertTrue(anEx1 instanceof Exception);
    Assert.assertTrue(anEx2 instanceof Exception);
    Assert.assertTrue(anEx3 instanceof Exception);

    //Other cases
    Assert.assertFalse(anEx1 instanceof RuntimeException);
    Assert.assertTrue(anEx2 instanceof RuntimeException);
    Assert.assertTrue(anEx3 instanceof RuntimeException);
}

@Test
public void isAssignableFrom() {
    Exception anEx1 = new Exception(""ex"");
    Exception anEx2 = new RuntimeException(""ex"");
    RuntimeException anEx3 = new RuntimeException(""ex"");

    //Correct usage = The base class goes first
    Assert.assertTrue(Exception.class.isAssignableFrom(anEx1.getClass()));
    Assert.assertTrue(Exception.class.isAssignableFrom(anEx2.getClass()));
    Assert.assertTrue(Exception.class.isAssignableFrom(anEx3.getClass()));

    //Incorrect usage = Method parameter is used in the wrong order
    Assert.assertTrue(anEx1.getClass().isAssignableFrom(Exception.class));
    Assert.assertFalse(anEx2.getClass().isAssignableFrom(Exception.class));
    Assert.assertFalse(anEx3.getClass().isAssignableFrom(Exception.class));
}

    some tests we did in our team show that A.class.isAssignableFrom(B.getClass()) works faster than B instanceof A. this can be very useful if you need to check this on large number of elements.
    ","[490, 535, 216, 119, 29, 6, 13, 34, 14, 3, 7, 0, 0, 0, -2]",273639,125,2009-01-30T19:44:24,2020-04-13 17:29:48Z,java 
How to restart a single container with docker-compose,"
                
I have a docker-compose.yml file that contains 4 containers: redis, postgres, api and worker.
During the development of the worker container, I often need to restart it in order to apply changes. Is there any good way to restart a single container (e.g. worker) without restarting the others?
    It is very simple: Use the command:

docker-compose restart worker


You can set the time to wait for stop before killing the container (in seconds)

docker-compose restart -t 30 worker


Note that this will restart the container but without rebuilding it. If you want to apply your changes and then restart, take a look at the other answers. 
    The other answers to restarting a single node are on target, docker-compose restart worker. That will bounce that container, but not include any changes, even if you rebuilt it separately. You can manually stop, rm, create, and start, but there are much easier methods.

If you've updated your code, you can do the build and reload in a single step with:

docker-compose up --detach --build


That will first rebuild your images from any changed code, which is fast if there are no changes since the cache is reused. And then it only replaces the changed containers. If your downloaded images are stale, you can precede the above command with:

docker-compose pull


To download any changed images first (the containers won't be restarted until you run a command like the up above). Doing an initial stop is unnecessary.

And to only do this for a single service, follow the up or pull command with the services you want to specify, e.g.:

docker-compose up --detach --build worker




Here's a quick example of the first option, the Dockerfile is structured to keep the frequently changing parts of the code near the end. In fact the requirements are pulled in separately for the pip install since that file rarely changes. And since the nginx and redis containers were up-to-date, they weren't restarted. Total time for the entire process was under 6 seconds:

$ time docker-compose -f docker-compose.nginx-proxy.yml up --detach --build
Building counter
Step 1 : FROM python:2.7-alpine
 ---> fc479af56697
Step 2 : WORKDIR /app
 ---> Using cache
 ---> d04d0d6d98f1
Step 3 : ADD requirements.txt /app/requirements.txt
 ---> Using cache
 ---> 9c4e311f3f0c
Step 4 : RUN pip install -r requirements.txt
 ---> Using cache
 ---> 85b878795479
Step 5 : ADD . /app
 ---> 63e3d4e6b539
Removing intermediate container 9af53c35d8fe
Step 6 : EXPOSE 80
 ---> Running in a5b3d3f80cd4
 ---> 4ce3750610a9
Removing intermediate container a5b3d3f80cd4
Step 7 : CMD gunicorn app:app -b 0.0.0.0:80 --log-file - --access-logfile - --workers 4 --keep-alive 0
 ---> Running in 0d69957bda4c
 ---> d41ff1635cb7
Removing intermediate container 0d69957bda4c
Successfully built d41ff1635cb7
counter_nginx_1 is up-to-date
counter_redis_1 is up-to-date
Recreating counter_counter_1

real    0m5.959s
user    0m0.508s
sys     0m0.076s

    Since some of the other answers include info on rebuilding, and my use case also required a rebuild, I had a better solution (compared to those).
There's still a way to easily target just the one single worker container that both rebuilds + restarts it in a single line, albeit it's not actually a single command.  The best solution for me was simply rebuild and restart:
docker-compose build worker && docker-compose restart worker

This accomplishes both major goals at once for me:

Targets the single worker container
Rebuilds and restarts it in a single line

Hope this helps anyone else getting here.
    To restart a service with changes here are the steps that I performed:
docker-compose stop -t 1 worker
docker-compose build worker
docker-compose up --no-start worker
docker-compose start worker

    Following command

docker-compose restart worker


will just STOP and START the container. i.e without loading any changes from the docker-compose.xml 

STOP is similar to hibernating in PC . Hence stop/start will not look for any changes made in configuration file . To reload from the recipe of container (docker-compose.xml) we need to remove and create the container (Similar analogy to rebooting the PC )

So commands will be as following

docker-compose stop worker       // go to hibernate
docker-compose rm worker        // shutdown the PC 
docker-compose create worker     // create the container from image and put it in hibernate

docker-compose start worker //bring container to life from hibernation

    The answer's here are talking about the reflection of the change on the docker-compose.yml file.

But what if I want to incorporate the changes I have done in my code, and I believe that will be only possible by rebuilding the image and that I do with following commands

1. docker container stop

docker stop container-id


2. docker container removal

docker rm container-id


3. docker image removal

docker rmi image-id


4. compose the container again

docker-compose up container-name

    Restart container
If you want to just restart your container:
docker-compose restart servicename
Think of this command as ""just restart the container by its name"", which is equivalent to docker restart command.
Note caveats:

If you changed ENV variables they won't updated in container. You need to stop it and start again. Or, using single command docker-compose up will detect changes and recreate container.

As many others mentioned, if you changed docker-compose.yml file itself, simple restart won't apply those changes.

If you copy your code inside container at the build stage (in Dockerfile using ADD or COPY commands), every time the code changes you have to rebuild the container (docker-compose build).


Correlation to your code
docker-compose restart should work perfectly fine, if your code gets path mapped into the container by volume directive in docker-compose.yml like so:
services:

  servicename:
    volumes:
      - .:/code

But I'd recommend to use live code reloading, which is probably provided by your framework of choice in DEBUG mode (alternatively, you can search for auto-reload packages in your language of choice). Adding this should eliminate the need to restart container every time after your code changes, instead reloading the process inside.
    Restart Service with docker-compose file

docker-compose -f [COMPOSE_FILE_NAME].yml restart [SERVICE_NAME]


Use Case #1: If the COMPOSE_FILE_NAME is docker-compose.yml and service is worker

docker-compose restart worker


Use Case #2: If the file name is sample.yml and service is worker

docker-compose -f sample.yml restart worker


By default docker-compose looks for the docker-compose.yml if we run the docker-compose command, else we have flag to give specific file name with -f [FILE_NAME].yml 
    Simple 'docker' command knows nothing about 'worker' container.
Use command like this

docker-compose -f docker-compose.yml restart worker
    After making changes, you need to pull the changes into the server and then reacreate the container. So as the documentation shows:
docker-compose pull worker && docker-compose up -d --no-deps worker

pull worker will make only this project to be pulled to the server, and --no-deps will prevent from restart containers the worker container depends on.
    ","[490, 578, 251, 13, 61, 29, 8, 7, 11, 7, 0]",318539,116,2015-07-16T23:55:01,2022-02-25 14:15:05Z,
LINQ Orderby Descending Query,"
                
I'm sure this will be a relatively simple one.

I have a LINQ query that I want to order by the most recently created date.

See:

        var itemList = from t in ctn.Items
                        where !t.Items && t.DeliverySelection
                        orderby t.Delivery.SubmissionDate descending
                        select t;


I have also tried:

       var itemList = (from t in ctn.Items
                        where !t.Items && t.DeliverySelection
                        select t).OrderByDescending();


but this gives an error :


  No overload for method
  'OrderByDescending' takes 0 arguments


From what I've read, I'm fairly sure the first way I've done it should work. I've tried changing descending to ascending just to see if it does anything but it stays the same. 

I'd be grateful if someone could take a look at the query and see if I'm doing anything wrong. Thanks :)
    I think this first failed because you are ordering value which is null. If Delivery is a foreign key associated table then you should include this table first, example below:

var itemList = from t in ctn.Items.Include(x=>x.Delivery)
                    where !t.Items && t.DeliverySelection
                    orderby t.Delivery.SubmissionDate descending
                    select t;

    You need to choose a Property to sort by and pass it as a lambda expression to OrderByDescending

like:

.OrderByDescending(x => x.Delivery.SubmissionDate);




Really, though the first version of your LINQ statement should work.  Is t.Delivery.SubmissionDate actually populated with valid dates?  
    Just to show it in a different format that I prefer to use for some reason:
The first way returns your itemList as an System.Linq.IOrderedQueryable

using(var context = new ItemEntities())
{
    var itemList = context.Items.Where(x => !x.Items && x.DeliverySelection)
                                .OrderByDescending(x => x.Delivery.SubmissionDate);
}


That approach is fine, but if you wanted it straight into a List Object:

var itemList = context.Items.Where(x => !x.Items && x.DeliverySelection)
                                .OrderByDescending(x => x.Delivery.SubmissionDate).ToList();


All you have to do is append a .ToList() call to the end of the Query.

Something to note, off the top of my head I can't recall if the !(not) expression is acceptable in the Where() call. 
    I think the second one should be

var itemList = (from t in ctn.Items
                where !t.Items && t.DeliverySelection
                select t).OrderByDescending(c => c.Delivery.SubmissionDate);

    ","[490, 198, 724, 10, 31]",1008670,51,2011-03-17T20:25:16,2019-03-14 10:32:56Z,c 
Update MongoDB field using value of another field,"
                
In MongoDB, is it possible to update the value of a field using the value from another field?  The equivalent SQL would be something like:

UPDATE Person SET Name = FirstName + ' ' + LastName


And the MongoDB pseudo-code would be:

db.person.update( {}, { $set : { name : firstName + ' ' + lastName } );

    The best way to do this is in version 4.2+ which allows using of aggregation pipeline in the update document and the updateOne, updateMany or update collection methods. Note that the latter has been deprecated in most if not all languages drivers.
MongoDB 4.2+
Version 4.2 also introduced the $set pipeline stage operator which is an alias for  $addFields. I will use $set here as it maps with what we are trying to achieve.
db.collection.<update method>(
    {},
    [
        {""$set"": {""name"": { ""$concat"": [""$firstName"", "" "", ""$lastName""]}}}
    ]
)

Note that square brackets in the second argument to the method which defines an aggregation pipeline instead of a plain update document. Using a plain document will not work correctly.
MongoDB 3.4+
In 3.4+ you can use $addFields and the $out aggregation pipeline operators.
db.collection.aggregate(
    [
        { ""$addFields"": { 
            ""name"": { ""$concat"": [ ""$firstName"", "" "", ""$lastName"" ] } 
        }},
        { ""$out"": ""collection"" }
    ]
)

Note that this does not update your collection but instead replaces the existing collection or creates a new one. Also for update operations that require ""typecasting"" you will need client-side processing, and depending on the operation, you may need to use the find() method instead of the .aggreate() method.
MongoDB 3.2 and 3.0
The way we do this is by $projecting our documents and using the $concat string aggregation operator to return the concatenated string.
From there, you then iterate the cursor and use the $set update operator to add the new field to your documents using bulk operations for maximum efficiency.
Aggregation query:
var cursor = db.collection.aggregate([ 
    { ""$project"":  { 
        ""name"": { ""$concat"": [ ""$firstName"", "" "", ""$lastName"" ] } 
    }}
])

MongoDB 3.2 or newer
from this, you need to use the bulkWrite method.
var requests = [];
cursor.forEach(document => { 
    requests.push( { 
        'updateOne': {
            'filter': { '_id': document._id },
            'update': { '$set': { 'name': document.name } }
        }
    });
    if (requests.length === 500) {
        //Execute per 500 operations and re-init
        db.collection.bulkWrite(requests);
        requests = [];
    }
});

if(requests.length > 0) {
     db.collection.bulkWrite(requests);
}

MongoDB 2.6 and  3.0
From this version, you need to use the now deprecated Bulk API and its associated methods.
var bulk = db.collection.initializeUnorderedBulkOp();
var count = 0;

cursor.snapshot().forEach(function(document) { 
    bulk.find({ '_id': document._id }).updateOne( {
        '$set': { 'name': document.name }
    });
    count++;
    if(count%500 === 0) {
        // Excecute per 500 operations and re-init
        bulk.execute();
        bulk = db.collection.initializeUnorderedBulkOp();
    }
})

// clean up queues
if(count > 0) {
    bulk.execute();
}

MongoDB 2.4
cursor[""result""].forEach(function(document) {
    db.collection.update(
        { ""_id"": document._id }, 
        { ""$set"": { ""name"": document.name } }
    );
})

    Starting Mongo 4.2, db.collection.update() can accept an aggregation pipeline, finally allowing the update/creation of a field based on another field:

// { firstName: ""Hello"", lastName: ""World"" }
db.collection.update(
  {},
  [{ $set: { name: { $concat: [ ""$firstName"", "" "", ""$lastName"" ] } } }],
  { multi: true }
)
// { ""firstName"" : ""Hello"", ""lastName"" : ""World"", ""name"" : ""Hello World"" }



The first part {} is the match query, filtering which documents to update (in our case all documents).
The second part [{ $set: { name: { ... } }] is the update aggregation pipeline (note the squared brackets signifying the use of an aggregation pipeline). $set is a new aggregation operator and an alias of $addFields.
Don't forget { multi: true }, otherwise only the first matching document will be updated.

    update() method takes aggregation pipeline as parameter like
db.collection_name.update(
  {
    // Query
  },
  [
    // Aggregation pipeline
    { ""$set"": { ""id"": ""$_id"" } }
  ],
  {
    // Options
    ""multi"": true // false when a single doc has to be updated
  }
)

The field can be set or unset with existing values using the aggregation pipeline.
Note: use $ with field name to specify the field which has to be read.
    For a database with high activity, you may run into issues where your updates affect actively changing records and for this reason I recommend using snapshot() 

db.person.find().snapshot().forEach( function (hombre) {
    hombre.name = hombre.firstName + ' ' + hombre.lastName; 
    db.person.save(hombre); 
});


http://docs.mongodb.org/manual/reference/method/cursor.snapshot/
    You should iterate through. For your specific case:

db.person.find().snapshot().forEach(
    function (elem) {
        db.person.update(
            {
                _id: elem._id
            },
            {
                $set: {
                    name: elem.firstname + ' ' + elem.lastname
                }
            }
        );
    }
);

    Regarding this answer, the snapshot function is deprecated in version 3.6, according to this update. So, on version 3.6 and above, it is possible to perform the operation this way:

db.person.find().forEach(
    function (elem) {
        db.person.update(
            {
                _id: elem._id
            },
            {
                $set: {
                    name: elem.firstname + ' ' + elem.lastname
                }
            }
        );
    }
);

    Apparently there is a way to do this efficiently since MongoDB 3.4, see styvane's answer.



Obsolete answer below

You cannot refer to the document itself in an update (yet). You'll need to iterate through the documents and update each document using a function. See this answer for an example, or this one for server-side eval().
    With MongoDB version 4.2+, updates are more flexible as it allows the use of aggregation pipeline in its update, updateOne and updateMany. You can now transform your documents using the aggregation operators then update without the need to explicity state the $set command (instead we use $replaceRoot: {newRoot: ""$$ROOT""})

Here we use the aggregate query to extract the timestamp from MongoDB's ObjectID ""_id"" field and update the documents (I am not an expert in SQL but I think SQL does not provide any auto generated ObjectID that has timestamp to it, you would have to automatically create that date) 

var collection = ""person""

agg_query = [
    {
        ""$addFields"" : {
            ""_last_updated"" : {
                ""$toDate"" : ""$_id""
            }
        }
    },
    {
        $replaceRoot: {
            newRoot: ""$$ROOT""
        } 
    }
]

db.getCollection(collection).updateMany({}, agg_query, {upsert: true})

    Here's what we came up with for copying one field to another for ~150_000 records. It took about 6 minutes, but is still significantly less resource intensive than it would have been to instantiate and iterate over the same number of ruby objects.

js_query = %({
  $or : [
    {
      'settings.mobile_notifications' : { $exists : false },
      'settings.mobile_admin_notifications' : { $exists : false }
    }
  ]
})

js_for_each = %(function(user) {
  if (!user.settings.hasOwnProperty('mobile_notifications')) {
    user.settings.mobile_notifications = user.settings.email_notifications;
  }
  if (!user.settings.hasOwnProperty('mobile_admin_notifications')) {
    user.settings.mobile_admin_notifications = user.settings.email_admin_notifications;
  }
  db.users.save(user);
})

js = ""db.users.find(#{js_query}).forEach(#{js_for_each});""
Mongoid::Sessions.default.command('$eval' => js)

    I tried the above solution but I found it unsuitable for large amounts of data. I then discovered the stream feature:

MongoClient.connect(""..."", function(err, db){
    var c = db.collection('yourCollection');
    var s = c.find({/* your query */}).stream();
    s.on('data', function(doc){
        c.update({_id: doc._id}, {$set: {name : doc.firstName + ' ' + doc.lastName}}, function(err, result) { /* result == true? */} }
    });
    s.on('end', function(){
        // stream can end before all your updates do if you have a lot
    })
})

    (I would have posted this as a comment, but couldn't)
For anyone who lands here trying to update one field using another in the document with the c# driver...
I could not figure out how to use any of the UpdateXXX methods and their associated overloads since they take an UpdateDefinition as an argument.
// we want to set Prop1 to Prop2
class Foo { public string Prop1 { get; set; } public string Prop2 { get; set;} } 

void Test()
{ 
     var update = new UpdateDefinitionBuilder<Foo>();
     update.Set(x => x.Prop1, <new value; no way to get a hold of the object that I can find>)
}

As a workaround, I found that you can use the RunCommand method on an IMongoDatabase (https://docs.mongodb.com/manual/reference/command/update/#dbcmd.update).
var command = new BsonDocument
        {
            { ""update"", ""CollectionToUpdate"" },
            { ""updates"", new BsonArray 
                 { 
                       new BsonDocument
                       {
                            // Any filter; here the check is if Prop1 does not exist
                            { ""q"", new BsonDocument{ [""Prop1""] = new BsonDocument(""$exists"", false) }}, 
                            // set it to the value of Prop2
                            { ""u"", new BsonArray { new BsonDocument { [""$set""] = new BsonDocument(""Prop1"", ""$Prop2"") }}},
                            { ""multi"", true }
                       }
                 }
            }
        };

 database.RunCommand<BsonDocument>(command);

    ","[490, 449, 27, 6, 48, 256, 14, 106, 1, 2, 8, 0]",296722,113,2010-10-20T05:22:01,2021-11-15 19:42:01Z,
jQuery AJAX cross domain,"
                
Here are two pages, test.php and testserver.php.

test.php

<script src=""scripts/jq.js"" type=""text/javascript""></script>
<script>
    $(function() {
        $.ajax({url:""testserver.php"",
            success:function() {
                alert(""Success"");
            },
            error:function() {
                alert(""Error"");
            },
            dataType:""json"",
            type:""get""
        }
    )})
</script>


testserver.php

<?php
$arr = array(""element1"",
             ""element2"",
             array(""element31"",""element32""));
$arr['name'] = ""response"";
echo json_encode($arr);
?>


Now my problem: when both of these files are on the same server (either localhost or web server), it works and alert(""Success"") is called; If it is on different servers, meaning testserver.php on web server and test.php on localhost, its not working, and alert(""Error"") is executing. Even if the URL inside ajax is changed to http://domain.com/path/to/file/testserver.php
    Use JSONP.

jQuery:

$.ajax({
     url:""testserver.php"",
     dataType: 'jsonp', // Notice! JSONP <-- P (lowercase)
     success:function(json){
         // do stuff with json (in this case an array)
         alert(""Success"");
     },
     error:function(){
         alert(""Error"");
     }      
});


PHP:

<?php
$arr = array(""element1"",""element2"",array(""element31"",""element32""));
$arr['name'] = ""response"";
echo $_GET['callback'].""("".json_encode($arr)."");"";
?>


The echo might be wrong, it's been a while since I've used php. In any case you need to output callbackName('jsonString') notice the quotes. jQuery will pass it's own callback name, so you need to get that from the GET params.

And as Stefan Kendall posted, $.getJSON() is a shorthand method, but then you need to append 'callback=?' to the url as GET parameter (yes, value is ?, jQuery replaces this with its own generated callback method).
    it works, all you need:

PHP:

header('Access-Control-Allow-Origin: http://www.example.com');
header(""Access-Control-Allow-Credentials: true"");
header('Access-Control-Allow-Methods: GET, PUT, POST, DELETE, OPTIONS');


JS (jQuery ajax): 

var getWBody = $.ajax({ cache: false,
        url: URL,
        dataType : 'json',
        type: 'GET',
        xhrFields: { withCredentials: true }
});

    I had to load webpage from local disk ""file:///C:/test/htmlpage.html"", call ""http://localhost/getxml.php"" url, and do this in IE8+ and Firefox12+ browsers, use jQuery v1.7.2 lib to minimize boilerplate code. After reading dozens of articles finally figured it out. Here is my summary.


server script (.php, .jsp, ...) must return http response header Access-Control-Allow-Origin: *
before using jQuery ajax set this flag in javascript:  jQuery.support.cors = true;
you may set flag once or everytime before using jQuery ajax function
now I can read .xml document in IE and Firefox. Other browsers I did not test.
response document can be plain/text, xml, json or anything else


Here is an example jQuery ajax call with some debug sysouts.

jQuery.support.cors = true;
$.ajax({
    url: ""http://localhost/getxml.php"",
    data: { ""id"":""doc1"", ""rows"":""100"" },
    type: ""GET"",
    timeout: 30000,
    dataType: ""text"", // ""xml"", ""json""
    success: function(data) {
        // show text reply as-is (debug)
        alert(data);

        // show xml field values (debug)
        //alert( $(data).find(""title"").text() );

        // loop JSON array (debug)
        //var str="""";
        //$.each(data.items, function(i,item) {
        //  str += item.title + ""\n"";
        //});
        //alert(str);
    },
    error: function(jqXHR, textStatus, ex) {
        alert(textStatus + "","" + ex + "","" + jqXHR.responseText);
    }
});

    JSONP is a good option, but there is an easier way. You can simply set the Access-Control-Allow-Origin header on your server. Setting it to * will accept cross-domain AJAX requests from any domain. (https://developer.mozilla.org/en/http_access_control)

The method to do this will vary from language to language, of course. Here it is in Rails:

class HelloController < ApplicationController
  def say_hello
    headers['Access-Control-Allow-Origin'] = ""*""
    render text: ""hello!""
  end
end


In this example, the say_hello action will accept AJAX requests from any domain and return a response of ""hello!"".

Here is an example of the headers it might return:

HTTP/1.1 200 OK 
Access-Control-Allow-Origin: *
Cache-Control: no-cache, no-store, max-age=0, must-revalidate
Content-Type: text/html; charset=utf-8
X-Ua-Compatible: IE=Edge
Etag: ""c4ca4238a0b923820dcc509a6f75849b""
X-Runtime: 0.913606
Content-Length: 6
Server: WEBrick/1.3.1 (Ruby/1.9.2/2011-07-09)
Date: Thu, 01 Mar 2012 20:44:28 GMT
Connection: Keep-Alive


Easy as it is, it does have some browser limitations. See http://caniuse.com/#feat=cors.
    You can control this via HTTP header by adding Access-Control-Allow-Origin. Setting it to * will accept cross-domain AJAX requests from any domain.

Using PHP it's really simple, just add the following line into the script that you want to have access outside from your domain:

header(""Access-Control-Allow-Origin: *"");


Don't forget to enable mod_headers module in httpd.conf.
    I know 3 way to resolve your problem:


First if you have access to both domains you can allow access for all other domain using : 

header(""Access-Control-Allow-Origin: *"");

or just a domain by adding code bellow to .htaccess file:

<FilesMatch ""\.(ttf|otf|eot|woff)$"">
<IfModule mod_headers.c>
    SetEnvIf Origin ""http(s)?://(www\.)?(google.com|staging.google.com|development.google.com|otherdomain.net|dev02.otherdomain.net)$"" AccessControlAllowOrigin=$0
    Header add Access-Control-Allow-Origin %{AccessControlAllowOrigin}e env=AccessControlAllowOrigin
</IfModule>
</FilesMatch>
you can have ajax request to a php file in your server and handle request to another domain using this php file.
you can use jsonp , because it doesn't need permission. for this you can read our friend @BGerrissen answer.

    You need to have a look at Same Origin Policy:


  In computing, the same origin policy
  is an important security concept for a
  number of browser-side programming
  languages, such as JavaScript. The
  policy permits scripts running on
  pages originating from the same site
  to access each other's methods and
  properties with no specific
  restrictions, but prevents access to
  most methods and properties across
  pages on different sites.


For you to be able to get data, it has to be:

Same protocol and host

You need to implement JSONP to workaround it.
    It is true that the same-origin policy prevents JavaScript from making requests across domains, but the CORS specification allows just the sort of API access you are looking for, and is supported by the current batch of major browsers.

See how to enable cross-origin resource sharing for client and server:

http://enable-cors.org/

""Cross-Origin Resource Sharing (CORS) is a specification that enables truly open access across domain-boundaries. If you serve public content, please consider using CORS to open it up for universal JavaScript/browser access.""
    This is possible, but you need to use JSONP, not JSON. Stefan's link pointed you in the right direction. The jQuery AJAX page has more information on JSONP.

Remy Sharp has a detailed example using PHP.
    I use Apache server, so I've used mod_proxy module. Enable modules:

LoadModule proxy_module modules/mod_proxy.so
LoadModule proxy_http_module modules/mod_proxy_http.so


Then add:

ProxyPass /your-proxy-url/ http://service-url:serviceport/


Finally, pass proxy-url to your script.
    Browser security prevents making an ajax call from a page hosted on one domain to a page hosted on a different domain; this is called the ""same-origin policy"".
    There are few examples for using JSONP which include error handling.

However, please note that the error-event is not triggered when using JSONP! See: http://api.jquery.com/jQuery.ajax/ or jQuery ajax request using jsonp error
    From the Jquery docs (link):


Due to browser security restrictions, most ""Ajax"" requests are subject to the same origin policy; the request can not successfully retrieve data from a different domain, subdomain, or protocol.
Script and JSONP requests are not subject to the same origin policy restrictions.


So I would take it that you need to use jsonp for the request. But haven't tried this myself.
    For Microsoft Azure, it's slightly different.

Azure has a special CORS setting that needs to be set.  It's essentially the same thing behind the scenes, but simply setting the header joshuarh mentions will not work. The Azure documentation for enabling cross domain can be found here:

https://docs.microsoft.com/en-us/azure/app-service-api/app-service-api-cors-consume-javascript

I fiddled around with this for a few hours before realizing my hosting platform had this special setting.
    ","[490, 419, 1, 18, 206, 32, 3, 20, 10, 9, 9, 8, 5, 4, 0]",786090,171,2010-08-17T19:31:01,2018-05-04 08:53:19Z,javascript 
C++11 rvalues and move semantics confusion (return statement),"
                
I'm trying to understand rvalue references and move semantics of C++11.
What is the difference between these examples, and which of them is going to do no vector copy?
First example
std::vector<int> return_vector(void)
{
    std::vector<int> tmp {1,2,3,4,5};
    return tmp;
}

std::vector<int> &&rval_ref = return_vector();

Second example
std::vector<int>&& return_vector(void)
{
    std::vector<int> tmp {1,2,3,4,5};
    return std::move(tmp);
}

std::vector<int> &&rval_ref = return_vector();

Third example
std::vector<int> return_vector(void)
{
    std::vector<int> tmp {1,2,3,4,5};
    return std::move(tmp);
}

std::vector<int> &&rval_ref = return_vector();

    First example
std::vector<int> return_vector(void)
{
    std::vector<int> tmp {1,2,3,4,5};
    return tmp;
}

std::vector<int> &&rval_ref = return_vector();

The first example returns a temporary which is caught by rval_ref. That temporary will have its life extended beyond the rval_ref definition and you can use it as if you had caught it by value.  This is very similar to the following:
const std::vector<int>& rval_ref = return_vector();

except that in my rewrite you obviously can't use rval_ref in a non-const manner.
Second example
std::vector<int>&& return_vector(void)
{
    std::vector<int> tmp {1,2,3,4,5};
    return std::move(tmp);
}

std::vector<int> &&rval_ref = return_vector();

In the second example you have created a run time error.  rval_ref now holds a reference to the destructed tmp inside the function.  With any luck, this code would immediately crash.
Third example
std::vector<int> return_vector(void)
{
    std::vector<int> tmp {1,2,3,4,5};
    return std::move(tmp);
}

std::vector<int> &&rval_ref = return_vector();

Your third example is roughly equivalent to your first.  The std::move on tmp is unnecessary and can actually be a performance pessimization as it will inhibit return value optimization.
The best way to code what you're doing is:
Best practice
std::vector<int> return_vector(void)
{
    std::vector<int> tmp {1,2,3,4,5};
    return tmp;
}

std::vector<int> rval_ref = return_vector();

I.e. just as you would in C++03.  tmp is implicitly treated as an rvalue in the return statement.  It will either be returned via return-value-optimization (no copy, no move), or if the compiler decides it can not perform RVO, then it will use vector's move constructor to do the return.  Only if RVO is not performed, and if the returned type did not have a move constructor would the copy constructor be used for the return.
    None of them will copy, but the second will refer to a destroyed vector. Named rvalue references almost never exist in regular code. You write it just how you would have written a copy in C++03.

std::vector<int> return_vector()
{
    std::vector<int> tmp {1,2,3,4,5};
    return tmp;
}

std::vector<int> rval_ref = return_vector();


Except now, the vector is moved. The user of a class doesn't deal with it's rvalue references in the vast majority of cases.
    None of those will do any extra copying.  Even if RVO isn't used, the new standard says that move construction is preferred to copy when doing returns I believe.

I do believe that your second example causes undefined behavior though because you're returning a reference to a local variable.
    Not an answer per se, but a guideline. Most of the time there is not much sense in declaring local T&& variable (as you did with std::vector<int>&& rval_ref). You will still have to std::move() them to use in foo(T&&) type methods. There is also the problem that was already mentioned that when you try to return such rval_ref from function you will get the standard reference-to-destroyed-temporary-fiasco.

Most of the time I would go with following pattern:

// Declarations
A a(B&&, C&&);
B b();
C c();

auto ret = a(b(), c());


You don't hold any refs to returned temporary objects, thus you avoid (inexperienced) programmer's error who wish to use a moved object.

auto bRet = b();
auto cRet = c();
auto aRet = a(std::move(b), std::move(c));

// Either these just fail (assert/exception), or you won't get 
// your expected results due to their clean state.
bRet.foo();
cRet.bar();


Obviously there are (although rather rare) cases where a function truly returns a T&& which is a reference to a non-temporary object that you can move into your object.

Regarding RVO: these mechanisms generally work and compiler can nicely avoid copying, but in cases where the return path is not obvious (exceptions, if conditionals determining the named object you will return, and probably couple others) rrefs are your saviors (even if potentially more expensive).
    As already mentioned in comments to the first answer, the return std::move(...); construct can make a difference in cases other than returning of local variables. Here's a runnable example that documents what happens when you return a member object with and without std::move():

#include <iostream>
#include <utility>

struct A {
  A() = default;
  A(const A&) { std::cout << ""A copied\n""; }
  A(A&&) { std::cout << ""A moved\n""; }
};

class B {
  A a;
 public:
  operator A() const & { std::cout << ""B C-value: ""; return a; }
  operator A() & { std::cout << ""B L-value: ""; return a; }
  operator A() && { std::cout << ""B R-value: ""; return a; }
};

class C {
  A a;
 public:
  operator A() const & { std::cout << ""C C-value: ""; return std::move(a); }
  operator A() & { std::cout << ""C L-value: ""; return std::move(a); }
  operator A() && { std::cout << ""C R-value: ""; return std::move(a); }
};

int main() {
  // Non-constant L-values
  B b;
  C c;
  A{b};    // B L-value: A copied
  A{c};    // C L-value: A moved

  // R-values
  A{B{}};  // B R-value: A copied
  A{C{}};  // C R-value: A moved

  // Constant L-values
  const B bc;
  const C cc;
  A{bc};   // B C-value: A copied
  A{cc};   // C C-value: A copied

  return 0;
}


Presumably, return std::move(some_member); only makes sense if you actually want to move the particular class member, e.g. in a case where class C represents short-lived adapter objects with the sole purpose of creating instances of struct A.

Notice how struct A always gets copied out of class B, even when the class B object is an R-value. This is because the compiler has no way to tell that class B's instance of struct A won't be used any more. In class C, the compiler does have this information from std::move(), which is why struct A gets moved, unless the instance of class C is constant.
    The simple answer is you should write code for rvalue references like you would regular references code, and you should treat them the same mentally 99% of the time.  This includes all the old rules about returning references (i.e. never return a reference to a local variable).

Unless you are writing a template container class that needs to take advantage of std::forward and be able to write a generic function that takes either lvalue or rvalue references, this is more or less true.

One of the big advantages to the move constructor and move assignment is that if you define them, the compiler can use them in cases were the RVO (return value optimization) and NRVO (named return value optimization) fail to be invoked.  This is pretty huge for returning expensive objects like containers & strings by value efficiently from methods.

Now where things get interesting with rvalue references, is that you can also use them as arguments to normal functions.  This allows you to write containers that have overloads for both const reference (const foo& other) and rvalue reference (foo&& other).   Even if the argument is too unwieldy to pass with a mere constructor call it can still be done:

std::vector vec;
for(int x=0; x<10; ++x)
{
    // automatically uses rvalue reference constructor if available
    // because MyCheapType is an unamed temporary variable
    vec.push_back(MyCheapType(0.f));
}


std::vector vec;
for(int x=0; x<10; ++x)
{
    MyExpensiveType temp(1.0, 3.0);
    temp.initSomeOtherFields(malloc(5000));

    // old way, passed via const reference, expensive copy
    vec.push_back(temp);

    // new way, passed via rvalue reference, cheap move
    // just don't use temp again,  not difficult in a loop like this though . . .
    vec.push_back(std::move(temp));
}


The STL containers have been updated to have move overloads for nearly anything (hash key and values, vector insertion, etc), and is where you will see them the most.

You can also use them to normal functions, and if you only provide an rvalue reference argument you can force the caller to create the object and let the function do the move.  This is more of an example than a really good use, but in my rendering library, I have assigned a string to all the loaded resources, so that it is easier to see what each object represents in the debugger.  The interface is something like this:

TextureHandle CreateTexture(int width, int height, ETextureFormat fmt, string&& friendlyName)
{
    std::unique_ptr<TextureObject> tex = D3DCreateTexture(width, height, fmt);
    tex->friendlyName = std::move(friendlyName);
    return tex;
}


It is a form of a 'leaky abstraction' but allows me to take advantage of the fact I had to create the string already most of the time, and avoid making yet another copying of it.  This isn't exactly high-performance code but is a good example of the possibilities as people get the hang of this feature.  This code actually requires that the variable either be a temporary to the call, or std::move invoked:

// move from temporary
TextureHandle htex = CreateTexture(128, 128, A8R8G8B8, string(""Checkerboard""));


or

// explicit move (not going to use the variable 'str' after the create call)
string str(""Checkerboard"");
TextureHandle htex = CreateTexture(128, 128, A8R8G8B8, std::move(str));


or

// explicitly make a copy and pass the temporary of the copy down
// since we need to use str again for some reason
string str(""Checkerboard"");
TextureHandle htex = CreateTexture(128, 128, A8R8G8B8, string(str));


but this won't compile!

string str(""Checkerboard"");
TextureHandle htex = CreateTexture(128, 128, A8R8G8B8, str);

    ","[490, 627, 45, 3, 4, 1, 16]",127548,331,2011-02-13T20:28:46,2019-03-06 09:52:41Z,c 
"Best way to ""negate"" an instanceof","
                
I was thinking if there exists a better/nicer way to negate an instanceof in Java.
Actually, I'm doing something like:
if(!(myObject instanceof SomeClass)) { /* do Something */ }

But I think that a ""beautiful"" syntax to do this should exist.
Does anyone know if it exists, and how the syntax look like?

EDIT:
By beautiful, I might say something like this:
if(myObject !instanceof SomeClass) { /* do Something */ } // compilation fails

    No, there is no better way; yours is canonical.
    I don't know what you imagine when you say ""beautiful"", but what about this? I personally think it's worse than the classic form you posted, but somebody might like it...

if (str instanceof String == false) { /* ... */ }

    Usually you don't want just an if but an else clause as well.

if(!(str instanceof String)) { /* do Something */ } 
else { /* do something else */ }


can be written as

if(str instanceof String) { /* do Something else */ } 
else { /* do something */ }


Or you can write the code so you don't need to know if its a String or not. e.g.

if(!(str instanceof String)) { str = str.toString(); } 


can be written as

str = str.toString();

    If you find it more understandable, you can do something like this with Java 8 : 

public static final Predicate<Object> isInstanceOfTheClass = 
    objectToTest -> objectToTest instanceof TheClass;

public static final Predicate<Object> isNotInstanceOfTheClass = 
    isInstanceOfTheClass.negate(); // or objectToTest -> !(objectToTest instanceof TheClass)

if (isNotInstanceOfTheClass.test(myObject)) {
    // do something
}

    You can achieve by doing below way.. just add a condition by adding bracket if(!(condition with instanceOf)) with the whole condition by adding ! operator at the start just the way mentioned in below code snippets.

if(!(str instanceof String)) { /* do Something */ } // COMPILATION WORK


instead of 

if(str !instanceof String) { /* do Something */ } // COMPILATION FAIL

    You could use the Class.isInstance method:

if(!String.class.isInstance(str)) { /* do Something */ }


... but it is still negated and pretty ugly.
    If you can use static imports, and your moral code allows them

public class ObjectUtils {
    private final Object obj;
    private ObjectUtils(Object obj) {
        this.obj = obj;
    }

    public static ObjectUtils thisObj(Object obj){
        return new ObjectUtils(obj);
    }

    public boolean isNotA(Class<?> clazz){
        return !clazz.isInstance(obj);
    }
}


And then...

import static notinstanceof.ObjectUtils.*;

public class Main {

    public static void main(String[] args) {
        String a = """";
        if (thisObj(a).isNotA(String.class)) {
            System.out.println(""It is not a String"");
        }
        if (thisObj(a).isNotA(Integer.class)) {
            System.out.println(""It is not an Integer"");
        }
    }    
}


This is just a fluent interface exercise, I'd never use that in real life code!
Go for your classic way, it won't confuse anyone else reading your code!
    I agree that in most cases the if (!(x instanceof Y)) {...} is the best approach, but in some cases creating an isY(x) function so you can if (!isY(x)) {...} is worthwhile.

I'm a typescript novice, and I've bumped into this S/O question a bunch of times over the last few weeks, so for the googlers the typescript way to do this is to create a typeguard like this:

typeGuards.ts

export function isHTMLInputElement (value: any): value is HTMLInputElement {
  return value instanceof HTMLInputElement
}


usage

if (!isHTMLInputElement(x)) throw new RangeError()
// do something with an HTMLInputElement


I guess the only reason why this might be appropriate in typescript and not regular js is that typeguards are a common convention, so if you're writing them for other interfaces, it's reasonable / understandable / natural to write them for classes too.

There's more detail about user defined type guards like this in the docs
    ok just my two cents, use a is string method:

public static boolean isString(Object thing) {
    return thing instanceof String;
}

public void someMethod(Object thing){
    if (!isString(thing)) {
        return null;
    }
    log.debug(""my thing is valid"");
}

    ","[490, 363, 156, 31, 5, 1, 64, 13, 1, 3]",205947,27,2012-01-30T17:35:34,2022-04-16 16:08:59Z,java 
Convert HTML to PDF in .NET [closed],"
                    
            
        
            
                
                    
                        Closed. This question needs details or clarity. It is not currently accepting answers.
                        
                    
                
            
        
            
        
                
                    
                
            
                
                    Want to improve this question? Add details and clarify the problem by editing this post.
                
                    Closed 6 months ago.

            
        
            
                    
                        Improve this question
                    
            

    

I want to generate a PDF by passing HTML contents to a function. I have made use of iTextSharp for this but it does not perform well when it encounters tables and the layout just gets messy.

Is there a better way?
    EDIT: New Suggestion
 HTML Renderer for PDF using PdfSharp 

(After trying wkhtmltopdf and suggesting to avoid it)

HtmlRenderer.PdfSharp is a 100% fully C# managed code, easy to use, thread safe and most importantly FREE (New BSD License) solution.

Usage


Download HtmlRenderer.PdfSharp nuget package. 
Use Example Method.

public static Byte[] PdfSharpConvert(String html)
{
    Byte[] res = null;
    using (MemoryStream ms = new MemoryStream())
    {
        var pdf = TheArtOfDev.HtmlRenderer.PdfSharp.PdfGenerator.GeneratePdf(html, PdfSharp.PageSize.A4);
        pdf.Save(ms);
        res = ms.ToArray();
    }
    return res;
}



A very Good Alternate Is a Free Version of iTextSharp

Until version 4.1.6 iTextSharp was licensed under the LGPL licence and versions until 4.16 (or there may be also forks) are available as packages and can be freely used. Of course someone can use the continued 5+ paid version.

I tried to integrate wkhtmltopdf solutions on my project and had a bunch of hurdles.

I personally would avoid using wkhtmltopdf - based solutions on Hosted Enterprise applications for the following reasons.


First of all wkhtmltopdf is C++ implemented not C#, and you will
experience various problems embedding it within your C# code,
especially while switching  between 32bit and 64bit builds of your
project. Had to try several workarounds including conditional
project building etc. etc. just to avoid ""invalid format exceptions""
on different machines.
If you manage your own virtual machine its ok. But if your project
is running within a constrained environment like (Azure
(Actually is impossible withing azure as mentioned by the
TuesPenchin author) , 
Elastic Beanstalk etc) it's a nightmare to configure that environment only for wkhtmltopdf to work.
wkhtmltopdf is creating files within your server so you have to
manage user permissions and grant ""write"" access to where
wkhtmltopdf is running.
Wkhtmltopdf is running as a standalone application, so its not
managed by your IIS application pool. So you have to either host it
as a service on another machine or you will experience processing spikes and memory consumption within your production
server.
It uses temp files to generate the pdf, and in cases Like AWS
EC2 which has really slow disk i/o it is a big performance
problem.
The most hated ""Unable to load DLL 'wkhtmltox.dll'"" error reported
by many users.


--- PRE Edit Section --- 

For anyone who want to generate pdf from html in simpler applications / environments I leave my old post as suggestion.

TuesPechkin 

https://www.nuget.org/packages/TuesPechkin/

or Especially For MVC Web Applications 
(But I think you may use it in any .net application)

Rotativa

https://www.nuget.org/packages/Rotativa/

They both utilize the 
wkhtmtopdf binary for converting html to pdf. Which uses the webkit engine for rendering the pages so it can also parse css style sheets.

They provide easy to use seamless integration with  C#. 

Rotativa can also generate directly PDFs from any Razor View. 

Additionally for real world web applications they also manage thread safety etc...
    Last Updated: October 2020
This is the list of options for HTML to PDF conversion in .NET that I have put together (some free some paid)

GemBox.Document

https://www.nuget.org/packages/GemBox.Document/
Free (up to 20 paragraphs)
$680 - https://www.gemboxsoftware.com/document/pricelist
https://www.gemboxsoftware.com/document/examples/c-sharp-convert-html-to-pdf/307


PDF Metamorphosis .Net

https://www.nuget.org/packages/sautinsoft.pdfmetamorphosis/
$539 - $1078 - https://www.sautinsoft.com/products/pdf-metamorphosis/order.php
https://www.sautinsoft.com/products/pdf-metamorphosis/convert-html-to-pdf-dotnet-csharp.php


HtmlRenderer.PdfSharp

https://www.nuget.org/packages/HtmlRenderer.PdfSharp/1.5.1-beta1
BSD-UNSPECIFIED License


PuppeteerSharp

https://www.puppeteersharp.com/examples/index.html
MIT License
https://github.com/kblok/puppeteer-sharp


EO.Pdf

https://www.nuget.org/packages/EO.Pdf/
$799 - https://www.essentialobjects.com/Purchase.aspx?f=3


WnvHtmlToPdf_x64

https://www.nuget.org/packages/WnvHtmlToPdf_x64/
$750 - $1600 - http://www.winnovative-software.com/Buy.aspx
demo - http://www.winnovative-software.com/demo/default.aspx


IronPdf

https://www.nuget.org/packages/IronPdf/
$399 - $1599 - https://ironpdf.com/licensing/
https://ironpdf.com/examples/using-html-to-create-a-pdf/


Spire.PDF

https://www.nuget.org/packages/Spire.PDF/
Free (up to 10 pages)
$599 - $1799 - https://www.e-iceblue.com/Buy/Spire.PDF.html
https://www.e-iceblue.com/Tutorials/Spire.PDF/Spire.PDF-Program-Guide/Convert-HTML-to-PDF-Customize-HTML-to-PDF-Conversion-by-Yourself.html


Aspose.Html

https://www.nuget.org/packages/Aspose.Html/
$599 - $1797 - https://purchase.aspose.com/pricing/html/net
https://docs.aspose.com/html/net/html-to-pdf-conversion/


EvoPDF

https://www.nuget.org/packages/EvoPDF/
$450 - $1200 - http://www.evopdf.com/buy.aspx


ExpertPdfHtmlToPdf

https://www.nuget.org/packages/ExpertPdfHtmlToPdf/
$550 - $1200 - https://www.html-to-pdf.net/Pricing.aspx


Zetpdf

https://zetpdf.com
$299 - $599 - https://zetpdf.com/pricing/
Is not a well know or supported library - ZetPDF - Does anyone know the background of this Product?


PDFtron

https://www.pdftron.com/documentation/samples/cs/HTML2PDFTes
$4000/year - https://www.pdftron.com/licensing/


WkHtmlToXSharp

https://github.com/pruiz/WkHtmlToXSharp
Free
Concurrent conversion is implemented as processing queue.


SelectPDF

https://www.nuget.org/packages/Select.HtmlToPdf/
Free (up to 5 pages)
$499 - $799 - https://selectpdf.com/pricing/
https://selectpdf.com/pdf-library-for-net/



If none of the options above help you you can always search the NuGet packages:
https://www.nuget.org/packages?q=html+pdf
    For all those looking for an working solution in .net 5 here you go.
Here are my working solutions.
Using wkhtmltopdf:

Download and install wkhtmltopdf latest version from here.
Use the below code.

public static string HtmlToPdf(string outputFilenamePrefix, string[] urls,
    string[] options = null,
    string pdfHtmlToPdfExePath = @""C:\Program Files\wkhtmltopdf\bin\wkhtmltopdf.exe"")
{
    string urlsSeparatedBySpaces = string.Empty;
    try
    {
        //Determine inputs
        if ((urls == null) || (urls.Length == 0))
            throw new Exception(""No input URLs provided for HtmlToPdf"");
        else
            urlsSeparatedBySpaces = String.Join("" "", urls); //Concatenate URLs

        string outputFilename = outputFilenamePrefix + ""_"" + DateTime.Now.ToString(""yyyy-MM-dd-hh-mm-ss-fff"") + "".PDF""; // assemble destination PDF file name

        var p = new System.Diagnostics.Process()
        {
            StartInfo =
            {
                FileName = pdfHtmlToPdfExePath,
                Arguments = ((options == null) ? """" : string.Join("" "", options)) + "" "" + urlsSeparatedBySpaces + "" "" + outputFilename,
                UseShellExecute = false, // needs to be false in order to redirect output
                RedirectStandardOutput = true,
                RedirectStandardError = true,
                RedirectStandardInput = true, // redirect all 3, as it should be all 3 or none
                WorkingDirectory = Path.Combine(Path.GetDirectoryName(Assembly.GetEntryAssembly().Location))
            }
        };

        p.Start();

        // read the output here...
        var output = p.StandardOutput.ReadToEnd();
        var errorOutput = p.StandardError.ReadToEnd();

        // ...then wait n milliseconds for exit (as after exit, it can't read the output)
        p.WaitForExit(60000);

        // read the exit code, close process
        int returnCode = p.ExitCode;
        p.Close();

        // if 0 or 2, it worked so return path of pdf
        if ((returnCode == 0) || (returnCode == 2))
            return outputFilename;
        else
            throw new Exception(errorOutput);
    }
    catch (Exception exc)
    {
        throw new Exception(""Problem generating PDF from HTML, URLs: "" + urlsSeparatedBySpaces + "", outputFilename: "" + outputFilenamePrefix, exc);
    }
}


And call the above method as HtmlToPdf(""test"", new string[] { ""https://www.google.com"" }, new string[] { ""-s A5"" });
If you need to convert HTML string to PDF, the tweak the above method and replace the Arguments to Process StartInfo as $@""/C echo | set /p=""""{htmlText}"""" | """"{pdfHtmlToPdfExePath}"""" {((options == null) ? """" : string.Join("" "", options))} - """"C:\Users\xxxx\Desktop\{outputFilename}"""""";

Drawbacks of this approach:

The latest build of wkhtmltopdf as of posting this answer does not support latest HTML5 and CSS3. Hence if you try to export any html that as CSS GRID then the output will not be as expected.
You need to handle concurrency issues.

Using chrome headless:

Download and install latest chrome browser from here.
Use the below code.

var p = new System.Diagnostics.Process()
{
    StartInfo =
    {
        FileName = ""C:/Program Files (x86)/Google/Chrome/Application/chrome.exe"",
        Arguments = @""/C --headless --disable-gpu --run-all-compositor-stages-before-draw --print-to-pdf-no-header --print-to-pdf=""""C:/Users/Abdul Rahman/Desktop/test.pdf"""" """"C:/Users/Abdul Rahman/Desktop/grid.html"""""",
    }
};

p.Start();

// ...then wait n milliseconds for exit (as after exit, it can't read the output)
p.WaitForExit(60000);

// read the exit code, close process
int returnCode = p.ExitCode;
p.Close();


This will convert html file to pdf file.
If you need to convert some url to pdf then use the following as Argument to Process StartInfo

@""/C --headless --disable-gpu --run-all-compositor-stages-before-draw --print-to-pdf-no-header --print-to-pdf=""""C:/Users/Abdul Rahman/Desktop/test.pdf"""" """"https://www.google.com"""""",
Drawbacks of this approach:

This works as expected with latest HTML5 and CSS3 features. Output will be same as you view in browser but when running this via IIS you need to run the AppliactionPool of your application under LocalSystem Identity or you need to provide read/write access to IISUSRS.

Using Selenium WebDriver:

Install Nuget Packages Selenium.WebDriver and Selenium.WebDriver.ChromeDriver.
Use the below code.

public async Task<byte[]> ConvertHtmlToPdf(string html)
{
    var directory = Path.Combine(Environment.GetFolderPath(Environment.SpecialFolder.CommonDocuments), ""ApplicationName"");
    Directory.CreateDirectory(directory);
    var filePath = Path.Combine(directory, $""{Guid.NewGuid()}.html"");
    await File.WriteAllTextAsync(filePath, html);

    var driverOptions = new ChromeOptions();
    // In headless mode, PDF writing is enabled by default (tested with driver major version 85)
    driverOptions.AddArgument(""headless"");
    using var driver = new ChromeDriver(driverOptions);
    driver.Navigate().GoToUrl(filePath);

    // Output a PDF of the first page in A4 size at 90% scale
    var printOptions = new Dictionary<string, object>
    {
        { ""paperWidth"", 210 / 25.4 },
        { ""paperHeight"", 297 / 25.4 },
        { ""scale"", 0.9 },
        { ""pageRanges"", ""1"" }
    };
    var printOutput = driver.ExecuteChromeCommandWithResult(""Page.printToPDF"", printOptions) as Dictionary<string, object>;
    var pdf = Convert.FromBase64String(printOutput[""data""] as string);

    File.Delete(filePath);

    return pdf;
}

Advantage of this method:

This just needs an Nuget installation and works as expected with latest HTML5 and CSS3 features. Output will be same as you view in browser.

Drawbacks of this approach:

This approach needs latest chrome browser to be installed in the server where the app runs.

With this approach, please make sure to add <PublishChromeDriver>true</PublishChromeDriver> in .csproj file as shown below:
<PropertyGroup>
  <TargetFramework>net5.0</TargetFramework>
  <LangVersion>latest</LangVersion>
  <Nullable>enable</Nullable>
  <PublishChromeDriver>true</PublishChromeDriver>
</PropertyGroup>

This will publish the chrome driver when publishing the project.
Here is the link to my working project repo - HtmlToPdf
I arrived at the above answer after almost spending 2 days with available options and finally implemented Selenium based solution and its working. Hope this helps you and save your time.
    If you want user to download the pdf of rendered page in the browser then the easiest solution to the problem is

window.print(); 


on client side it will prompt user to save pdf of current page. You can also customize the appearance of pdf by linking style

<link rel=""stylesheet"" type=""text/css"" href=""print.css"" media=""print"">


print.css is applied to the html while printing.

Limitation

You can't store the file on server side.
User prompt to print the page than he had to save page manually.
Page must to be rendered in a tab.
    Quite likely most projects will wrap a C/C++ engine rather than implementing a C# solution from scratch. Try Project Gotenberg.
To test it
docker run --rm -p 3000:3000 thecodingmachine/gotenberg:6

Curl sample
curl --request POST \
    --url http://localhost:3000/convert/url \
    --header 'Content-Type: multipart/form-data' \
    --form remoteURL=https://brave.com \
    --form marginTop=0 \
    --form marginBottom=0 \
    --form marginLeft=0 \
    --form marginRight=0 \
    -o result.pdf

C# sample.cs
using System;
using System.Net.Http;
using System.Threading.Tasks;
using System.IO;
using static System.Console;

namespace Gotenberg
{
    class Program
    {
        public static async Task Main(string[] args)
        {
            try
            {
                var client = new HttpClient();            
                var formContent = new MultipartFormDataContent
                    {
                        {new StringContent(""https://brave.com/""), ""remoteURL""},
                        {new StringContent(""0""), ""marginTop"" }
                    };
                var result = await client.PostAsync(new Uri(""http://localhost:3000/convert/url""), formContent);
                await File.WriteAllBytesAsync(""brave.com.pdf"", await result.Content.ReadAsByteArrayAsync());
            }
            catch (Exception ex)
            {
                WriteLine(ex);
            }
        }
    }
}

To compile
csc sample.cs -langversion:latest -reference:System.Net.Http.dll && mono ./sample.exe

    To convert HTML to PDF in C# use ABCpdf.

ABCpdf can make use of the Gecko or Trident rendering engines, so your HTML table will look the same as it appears in FireFox and Internet Explorer.

There's an on-line demo of ABCpdf at www.abcpdfeditor.com. You could use this to check out how your tables will render first, without needing to download and install software.

For rendering entire web pages you'll need the AddImageUrl or AddImageHtml functions. But if all you want to do is simply add HTML styled text then you could try the AddHtml function, as below:

Doc theDoc = new Doc();
theDoc.FontSize = 72;
theDoc.AddHtml(""<b>Some HTML styled text</b>"");
theDoc.Save(Server.MapPath(""docaddhtml.pdf""));
theDoc.Clear();


ABCpdf is a commercial software title, however the standard edition can often be obtained for free under special offer.
    You can use Google Chrome print-to-pdf feature from its headless mode. I found this to be the simplest yet the most robust method.

var url = ""https://stackoverflow.com/questions/564650/convert-html-to-pdf-in-net"";
var chromePath = @""C:\Program Files (x86)\Google\Chrome\Application\chrome.exe"";
var output = Path.Combine(Environment.CurrentDirectory, ""printout.pdf"");
using (var p = new Process())
    {
        p.StartInfo.FileName = chromePath;
        p.StartInfo.Arguments = $""--headless --disable-gpu --print-to-pdf={output} {url}"";
        p.Start();
        p.WaitForExit();
    }


    Instead of parsing HTML directly to PDF, you can create an Bitmap of your HTML-page and then insert the Bitmap into your PDF, using for example iTextSharp.

Here's a code how to get an Bitmap of an URL. I found it somewhere here on SO, if I find the source I'll link it.

public System.Drawing.Bitmap HTMLToImage(String strHTML)
{
    System.Drawing.Bitmap myBitmap = null;

    System.Threading.Thread myThread = new System.Threading.Thread(delegate()
    {
        // create a hidden web browser, which will navigate to the page
        System.Windows.Forms.WebBrowser myWebBrowser = new System.Windows.Forms.WebBrowser();
        // we don't want scrollbars on our image
        myWebBrowser.ScrollBarsEnabled = false;
        // don't let any errors shine through
        myWebBrowser.ScriptErrorsSuppressed = true;
        // let's load up that page!    
        myWebBrowser.Navigate(""about:blank"");

        // wait until the page is fully loaded
        while (myWebBrowser.ReadyState != System.Windows.Forms.WebBrowserReadyState.Complete)
            System.Windows.Forms.Application.DoEvents();

        myWebBrowser.Document.Body.InnerHtml = strHTML;

        // set the size of our web browser to be the same size as the page
        int intScrollPadding = 20;
        int intDocumentWidth = myWebBrowser.Document.Body.ScrollRectangle.Width + intScrollPadding;
        int intDocumentHeight = myWebBrowser.Document.Body.ScrollRectangle.Height + intScrollPadding;
        myWebBrowser.Width = intDocumentWidth;
        myWebBrowser.Height = intDocumentHeight;
        // a bitmap that we will draw to
        myBitmap = new System.Drawing.Bitmap(intDocumentWidth - intScrollPadding, intDocumentHeight - intScrollPadding);
        // draw the web browser to the bitmap
        myWebBrowser.DrawToBitmap(myBitmap, new System.Drawing.Rectangle(0, 0, intDocumentWidth - intScrollPadding, intDocumentHeight - intScrollPadding));
    });
    myThread.SetApartmentState(System.Threading.ApartmentState.STA);
    myThread.Start();
    myThread.Join();

    return myBitmap;
}

    I highly recommend NReco, seriously. It has the free and paid version, and really worth it. It uses wkhtmtopdf in background, but you just need one assembly. Fantastic.

Example of use:

Install via NuGet.

var htmlContent = String.Format(""<body>Hello world: {0}</body>"", DateTime.Now);
var pdfBytes = (new NReco.PdfGenerator.HtmlToPdfConverter()).GeneratePdf(htmlContent);


Disclaimer: I'm not the developer, just a fan of the project :)
    It seems like so far the best free .NET solution is the TuesPechkin library which is a wrapper around the wkhtmltopdf native library.

I've now used the single-threaded version to convert a few thousand HTML strings to PDF files and it seems to work great. It's supposed to also work in multi-threaded environments (IIS, for example) but I haven't tested that.

Also since I wanted to use the latest version of wkhtmltopdf (0.12.5 at the time of writing), I downloaded the DLL from the official website, copied it to my project root, set copy to output to true, and initialized the library like so:

var dllDir = AppDomain.CurrentDomain.BaseDirectory;
Converter = new StandardConverter(new PdfToolset(new StaticDeployment(dllDir)));


Above code will look exactly for ""wkhtmltox.dll"", so don't rename the file. I used the 64-bit version of the DLL.

Make sure you read the instructions for multi-threaded environments, as you will have to initialize it only once per app lifecycle so you'll need to put it in a singleton or something.
    You can also check Spire, it allow you to create HTML to PDF with this simple piece of code
 string htmlCode = ""<p>This is a p tag</p>"";
 
//use single thread to generate the pdf from above html code
Thread thread = new Thread(() =>
{ pdf.LoadFromHTML(htmlCode, false, setting, htmlLayoutFormat); });
thread.SetApartmentState(ApartmentState.STA);
thread.Start();
thread.Join();
 
// Save the file to PDF and preview it.
pdf.SaveToFile(""output.pdf"");
System.Diagnostics.Process.Start(""output.pdf"");

    This is a free library and works very easily : OpenHtmlToPdf

string timeStampForPdfName = DateTime.Now.ToString(""yyMMddHHmmssff"");

string serverPath = System.Web.Hosting.HostingEnvironment.MapPath(""~/FolderName"");
string pdfSavePath = Path.Combine(@serverPath, ""FileName"" + timeStampForPdfName + "".FileExtension"");


//OpenHtmlToPdf Library used for Performing PDF Conversion
var pdf = Pdf.From(HTML_String).Content();

//FOr writing to file from a ByteArray
 File.WriteAllBytes(pdfSavePath, pdf.ToArray()); // Requires System.Linq

    Another suggestion it to try the solution by https://grabz.it. 

They provide a nice .NET API to catch screenshots and manipulate it in an easy and flexible approach.

To use it in your app you will need to first get key + secret and download the .NET SDK (it's free). 

Now a short example of using it.

To use the API you will first need to create an instance of the GrabzItClient class, passing your application key and application secret from your GrabzIt account to the constructor, as shown in the below example:

//Create the GrabzItClient class
//Replace ""APPLICATION KEY"", ""APPLICATION SECRET"" with the values from your account!
private GrabzItClient grabzIt = GrabzItClient.Create(""Sign in to view your Application Key"", ""Sign in to view your Application Secret"");


Now, to convert the HTML to PDF all you need to do it:

grabzIt.HTMLToPDF(""<html><body><h1>Hello World!</h1></body></html>"");


You can convert to image as well:

grabzIt.HTMLToImage(""<html><body><h1>Hello World!</h1></body></html>"");     


Next you need to save the image. You can use one of the two save methods available, Save if publicly accessible callback handle available and SaveTo if not. Check the documentation for details.
    As a representative of HiQPdf Software I believe the best solution is HiQPdf HTML to PDF converter for .NET. It contains the most advanced HTML5, CSS3, SVG and JavaScript rendering engine on market. There is also a free version of the HTML to PDF library which you can use to produce for free up to 3 PDF pages. The minimal C# code to produce a PDF as a byte[] from a HTML page is:

HtmlToPdf htmlToPdfConverter = new HtmlToPdf();

// set PDF page size, orientation and margins
htmlToPdfConverter.Document.PageSize = PdfPageSize.A4;
htmlToPdfConverter.Document.PageOrientation = PdfPageOrientation.Portrait;
htmlToPdfConverter.Document.Margins = new PdfMargins(0);

// convert HTML to PDF 
byte[] pdfBuffer = htmlToPdfConverter.ConvertUrlToMemory(url);


You can find more detailed examples both for ASP.NET and MVC in HiQPdf HTML to PDF Converter examples repository.
    Below is an example of converting html + css to PDF using iTextSharp (iTextSharp + itextsharp.xmlworker)   

using iTextSharp.text;
using iTextSharp.text.pdf;
using iTextSharp.tool.xml;


byte[] pdf; // result will be here

var cssText = File.ReadAllText(MapPath(""~/css/test.css""));
var html = File.ReadAllText(MapPath(""~/css/test.html""));

using (var memoryStream = new MemoryStream())
{
        var document = new Document(PageSize.A4, 50, 50, 60, 60);
        var writer = PdfWriter.GetInstance(document, memoryStream);
        document.Open();

        using (var cssMemoryStream = new MemoryStream(System.Text.Encoding.UTF8.GetBytes(cssText)))
        {
            using (var htmlMemoryStream = new MemoryStream(System.Text.Encoding.UTF8.GetBytes(html)))
            {
                XMLWorkerHelper.GetInstance().ParseXHtml(writer, document, htmlMemoryStream, cssMemoryStream);
            }
        }

        document.Close();

        pdf = memoryStream.ToArray();
}

    You need to use a commercial library if you need perfect html rendering in pdf.

ExpertPdf Html To Pdf Converter is very easy to use and it supports the latest html5/css3. You can either convert an entire url to pdf:

using ExpertPdf.HtmlToPdf; 
byte[] pdfBytes = new PdfConverter().GetPdfBytesFromUrl(url);


or a html string:

using ExpertPdf.HtmlToPdf; 
byte[] pdfBytes = new PdfConverter().GetPdfBytesFromHtmlString(html, baseUrl);


You also have the alternative to directly save the generated pdf document to a Stream of file on the disk.
    With Winnovative HTML to PDF converter you can convert a HTML string in a single line

byte[] outPdfBuffer = htmlToPdfConverter.ConvertHtml(htmlString, baseUrl);


The base URL is used to resolve the images referenced by relative URLs in HTML string. Alternatively you can use full URLs in HTML or embed images using src=""data:image/png"" for image tag.

In answer to 'fubaar' user comment about Winnovative converter, a correction is necessary. The converter does not use IE as rendering engine. It actually does not depend on any installed software and the rendering is compatible with WebKit engine.
    Most HTML to PDF converter relies on IE to do the HTML parsing and rendering. This can break when user updates their IE. Here is one that does not rely on IE.

The code is something like this:

EO.Pdf.HtmlToPdf.ConvertHtml(htmlText, pdfFileName);


Like many other converters, you can pass text, file name, or Url. The result can be saved into a file or a stream.
    2018's update, and Let's use standard HTML+CSS=PDF equation!

There are good news for HTML-to-PDF demands. As this answer showed, the W3C standard css-break-3 will solve the problem... It is a Candidate Recommendation with plan to turn into definitive Recommendation in 2017 or 2018, after tests.

As not-so-standard there are solutions, with plugins for C#, as showed by print-css.rocks.
    It depends on any other requirements you have. 

A really simple but not easily deployable solution is to use a WebBrowser control to load the Html and then using the Print method printing to a locally installed PDF printer. There are several free PDF printers available and the WebBrowser control is a part of the .Net framework. 

EDIT:
If you Html is XHtml you can use PDFizer to do the job.
    I was also looking for this a while back. I ran into HTMLDOC http://www.easysw.com/htmldoc/ which is a free open source command line app that takes an HTML file as an argument and spits out a PDF from it. It's worked for me pretty well for my side project, but it all depends on what you actually need. 

The company that makes it sells the compiled binaries, but you are free to download and compile from source and use it for free. I managed to compile a pretty recent revision (for version 1.9) and I intend on releasing a binary installer for it in a few days, so if you're interested I can provide a link to it as soon as I post it.

Edit (2/25/2014): Seems like the docs and site moved to http://www.msweet.org/projects.php?Z1
    Best Tool i have found and used for generating PDF of javascript and styles rendered views or html pages is phantomJS.

Download the .exe file with the rasterize.js function found in root of exe of example folder and put inside solution.

It Even allows you to download the file in any code without opening that file also it also allows to download the file when the styles and specially jquery are applied.

Following code generate PDF File :

public ActionResult DownloadHighChartHtml()
{
    string serverPath = Server.MapPath(""~/phantomjs/"");
    string filename = DateTime.Now.ToString(""ddMMyyyy_hhmmss"") + "".pdf"";
    string Url = ""http://wwwabc.com"";

    new Thread(new ParameterizedThreadStart(x =>
    {
        ExecuteCommand(string.Format(""cd {0} & E: & phantomjs rasterize.js {1} {2} \""A4\"""", serverPath, Url, filename));
                           //E: is the drive for server.mappath
    })).Start();

    var filePath = Path.Combine(Server.MapPath(""~/phantomjs/""), filename);

    var stream = new MemoryStream();
    byte[] bytes = DoWhile(filePath);

    Response.ContentType = ""application/pdf"";
    Response.AddHeader(""content-disposition"", ""attachment;filename=Image.pdf"");
    Response.OutputStream.Write(bytes, 0, bytes.Length);
    Response.End();
    return RedirectToAction(""HighChart"");
}



private void ExecuteCommand(string Command)
{
    try
    {
        ProcessStartInfo ProcessInfo;
        Process Process;

        ProcessInfo = new ProcessStartInfo(""cmd.exe"", ""/K "" + Command);

        ProcessInfo.CreateNoWindow = true;
        ProcessInfo.UseShellExecute = false;

        Process = Process.Start(ProcessInfo);
    }
    catch { }
}


private byte[] DoWhile(string filePath)
{
    byte[] bytes = new byte[0];
    bool fail = true;

    while (fail)
    {
        try
        {
            using (FileStream file = new FileStream(filePath, FileMode.Open, FileAccess.Read))
            {
                bytes = new byte[file.Length];
                file.Read(bytes, 0, (int)file.Length);
            }

            fail = false;
        }
        catch
        {
            Thread.Sleep(1000);
        }
    }

    System.IO.File.Delete(filePath);
    return bytes;
}

    Try this PDF Duo .Net converting component for converting HTML to PDF from ASP.NET application without using additional dlls.

You can pass the HTML string or file, or stream to generate the PDF.
Use the code below (Example C#):

string file_html = @""K:\hdoc.html"";   
string file_pdf = @""K:\new.pdf"";   
try   
{   
    DuoDimension.HtmlToPdf conv = new DuoDimension.HtmlToPdf();   
    conv.OpenHTML(file_html);   
    conv.SavePDF(file_pdf);   
    textBox4.Text = ""C# Example: Converting succeeded"";   
}   


Info + C#/VB examples you can find at: http://www.duodimension.com/html_pdf_asp.net/component_html_pdf.aspx
    PDFmyURL recently released a .NET component for web page / HTML to PDF conversion as well. This has a very user friendly interface, for example:

PDFmyURL pdf = new PDFmyURL(""yourlicensekey"");
pdf.ConvertURL(""http://www.example.com"", Application.StartupPath + @""\example.pdf"");


Documentation: PDFmyURL .NET component documentation

Disclaimer: I work for the company that owns PDFmyURL
    Already if you are using itextsharp dll, no need to add third party dll's(plugin), I think you are using htmlworker instead of it use xmlworker you can easily convert your html to pdf.
Some css won't work they are Supported CSS
Full Explain with example Reference Click here 



        MemoryStream memStream = new MemoryStream();
        TextReader xmlString = new StringReader(outXml);
        using (Document document = new Document())
        {
            PdfWriter writer = PdfWriter.GetInstance(document, memStream);
            //document.SetPageSize(iTextSharp.text.PageSize.A4);
            document.Open();
            byte[] byteArray = System.Text.Encoding.UTF8.GetBytes(outXml);
            MemoryStream ms = new MemoryStream(byteArray);
            XMLWorkerHelper.GetInstance().ParseXHtml(writer, document, ms, System.Text.Encoding.UTF8);
            document.Close();
        }

        Response.ContentType = ""application/pdf"";
        Response.AddHeader(""content-disposition"", ""attachment;filename="" + filename + "".pdf"");
        Response.Cache.SetCacheability(HttpCacheability.NoCache);
        Response.BinaryWrite(memStream.ToArray());
        Response.End();
        Response.Flush();

    Another trick you can use WebBrowser control, below is my full working code

Assigning Url to text box control in my case

  protected void Page_Load(object sender, EventArgs e)
{

   txtweburl.Text = ""https://www.google.com/"";

 }


Below is code for generate screeen using thread

  protected void btnscreenshot_click(object sender, EventArgs e)
  {
    //  btnscreenshot.Visible = false;
    allpanels.Visible = true;
    Thread thread = new Thread(GenerateThumbnail);
    thread.SetApartmentState(ApartmentState.STA);
    thread.Start();
    thread.Join();

}

private void GenerateThumbnail()
{
    //  btnscreenshot.Visible = false;
    WebBrowser webrowse = new WebBrowser();
    webrowse.ScrollBarsEnabled = false;
    webrowse.AllowNavigation = true;
    string url = txtweburl.Text.Trim();
    webrowse.Navigate(url);
    webrowse.Width = 1400;
    webrowse.Height = 50000;

    webrowse.DocumentCompleted += webbrowse_DocumentCompleted;
    while (webrowse.ReadyState != WebBrowserReadyState.Complete)
    {
        System.Windows.Forms.Application.DoEvents();
    }
}


In below code I am saving the pdf file after download 

        private void webbrowse_DocumentCompleted(object sender, WebBrowserDocumentCompletedEventArgs e)
{
    // btnscreenshot.Visible = false;
    string folderPath = Server.MapPath(""~/ImageFiles/"");

    WebBrowser webrowse = sender as WebBrowser;
    //Bitmap bitmap = new Bitmap(webrowse.Width, webrowse.Height);

    Bitmap bitmap = new Bitmap(webrowse.Width, webrowse.Height, PixelFormat.Format16bppRgb565);

    webrowse.DrawToBitmap(bitmap, webrowse.Bounds);


    string Systemimagedownloadpath = System.Configuration.ConfigurationManager.AppSettings[""Systemimagedownloadpath""].ToString();
    string fullOutputPath = Systemimagedownloadpath + Request.QueryString[""VisitedId""].ToString() + "".png"";
    MemoryStream stream = new MemoryStream();
    bitmap.Save(fullOutputPath, System.Drawing.Imaging.ImageFormat.Jpeg);



    //generating pdf code 
     Document pdfDoc = new Document(new iTextSharp.text.Rectangle(1100f, 20000.25f));
     PdfWriter writer = PdfWriter.GetInstance(pdfDoc, Response.OutputStream);
     pdfDoc.Open();
     iTextSharp.text.Image img = iTextSharp.text.Image.GetInstance(fullOutputPath);   
     img.ScaleAbsoluteHeight(20000);
     img.ScaleAbsoluteWidth(1024);     
     pdfDoc.Add(img);
     pdfDoc.Close();
     //Download the PDF file.
     Response.ContentType = ""application/pdf"";
     Response.AddHeader(""content-disposition"", ""attachment;filename=ImageExport.pdf"");
     Response.Cache.SetCacheability(HttpCacheability.NoCache);
     Response.Write(pdfDoc);
     Response.End();


}


You can also refer my oldest post for more information: Navigation to the webpage was canceled getting message in asp.net web form
    ","[490, 249, 108, 8, 1, 5, 1, 12, 1, 27, 3, 1, 2, 0, 1, 4, 2, 0, 28, 6, 3, 2, 1, 0, 0, 0, 0]",760960,233,2009-02-19T10:21:22,2022-02-02 14:20:17Z,c html 
How to map with index in Ruby?,"
                
What is the easiest way to convert 

[x1, x2, x3, ... , xN]


to

[[x1, 2], [x2, 3], [x3, 4], ... , [xN, N+1]]

    If you're using ruby 1.8.7 or 1.9, you can use the fact that iterator methods like each_with_index, when called without a block, return an Enumerator object, which you can call Enumerable methods like map on. So you can do:

arr.each_with_index.map { |x,i| [x, i+2] }


In 1.8.6 you can do:

require 'enumerator'
arr.enum_for(:each_with_index).map { |x,i| [x, i+2] }

    Ruby has Enumerator#with_index(offset = 0), so first convert the array to an enumerator using Object#to_enum or Array#map:

[:a, :b, :c].map.with_index(2).to_a
#=> [[:a, 2], [:b, 3], [:c, 4]]

    In ruby 1.9.3 there is a chainable method called with_index which can be chained to map.

For example:

array.map.with_index { |item, index| ... }

    I have always enjoyed the syntax of this style:

a = [1, 2, 3, 4]
a.each_with_index.map { |el, index| el + index }
# => [1, 3, 5, 7]


Invoking each_with_index gets you an enumerator you can easily map over with your index available.
    module Enumerable
  def map_with_index(&block)
    i = 0
    self.map { |val|
      val = block.call(val, i)
      i += 1
      val
    }
  end
end

[""foo"", ""bar""].map_with_index {|item, index| [item, index] } => [[""foo"", 0], [""bar"", 1]]

    Over the top obfuscation:

arr = ('a'..'g').to_a
indexes = arr.each_index.map(&2.method(:+))
arr.zip(indexes)

    A fun, but useless way to do this:

az  = ('a'..'z').to_a
azz = az.map{|e| [e, az.index(e)+2]}

    a = [1, 2, 3]
p [a, (2...a.size+2).to_a].transpose

    I often do this:

arr = [""a"", ""b"", ""c""]

(0...arr.length).map do |int|
  [arr[int], int + 2]
end

#=> [[""a"", 2], [""b"", 3], [""c"", 4]]


Instead of directly iterating over the elements of the array, you're iterating over a range of integers and using them as the indices to retrieve the elements of the array.
    Here are two more options for 1.8.6 (or 1.9) without using enumerator:

# Fun with functional
arr = ('a'..'g').to_a
arr.zip( (2..(arr.length+2)).to_a )
#=> [[""a"", 2], [""b"", 3], [""c"", 4], [""d"", 5], [""e"", 6], [""f"", 7], [""g"", 8]]

# The simplest
n = 1
arr.map{ |c| [c, n+=1 ] }
#=> [[""a"", 2], [""b"", 3], [""c"", 4], [""d"", 5], [""e"", 6], [""f"", 7], [""g"", 8]]

    ","[489, 905, 292, 176, 13, 2, 19, 5, 3, 1, 9]",271400,64,2011-01-15T01:34:34,2019-04-26 10:42:34Z,ruby 
Server certificate verification failed. CAfile: /etc/ssl/certs/ca-certificates.crt CRLfile: none,"
                
I can push by clone project using ssh, but it doesn't work when I clone project with https.
The error message that it shows me is:
server certificate verification failed. CAfile: /etc/ssl/certs/cacertificates.crt CRLfile: none

    TLDR:
hostname=XXX
port=443
trust_cert_file_location=`curl-config --ca`

sudo bash -c ""echo -n | openssl s_client -showcerts -connect $hostname:$port -servername $hostname \
    2>/dev/null  | sed -ne '/-BEGIN CERTIFICATE-/,/-END CERTIFICATE-/p'  \
    >> $trust_cert_file_location""

Warning: as noted in gareththered's excellent answer, this adds all certificates, instead of only the Root CAs.
Blindly adding all (any) certificate to your trustStore without due diligence is not the best course of action.

Long answer
The basic reason is that your computer doesn't trust the certificate authority that signed the certificate used on the Gitlab server. This doesn't mean the certificate is suspicious, but it could be self-signed or signed by an institution/company that isn't in the list of your OS's list of CAs. What you have to do to circumvent the problem on your computer is telling it to trust that certificate - if you don't have any reason to be suspicious about it.
You need to check the web certificate used for your gitLab server, and add it to your </git_installation_folder>/bin/curl-ca-bundle.crt.
To check if at least the clone works without checking said certificate, you can set:
export GIT_SSL_NO_VERIFY=1
#or
git config --global http.sslverify false

But that would be for testing only, as illustrated in ""SSL works with browser, wget, and curl, but fails with git"", or in this blog post.
Check your GitLab settings, a in issue 4272.

To get that certificate (that you would need to add to your curl-ca-bundle.crt file), type a:
echo -n | openssl s_client -showcerts -connect yourserver.com:YourHttpsGitlabPort \
  2>/dev/null  | sed -ne '/-BEGIN CERTIFICATE-/,/-END CERTIFICATE-/p'

(with 'yourserver.com' being your GitLab server name, and YourHttpsGitlabPort is the https port, usually 443)
To check the CA (Certificate Authority issuer), type a:
echo -n | openssl s_client -showcerts -connect yourserver.com:YourHttpsGilabPort \
  2>/dev/null  | sed -ne '/-BEGIN CERTIFICATE-/,/-END CERTIFICATE-/p' \
  | openssl x509 -noout -text | grep ""CA Issuers"" | head -1

Note: Valeriy Katkov suggests in the comments to add -servername option to the openssl command, otherwise the command isn't showed certificate for www.github.com in Valeriy's case.

openssl s_client -showcerts -servername www.github.com -connect www.github.com:443



Findekano adds in the comments:

to identify the location of curl-ca-bundle.crt, you could use the command

curl-config --ca


Also, see my more recent answer ""github: server certificate verification failed"": you might have to renistall those certificates:
sudo apt-get install --reinstall ca-certificates
sudo mkdir /usr/local/share/ca-certificates/cacert.org
sudo wget -P /usr/local/share/ca-certificates/cacert.org http://www.cacert.org/certs/root.crt http://www.cacert.org/certs/class3.crt
sudo update-ca-certificates
git config --global http.sslCAinfo /etc/ssl/certs/ca-certificates.crt

    
  Note: This has major security implications.


Open your terminal and run following command:

export GIT_SSL_NO_VERIFY=1


It works for me and I am using Linux system.
    
Note: This has major security implications.

If you are using a git server inside a private network and are using a self-signed certificate or a certificate over an IP address ; you may also simply use the git global config to disable the ssl checks:
git config --global http.sslverify ""false""

    Last updated: Sep 30, 2021 | See all Documentation
The main determining factor for whether a platform can validate Let’s Encrypt certificates is whether that platform trusts ISRG’s “ISRG Root X1” certificate. Prior to September 2021, some platforms could validate our certificates even though they don’t include ISRG Root X1, because they trusted IdenTrust’s “DST Root CA X3” certificate. From October 2021 onwards, only those platforms that trust ISRG Root X1 will validate Let’s Encrypt certificates (with the exception of Android).
Current system
In case your system is quite current but for some reason automatic update didn't work, there should be enough to:
apt update
apt upgrade
sudo dpkg-reconfigure ca-certificates

and in reconfigure stage, deselect ""DST Root CA X3"" certificate
Outdated system
To resolve, on old Linux server like Ubuntu 16 or Debian 8 jessie, few steps required:

upgrade openssl to anything >=1.0.2
On Debian jessie enable backports source, add this line to sources.list:
deb http://archive.debian.org/debian jessie-backports main contrib non-free
and do apt-get install -t jessie-backports openssl
ensure security updates for ca-certificates package
apt upgrade
download latest LetsEncrypt root CA certs:
sudo curl -k https://letsencrypt.org/certs/isrgrootx1.pem.txt -o /usr/local/share/ca-certificates/isrgrootx1.crt
sudo curl -k https://letsencrypt.org/certs/letsencryptauthorityx1.pem.txt -o /usr/local/share/ca-certificates/letsencryptauthorityx1.crt
sudo curl -k https://letsencrypt.org/certs/letsencryptauthorityx2.pem.txt -o /usr/local/share/ca-certificates/letsencryptauthorityx2.crt
sudo curl -k https://letsencrypt.org/certs/lets-encrypt-x1-cross-signed.pem.txt -o /usr/local/share/ca-certificates/letsencryptx1.crt
sudo curl -k https://letsencrypt.org/certs/lets-encrypt-x2-cross-signed.pem.txt -o /usr/local/share/ca-certificates/letsencryptx2.crt
sudo curl -k https://letsencrypt.org/certs/lets-encrypt-x3-cross-signed.pem.txt -o /usr/local/share/ca-certificates/letsencryptx3.crt
sudo curl -k https://letsencrypt.org/certs/lets-encrypt-x4-cross-signed.pem.txt -o /usr/local/share/ca-certificates/letsencryptx4.crt
sudo dpkg-reconfigure ca-certificates


during reconfigure stage, please deselect ""DST Root CA X3"" certificate

After these steps, apt update should work for LetsEncrypt based sources and wget and curl should not complain.
Special note to curl -k allows to connect 'insecure' SSL server, which is the case, as LetsEncrypt certificate is not trusted.
    I met this issue in a GitLab server.   Solved it after updating the  Trusted CA List of Linux by the cmd:
sudo apt-get install --reinstall ca-certificates

Here are the steps:
The git trace return errors like this:
 GIT_CURL_VERBOSE=1 GIT_TRACE=2 git clone https://mygitlab
...
...

* SSL connection using TLS1.2 / ECDHE_RSA_AES_256_GCM_SHA384
* server certificate verification failed. CAfile: none CRLfile: none
* Closing connection 0
**fatal: unable to access 'https://mygitlab/some.git/': server certificate verification failed. CAfile: none CRLfile: none**

Check the CA Issuer of git server:
echo -n | openssl s_client -showcerts -connect yourserver.com:YourHttpGilabPort \
  2>/dev/null  | sed -ne '/-BEGIN CERTIFICATE-/,/-END CERTIFICATE-/p' \
  | openssl x509 -noout -text | grep""CA Issuers"" | head -1
...
...

CA Issuers - URI:http://r3.i.lencr.org/

Why is the r3.i.lencr.org untrusted?  I tried to update the CA list, and it works.
    Another cause of this problem might be that your clock might be off.  Certificates are time sensitive.

To check the current system time:

date -R


You might consider installing NTP to automatically sync the system time with trusted internet timeservers from the global NTP pool. For example, to install on Debian/Ubuntu:

apt-get install ntp

    The most voted for answer is, unfortunately, wrong.  It will have the desired effect, but for the wrong reasons.
The commands in VonC's answer adds all certificates in the chain to the trust-anchor store.  However, these certificates are not trust-anchors (or Root CA certificates in other words); they are the end-entity and intermediate CA certificates.
The standard for TLS RFC 5246 states:

certificate_list
This is a sequence (chain) of certificates.  The sender's
certificate MUST come first in the list.  Each following
certificate MUST directly certify the one preceding it.  Because
certificate validation requires that root keys be distributed
independently, the self-signed certificate that specifies the root
certificate authority MAY be omitted from the chain, under the
assumption that the remote end must already possess it in order to
validate it in any case.

Therefore VonC's (and others') command may well add all the wrong certificates and not the Root CA.
A end-entity or intermediate CA certificate is not a trust-anchor.  These certificate may and do change over time, in which case the same problem will rear it's ugly head again.  Also, what happens if the end-entity certificate is revoked for some reason?  Your computer may well continue to trust the revoked certificate - in practice, the exact response may depends on the crypto library being used as this isn't well defined in the standards and therefore subject to variation in implementation.
The correct way to fix this would involve looking at the last certificate in the chain, confirming it is not a Root CA (as that may be sent by the server - see the RFC extract quoted above) and if that is the case, looking at the Issuer and potentially the AKI field to ascertain which Root CA issued this first intermediate CA certificate.  Once the details have been worked out, you'll need to visit the repository of that Root CA and download (and verify the hash) of that certificate before downloading it.  You should review the CP/CPS of this Root CA before deciding to install it in your trust-anchor store.
If the last certificate is the Root CA, then use openssl x509... commands to view the details, then carry out due-diligence before deciding whether you should install that single certificate in your trust-anchor store.
There can't be, and shouldn't be, an automatic process for you to carry out the above as you need to verify the provenance of the trust-anchor before you decide to add it to your trust-anchor store.  Ask yourself why it wasn't part of the ca-certificate package (or equivalent for your distro) before blindly installing it.
However, running something like the following will display the Subject and Issuer of the last certificate in the chain, which may help you trace down the missing Root CA certificate:
echo -n | openssl s_client -showcerts -servername www.github.com -connect www.github.com:443 2>/dev/null | tac | awk '/-END CERTIFICATE-/{f=1} f;/-BEGIN CERTIFICATE-/{exit}' | tac | openssl x509 -noout -subject -issuer

Which (in my case in late May 2021) results in:
subject=C = US, O = ""DigiCert, Inc."", CN = DigiCert High Assurance TLS Hybrid ECC SHA256 2020 CA1
issuer=C = US, O = DigiCert Inc, OU = www.digicert.com, CN = DigiCert High Assurance EV Root CA

From the above, we can see that the server sent the intermediate CA certificate, not the root (the subject and issuer are different).  That intermediate CA certificate was signed by DigiCert's High Assurance EV Root CA.  We can now go to DigiCert's repository and download that particular certificate.
Before installing that certificate, make sure it is the one which signed your intermediate CA by running openssl x509 -noout -text -in <downloaded.crt.pem> against it and comparing the value of the X509v3 Authority Key Identifier extension against the same extension in the certificate sent by the server.  Note: you can view that extension on the intermediate CA certificate sent by the server by changing -subject -issuer at the end of the previous command to -text.
Once you're certain that the Root CA certificate you've downloaded is the correct one, and you've carried out due-diligence and decided that you trust this Root CA, add it to your trust-anchor store:
sudo mv <downloaded.crt.pem> /usr/local/share/ca-certificates/<downloaded.crt>
sudo update-ca-certificates

Note that the file must be in PEM format and the filename must end in .crt otherwise update-ca-certificates won't recognise it.
    Had same problem. Caused by self issued certificate authority.
Solved it by adding .pem file to /usr/local/share/ca-certificates/
and calling 

sudo update-ca-certificates


PS: pem file in folder ./share/ca-certificates MUST have extension .crt
    What i did to solve this problem in the terminal(Ubuntu 18.04):

openssl s_client -showcerts -servername www.github.com -connect www.github.com:443


I got two chunks of certificate chunks. And i copied the certificate chunks to my certificate file to /etc/ssl/certs/ca-certificates.crt.
    Lets's encrypt Sept. 30th 2021 ROOT CA expiry
Another source for this error is an expired Root CA, it happened yesterday for one of them if you're using Let's Encrypt:
https://docs.certifytheweb.com/docs/kb/kb-202109-letsencrypt/
You can confirm it by running
openssl s_client -showcerts -connect $hostname:$port -servername $hostname | grep ""certificate has expired""

In this case you need to edit the gitlab certificate, in /etc/gitlab/ssl/$hostname.crt
Replace expired DST Root CA X3 block in file with content of https://letsencrypt.org/certs/isrgrootx1.pem, and reload the server.
    I tried many solutions from here but none worked for me. I had 4 servers running on ubuntu 16.04, and the way I was actually able to fix this problem was 3-fold (you should sudo apt update first):

update openssl as the version I had installed was missing a fix that would allow some of the solutions here to work. sudo apt install --only-upgrade openssl. Openssl needs to be at least 1.0.2g-1ubuntu4.20.
then I had to do the same with the certs: sudo apt install --only-upgrade ca-certificates
only then did reconfiguring the certs sudo dpkg-reconfigure ca-certificates (or editing the config file I guess) and removing the DST_Root_CA_X3 from the list bring positive results.

    For Linux/Debian use:
sudo cp /etc/ca-certificates.conf /etc/ca-certificates.conf.orig
sudo nano /etc/ca-certificates.conf
Change “mozilla/DST_Root_CA_X3.crt” in “!mozilla/DST_Root_CA_X3.crt” an save
sudo update-ca-certificates

https://talk.plesk.com/threads/lets-encrypt-root-certificate-expiration-on-30-september-2021.362224/
    GIT_CURL_VERBOSE=1 git [clone|fetch]…


should tell you where the problem is.  In my case it was due to cURL not supporting PEM certificates when built against NSS, due to that support not being mainline in NSS (#726116 #804215 #402712 and more).
    Based on the very good answer from VonC, I just created a bash script that installs the missing x509 certificate to your certificate bundle. It's for debian based linux distros.
#!/bin/bash

CERTIFICATE_PEM=certificate.pem
CERTIFICATE_CRT=certificate.crt

# get certificate
echo -n | openssl s_client -showcerts -connect gitlab.sehlat.io:443 \
  2>/dev/null  | sed -ne '/-BEGIN CERTIFICATE-/,/-END CERTIFICATE-/p' \
  > $CERTIFICATE_PEM

# format certificate from PEM (human-readable) to CRT
openssl x509 -in $CERTIFICATE_PEM -out $CERTIFICATE_CRT

# move it to ca-certificates folder & update the bundle file
sudo mv ./$CERTIFICATE_CRT /usr/local/share/ca-certificates/
sudo update-ca-certificates

# configuring git
git config --global http.sslCAinfo /etc/ssl/certs/ca-certificates.crt

    I was facing the same problem with aging Ubuntu 16.04 and GitLab (other computers worked well).
The problem was actually the old version of gnutls library which is used internally by Git. This old library was sensitive for the certificate order on the server side - more information in this question. The final solution was as simple as:
apt-get update
apt-get upgrade libgnutls*

    What worked for me when trying to git clone inside of a Dockerfile was to fetch the SSL certificate and add it to the local certificate list:
openssl s_client -showcerts -servername git.mycompany.com -connect git.mycompany.com:443 </dev/null 2>/dev/null | sed -n -e '/BEGIN\ CERTIFICATE/,/END\ CERTIFICATE/ p'  > git-mycompany-com.pem

cat git-mycompany-com.pem | sudo tee -a /etc/ssl/certs/ca-certificates.crt

Credits: https://fabianlee.org/2019/01/28/git-client-error-server-certificate-verification-failed/
    I faced the problem with my Jenkins. When I have renewed the certificate I started facing this error.
stderr fatal: unable to access server certificate verification failed. CAfile: /etc/ssl/certs/ca-certificates.crt

So I have added my new certificate in the following file:
/etc/ssl/certs/ca-certificates.crt

The content of that file looks like this:
-----BEGIN CERTIFICATE-----
blahblha
-----END CERTIFICATE-----
-----BEGIN CERTIFICATE-----
blahblha
-----END CERTIFICATE-----
-----BEGIN CERTIFICATE-----
blahblha
-----END CERTIFICATE-----

Just append your certificate in the bottom:
-----BEGIN CERTIFICATE-----
blahblha
-----END CERTIFICATE-----

    Or simply run this comment to add the server Certificate to your database:

echo $(echo -n | openssl s_client -showcerts -connect yourserver.com:YourHttpGilabPort 2>/dev/null  | sed -ne '/-BEGIN CERTIFICATE-/,/-END CERTIFICATE-/p') >> /etc/ssl/certs/ca-certificates.crt


Then do git clone again.
    I just encountered the very same problem with a git repository which always works for me. The problem was that I accessed it through public WiFi access, which redirects to a captive portal upon the first connection (for example to show ads and agree with tos).
    For MINGW64 Git Bash users on Windows

Launch Git Bash as Administrator

From within the MINGW64 terminal run:
echo -n | openssl s_client -showcerts -connect yourserver.com:YourHttpsGitlabPort 2>/dev/null  | sed -ne '/-BEGIN CERTIFICATE-/,/-END CERTIFICATE-/p' >> /c/Program\ Files/Git/mingw64/ssl/certs/ca-bundle.trust.crt


Close Git Bash as Administrator

Launch Git Bash (as not Administrator)

From within the MINGW64 terminal run:
  $ git config --global http.sslBackend schannel
  $ git config --global http.sslverify true



    Check your system clock,

$ date    

If it's not correct the certificate check will fail. To correct the system clock,

$ apt-get install ntp    

The clock should synchronise itself.

Finally enter the clone command again.
    The first thing you should check for is the file permission of /etc/ssl and /etc/ssl/certs.

I made the mistake of dropping file permissions (or blowing away the SSL rm -rf /etc/ssl/* directories) when using ssl-cert group name/ID while working on my Certificate Authority Management Tool.

It was then that I noticed the exact same error message for wget and curl CLI browser tools:

server certificate verification failed. CAfile: /etc/ssl/certs/ca-certificates.crt CRLfile: none


Once I brought the /etc/ssl and /etc/ssl/cert directories' file permission up to o+rx-w, those CLI browser tools started to breath a bit easier:

mkdir -p /etc/ssl/certs
chmod u+rwx,go+rx /etc/ssl /etc/ssl/certs


I also had to recreate Java subdirectory and reconstruct the Trusted CA certificate directories:

mkdir /etc/ssl/certs/java
chmod u+rwx,go+rx /etc/ssl/certs/java
update-ca-certificates


and the coast was clear.
    I messed up with my CA files while I setup up goagent proxy. Can't pull data from github, and get the same warning:


  server certificate verification failed. CAfile: /etc/ssl/certs/ca-certificates.crt CRLfile: none


use Vonc's method, get the certificate from github, and put it into /etc/ssl/certs/ca-certificates.crt, problem solved. 


  echo -n | openssl s_client -showcerts -connect github.com:443 2>/dev/null  | sed -ne '/-BEGIN CERTIFICATE-/,/-END CERTIFICATE-/p'

    there is no need to set git ssl verification to set to false. It is caused when the system does not have the all CA authority certificates. Mostly people who have genuine SSL certificate missing the intermediate certificate. 

Just adding the complete text of intermediate certificate (whole chain of missing CA and intermediate certificate)  to  

sudo gedit /etc/ssl/certs/ca-certificates.crt 


works without running the update-ca-certificates.

Same goes for manually generated certificates, just add the CA certificate text.

At the end : Push successful: Everything is up-to-date
    I installed Xubuntu on a Raspberry pi 2, found the same issue with time, as NTP and Automatic Server sync was off (or not installed) . Get NTP

sudo apt-get install ntp


and change the ""Time and Date"" from ""Manual"" to ""Keep synchronized with Internet Servers""
    Eventually, add the http.sslverify to your .git/config.

[core]
    repositoryformatversion = 0
    filemode = true
    bare = false
    logallrefupdates = true
[remote ""origin""]
    url = https://server/user/project.git
    fetch = +refs/heads/*:refs/remotes/origin/*
[branch ""master""]
    remote = origin
    merge = refs/heads/master
[http]
        sslVerify = false

    Have the certificate and bundle copied in one .crt file and make sure that there is a blank line between the certificates in the file.

This worked for me on a GitLab server after trying everything on the Internet.
    Before anything else, check if you have a proxy running, like Zscaler, that you can temporarily turn off. Then check your dates, as above.
    I ran into this problem today with freedesktop.org, when using Git for Windows.  I updated my git version to 2.35 (from 2.28), and the problem was solved.  Probably the integrated shell environment in the windows version did not have updated certs.
Hopefully this helps someone who uses the Windows version.
    I know this is old, but now and then the error pop up again. If you are sure you can trust your local installation, you can simply add: GIT_SSL_NO_VERIFY: ""true"" in your variables section. In this way you simply disable the certificate validation.
This solution is similar to the one proposed here but it applies only to the current git tree and not the global git configuration.
    ","[489, 534, 308, 109, 23, 6, 170, 18, 50, 13, 37, 10, 7, 32, 1, 1, 4, 4, 20, 1, 1, 38, 2, 10, 8, 3, 1, 0, 0, 0, 0]",794111,174,2014-01-17T08:34:42,2022-04-26 04:03:48Z,
"How to line-break from css, without using <br />?","
                
output:


hello
How are you


code:

<p>hello <br> How are you </p>


How to achieve same output without <br>?
    You can use white-space: pre; to make elements act like <pre>, which preserves newlines.  Example:

p {
  white-space: pre;
}<p>hello 
How are you</p>


Note for IE that this only works in IE8+.
    Impossible with the same HTML structure, you must have something to distinguish between Hello and How are you.

I suggest using spans that you will then display as blocks (just like a <div> actually).

p span {
  display: block;
}<p><span>hello</span><span>How are you</span></p>

    There are several options for defining the handling of white spaces and line breaks. 
If one can put the content in e.g. a <p> tag it is pretty easy to get whatever one wants.

For preserving line breaks but not white spaces use pre-line (not pre) like in:

<style>
 p {
     white-space: pre-line; /* collapse WS, preserve LB */
   }
</style>

<p>hello
How are you</p>


If another behavior is wanted choose among one of these (WS=WhiteSpace, LB=LineBreak):

     white-space: normal;   /* collapse WS, wrap as necessary, collapse LB */
     white-space: nowrap;   /* collapse WS, no wrapping,       collapse LB */
     white-space: pre;      /* preserve WS, no wrapping,       preserve LB */
     white-space: pre-wrap; /* preserve WS, wrap as necessary, preserve LB */
     white-space: inherit;  /* all as parent element */


SOURCE: W3 Schools
    Use <br/> as normal, but hide it with display: none when you don't want it.
I would expect most people finding this question want to use css / responsive design to decide whether or not a line-break appears in a specific place. (and don't have anything personal against <br/>)
While not immediately obvious, you can actually apply display:none to a <br/> tag to hide it, which enables the use of media queries in tandem with semantic BR tags.
<div>
  The quick brown fox<br />
  jumps over the lazy dog
</div>

@media screen and (min-width: 20em) {
  br {
    display: none; /* hide the BR tag for wider screens (i.e. disable the line break) */
  }
}

This is useful in responsive design where you need to force text into two lines at an exact break.
jsfiddle example
    Use overflow-wrap: break-word;  like:
.yourelement{
  overflow-wrap: break-word;
}

    The code can be:
<div class=""text-class""><span>hello</span><span>How are you</span></div>

CSS would be:
.text-class {
  display: flex;
  justify-content: flex-start;
  flex-direction: column;
  align-items: center;
}

    The ""\a"" command in CSS generates a carriage return. This is CSS, not HTML, so it shall be closer to what you want: no extra markup.
In a blockquote, the example below displays both the title and the source link and separate the two with a carriage return (""\a""):
blockquote[title][cite]:after {
  content:attr(title)""\a""attr(cite)
}

    In the CSS use the code
p {
  white-space: pre-line;
}

With this CSS every enter inside the P tag will be a break-line at the HTML.
    Maybe someone will have the same issue as me:

I was in a element with display: flex so I had to use flex-direction: column.
    You need to declare the content within <span class=""class_name""></span>. After it the line will be break. 

\A means line feed character.

.class_name::after {
  content: ""\A"";
  white-space: pre;
}

    To make an element have a line break afterwards, assign it:

display:block;

Non-floated elements after a block level element will appear on the next line. Many elements, such as <p> and <div> are already block level elements so you can just use those.

But while this is good to know, this really depends more on the context of your content. In your example, you would not want to use CSS to force a line break. The <br /> is appropriate because semantically the p tag is the the most appropriate for the text you are displaying. More markup just to hang CSS off it is unnecessary. Technically it's not exactly a paragraph, but there is no <greeting> tag, so use what you have. Describing your content well with HTMl is way more important - after you have that then figure out how to make it look pretty.
    Building on what has been said before, this is a pure CSS solution that works.

<style>
  span {
    display: inline;
  }
  span:before {
    content: ""\a "";
    white-space: pre;
  }
</style>
<p>
  First line of text. <span>Next line.</span>
</p>

    Here's a bad solution to a bad question, but one that literally meets the brief:

p {
    width : 12ex;
}

p:before {
    content: ""."";
    float: right;
    padding-left: 6ex;
    visibility: hidden;
}

    <pre> <---------------------------------------
lorem ipsum
lorem ipsum
lorem ipsum
lorem ipsum
lorem ipsum
</pre> <--------------------------------------


OR

<div style=""white-space:pre"">  <-----------------------------------
lorem ipsum
lorem ipsum
lorem ipsum
lorem ipsum
lorem ipsum
</div>                         <-----------------------------------


source: https://stackoverflow.com/a/36191199/2377343
    Setting a br tag to display: none is helpful, but then you can end up with WordsRunTogether. I've found it more helpful to instead replace it with a space character, like so:

HTML:

<h1>
    Breaking<br />News:<br />BR<br />Considered<br />Harmful!
</h1>


CSS:

@media (min-device-width: 1281px){
    h1 br {content: ' ';}
    h1 br:after {content: ' ';}
}

    For a List of Links
The other answers provide some good ways of adding line breaks, depending on the situation. But it should be noted that the :after selector is one of the better ways to do this for CSS control over lists of links (and similar things), for reasons noted below.
Here's an example, assuming a table of contents:
<style type=""text/css"">
    .toc a:after{ content: ""\a""; white-space: pre; }
</style>

<span class=""toc"">
    <a href=""#a1"">Item A1</a> <a href=""#a2"">Item A2</a>
    <a href=""#b1"">Item B1</a> <a href=""#b2"">Item B2</a>
</span>

And here's Simon_Weaver's technique, which is simpler and more compatible. It doesn't separate style and content as much, requires more code, and there may be cases where you want to add breaks after the fact. Still a great solution though, especially for older IE.
<style type=""text/css"">
    .toc br{ display: none; } /* comment out for horizontal links */
</style>

<span class=""toc"">
    <a href=""#a1"">Item A1</a><br/> <a href=""#a2"">Item A2</a><br/>
    <a href=""#b1"">Item B1</a><br/> <a href=""#b2"">Item B2</a><br/>
</span>

Note the advantages of the above solutions:

No matter the whitespace in the HTML, the output is the same (vs. pre)
No extra padding is added to the elements (see NickG's display:block comments)
You can easily switch between horizontal and vertical lists of links with some shared CSS without going into every HTML file for a style change
No float or clear styles affecting surrounding content
The style is separate from the content (vs. <br/>, or pre with hard-coded breaks)
This can also work for loose links using a.toc:after and <a class=""toc"">
You can add multiple breaks and even prefix/suffix text

    How about<pre> tag?

source: http://www.w3schools.com/tags/tag_pre.asp
    You can add a lot of padding and force text to be split to new line, for example
p {
  padding-right: 50%;
}

Worked fine for me in a situation with responsive design, where only within a certain width range it was needed for text to be split.
    Using &nbsp; instead of spaces will prevent a break.

<span>I&nbsp;DONT&nbsp;WANT&nbsp;TO&nbsp;BREAK&nbsp;THIS&nbsp;LINE&nbsp;UP, but this text can be on any line.</span>

    I like very simple solutions, here is one more:
<p>hello <span>How are you</span></p>

and CSS:
p {
  display: flex;
  flex-direction: column;
}

    Both Vincent Robert and Joey Adams answers are valid. If you don't want, however, change the markup, you can just insert a <br /> using javascript.

There is no way to do it in CSS without changing the markup.
    In my case, I needed an input button to have a line break before it.
I applied the following style to the button and it worked:

clear:both;

    In case this helps someone...

You could do this:

<p>This is an <a class=""on-new-line"">inline link</a>?</p>


With this css:

a.on-new-line:before { 
  content: '&nbsp;'; 
  font-size:0; 
  display:block;
  line-height:0;
}

    I'm guessing you did not want to use a breakpoint because it will always break the line. Is that correct? If so how about adding a breakpoint <br /> in your text, then giving it a class like <br class=""hidebreak""/> then using media query right above the size you want it to break to hide the <br /> so it breaks at a specific width but stays inline above that width.

HTML:

<p>
The below line breaks at 766px.
</p>

<p>
 This is the line of text<br class=""hidebreak""> I want to break.
</p>


CSS:

@media (min-width: 767px) {
  br.hidebreak {display:none;}
}


https://jsfiddle.net/517Design/o71yw5vd/
    This works in Chrome:
p::after {
  content: ""-"";
  color: transparent;
  display: block;
}

    Using white-space will not work for long sentences without spaces like HiHowAreYouHopeYouAreDoingGood...etc to fix this consider using word-wrap: break-word; instead
it's made to allow long words to be able to break and wrap onto the next line., its used by Facebook, Instagram and me 😆
Example
#container {
    width: 40%;
    background-color: grey;
    overflow:hidden;
    margin:10px;
}
#container p{
   white-space: pre-line;
    background-color: green;
}
.flex{
    display: flex;
}

#wrap {
    width: 30%;
    background-color: grey;
    overflow:hidden;
    margin:10px;
}
#wrap p{
   word-wrap: break-word;
    background-color: green;
}<h1> white-space: pre-line;</h1>
<div class='flex'>

<div id=""container"">
<h5>With spaces </h5>
    <p>Sample Text 1 Sample Text 1 Sample Text 1 Sample Text 1 Sample Text 1 Sample Text 1 Sample Text 1</p>
</div>

<div id=""container"">
  <h5>No specaes (not working )</h5>  <p>HiHowAreYouHopeYouAreDoingGoodHiHowAreYouHopeYouAreDoingGoodHiHowAreYouHopeYouAreDoingGood</p>
</div>
</div>




<h1>  word-wrap: break-word;</h1>
<div class='flex'>

<div id=""wrap"">
<h5>With spaces </h5>
    <p>Sample Text 1 Sample Text 1 Sample Text 1 Sample Text 1 Sample Text 1 Sample Text 1 Sample Text 1</p>
</div>

<div id=""wrap"">
  <h5>No specaes (working )</h5>  <p>HiHowAreYouHopeYouAreDoingGoodHiHowAreYouHopeYouAreDoingGoodHiHowAreYouHopeYouAreDoingGoodHiHowAreYouHopeYouAreDoingGood</p>
</div>
</div>

    ","[489, 456, 449, 137, 144, 7, 2, 68, 37, 5, 2, 10, 30, 8, 10, 4, 5, 3, 2, 0, 2, 0, 0, 0, 0, 0, 0]",1292596,87,2010-04-24T07:22:37,2021-09-07 11:39:45Z,html css 
'pip' is not recognized as an internal or external command,"
                
I'm running into a weird error when trying to install Django on my computer.
This is the sequence that I typed into my command line:
C:\Python34> python get-pip.py
Requirement already up-to-date: pip in c:\python34\lib\site-packages
Cleaning up...

C:\Python34> pip install Django
'pip' is not recognized as an internal or external command,
operable program or batch file.

C:\Python34> lib\site-packages\pip install Django
'lib\site-packages\pip' is not recognized as an internal or external command,
operable program or batch file.

What could be causing this?
This is what I get when I type in echo %PATH%:
C:\Python34>echo %PATH%
C:\Program Files\ImageMagick-6.8.8-Q16;C:\Program Files (x86)\Intel\iCLS Client\
;C:\Program Files\Intel\iCLS Client\;C:\Windows\system32;C:\Windows;C:\Windows\S
ystem32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\
Windows Live\Shared;C:\Program Files (x86)\Intel\OpenCL SDK\2.0\bin\x86;C:\Progr
am Files (x86)\Intel\OpenCL SDK\2.0\bin\x64;C:\Program Files\Intel\Intel(R) Mana
gement Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine C
omponents\IPT;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components
\DAL;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\IPT;C:\P
rogram Files (x86)\nodejs\;C:\Program Files (x86)\Heroku\bin;C:\Program Files (x
86)\git\cmd;C:\RailsInstaller\Ruby2.0.0\bin;C:\RailsInstaller\Git\cmd;C:\RailsIn
staller\Ruby1.9.3\bin;C:\Users\Javi\AppData\Roaming\npm

    As of now, version 3.7.3 I had a little bit of an issue with getting the right system variable.
Try this:

Type start %appdata% in cmd.

After that file explorer should pop up in ../AppData/Roaming.


Go back one directory and navigate to Local/Programs/Python/Python37-32/Scripts.

NOTE: The version number may be different so if you copy and paste the above file path it could not work.
After you do this you now have the correct location of your downloaded Python. Copy your file path by selecting the whole directory in the address bar.

Once you do that click the start icon and navigate to the Control Panel → System and Security → System. Then click ""Advanced System Settings"" on the left side of the panel.
Once there, click Environment Variables on the bottom right and there will be two boxes, an upper and a lower box. In the upper box: Click on the 'Path' Variable and click Edit located on the right. Click New and paste your directory Path. It should look something like this:

Click OK three times, open a new window of cmd and type: pip. See if it works.
    You need to add the path of your pip installation to your PATH system variable. By default, pip is installed to C:\Python34\Scripts\pip (pip now comes bundled with new versions of python), so the path ""C:\Python34\Scripts"" needs to be added to your PATH variable.

To check if it is already in your PATH variable, type echo %PATH% at the CMD prompt

To add the path of your pip installation to your PATH variable, you can use the Control Panel or the setx command. For example:

setx PATH ""%PATH%;C:\Python34\Scripts""




Note:
According to the official documentation, ""[v]ariables set with setx variables are available in future command windows only, not in the current command window"". In particular, you will need to start a new cmd.exe instance after entering the above command in order to utilize the new environment variable. 

Thanks to Scott Bartell for pointing this out.
    For Windows, when you install a package, you type:
python -m pip install [packagename]

    The only way that worked on my Windows 10 machine was as follows:
py -3 -m pip install xxxxx

    I was having the same problem just now.
After adding the proper folder (C:\Python33\Scripts) to the path, I still could not get pip to run. All it took was running
pip.exe install -package- instead of
pip install -package-.
    Control Panel -> add/remove programs -> Python -> Modify -> optional Features (you can click everything) then press next -> Check ""Add python to environment variables"" -> Install



And that should solve your path issues, so jump to command prompt and you can use pip now.
    Go to control Panel >> Uninstall or change Program and double click on Python XXX to modify install. Make sure PIP component is checked and install.


    In latest version Python 3.6.2 and above, is available in

C:\Program Files (x86)\Python36-32\Scripts

You can add the path to our environment variable path as below

Make sure you close your command prompt or Git after setting up your path. Also should you open your command prompt in administrator mode. This is example for Windows 10.
    For me the command:
set PATH=%PATH%;C:\Python34\Scripts

worked immediately (try after echo %PATH% and you will see that your path has the value C:\Python34\Scripts).
Thanks to: Adding a directory to the PATH environment variable in Windows
    Alternate way.

If you don't want to add the PATH as the previous well written answers pointed out, 

but you want to execute pip as your command then you can do that with py -m as prefix.

Given that you have to do it again and again.

eg.

py -m <command>


as in

py -m pip install --upgrade pip setuptools


Also make sure to have pip and py installed


    I deleted the older version using the control panel and then installed the new version however the newer version was not reflecting pip even after adding the right paths in the environment variables. However, the thing that worked for me was deleting the folders of old python that were there in the local App folder even after uninstall. For me, the path was like below. Deleting this folder solved my issue
C:\Users\username\AppData\Local\Programs\Python38

    As per Python 3.6 Documentation 


  It is possible that pip does not get installed by default. One
  potential fix is:


python -m ensurepip --default-pip

    I was facing the same issue. Run Windows PowerShell as Administrator. It resolved my issue.

    Try going to Windows PowerShell or cmd prompt and typing:
python -m pip install openpyxl

    Also, the long method - it was a last resort after trying all previous answers:
C:\python27\scripts\pip.exe install [package].whl

This after cd in directory where the wheel is located.
    Most frequently it is: 

in cmd.exe write

python -m pip install --user [name of your module here without brackets]

    Or if you are using PyCharm (2017-03-03) like me, just change directory in terminal and install:
cd C:\Users\{user}\PycharmProjects\test\venv\Scripts
pip install ..

    I have just installed Python 3.6.2.
I got the path as

C:\Users\USERNAME\AppData\Local\Programs\Python\Python36-32\Scripts

    Even I'm new to this, but pip install django worked for me.
The path should be set as where the script folder of the Python installation is, i.e.C:\Python34\Scripts.
I suppose it's because Django is a framework which is based on Python, and that's why this directory structure has to be maintained while installing.
    Use
set Path = `%PATH%;C:\Python34\;C:\Python27\Scripts`

Source
    In your Python folder path in Terminal, just type
  py -m pip

in order to check the current version of your pip.
You will also see a list of commands, you can use...

    None of these actually worked for me, but running
python -m pip install -U pip

and then adding the specified directory to the PATH as suggested got it working
    In Windows, open cmd and find the location of PYTHON_HOME using  where python. Now add this location to your environment variable PATH using:
set PATH=%PATH%;<PYTHON_HOME>\Scripts

Or refer to this.

In Linux, open a terminal and find the location of PYTHON_HOME using which python. Now add the PYTHON_HOME/Scripts to the PATH variable using:
PATH=$PATH:<PYTHON_HOME>\Scripts
export PATH

    For Mac, run the below command in a terminal window:
echo  export ""PATH=$HOME/Library/Python/2.7/bin:$PATH""

    You can try pip3. Something like:
pip3 install pandas

    I think from Python 2.7.9 and higher pip comes pre installed and it will be in your scripts folder.
So you have to add the ""scripts"" folder to the path. Mine is installed in C:\Python27\Scripts. Check yours to see what your path is so that you can alter the below accordingly. Then go to PowerShell, paste the below code in PowerShell and hit Enter key. After that, reboot and your issue will be resolved.
[Environment]::SetEnvironmentVariable(""Path"", ""$env:Path;C:\Python27\Scripts"", ""User"")

    In a Windows environment, just execute the below commands in a DOS shell.

path=%path%;D:\Program Files\python3.6.4\Scripts;
(new path=current path;path of the Python script folder)

    If you are working with Python, e.g. PyCharm, you should install the library to the Python library path like this:
pip install --target=C:\Users\<...>\lib <Library-Name>

real e.g.
pip install --target=C:\Users\devel\AppData\Local\Programs\Python\Python36\Lib requests <br>

PS: If you want to check if it's installed,
<Library-Name> --version

will not work correctly.
    I had this same issue. You just need to go to your 


  C:\Python27\Scripts


and add it to environment variables. After path setting just run pip.exe file on C:\Python27\Scripts and then try pip in cmd. But if nothing happens try running all pip applications like pip2.7 and pip2.exe. And pip will work like a charm.
    Small clarification: in ""Windows 7 64 bit PC"", after adding ...Python34\Scripts to the path variable, pip install pygame didn't work for me.

So I checked the ""...Python34\Scripts"" folder, it didn't have pip, but it had pip3 and pip3.4. So I ran pip3.4 install pygame .... .whl. It worked.

(Further open a command window in the same folder where you have the downloaded pygame...whl file.)
    ","[489, 151, 686, 247, 36, 12, 13, 13, 9, 78, 41, 1, 15, 2, 10, 24, 3, 4, 3, 3, 8, 2, 2, 2, 1, 2, 1, 1, -4, 0, 0]",1922691,141,2014-05-17T07:45:57,2022-04-08 18:04:05Z,python 
No module named MySQLdb,"
                
I am using Python version 2.5.4 and install MySQL version 5.0 and Django. Django is working fine with Python, but not MySQL. I am using it in Windows Vista.
    You need to use one of the following commands. Which one depends on what OS and software you have and use.


easy_install mysql-python (mix os)
pip install mysql-python (mix os/ python 2)
pip install mysqlclient (mix os/ python 3)
apt-get install python-mysqldb (Linux Ubuntu, ...)
cd /usr/ports/databases/py-MySQLdb && make install clean (FreeBSD)
yum install MySQL-python (Linux Fedora, CentOS ...)


For Windows, see this answer: Install mysql-python (Windows)
    For Python 3.6+
sudo apt-get install libmysqlclient-dev
pip3 install mysqlclient

does the trick
    For anyone coming to this page when trying to find a solution for sqlalchemy, all you need to do is:
pip install PyMySQL

And adjust your connection string to use PyMySQL, from mysql:// to mysql+pymysql://.
    I am at ubuntu (linux) and what worked for me was

sudo apt-get install python3-dev default-libmysqlclient-dev build-essential


and then finally

pip install mysqlclient

    ...and remember there is no MySQLdb for python3.x

(I know the question is about python2.x but google rates this post quite high)



EDIT: As stated in the comments, there's a MySQLdb's fork that adds Python 3 support: github.com/PyMySQL/mysqlclient-python

    if your python version is 3.5, do a pip install mysqlclient, other things didn't work for me
    Python 3.8
sudo apt-get install libmysqlclient-dev
sudo apt-get install -y python3-mysqldb

pip3 install pymysql

settings.py
import pymysql
pymysql.install_as_MySQLdb()

    for Windows :
pip install mysqlclient pymysql

then:
import pymysql
pymysql.install_as_MySQLdb()

for python 3 Ubuntu
sudo apt-get install -y python3-mysqldb

    If pip install mysqlclient produces an error and you use Ubuntu, try:

sudo apt-get install -y python-dev libmysqlclient-dev && sudo pip install mysqlclient

    Python 3
Make sure the import order:
#BAD
import MySQLdb             # <------ NOT here
import pymysql
pymysql.install_as_MySQLdb()

#GOOD
import pymysql
pymysql.install_as_MySQLdb()
import MySQLdb              # <------- HERE!

    Note this is not tested for python 3.x
In CMD
pip install wheel
pip install pymysql

in settings.py
import pymysql
pymysql.install_as_MySQLdb()

It worked with me
    If you are running on Vista, you may want to check out the Bitnami Django stack. It is an all-in-one stack of Apache, Python, MySQL, etc. packaged with Bitrock crossplatform installers to make it really easy to get started. It runs on Windows, Mac and Linux. Oh, and is completely free :)
    pip install PyMySQL


and then add this two lines to your Project/Project/init.py

import pymysql
pymysql.install_as_MySQLdb()


Works on WIN and python 3.3+
    On Debian Buster, the following solution worked for me with python 3.7:

sudo apt-get install libmysqlclient-dev
sudo apt-get install libssl-dev
pip install mysqlclient

    I personally recommend using pymysql instead of using the genuine MySQL connector, which provides you with a platform independent interface and could be installed through pip.

And you could edit the SQLAlchemy URL schema like this:
mysql+pymysql://username:passwd@host/database
    Ubuntu: 

sudo apt-get install python-mysqldb

    None of the above worked for me on an Ubuntu 18.04 fresh install via docker image.

The following solved it for me:

apt-get install holland python3-mysqldb
    pip install --user mysqlclient 


above works for me like charm for me.I go the error from sqlalchemy actually.
Environment information :

Python : 3.6, Ubuntu : 16.04,conda 4.6.8
    mysqldb is a module for Python that doesn't come pre-installed or with Django. You can download mysqldb here.
    Try this. 

pip install MySQL-python

    I met the same situation under windows, and searched for the solution.

Seeing this post Install mysql-python (Windows).

It points out installing such a pip environment is difficult, needs many other dependencies.

But I finally know that if we use mysqlclient with a version down to 1.3.4, it don't need that requirements any more, so try:

pip install mysqlclient==1.3.4

    If your are using SQLAlchemy and the error is in /site-packages/sqlalchemy/dialects/mysql/mysqldb.py:

from ...connectors.mysqldb import (
                        MySQLDBExecutionContext,
                        MySQLDBCompiler,
                        MySQLDBIdentifierPreparer,
                        MySQLDBConnector
                    )


so you may have missed mysqldb connector for SQLAlchemy and the solution is to re-install sqlalchemy after installing mysql-python module.
    Thanks to derevo but I think there's another good way for doing this:


Download and install ActivePython
Open Command Prompt
Type pypm install mysql-python
Read the notes specific to this package.


I think pypm is more powerful and reliable than easy_install.
    I have tried methods above, but still no module named 'MySQLdb', finally, I succeed with 

easy_install mysql-python


my env is unbuntu 14.04
    On OSX these commands worked for me

brew install mysql-connector-c 
pip install MySQL-python

    On my mac running Catalina v10.15.2, I had the following MySQLdb version conflict:

ImportError: this is MySQLdb version (1, 2, 5, 'final', 1), but _mysql is version (1, 4, 6, 'final', 0)


To resolve it, I did the following:

pip uninstall MySQL-python
pip install MySQL-python

    Faced this issue with mysql.connector.python version 8.0.24 on mac(if code base is same then the issue should happen in windows as well). This file on line 51 imports ""from django.db.backends.mysql.base import DatabaseWrapper as MySQLDatabaseWrapper"".  The imported file has following code 14-20(exact code and error that you received is part of code
try:
    import MySQLdb as Database
except ImportError as err:
    raise ImproperlyConfigured(
        'Error loading MySQLdb module.\n'
        'Did you install mysqlclient?'
    ) from err

The error is formed here. Not sure why this import keeps coming back in different version of mysql connector but 8.0.23 does not have the import, so I reverted to that version and error was gone... This is incase you wish to continue to work with mysql.connector.python
    
Go to your project directory with cd.
source/bin/activate (activate your env. if not previously).
Run the command easy_install MySQL-python

    For Python 3+ version

install mysql-connector as:

pip3 install mysql-connector 


Sample Python DB connection code:

import mysql.connector
db_connection = mysql.connector.connect(
  host=""localhost"",
  user=""root"",
  passwd=""""
)
print(db_connection)


Output:

> <mysql.connector.connection.MySQLConnection object at > 0x000002338A4C6B00>


This means, database is correctly connected.
    Win10 / Python27
this worked for me:

easy_install mysql-python


all other 'pip install...' failed with dependency errors
    ","[489, 715, 8, 16, 23, 169, 92, 6, 22, 13, 3, 31, 4, 18, 3, 6, 36, 2, 6, 49, 13, 7, 2, 4, 2, 2, 1, 1, 5, 3, 0]",795210,103,2009-01-18T09:13:38,2022-03-27 10:31:48Z,python 
How to check if a column exists in Pandas,"
                
Is there a way to check if a column exists in a Pandas DataFrame?

Suppose that I have the following DataFrame:

>>> import pandas as pd
>>> from random import randint
>>> df = pd.DataFrame({'A': [randint(1, 9) for x in xrange(10)],
                       'B': [randint(1, 9)*10 for x in xrange(10)],
                       'C': [randint(1, 9)*100 for x in xrange(10)]})
>>> df
   A   B    C
0  3  40  100
1  6  30  200
2  7  70  800
3  3  50  200
4  7  50  400
5  4  10  400
6  3  70  500
7  8  30  200
8  3  40  800
9  6  60  200


and I want to calculate df['sum'] = df['A'] + df['C']

But first I want to check if df['A'] exists, and if not, I want to calculate df['sum'] = df['B'] + df['C'] instead.
    This will work:

if 'A' in df:


But for clarity, I'd probably write it as:

if 'A' in df.columns:

    To check if one or more columns all exist, you can use set.issubset, as in:
if set(['A','C']).issubset(df.columns):
   df['sum'] = df['A'] + df['C']                

As @brianpck points out in a comment, set([]) can alternatively be constructed with curly braces,
if {'A', 'C'}.issubset(df.columns):

See this question for a discussion of the curly-braces syntax.
Or, you can use a generator comprehension, as in:
if all(item in df.columns for item in ['A','C']):

    You can use the set's method issuperset:
set(df).issuperset(['A', 'B'])
# set(df.columns).issuperset(['A', 'B'])

    Just to suggest another way without using if statements, you can use the get() method for DataFrames. For performing the sum based on the question:

df['sum'] = df.get('A', df['B']) + df['C']


The DataFrame get method has similar behavior as python dictionaries.
    ","[489, 977, 158, 5, 18]",438401,68,2014-07-21T16:43:02,2022-02-21 15:39:49Z,python 
How to make VS Code treat a file extensions as a certain language?,"
                
Or is there a way to switch the current file's language so that the syntax is highlighted correctly?
For example, *.jsx is actually JavaScript but VS Code doesn't recognize it.
    The easiest way I've found for a global association is simply to Ctrl+k m (or Ctrl+Shift+P and type ""change language mode"") with a file of the type you're associating open.
In the first selections will be the option ""Configure File Association for 'x' "" (whatever file type - see image attached). Selecting this gives you the option to choose the language and will then make the filetype association permanent.

This may have changed (probably did) since the original question and accepted answer (and I don't know when it changed) but it's so much easier than the manual editing steps in the accepted and some of the other answers, and totaly avoids having to muss with IDs that may not be obvious.
    Update
Please note that JoelAZ's answer is much easier and results in the same setting changes! The answer below is still valid, just more steps & more fuss.
Old answer
In Visual Studio Code, you can add persistent file associations for language highlighting to your settings.json file like this:
// Place your settings in this file to overwrite the default settings
{
  ""some_setting"": custom_value,
  ...

  ""files.associations"": {
    ""*.thor"": ""ruby"",
    ""*.jsx"": ""javascript"",
    ""Jenkinsfile*"": ""groovy""
  }
}

You can use Ctrl+Shift+P (or View -> Command Palette from the menu) and then type settings JSON. Choose Preferences: Open Settings (JSON) to open your settings.json.
To find the proper language ID, use Ctrl+Shift+P (or View -> Command Palette from the menu) and then type Change Language Mode. You can see the language ID in the list, e.g. type docker to find the language ID for Docker files (dockerfile). In the first entry in the example above, .thor is the file ending, ruby is the language ID.
The Files: Associations feature was first introduced in Visual Studio Code version 1.0 (March 2016). Check the available wildcard patterns in the release notes and the known language strings in the documentation.
    Hold down Ctrl+Shift+P (or cmd on Mac), select ""Change Language Mode"" and there it is.

But I still can't find a way to make VS Code recognized files with specific extension as some certain language.
    This works for me.



{
""files.associations"": {""*.bitesize"": ""yaml""}
 }

    eg:

// .vscode/settings.json in workspace

{
  ""files.associations"": {
    ""*Container.js"": ""javascriptreact"",
    ""**/components/*/*.js"": ""javascriptreact"",
    ""**/config/routes.js"": ""javascriptreact""
  }
}

    Following the steps on  https://code.visualstudio.com/docs/customization/colorizer#_common-questions worked well for me:


  To extend an existing colorizer, you would create a simple
  package.json in a new folder under .vscode/extensions and provide the
  extensionDependencies attribute specifying the customization you want
  to add to. In the example below, an extension .mmd is added to the
  markdown colorizer. Note that not only must the extensionDependency
  name match the customization but also the language id must match the
  language id of the colorizer you are extending.


{
    ""name"": ""MyMarkdown"",
    ""version"": ""0.0.1"",
    ""engines"": {
        ""vscode"": ""0.10.x""
    },
    ""publisher"": ""none"",
    ""extensionDependencies"": [
        ""markdown""
    ],
    ""contributes"": {
        ""languages"": [{
            ""id"": ""markdown"",
            ""aliases"": [""mmd""],
            ""extensions"": ["".mmd""]
        }]
    }
}

    I have followed a different approach to solve pretty much the same problem, in my case, I made a new extension that adds PHP syntax highlighting support for Drupal-specific files (such as .module and .inc): https://github.com/mastazi/VS-code-drupal

As you can see in the code, I created a new extension rather than modifying the existing PHP extension. Obviously I declare a dependency on the PHP extension in the Drupal extension.

The advantage of doing it this way is that if there is an update to the PHP extension, my custom support for Drupal doesn't get lost in the update process.
    You can add the md.html extension to your settings.json file associations to enable markdown formatting for markdeep files like this:
    ""files.associations"": {
        ""*.md.html"": ""markdown""
    },

The settings.json file lives in various locations, depending on your OS. For instance it is ~/Library/Application Support/Code/User/settings.json in macOS.
You can open and edit it with Ctrl+Shift+p in VS Code.
    This, for example, will make files ending in .variables and .overrides being treated just like any other LESS file. In terms of code coloring, in terms of (auto) formatting. Define in user settings or project settings, as you like.



(Semantic UI uses these weird extensions, in case you wonder)
    I found solution here: https://code.visualstudio.com/docs/customization/colorizer

Go to VS_CODE_FOLDER/resources/app/extensions/ and there update package.json
    ","[489, 200, 675, 150, 23, 51, 10, 6, 7, 12, 11]",182885,77,2015-04-30T16:57:30,2021-12-06 09:56:09Z,
CSS Box Shadow Bottom Only [duplicate],"
                    
            
        
            
                
                    
                        This question already has answers here:
                        
                    
                
            
                    
                        How to create a drop shadow only on one side of an element?
                            
                                (16 answers)
                            
                    
                Closed 8 years ago.
        

    

How can I do this? I want my element to look as though it has a shadow underline. I don't want the shadow for the other 3 sides.
    Do this:                    

box-shadow: 0 4px 2px -2px gray;


It's actually much simpler, whatever you set the blur to (3rd value), set the spread (4th value) to the negative of it.
    You can use two elements, one inside the other, and give the outer one overflow: hidden and a width equal to the inner element together with a bottom padding so that the shadow on all the other sides are ""cut off""

#outer {
    width: 100px;
    overflow: hidden;
    padding-bottom: 10px;
}

#outer > div {
    width: 100px;
    height: 100px;
    background: orange;

    -moz-box-shadow: 0 4px 4px rgba(0, 0, 0, 0.4);
    -webkit-box-shadow: 0 4px 4px rgba(0, 0, 0, 0.4);
    box-shadow: 0 4px 4px rgba(0, 0, 0, 0.4);
}


Alternatively, float the outer element to cause it to shrink to the size of the inner element. See: http://jsfiddle.net/QJPd5/1/
    Try this 

-moz-box-shadow:0 5px 5px rgba(182, 182, 182, 0.75);
-webkit-box-shadow: 0 5px 5px rgba(182, 182, 182, 0.75);
box-shadow: 0 5px 5px rgba(182, 182, 182, 0.75);


You can see it in http://jsfiddle.net/wJ7qp/
    try this to get the box-shadow under your full control.

    <html>

    <head>
        <style> 
            div {
                width:300px;
                height:100px;
                background-color:yellow;
                box-shadow: 0 10px black inset,0 -10px red inset, -10px 0 blue inset, 10px 0 green inset;
           }
        </style>
    </head>
    <body>
        <div>
        </div>
    </body>

    </html>


this would apply to outer box-shadow as well.
    ","[489, 1044, 58, 26, 11]",765752,84,2010-12-30T08:25:49,2019-06-24 15:00:33Z,css 
Returning value that was passed into a method,"
                
I have a method on an interface:

string DoSomething(string whatever);


I want to mock this with MOQ, so that it returns whatever was passed in - something like:

_mock.Setup( theObject => theObject.DoSomething( It.IsAny<string>( ) ) )
   .Returns( [the parameter that was passed] ) ;


Any ideas?
    You can use a lambda with an input parameter, like so:

.Returns((string myval) => { return myval; });


Or slightly more readable:

.Returns<string>(x => x);

    Even more useful, if you have multiple parameters you can access any/all of them with:

_mock.Setup(x => x.DoSomething(It.IsAny<string>(),It.IsAny<string>(),It.IsAny<string>())
     .Returns((string a, string b, string c) => string.Concat(a,b,c));


You always need to reference all the arguments, to match the method's signature, even if you're only going to use one of them.
    The generic Returns<T> method can handle this situation nicely.

_mock.Setup(x => x.DoSomething(It.IsAny<string>())).Returns<string>(x => x);


Or if the method requires multiple inputs, specify them like so:

_mock.Setup(x => x.DoSomething(It.IsAny<string>(), It.IsAny<int>())).Returns((string x, int y) => x);

    ","[489, 669, 324, 87]",171393,44,2009-06-15T15:00:50,2018-03-29 10:42:17Z,c 
grep a tab in UNIX,"
                
How do I grep tab (\t) in files on the Unix platform?
    The trick is to use $ sign before single quotes. It also works for cut and other tools.

grep $'\t' sample.txt

    If using GNU grep, you can use the Perl-style regexp:

grep -P '\t' *

    

Another way of inserting the tab literally inside the expression is using the lesser-known $'\t' quotation in Bash:
grep $'foo\tbar'        # matches eg. 'foo<tab>bar'

(Note that if you're matching for fixed strings you can use this with -F mode.)
Sometimes using variables can make the notation a bit more readable and manageable:
tab=$'\t'               # `tab=$(printf '\t')` in POSIX
id='[[:digit:]]\+'
name='[[:alpha:]_][[:alnum:]_-]*'
grep ""$name$tab$id""     # matches eg. `bob2<tab>323`

    From this answer on Ask Ubuntu:


  Tell grep to use the regular expressions as defined by Perl (Perl has
  \t as tab):

grep -P ""\t"" <file name>

  
  Use the literal tab character:

grep ""^V<tab>"" <filename>

  
  Use printf to print a tab character for you:

grep ""$(printf '\t')"" <filename>


    I never managed to make the '\t' metacharacter work with grep.
However I found two alternate solutions:


Using <Ctrl-V> <TAB> (hitting Ctrl-V then typing tab)
Using awk: foo | awk '/\t/'

    One way is (this is with Bash)

grep -P '\t'


-P turns on Perl regular expressions so \t will work.

As user unwind says, it may be specific to GNU grep. The alternative is to literally insert a tab in there if the shell, editor or terminal will allow it.
    On ksh I used 

grep ""[^I]"" testfile

    A good choice is to use sed.
sed -n '/\t/p' file

Examples (works in bash, sh, ksh, csh,..):
[~]$ cat testfile
12 3
1 4 abc
xa      c
        a       c\2
1 23


[~]$ sed -n '/\t/p' testfile 
xa      c
        a       c\2
[~]$ sed -n '/\ta\t/p' testfile
        a       c\2

(This answer has been edited following suggestions in comments. Thank you all)
    Use echo to insert the tab for you grep ""$(echo -e \\t)""
    grep ""$(printf '\t')"" worked for me on Mac OS X
    There are basically two ways to address it:


(Recommended) Use regular expression syntax supported by grep(1). Modern grep(1) supports two forms of POSIX 1003.2 regex syntax: basic (obsolete) REs, and modern REs. Syntax is described in details on re_format(7) and regex(7) man pages which are part of BSD and Linux systems respectively. The GNU grep(1) also supports Perl-compatible REs as provided by the pcre(3) library. 

In regex language the tab symbol is usually encoded by \t atom. The atom is supported by BSD extended regular expressions (egrep, grep -E on BSD compatible system), as well as Perl-compatible REs (pcregrep, GNU grep -P).

Both basic regular expressions and Linux extended REs apparently have no support for the \t. Please consult UNIX utility man page to know which regex language it supports (hence the difference between sed(1), awk(1), and pcregrep(1) regular expressions).

Therefore, on Linux:

$ grep -P '\t' FILE ...


On BSD alike system:

$ egrep '\t' FILE ...
$ grep -E '\t' FILE ...

Pass the tab character into pattern. This is straightforward when you edit a script file:

# no tabs for Python please!
grep -q '   ' *.py && exit 1


However, when working in an interactive shell you may need to rely on shell and terminal capabilities to type the proper symbol into the line. On most terminals this can be done through Ctrl+V key combination which instructs terminal to treat the next input character literally (the V is for ""verbatim""):

$ grep '<Ctrl>+<V><TAB>' FILE ...


Some shells may offer advanced support for command typesetting. Such, in bash(1) words of the form $'string' are treated specially:

bash$ grep $'\t' FILE ...


Please note though, while being nice in a command line this may produce compatibility issues when the script will be moved to another platform. Also, be careful with quotes when using the specials, please consult bash(1) for details.

For Bourne shell (and not only) the same behaviour may be emulated using command substitution augmented by printf(1) to construct proper regex:

$ grep ""`printf '\t'`"" FILE ...


    use gawk, set the field delimiter to tab (\t) and check for number of fields. If more than 1, then there is/are tabs

awk -F""\t"" 'NF>1' file

    Look for blank spaces many times [[:space:]]* 

grep [[:space:]]*'.''.'

Will find something like this:

'the tab' ..

These are single quotations ('), and not double (""). This is how you make concatenation in grep. =-)
    You can type 
grep \t foo
or


grep '\t' foo


to search for the tab character in the file foo.  You can probably also do other escape codes, though I've only tested \n.  Although it's rather time-consuming, and unclear why you would want to, in zsh you can also type the tab character, back to the begin, grep and enclose the tab with quotes.
    +1 way, that works in ksh, dash, etc: use printf to insert TAB:

grep ""$(printf 'BEGIN\tEND')"" testfile.txt

    The answer is simpler. Write your grep and within the quote type the tab key, it works well at least in ksh

grep ""  "" *

    Using the 'sed-as-grep' method, but replacing the tabs with a visible character of personal preference is my favourite method, as it clearly shows both which files contain the requested info, and also where it is placed within lines:

sed -n 's/\t/\*\*\*\*/g' file_name


If you wish to make use of line/file info, or other grep options, but also want to see the visible replacement for the tab character, you can achieve this by

grep -[options] -P '\t' file_name | sed 's/\t/\*\*\*\*/g'


As an example:

$ echo ""A\tB\nfoo\tbar"" > test
$ grep -inH -P '\t' test | sed 's/\t/\*\*\*\*/g'
test:1:A****B
test:2:foo****bar


EDIT: Obviously the above is only useful for viewing file contents to locate tabs --- if the objective is to handle tabs as part of a larger scripting session, this doesn't serve any useful purpose.
    This works well for AIX. I am searching for lines containing JOINED<\t>ACTIVE

voradmin cluster status | grep  JOINED$'\t'ACTIVE

 vorudb201   1       MEMBER(g) JOINED        ACTIVE
*vorucaf01   2       SECONDARY JOINED        ACTIVE

    You might want to use grep ""$(echo -e '\t')""

Only requirement is echo to be capable of interpretation of backslash escapes.
    These alternative binary identification methods are totally functional. And, I really like the one's using awk, as I couldn't quite remember the syntaxic use with single binary chars. However, it should also be possible to assign a shell variable a value in a POSIX portable fashion (i.e. TAB=echo ""@"" | tr ""\100"" ""\011""), and then employ it from there everywhere, in a POSIX portable fashion; as well (i.e grep ""$TAB"" filename). While this solution works well with TAB, it will also work well other binary chars, when another desired binary value is used in the assignment (instead of the value for the TAB character to 'tr').
    The $'\t' notation given in other answers is shell-specific -- it seems to work in bash and zsh but is not universal.

NOTE: The following is for the fish shell and does not work in bash:

In the fish shell, one can use an unquoted \t, for example:

grep \t foo.txt


Or one can use the hex or unicode notations e.g.:

grep \X09 foo.txt
grep \U0009 foo.txt


(these notations are useful for more esoteric characters)

Since these values must be unquoted, one can combine quoted and unquoted values by concatenation:

grep ""foo""\t""bar""

    You can also use a Perl one-liner instead of grep resp. grep -P:
perl -ne 'print if /\t/' FILENAME

    ","[489, 382, 425, 24, 49, 95, 33, 1, 4, 8, 5, 8, 2, -6, -5, 2, 0, 0, 0, 0, 0, 0, 0]",311439,58,2009-12-01T11:23:13,2021-12-15 09:02:34Z,
React - changing an uncontrolled input,"
                
I have a simple react component with the form which I believe to have one controlled input:

import React from 'react';

export default class MyForm extends React.Component {
    constructor(props) {
        super(props);
        this.state = {}
    }

    render() {
        return (
            <form className=""add-support-staff-form"">
                <input name=""name"" type=""text"" value={this.state.name} onChange={this.onFieldChange('name').bind(this)}/>
            </form>
        )
    }

    onFieldChange(fieldName) {
        return function (event) {
            this.setState({[fieldName]: event.target.value});
        }
    }
}

export default MyForm;


When I run my application I get the following warning:


  Warning: MyForm is changing an uncontrolled input of type text to be
  controlled. Input elements should not switch from uncontrolled to
  controlled (or vice versa). Decide between using a controlled or
  uncontrolled input element for the lifetime of the component


I believe my input is controlled since it has a value.  I am wondering what am I doing wrong?

I am using React 15.1.0
    
  I believe my input is controlled since it has a value.


For an input to be controlled, its value must correspond to that of a state variable.

That condition is not initially met in your example because this.state.name is not initially set. Therefore, the input is initially uncontrolled. Once the onChange handler is triggered for the first time, this.state.name gets set. At that point, the above condition is satisfied and the input is considered to be controlled. This transition from uncontrolled to controlled produces the error seen above.

By initializing this.state.name in the constructor:

e.g.

this.state = { name: '' };


the input will be controlled from the start, fixing the issue. See React Controlled Components for more examples.

Unrelated to this error, you should only have one default export. Your code above has two.
    When you first render your component, this.state.name isn't set, so it evaluates to undefined or null, and you end up passing value={undefined} or  value={null}to your input.

When ReactDOM checks to see if a field is controlled, it checks to see if value != null (note that it's !=, not !==), and since undefined == null in JavaScript, it decides that it's uncontrolled.

So, when onFieldChange() is called, this.state.name is set to a string value, your input goes from being uncontrolled to being controlled.

If you do this.state = {name: ''} in your constructor, because '' != null, your input will have a value the whole time, and that message will go away.
    I had the same problem.
the problem was when i kept the state info blank
  const [name, setName] = useState()

I fixed it by adding empty string like this
  const [name, setName] = useState('')

    Another approach it could be setting the default value inside your input, like this:

 <input name=""name"" type=""text"" value={this.state.name || ''} onChange={this.onFieldChange('name').bind(this)}/>

    
I believe my input is controlled since it has a value.

Now you can do this two ways the best way is to have a state key to each input with 1 onChange handler. If you have checkboxes you will need to write a separate onChange handler.
With a Class component you would want to write it like this 👇

import React from 'react';

export default class MyForm extends React.Component {
    constructor(props) {
        super(props);
        this.state = {
         myFormFields: {
           name: '',
           dob: '',
           phone: ''
         }
        }

      this.onFormFieldChange = this.onFormFieldChange.bind(this)
    }


// Always have your functions before your render to keep state batches in sync.
    onFormFieldChange(e) {
       // No need to return this function can be void
       this.setState({
         myFormFields: {
            ...this.state.myFormFields,
            [e.target.name]: e.target.value 
         }
       })
    }


    render() {
       // Beauty of classes we can destruct our state making it easier to place
       const { myFormFields } = this.state
      
        return (
            <form className=""add-support-staff-form"">
                <input name=""name"" type=""text"" value={myFormFields.name} onChange={this.onFormFieldChange}/>
                <input name=""dob"" type=""date"" value={myFormFields.dob} onChange={this.onFormFieldChange}/>
                <input name=""phone"" type=""number"" value={myFormFields.phone} onChange={this.onFormFieldChange}/>
            </form>
        )
    }

}

export default MyForm;

Hope that helps for a class but the most performative and what the newest thing the devs are pushing everyone to use is Functional Components.  This is what you would want to steer to as class components don't intertwine well with the latest libraries as they all use custom hooks now.
To write as a Functional Component

import React, { useState } from 'react';

const MyForm = (props) => {
    // Create form initial state
    const [myFormFields, setFormFields] = useState({
       name: '',
       dob: '',
       phone: ''
    })


   // Always have your functions before your return to keep state batches in sync.
    const onFormFieldChange = (e) => {
       // No need to return this function can be void
       setFormFields({
         ...myFormFields,
         [e.target.name]: e.target.value 
       })
    }

      
       return (
            <form className=""add-support-staff-form"">
                <input name=""name"" type=""text"" value={myFormFields.name} onChange={onFormFieldChange}/>
                <input name=""dob"" type=""date"" value={myFormFields.dob} onChange={onFormFieldChange}/>
                <input name=""phone"" type=""number"" value={myFormFields.phone} onChange={onFormFieldChange}/>
            </form>
        )

}

export default MyForm;

Hope this helps! 😎
    In short, if you are using class component you have to initialize the input using state, like this:
this.state = { the_name_attribute_of_the_input: ""initial_value_or_empty_value"" };

and you have to do this for all of your inputs you'd like to change their values in code.
In the case of using functional components, you will be using hooks to manage the input value, and you have to put initial value for each input you'd like to manipulate later like this:
const [name, setName] = React.useState({name: 'initialValue'});

If you'd like to have no initial value, you can put an empty string.
    Simply create a fallback to '' if the this.state.name is null. 

<input name=""name"" type=""text"" value={this.state.name || ''} onChange={this.onFieldChange('name').bind(this)}/>


This also works with the useState variables.
    I know others have answered this already. But a very important factor here that may help other people experiencing similar issue:

You must have an onChange handler added in your input field (e.g. textField, checkbox, radio, etc). Always handle activity through the onChange handler. 

Example: 

<input ... onChange={ this.myChangeHandler} ... />


When you are working with checkbox you may need to handle its checked state with !!.

Example:

<input type=""checkbox"" checked={!!this.state.someValue} onChange={.....} >



  Reference: https://github.com/facebook/react/issues/6779#issuecomment-326314716

    If the props on your component was passed as a state, put a default value for your input tags

<input type=""text"" placeholder={object.property} value={object.property ? object.property : """"}>

    Simple solution to resolve this problem is to set an empty value by default : 

<input name='myInput' value={this.state.myInput || ''} onChange={this.handleChange} />

    In my case, I was missing something really trivial. 

<input value={state.myObject.inputValue} />

My state was the following when I was getting the warning:

state = {
   myObject: undefined
}


By alternating my state to reference the input of my value, my issue was solved:

state = {
   myObject: {
      inputValue: ''
   }
}

    In my case component was rerendering and throwing A component is changing an uncontrolled input of type checkbox to be controlled error. It turned out that this behaviour was a result of not keeping true or false for checkbox checked state (sometimes I got undefined). Here what my faulty component looked like:
import * as React from 'react';
import { WrappedFieldProps } from 'redux-form/lib/Field';

type Option = {
  value: string;
  label: string;
};

type CheckboxGroupProps = {
  name: string;
  options: Option[];
} & WrappedFieldProps;


const CheckboxGroup: React.FC<CheckboxGroupProps> = (props) => {

  const {
    name,
    input,
    options,
  } = props;

  const [value, setValue] = React.useState<string>();
  const [checked, setChecked] = React.useState<{ [name: string]: boolean }>(
    () => options.reduce((accu, option) => {
      accu[option.value] = false;
      return accu;
    }, {}),
  );

  React.useEffect(() => {
    input.onChange(value);

    if (value) {
      setChecked({
        [value]: true, // that setChecked argument is wrong, causes error
      });
    } else {
      setChecked(() => options.reduce((accu, option) => {
        accu[option.value] = false;
        return accu;
      }, {}));
    }

  }, [value]);

  return (
    <>
      {options.map(({ value, label }, index) => {
        return (
          <LabeledContainer
            key={`${value}${index}`}
          >
            <Checkbox
              name={`${name}[${index}]`}
              checked={checked[value]}
              value={value}
              onChange={(event) => {
                if (event.target.checked) {
                  setValue(value);
                } else {
                  setValue(undefined);
                }
                return true;
              }}
            />
            {label}
          </LabeledContainer>
        );
      })}
    </>
  );
};

To fix that problem I changed useEffect to this
React.useEffect(() => {
  input.onChange(value);

  setChecked(() => options.reduce((accu, option) => {
      accu[option.value] = option.value === value;
      return accu;
    }, {}));

}, [value]);


That made all checkboxes keep their state as true or false without falling into undefined which switches control from React to developer and vice versa.
    For people using Formik, you need to add a default value for the specific field name to the form's initialValues.
    An update for this. For React Hooks use const [name, setName] = useState("" "")
    Please try this code
import React from ""react"";

class MyForm extends React.Component {
    constructor(props) {
        super(props);
        this.state = { name: """" };
        this.onFieldChange = this.onFieldChange.bind(this);
    }

    onFieldChange(e) {
        this.setState({[e.target.name]: e.target.value});
    }

    render() {
        return (
            <form className=""add-support-staff-form"">
                <input name=""name"" type=""text"" value={this.state.name} onChange={this.onFieldChange} />
        </form>
        );
    }
}

export default MyForm;

    One potential downside with setting the field value to """" (empty string) in the constructor is if the field is an optional field and is left unedited. Unless you do some massaging before posting your form, the field will be persisted to your data storage as an empty string instead of NULL. 

This alternative will avoid empty strings:

constructor(props) {
    super(props);
    this.state = {
        name: null
    }
}

... 

<input name=""name"" type=""text"" value={this.state.name || ''}/>

    Set a value to 'name' property in initial state.

this.state={ name:''};

    When you use onChange={this.onFieldChange('name').bind(this)} in your input you must declare your state empty string as a value of property field.

incorrect way:

this.state ={
       fields: {},
       errors: {},
       disabled : false
    }


correct way:

this.state ={
       fields: {
         name:'',
         email: '',
         message: ''
       },
       errors: {},
       disabled : false
    }

    This generally happens only when you are not controlling the value of the filed when the application started and after some event or some function fired or the state changed, you are now trying to control the value in input field. 

This transition of not having control over the input and then having control over it is what causes the issue to happen in the first place.

The best way to avoid this is by declaring some value for the input in the constructor of the component. 
So that the input element has value from the start of the application. 
    For dynamically setting state properties for form inputs and keeping them controlled you could do something like this:

const inputs = [
    { name: 'email', type: 'email', placeholder: ""Enter your email""},
    { name: 'password', type: 'password', placeholder: ""Enter your password""},
    { name: 'passwordConfirm', type: 'password', placeholder: ""Confirm your password""},
]

class Form extends Component {
  constructor(props){
    super(props)
    this.state = {} // Notice no explicit state is set in the constructor
  }

  handleChange = (e) => {
    const { name, value } = e.target;

    this.setState({
      [name]: value
    }
  }

  handleSubmit = (e) => {
    // do something
  }

  render() {
     <form onSubmit={(e) => handleSubmit(e)}>
       { inputs.length ?
         inputs.map(input => {
           const { name, placeholder, type } = input;
           const value = this.state[name] || ''; // Does it exist? If so use it, if not use an empty string

           return <input key={name}  type={type} name={name} placeholder={placeholder} value={value} onChange={this.handleChange}/>
       }) :
         null
       }
       <button type=""submit"" onClick={(e) => e.preventDefault }>Submit</button>
     </form>    
  }
}

    ","[489, 631, 165, 3, 72, 5, 1, 5, 28, 7, 20, 9, 3, 3, 5, 2, 10, 6, 8, 2, 0]",343244,88,2016-05-25T03:50:59,2022-02-14 15:25:47Z,javascript 
Circular (or cyclic) imports in Python,"
                
What will happen if two modules import each other?

To generalize the problem, what about the cyclic imports in Python?
    If you do import foo (inside bar.py) and import bar (inside foo.py), it will work fine. By the time anything actually runs, both modules will be fully loaded and will have references to each other.
The problem is when instead you do from foo import abc (inside bar.py) and from bar import xyz (inside foo.py). Because now each module requires the other module to already be imported (so that the name we are importing exists) before it can be imported.
    There was a really good discussion on this over at comp.lang.python last year. It answers your question pretty thoroughly.


  Imports are pretty straightforward really. Just remember the following:
  
  'import' and 'from xxx import yyy' are executable statements. They execute
  when the running program reaches that line.
  
  If a module is not in sys.modules, then an import creates the new module
  entry in sys.modules and then executes the code in the module. It does not
  return control to the calling module until the execution has completed.
  
  If a module does exist in sys.modules then an import simply returns that
  module whether or not it has completed executing. That is the reason why
  cyclic imports may return modules which appear to be partly empty.
  
  Finally, the executing script runs in a module named __main__, importing
  the script under its own name will create a new module unrelated to
  __main__.
  
  Take that lot together and you shouldn't get any surprises when importing
  modules. 

    To my surprise, no one has mentioned cyclic imports caused by type hints yet.
If you have cyclic imports only as a result of type hinting, they can be avoided in a clean manner.
Consider main.py which makes use of exceptions from another file:
from src.exceptions import SpecificException

class Foo:
    def __init__(self, attrib: int):
        self.attrib = attrib

raise SpecificException(Foo(5))

And the dedicated exception class exceptions.py:
from src.main import Foo

class SpecificException(Exception):
    def __init__(self, cause: Foo):
        self.cause = cause

    def __str__(self):
        return f'Expected 3 but got {self.cause.attrib}.'

This will trivially raise an ImportError as main.py imports exception.py and vice versa through Foo and SpecificException.
Because Foo is only required in exceptions.py during type checking, we can safely make its import conditional using the TYPE_CHECKING constant from the typing module. The constant is only True during type checking, which allows us to conditionally import Foo and thereby avoid the circular import error.
In Python 3.6, with the use of forward references:
from typing import TYPE_CHECKING
if TYPE_CHECKING:  # Only imports the below statements during type checking
   ​from src.main import Foo

class SpecificException(Exception):
   ​def __init__(self, cause: 'Foo'):  # The quotes make Foo a forward reference
       ​self.cause = cause

   ​def __str__(self):
       ​return f'Expected 3 but got {self.cause.attrib}.'

In Python 3.7+, postponed evaluation of annotations (introduced in PEP 563) allows 'normal' types to be used instead of forward references:
from __future__ import annotations
from typing import TYPE_CHECKING
if TYPE_CHECKING:  # Only imports the below statements during type checking
   ​from src.main import Foo

class SpecificException(Exception):
   ​def __init__(self, cause: Foo):  # Foo can be used in type hints without issue
       ​self.cause = cause

   ​def __str__(self):
       ​return f'Expected 3 but got {self.cause.attrib}.'

In Python 3.11+, from __future__ import annotations is active by default and can therefore be omitted.
This answer is based on Yet another solution to dig you out of a circular import hole in Python by Stefaan Lippens.
    Cyclic imports terminate, but you need to be careful not to use the cyclically-imported modules during module initialization.

Consider the following files:

a.py:

print ""a in""
import sys
print ""b imported: %s"" % (""b"" in sys.modules, )
import b
print ""a out""


b.py:

print ""b in""
import a
print ""b out""
x = 3


If you execute a.py, you'll get the following:

$ python a.py
a in
b imported: False
b in
a in
b imported: True
a out
b out
a out


On the second import of b.py (in the second a in), the Python interpreter does not import b again, because it already exists in the module dict.

If you try to access b.x from a during module initialization, you will get an AttributeError.

Append the following line to a.py:

print b.x


Then, the output is:

$ python a.py
a in                    
b imported: False
b in
a in
b imported: True
a out
Traceback (most recent call last):
  File ""a.py"", line 4, in <module>
    import b
  File ""/home/shlomme/tmp/x/b.py"", line 2, in <module>
    import a
 File ""/home/shlomme/tmp/x/a.py"", line 7, in <module>
    print b.x
AttributeError: 'module' object has no attribute 'x'


This is because modules are executed on import and at the time b.x is accessed, the line x = 3 has not be executed yet, which will only happen after b out.
    As other answers describe this pattern is acceptable in python:

def dostuff(self):
     from foo import bar
     ...


Which will avoid the execution of the import statement when the file is imported by other modules. Only if there is a logical circular dependency, this will fail.

Most Circular Imports are not actually logical circular imports but rather raise ImportError errors, because of the way import() evaluates top level statements of the entire file when called.

These ImportErrors can almost always be avoided  if you positively want your imports on top:

Consider this circular import:

App A

# profiles/serializers.py

from images.serializers import SimplifiedImageSerializer

class SimplifiedProfileSerializer(serializers.Serializer):
    name = serializers.CharField()

class ProfileSerializer(SimplifiedProfileSerializer):
    recent_images = SimplifiedImageSerializer(many=True)


App B

# images/serializers.py

from profiles.serializers import SimplifiedProfileSerializer

class SimplifiedImageSerializer(serializers.Serializer):
    title = serializers.CharField()

class ImageSerializer(SimplifiedImageSerializer):
    profile = SimplifiedProfileSerializer()


From David Beazleys excellent talk Modules and Packages: Live and Let Die! - PyCon 2015, 1:54:00, here is a way to deal with circular imports in python:

try:
    from images.serializers import SimplifiedImageSerializer
except ImportError:
    import sys
    SimplifiedImageSerializer = sys.modules[__package__ + '.SimplifiedImageSerializer']


This tries to import SimplifiedImageSerializer and if ImportError is raised, because it already is imported, it will pull it from the importcache.

PS: You have to read this entire post in David Beazley's voice.
    Module a.py :

import b
print(""This is from module a"")


Module b.py

import a
print(""This is from module b"")


Running ""Module a"" will output:

>>> 
'This is from module a'
'This is from module b'
'This is from module a'
>>> 


It output this 3 lines while it was supposed to output infinitival because of circular importing.
What happens line by line while running""Module a"" is listed here:


The first line is import b. so it will visit module b
The first line at module b is import a. so it will visit module a
The first line at module a is import b but note that this line won't be executed again anymore, because every file in python execute an import line just for once, it does not matter where or when it is executed. so it will pass to the next line and print ""This is from module a"".
After finish visiting whole module a from module b, we are still at module b. so the next line will print ""This is from module b""
Module b lines are executed completely. so we will go back to module a where we started module b.
import b line have been executed already and won't be executed again. the next line will print ""This is from module a"" and program will be finished.

    I got an example here that struck me!

foo.py

import bar

class gX(object):
    g = 10


bar.py

from foo import gX

o = gX()


main.py

import foo
import bar

print ""all done""


At the command line: $ python main.py

Traceback (most recent call last):
  File ""m.py"", line 1, in <module>
    import foo
  File ""/home/xolve/foo.py"", line 1, in <module>
    import bar
  File ""/home/xolve/bar.py"", line 1, in <module>
    from foo import gX
ImportError: cannot import name gX

    There are a lot of great answers here. While there are usually quick solutions to the problem, some of which feel more pythonic than others, if you have the luxury of doing some refactoring, another approach is to analyze the organization of your code, and try to remove the circular dependency. You may find, for example, that you have:

File a.py

from b import B

class A:
    @staticmethod
    def save_result(result):
        print('save the result')

    @staticmethod
    def do_something_a_ish(param):
        A.save_result(A.use_param_like_a_would(param))

    @staticmethod
    def do_something_related_to_b(param):
        B.do_something_b_ish(param)


File b.py

from a import A

class B:
    @staticmethod
    def do_something_b_ish(param):
        A.save_result(B.use_param_like_b_would(param))


In this case, just moving one static method to a separate file, say c.py:

File c.py

def save_result(result):
    print('save the result')


will allow removing the save_result method from A, and thus allow removing the import of A from a in b:

Refactored File a.py

from b import B
from c import save_result

class A:
    @staticmethod
    def do_something_a_ish(param):
        A.save_result(A.use_param_like_a_would(param))

    @staticmethod
    def do_something_related_to_b(param):
        B.do_something_b_ish(param)


Refactored File b.py

from c import save_result

class B:
    @staticmethod
    def do_something_b_ish(param):
        save_result(B.use_param_like_b_would(param))


In summary, if you have a tool (e.g. pylint or PyCharm) that reports on methods that can be static, just throwing a staticmethod decorator on them might not be the best way to silence the warning. Even though the method seems related to the class, it might be better to separate it out, especially if you have several closely related modules that might need the same functionality and you intend to practice DRY principles.
    Ok, I think I have a pretty cool solution.
Let's say you have file a and file b.
You have a def or a class in file b that you want to use in module a, but you have something else, either a def, class, or variable from file a that you need in your definition or class in file b. 
What you can do is, at the bottom of file a, after calling the function or class in file a that is needed in file b, but before calling the function or class from file b that you need for file a, say import b
Then, and here is the key part, in all of the definitions or classes in file b that need the def or class from file a (let's call it CLASS), you say from a import CLASS

This works because you can import file b without Python executing any of the import statements in file b, and thus you elude any circular imports.

For example:

File a:

class A(object):

     def __init__(self, name):

         self.name = name

CLASS = A(""me"")

import b

go = B(6)

go.dostuff


File b:

class B(object):

     def __init__(self, number):

         self.number = number

     def dostuff(self):

         from a import CLASS

         print ""Hello "" + CLASS.name + "", "" + str(number) + "" is an interesting number.""


Voila.
    Circular imports can be confusing because import does two things:


it executes imported module code
adds imported module to importing module global symbol table


The former is done only once, while the latter at each import statement. Circular import creates situation when importing module uses imported one with partially executed code. In consequence it will not see objects created after import statement. Below code sample demonstrates it.

Circular imports are not the ultimate evil to be avoided at all cost. In some frameworks like Flask they are quite natural and tweaking your code to eliminate them does not make the code better. 

main.py

print 'import b'
import b
print 'a in globals() {}'.format('a' in globals())
print 'import a'
import a
print 'a in globals() {}'.format('a' in globals())
if __name__ == '__main__':
    print 'imports done'
    print 'b has y {}, a is b.a {}'.format(hasattr(b, 'y'), a is b.a)


b.by

print ""b in, __name__ = {}"".format(__name__)
x = 3
print 'b imports a'
import a
y = 5
print ""b out""


a.py

print 'a in, __name__ = {}'.format(__name__)
print 'a imports b'
import b
print 'b has x {}'.format(hasattr(b, 'x'))
print 'b has y {}'.format(hasattr(b, 'y'))
print ""a out""


python main.py output with comments

import b
b in, __name__ = b    # b code execution started
b imports a
a in, __name__ = a    # a code execution started
a imports b           # b code execution is already in progress
b has x True
b has y False         # b defines y after a import,
a out
b out
a in globals() False  # import only adds a to main global symbol table 
import a
a in globals() True
imports done
b has y True, a is b.a True # all b objects are available

    I completely agree with pythoneer's answer here. But I have stumbled on some code that was flawed with circular imports and caused issues when trying to add unit tests. So to quickly patch it without changing everything you can resolve the issue by doing a dynamic import.

# Hack to import something without circular import issue
def load_module(name):
    """"""Load module using imp.find_module""""""
    names = name.split(""."")
    path = None
    for name in names:
        f, path, info = imp.find_module(name, path)
        path = [path]
    return imp.load_module(name, f, path[0], info)
constants = load_module(""app.constants"")


Again, this isn't a permanent fix but may help someone that wants to fix an import error without changing too much of the code.

Cheers! 
    I solved the problem the following way, and it works well without any error. 
Consider two files a.py and b.py.

I added this to a.py and it worked. 

if __name__ == ""__main__"":
        main ()


a.py:

import b
y = 2
def main():
    print (""a out"")
    print (b.x)

if __name__ == ""__main__"":
    main ()


b.py:

import a
print (""b out"")
x = 3 + a.y


The output I get is 

>>> b out 
>>> a out 
>>> 5

    Suppose you are running a test python file named request.py
In request.py, you write
import request

so this also most likely a circular import.
Solution:
Just change your test file to another name such as aaa.py, other than request.py.
Do not use names that are already used by other libs.
    ","[489, 412, 342, 11, 119, 45, 14, 12, 5, 0, 2, 4, 1, 1]",301211,146,2009-04-13T16:07:07,2021-12-02 15:02:43Z,python 
Aren't promises just callbacks?,"
                
I've been developing JavaScript for a few years and I don't understand the fuss about promises at all.

It seems like all I do is change:

api(function(result){
    api2(function(result2){
        api3(function(result3){
             // do work
        });
    });
});


Which I could use a library like async for anyway, with something like:

api().then(function(result){
     api2().then(function(result2){
          api3().then(function(result3){
               // do work
          });
     });
});


Which is more code and less readable. I didn't gain anything here, it's not suddenly magically 'flat' either. Not to mention having to convert things to promises.

So, what's the big fuss about promises here?
    Promises are not callbacks. A promise represents the future result of an asynchronous operation. Of course, writing them the way you do, you get little benefit. But if you write them the way they are meant to be used, you can write asynchronous code in a way that resembles synchronous code and is much more easy to follow:

api().then(function(result){
    return api2();
}).then(function(result2){
    return api3();
}).then(function(result3){
     // do work
});


Certainly, not much less code, but much more readable. 

But this is not the end. Let's discover the true benefits: What if you wanted to check for any error in any of the steps? It would be hell to do it with callbacks, but with promises, is a piece of cake:

api().then(function(result){
    return api2();
}).then(function(result2){
    return api3();
}).then(function(result3){
     // do work
}).catch(function(error) {
     //handle any error that may occur before this point
});


Pretty much the same as a try { ... } catch block. 

Even better:

api().then(function(result){
    return api2();
}).then(function(result2){
    return api3();
}).then(function(result3){
     // do work
}).catch(function(error) {
     //handle any error that may occur before this point
}).then(function() {
     //do something whether there was an error or not
     //like hiding an spinner if you were performing an AJAX request.
});


And even better: What if those 3 calls to api, api2, api3 could run simultaneously (e.g. if they were AJAX calls) but you needed to wait for the three? Without promises, you should have to create some sort of counter. With promises, using the ES6 notation, is another piece of cake and pretty neat:

Promise.all([api(), api2(), api3()]).then(function(result) {
    //do work. result is an array contains the values of the three fulfilled promises.
}).catch(function(error) {
    //handle the error. At least one of the promises rejected.
});


Hope you see Promises in a new light now.
    Yes, Promises are asynchronous callbacks. They can't do anything that callbacks can't do, and you face the same problems with asynchrony as with plain callbacks.

However, Promises are more than just callbacks. They are a very mighty abstraction, allow cleaner and better, functional code with less error-prone boilerplate.


  So what's the main idea?


Promises are objects representing the result of a single (asynchronous) computation. They resolve to that result only once. There's a few things what this means:

Promises implement an observer pattern:


You don't need to know the callbacks that will use the value before the task completes. 
Instead of expecting callbacks as arguments to your functions, you can easily return a Promise object
The promise will store the value, and you can transparently add a callback whenever you want. It will be called when the result is available. ""Transparency"" implies that when you have a promise and add a callback to it, it doesn't make a difference to your code whether the result has arrived yet - the API and contracts are the same, simplifying caching/memoisation a lot.
You can add multiple callbacks easily


Promises are chainable (monadic, if you want):


If you need to transform the value that a promise represents, you map a transform function over the promise and get back a new promise that represents the transformed result. You cannot synchronously get the value to use it somehow, but you can easily lift the transformation in the promise context. No boilerplate callbacks.
If you want to chain two asynchronous tasks, you can use the .then() method. It will take a callback to be called with the first result, and returns a promise for the result of the promise that the callback returns.


Sounds complicated? Time for a code example.

var p1 = api1(); // returning a promise
var p3 = p1.then(function(api1Result) {
    var p2 = api2(); // returning a promise
    return p2; // The result of p2 …
}); // … becomes the result of p3

// So it does not make a difference whether you write
api1().then(function(api1Result) {
    return api2().then(console.log)
})
// or the flattened version
api1().then(function(api1Result) {
    return api2();
}).then(console.log)


Flattening does not come magically, but you can easily do it. For your heavily nested example, the (near) equivalent would be

api1().then(api2).then(api3).then(/* do-work-callback */);


If seeing the code of these methods helps understanding, here's a most basic promise lib in a few lines.


  What's the big fuss about promises?


The Promise abstraction allows much better composability of functions. For example, next to then for chaining, the all function creates a promise for the combined result of multiple parallel-waiting promises.

Last but not least Promises come with integrated error handling. The result of the computation might be that either the promise is fulfilled with a value, or it is rejected with a reason. All the composition functions handle this automatically and propagate errors in promise chains, so that you don't need to care about it explicitly everywhere - in contrast to a plain-callback implementation. In the end, you can add a dedicated error callback for all occurred exceptions.


  Not to mention having to convert things to promises.


That's quite trivial actually with good promise libraries, see How do I convert an existing callback API to promises?
    In addition to the awesome answers above, 2 more points may be added:

1. Semantic difference:

Promises may be already resolved upon creation. This means they guarantee conditions rather than events. If they are resolved already, the resolved function passed to it is still called.

Conversely, callbacks handle events. So, if the event you are interested in has happened before the callback has been registered, the callback is not called.

2. Inversion of control

Callbacks involve inversion of control. When you register a callback function with any API, the Javascript runtime stores the callback function and calls it from the event loop once it is ready to be run. 

Refer The Javascript Event loop for an explanation.

With Promises, control resides with the calling program. The .then() method may be called at any time if we store the promise object.
    In addition to the already established answers, with ES6 arrow functions Promises turn from a modestly shining small blue dwarf straight into a red giant. That is about to collapse into a supernova:

api().then(result => api2()).then(result2 => api3()).then(result3 => console.log(result3))


As oligofren pointed out, without arguments between api calls you don't need the anonymous wrapper functions at all:

api().then(api2).then(api3).then(r3 => console.log(r3))


And finally, if you want to reach a supermassive black hole level, Promises can be awaited:

async function callApis() {
    let api1Result = await api();
    let api2Result = await api2(api1Result);
    let api3Result = await api3(api2Result);

    return api3Result;
}

    In addition to the other answers, the ES2015 syntax blends seamlessly with promises, reducing even more boilerplate code:

// Sequentially:
api1()
  .then(r1 => api2(r1))
  .then(r2 => api3(r2))
  .then(r3 => {
      // Done
  });

// Parallel:
Promise.all([
    api1(),
    api2(),
    api3()
]).then(([r1, r2, r3]) => {
    // Done
});

    No promises are just wrapper on callbacks

example
    You can use javascript native promises with node js

my cloud 9 code link : https://ide.c9.io/adx2803/native-promises-in-node

/**
* Created by dixit-lab on 20/6/16.
*/

var express = require('express');
var request = require('request');   //Simplified HTTP request client.


var app = express();

function promisify(url) {
    return new Promise(function (resolve, reject) {
    request.get(url, function (error, response, body) {
    if (!error && response.statusCode == 200) {
        resolve(body);
    }
    else {
        reject(error);
    }
    })
    });
}

//get all the albums of a user who have posted post 100
app.get('/listAlbums', function (req, res) {
//get the post with post id 100
promisify('http://jsonplaceholder.typicode.com/posts/100').then(function (result) {
var obj = JSON.parse(result);
return promisify('http://jsonplaceholder.typicode.com/users/' + obj.userId + '/albums')
})
.catch(function (e) {
    console.log(e);
})
.then(function (result) {
    res.end(result);
}
)

})


var server = app.listen(8081, function () {

var host = server.address().address
var port = server.address().port

console.log(""Example app listening at http://%s:%s"", host, port)

})


//run webservice on browser : http://localhost:8081/listAlbums

    No, Not at all.

Callbacks are simply Functions In JavaScript which are to be called and then executed after the execution of another function has finished. So how it happens? 

Actually, In JavaScript, functions are itself considered as objects and hence as all other objects, even functions can be sent as arguments to other functions. The most common and generic use case one can think of is setTimeout() function in JavaScript.

Promises are nothing but a much more improvised approach of handling and structuring asynchronous code in comparison to doing the same with callbacks. 

The Promise receives two Callbacks in constructor function:  resolve and reject. These callbacks inside promises provide us with fine-grained control over error handling and success cases. The resolve callback is used when the execution of promise performed successfully and the reject callback is used to handle the error cases.
    JavaScript Promises actually use callback functions to determine what to do after a Promise has been resolved or rejected, therefore both are not fundamentally different. The main idea behind Promises is to take callbacks - especially nested callbacks where you want to perform a sort of actions, but it would be more readable.
    Promises are not callbacks, both are programming idioms that facilitate async programming. Using an async/await-style of programming using coroutines or generators that return promises could be considered a 3rd such idiom. A comparison of these idioms across different programming languages (including Javascript) is here: https://github.com/KjellSchubert/promise-future-task
    Promises overview:

In JS we can wrap asynchronous operations (e.g database calls, AJAX calls) in promises.  Usually we want to run some additional logic on the retrieved data. JS promises have handler functions which process the result of the asynchronous operations. The handler functions can even have other asynchronous operations within them which could rely on the value of the previous asynchronous operations.

A promise always has of the 3 following states:


pending: starting state of every promise, neither fulfilled nor rejected.
fulfilled: The operation completed successfully.
rejected: The operation failed.


A pending promise can be resolved/fullfilled or rejected with a value. Then the following handler methods which take callbacks as arguments are called:


Promise.prototype.then() : When the promise is resolved the callback argument of this function will be called.
Promise.prototype.catch() : When the promise is rejected the callback argument of this function will be called.


Although the above methods skill get callback arguments they are far superior than using 
only callbacks here is an example that will clarify a lot:

Example

function createProm(resolveVal, rejectVal) {
    return new Promise((resolve, reject) => {
        setTimeout(() => {
            if (Math.random() > 0.5) {
                console.log(""Resolved"");
                resolve(resolveVal);
            } else {
                console.log(""Rejected"");
                reject(rejectVal);
            }
        }, 1000);
    });
}

createProm(1, 2)
    .then((resVal) => {
        console.log(resVal);
        return resVal + 1;
    })
    .then((resVal) => {
        console.log(resVal);
        return resVal + 2;
    })
    .catch((rejectVal) => {
        console.log(rejectVal);
        return rejectVal + 1;
    })
    .then((resVal) => {
        console.log(resVal);
    })
    .finally(() => {
        console.log(""Promise done"");
    });



The createProm function creates a promises which is resolved or rejected based on a random Nr after 1 second
If the promise is resolved the first then method is called and the resolved value is passed in as an argument of the callback
If the promise is rejected the first catch method is called and the rejected value is passed in as an argument
The catch and then methods return promises that's why we can chain them. They wrap any returned value in Promise.resolve and any thrown value (using the throw keyword) in Promise.reject. So any value returned is transformed into a promise and on this promise we can again call a handler function.
Promise chains give us more fine tuned control and better overview than nested callbacks. For example the catch method handles all the errors which have occurred before the catch handler.

    ","[489, 695, 191, 21, 25, 15, 3, 6, 1, 5, 0]",120283,259,2014-03-20T16:49:08,2020-05-06 09:03:41Z,javascript 
Is DateTime.Now the best way to measure a function's performance? [closed],"
                    
            
        
            
                
                    
                        Closed. This question is opinion-based. It is not currently accepting answers.
                        
                    
                
            
        
            
        
                
                    
                
            
                
                    Want to improve this question? Update the question so it can be answered with facts and citations by editing this post.
                
                    Closed 1 year ago.

            
        
            
                    
                        Improve this question
                    
            

    

I need to find a bottleneck and need to accurately as possible measure time.

Is the following code snippet the best way to measure the performance?

DateTime startTime = DateTime.Now;

// Some execution process

DateTime endTime = DateTime.Now;
TimeSpan totalTimeTaken = endTime.Subtract(startTime);

    No, it's not. Use the Stopwatch (in System.Diagnostics)

Stopwatch sw = Stopwatch.StartNew();
PerformWork();
sw.Stop();

Console.WriteLine(""Time taken: {0}ms"", sw.Elapsed.TotalMilliseconds);


Stopwatch automatically checks for the existence of high-precision timers.

It is worth mentioning that DateTime.Now often is quite a bit slower than DateTime.UtcNow due to the work that has to be done with timezones, DST and such.

DateTime.UtcNow typically has a resolution of 15 ms. See John Chapman's blog post about DateTime.Now precision for a great summary.

Interesting trivia: The stopwatch falls back on DateTime.UtcNow if your hardware doesn't support a high frequency counter. You can check to see if Stopwatch uses hardware to achieve high precision by looking at the static field Stopwatch.IsHighResolution.
    This article says that first of all you need to compare three alternatives, Stopwatch, DateTime.Now AND DateTime.UtcNow.

It also shows that in some cases (when performance counter doesn't exist) Stopwatch is using DateTime.UtcNow + some extra processing. Because of that it's obvious that in that case DateTime.UtcNow is the best option (because other use it + some processing)

However, as it turns out, the counter almost always exists - see Explanation about high-resolution performance counter and its existence related to .NET Stopwatch?.

Here is a performance graph. Notice how low performance cost UtcNow has compared to alternatives:



The X axis is sample data size, and the Y axis is the relative time of the example.

One thing Stopwatch is better at is that it provides higher resolution time measurements. Another is its more OO nature. However, creating an OO wrapper around UtcNow can't be hard.
    If you want something quick and dirty I would suggest using Stopwatch instead for a greater degree of precision.  

Stopwatch sw = new Stopwatch();
sw.Start();
// Do Work
sw.Stop();

Console.WriteLine(""Elapsed time: {0}"", sw.Elapsed.TotalMilliseconds);


Alternatively, if you need something a little more sophisticated you should probably consider using a 3rd party profiler such as ANTS.
    The stopwatch functionality would be better (higher precision).  I'd also recommend just downloading one of the popular profilers, though (DotTrace and ANTS are the ones I've used the most... the free trial for DotTrace is fully functional and doesn't nag like some of the others).
    It's useful to push your benchmarking code into a utility class/method. The StopWatch class does not need to be Disposed or Stopped on error.  So, the simplest code to time some action is

public partial class With
{
    public static long Benchmark(Action action)
    {
        var stopwatch = Stopwatch.StartNew();
        action();
        stopwatch.Stop();
        return stopwatch.ElapsedMilliseconds;
    }
}


Sample calling code

public void Execute(Action action)
{
    var time = With.Benchmark(action);
    log.DebugFormat(“Did action in {0} ms.”, time);
}


Here is the extension method version

public static class Extensions
{
    public static long Benchmark(this Action action)
    {
        return With.Benchmark(action);
    }
}


And sample calling code

public void Execute(Action action)
{
    var time = action.Benchmark()
    log.DebugFormat(“Did action in {0} ms.”, time);
}

    Use the System.Diagnostics.Stopwatch class. 

Stopwatch sw = new Stopwatch();
sw.Start();

// Do some code.

sw.Stop();

// sw.ElapsedMilliseconds = the time your ""do some code"" took.

    This is the correct way:

using System;
using System.Diagnostics;

class Program
{
    public static void Main()
    {
        Stopwatch stopWatch = Stopwatch.StartNew();

            // some other code

        stopWatch.Stop();

        // this not correct to get full timer resolution
        Console.WriteLine(""{0} ms"", stopWatch.ElapsedMilliseconds);

        // Correct way to get accurate high precision timing
        Console.WriteLine(""{0} ms"", stopWatch.Elapsed.TotalMilliseconds);
    }
}


For more information go through Use Stopwatch instead of DataTime for getting accurate performance counter.
    The way I use within my programs is using the StopWatch class as shown here.

Stopwatch sw = new Stopwatch();
sw.Start();


// Critical lines of code

long elapsedMs = sw.Elapsed.TotalMilliseconds;

    Ditto Stopwatch, it is way better.

Regarding performance measuring you should also check whether your ""// Some Execution Process"" is a very short process.

Also bear in mind that the first run of your ""// Some Execution Process"" might be way slower than subsequent runs.

I typically test a method by running it 1000 times or 1000000 times in a loop and I get much more accurate data than running it once.
    These are all great ways to measure time, but that is only a very indirect way to find bottleneck(s).

The most direct way to find a bottneck in a thread is to get it running, and while it is doing whatever makes you wait, halt it with a pause or break key. Do this several times. If your bottleneck takes X% of time, X% is the probability that you will catch it in the act on each snapshot.

Here's a more complete explanation of how and why it works
    @Sean Chambers

FYI, the .NET Timer class is not for diagnostics, it generates events at a preset interval, like this (from MSDN):

System.Timers.Timer aTimer;
public static void Main()
{
    // Create a timer with a ten second interval.
    aTimer = new System.Timers.Timer(10000);

    // Hook up the Elapsed event for the timer.
    aTimer.Elapsed += new ElapsedEventHandler(OnTimedEvent);

    // Set the Interval to 2 seconds (2000 milliseconds).
    aTimer.Interval = 2000;
    aTimer.Enabled = true;

    Console.WriteLine(""Press the Enter key to exit the program."");
    Console.ReadLine();
}

// Specify what you want to happen when the Elapsed event is 
// raised.
private static void OnTimedEvent(object source, ElapsedEventArgs e)
{
    Console.WriteLine(""The Elapsed event was raised at {0}"", e.SignalTime);
}


So this really doesn't help you know how long something took, just that a certain amount of time has passed.

The timer is also exposed as a control in System.Windows.Forms... you can find it in your designer tool box in VS05/VS08
    Visual Studio Team System has some features that may help with this problem. Essentially you can write unit tests and mix them in different scenarios to run against your software as part of a stress or load test. This may help to identify areas of code that impact your applications performance the most.

Microsoft' Patterns and Practices group has some guidance in Visual Studio Team System Performance Testing Guidance.
    I just found a post in Vance Morrison's blog about a CodeTimer class he wrote that makes using StopWatch easier and does some neat stuff on the side.
    I've done very little of this sort of performance checking (I tend to just think ""this is slow, make it faster"") so I have pretty much always gone with this.
A google does reveal a lot of resources/articles for performance checking.
Many mention using pinvoke to get performance information. A lot of the materials I study only really mention using perfmon..
Edit:
Seen the talks of StopWatch.. Nice! I have learned something :)
This looks like a good article
    This is not professional enough:

Stopwatch sw = Stopwatch.StartNew();
PerformWork();
sw.Stop();

Console.WriteLine(""Time taken: {0}ms"", sw.Elapsed.TotalMilliseconds);


A more reliable version is:

PerformWork();

int repeat = 1000;

Stopwatch sw = Stopwatch.StartNew();
for (int i = 0; i < repeat; i++)
{
   PerformWork();
}

sw.Stop();

Console.WriteLine(""Time taken: {0}ms"", sw.Elapsed.TotalMilliseconds / repeat);


In my real code, I will add GC.Collect call to change managed heap to a known state, and add Sleep call so that different intervals of code can be easily separated in ETW profile.
    Since I do not care to much about precision I ended up comparing them. I am capturing lots of packets on the network and I want to place the time when I receive each packet. Here is the code that tests 5 million iterations
    int iterations = 5000000;

    // Test using datetime.now
    {
        var date = DateTime.UtcNow.AddHours(DateTime.UtcNow.Second);

        var now = DateTime.UtcNow;

        for (int i = 0; i < iterations; i++)
        {
            if (date == DateTime.Now)
                Console.WriteLine(""it is!"");
        }
        Console.WriteLine($""Done executing {iterations} iterations using datetime.now. It took {(DateTime.UtcNow - now).TotalSeconds} seconds"");
    }

    // Test using datetime.utcnow
    {
        var date = DateTime.UtcNow.AddHours(DateTime.UtcNow.Second);

        var now = DateTime.UtcNow;

        for (int i = 0; i < iterations; i++)
        {
            if (date == DateTime.UtcNow)
                Console.WriteLine(""it is!"");
        }
        Console.WriteLine($""Done executing {iterations} iterations using datetime.utcnow. It took {(DateTime.UtcNow - now).TotalSeconds} seconds"");
    }

    // Test using stopwatch
    {
        Stopwatch sw = new Stopwatch();
        sw.Start();

        var now = DateTime.UtcNow;

        for (int i = 0; i < iterations; i++)
        {
            if (sw.ElapsedTicks == DateTime.Now.Ticks)
                Console.WriteLine(""it is!"");
        }
        Console.WriteLine($""Done executing {iterations} iterations using stopwatch. It took {(DateTime.UtcNow - now).TotalSeconds} seconds"");
    }

The output is:
Done executing 5000000 iterations using datetime.now. It took 0.8685502 seconds 
Done executing 5000000 iterations using datetime.utcnow. It took 0.1074324 seconds 
Done executing 5000000 iterations using stopwatch. It took 0.9625021 seconds

So in conclusion DateTime.UtcNow is the fastest if you do not care to much about precision. This also supports the answer https://stackoverflow.com/a/6986472/637142 from this question.
    ","[489, 664, 60, 94, 17, 19, 14, 7, 5, 11, 9, 7, 6, 5, 4, 4, 0]",70832,152,2008-08-26T17:09:45,2020-10-21 17:46:26Z,c 
How can I do three table JOINs in an UPDATE query?,"
                
I asked a question and got this reply which helped.
   UPDATE TABLE_A a JOIN TABLE_B b
   ON a.join_col = b.join_col AND a.column_a = b.column_b
   SET a.column_c = a.column_c + 1

Now I am looking to do this if there are three tables involved something like this.
    UPDATE tableC c JOIN tableB b JOIN tableA a

My question is basically... is it possible to do three table joins on an UPDATE statement? And what is the correct syntax for it?
Do I do the following?
 JOIN tableB, tableA
 JOIN tableB JOIN tableA

    The answer is yes, you can.
Try it like this:
UPDATE TABLE_A a
    JOIN TABLE_B b ON a.join_col = b.join_col AND a.column_a = b.column_b
    JOIN TABLE_C c ON [condition]
SET a.column_c = a.column_c + 1

For a general update join:
UPDATE TABLEA a
JOIN TABLEB b ON a.join_colA = b.join_colB
SET a.columnToUpdate = [something]

    Below is the update query which includes both JOIN and WHERE. In the same way, we can use multiple join/where clauses:
UPDATE opportunities_cstm oc JOIN opportunities o ON oc.id_c = o.id
 SET oc.forecast_stage_c = 'APX'
 WHERE o.deleted = 0
   AND o.sales_stage IN('ABC','PQR','XYZ')

    Yes, you can do a thre-table join for an update statement. Here is an example:
UPDATE customer_table c

  JOIN
      employee_table e
      ON c.city_id = e.city_id
  JOIN
      anyother_ table a
      ON a.someID = e.someID

SET c.active = ""Yes""

WHERE c.city = ""New york"";

    An alternative general plan:
UPDATE table A
JOIN table B ON {join fields}
JOIN table C ON {join fields}
JOIN {as many tables as you need}
SET A.column = {expression}

Example:
UPDATE person P
JOIN address A ON P.home_address_id = A.id
JOIN city C ON A.city_id = C.id
SET P.home_zip = C.zipcode;

    An alternative way of achieving the same result is not to use the JOIN keyword at all.
UPDATE TABLE_A, TABLE_B
SET TABLE_A.column_c = TABLE_B.column_c + 1
WHERE TABLE_A.join_col = TABLE_B.join_col

    For a PostgreSQL example:
UPDATE TableA AS a
SET param_from_table_a=FALSE -- param FROM TableA
FROM TableB AS b
WHERE b.id=a.param_id AND a.amount <> 0;

    none of answer does not work for me I find this on mysql manual
UPDATE T1,T2 INNER JOIN T2 ON T1.C1 = T2.C1 SET T1.C2 = T2.C2,       T2.C3 = expr WHERE condition

    ","[489, 852, 13, 2, 3, 46, 1, 0]",499217,75,2013-03-04T19:24:47,2022-01-01 10:53:18Z,
PHP ternary operator vs null coalescing operator,"
                
Can someone explain the differences between ternary operator shorthand (?:) and null coalescing operator (??) in PHP?
When do they behave differently and when in the same way (if that even happens)?
$a ?: $b

VS.
$a ?? $b

    Ran the below on php interactive mode (php -a on terminal). The comment on each line shows the result.
var_export (false ?? 'value2');   // false
var_export (true  ?? 'value2');   // true
var_export (null  ?? 'value2');   // value2
var_export (''    ?? 'value2');   // """"
var_export (0     ?? 'value2');   // 0

var_export (false ?: 'value2');   // value2
var_export (true  ?: 'value2');   // true
var_export (null  ?: 'value2');   // value2
var_export (''    ?: 'value2');   // value2
var_export (0     ?: 'value2');   // value2

The Null Coalescing Operator ??

?? is like a ""gate"" that only lets NULL through.
So, it always returns first parameter, unless first parameter happens to be NULL.
This means ?? is same as ( !isset() || is_null() )

Use of ??

shorten !isset() || is_null()  check
e.g $object = $object ?? new objClassName();

Stacking Null Coalese Operator
        $v = $x ?? $y ?? $z; 

        // This is a sequence of ""SET && NOT NULL""s:

        if( $x  &&  !is_null($x) ){ 
            return $x; 
        } else if( $y && !is_null($y) ){ 
            return $y; 
        } else { 
            return $z; 
        }


The Ternary Operator ?:

?: is like a gate that lets anything falsy through - including NULL
Anything falsy: 0, empty string, NULL, false, !isset(), empty()
Same like old ternary operator: X ? Y : Z
Note: ?: will throw PHP NOTICE on undefined (unset or !isset()) variables

Use of ?:

checking empty(), !isset(), is_null() etc
shorten ternary operation like !empty($x) ? $x : $y  to $x ?: $y
shorten if(!$x) { echo $x; } else { echo $y; } to echo $x ?: $y

Stacking Ternary Operator
        echo 0 ?: 1 ?: 2 ?: 3; //1
        echo 1 ?: 0 ?: 3 ?: 2; //1
        echo 2 ?: 1 ?: 0 ?: 3; //2
        echo 3 ?: 2 ?: 1 ?: 0; //3
    
        echo 0 ?: 1 ?: 2 ?: 3; //1
        echo 0 ?: 0 ?: 2 ?: 3; //2
        echo 0 ?: 0 ?: 0 ?: 3; //3

    
        // Source & Credit: http://php.net/manual/en/language.operators.comparison.php#95997
   
        // This is basically a sequence of:

 
        if( truthy ) {}
        else if(truthy ) {}
        else if(truthy ) {}
        ..
        else {}


Stacking both, we can shorten this:
        if( isset($_GET['name']) && !is_null($_GET['name'])) {
            $name = $_GET['name'];
        } else if( !empty($user_name) ) {
             $name = $user_name; 
        } else {
            $name = 'anonymous';
        }


To this:
        $name = $_GET['name'] ?? $user_name ?: 'anonymous';

Cool, right? :-)
    When your first argument is null, they're basically the same except that the null coalescing won't output an E_NOTICE when you have an undefined variable. The PHP 7.0 migration docs has this to say:


  The null coalescing operator (??) has been added as syntactic sugar
  for the common case of needing to use a ternary in conjunction with
  isset(). It returns its first operand if it exists and is not NULL;
  otherwise it returns its second operand.


Here's some example code to demonstrate this:

<?php

$a = null;

print $a ?? 'b'; // b
print ""\n"";

print $a ?: 'b'; // b
print ""\n"";

print $c ?? 'a'; // a
print ""\n"";

print $c ?: 'a'; // Notice: Undefined variable: c in /in/apAIb on line 14
print ""\n"";

$b = array('a' => null);

print $b['a'] ?? 'd'; // d
print ""\n"";

print $b['a'] ?: 'd'; // d
print ""\n"";

print $b['c'] ?? 'e'; // e
print ""\n"";

print $b['c'] ?: 'e'; // Notice: Undefined index: c in /in/apAIb on line 33
print ""\n"";


The lines that have the notice are the ones where I'm using the shorthand ternary operator as opposed to the null coalescing operator. However, even with the notice, PHP will give the same response back.

Execute the code: https://3v4l.org/McavC

Of course, this is always assuming the first argument is null. Once it's no longer null, then you end up with differences in that the ?? operator would always return the first argument while the ?: shorthand would only if the first argument was truthy, and that relies on how PHP would type-cast things to a boolean.

So:

$a = false ?? 'f'; // false
$b = false ?: 'g'; // 'g'


would then have $a be equal to false and $b equal to 'g'.
    If you use the shortcut ternary operator like this, it will cause a notice if $_GET['username'] is not set:

$val = $_GET['username'] ?: 'default';


So instead you have to do something like this:

$val = isset($_GET['username']) ? $_GET['username'] : 'default';


The null coalescing operator is equivalent to the above statement, and will return 'default' if $_GET['username'] is not set or is null:

$val = $_GET['username'] ?? 'default';


Note that it does not check truthiness. It checks only if it is set and not null.

You can also do this, and the first defined (set and not null) value will be returned:

$val = $input1 ?? $input2 ?? $input3 ?? 'default';


Now that is a proper coalescing operator.
    Scroll down on this link and view the section, it gives you a comparative example as seen below:
<?php
/** Fetches the value of $_GET['user'] and returns 'nobody' if it does not exist. **/
$username = $_GET['user'] ?? 'nobody';
/** This is equivalent to: **/
$username = isset($_GET['user']) ? $_GET['user'] : 'nobody';

/** Coalescing can be chained: this will return the first defined value out of $_GET['user'], $_POST['user'], and 'nobody'. **/
$username = $_GET['user'] ?? $_POST['user'] ?? 'nobody';
?>


The null coalescing operator (??) has been added as syntactic sugar for the common case of needing to use a ternary in conjunction with isset(). It returns its first operand if it exists and is not NULL; otherwise it returns its second operand.

Essentially, using the coalescing operator will make it auto check for null unlike the ternary operator.
    For the beginners:

Null coalescing operator (??) 

Everything is true except null values and undefined (variable/array index/object attributes)

ex:

$array = [];
$object = new stdClass();

var_export (false ?? 'second');                           # false
var_export (true  ?? 'second');                           # true
var_export (null  ?? 'second');                           # 'second'
var_export (''    ?? 'second');                           # """"
var_export ('some text'    ?? 'second');                  # ""some text""
var_export (0     ?? 'second');                           # 0
var_export ($undefinedVarible ?? 'second');               # ""second""
var_export ($array['undefined_index'] ?? 'second');       # ""second""
var_export ($object->undefinedAttribute ?? 'second');     # ""second""


this is basically check the variable(array index, object attribute.. etc) is exist and not null. similar to isset function

Ternary operator shorthand (?:) 

every false things (false,null,0,empty string) are come as false, but if it's a undefined it also come as false but Notice will throw

ex

$array = [];
$object = new stdClass();

var_export (false ?: 'second');                           # ""second""
var_export (true  ?: 'second');                           # true
var_export (null  ?: 'second');                           # ""second""
var_export (''    ?: 'second');                           # ""second""
var_export ('some text'    ?? 'second');                  # ""some text""
var_export (0     ?: 'second');                           # ""second""
var_export ($undefinedVarible ?: 'second');               # ""second"" Notice: Undefined variable: ..
var_export ($array['undefined_index'] ?: 'second');       # ""second"" Notice: Undefined index: ..
var_export ($object->undefinedAttribute ?: 'second');     # ""Notice: Undefined index: ..


Hope this helps 
    Both of them behave differently when it comes to dynamic data handling.

If the variable is empty ( '' ) the null coalescing will treat the variable as true but the shorthand ternary operator won't. And that's something to have in mind.

$a = NULL;
$c = '';

print $a ?? '1b';
print ""\n"";

print $a ?: '2b';
print ""\n"";

print $c ?? '1d';
print ""\n"";

print $c ?: '2d';
print ""\n"";

print $e ?? '1f';
print ""\n"";

print $e ?: '2f';


And the output:

1b
2b

2d
1f

Notice: Undefined variable: e in /in/ZBAa1 on line 21
2f


Link: https://3v4l.org/ZBAa1
    Both are shorthands for longer expressions.

?: is short for $a ? $a : $b. This expression will evaluate to $a if $a evaluates to TRUE.

?? is short for isset($a) ? $a : $b. This expression will evaluate to $a if $a is set and not null.

Their use cases overlaps when $a is undefined or null. When $a is undefined ?? will not produce an E_NOTICE, but the results are the same. When $a is null the result is the same.
    The major difference is that   


Ternary Operator expression  expr1 ?: expr3 returns expr1 if expr1 evaluates to
TRUE but on the other hand Null Coalescing Operator expression   (expr1) ?? (expr2)
evaluates to expr1 if expr1 is not NULL
Ternary
Operator expr1 ?: expr3 emit a notice if the left-hand side
value (expr1)   does not exist but on the other hand Null Coalescing Operator (expr1) ?? (expr2) In particular, does not emit a notice if the left-hand side value (expr1)   does
not exist, just like isset().   
TernaryOperator is left associative  

((true ? 'true' : false) ? 't' : 'f');


Null Coalescing Operator is right associative  

($a ?? ($b ?? $c));



Now lets explain the difference between by example :  

Ternary Operator (?:)  

$x='';
$value=($x)?:'default';
var_dump($value);

// The above is identical to this if/else statement
if($x){
  $value=$x;
}
else{
  $value='default';
}
var_dump($value);


Null Coalescing Operator (??)

$value=($x)??'default';
var_dump($value);

// The above is identical to this if/else statement
if(isset($x)){
  $value=$x;
}
else{
  $value='default';
}
var_dump($value);


Here is the table that explain the difference and similarity between '??' and ?:    

 


  Special Note : null coalescing operator and ternary operator is an
  expression, and that it doesn't evaluate to a variable, but to the
  result of an expression. This is important to know if you want to
  return a variable by reference. The statement return $foo ?? $bar; and
  return $var == 42 ? $a : $b; in a return-by-reference function will
  therefore not work and a warning is issued.

    class a
{
    public $a = 'aaa';
}

$a = new a();

echo $a->a;  // Writes 'aaa'
echo $a->b;  // Notice: Undefined property: a::$b

echo $a->a ?? '$a->a does not exists';  // Writes 'aaa'

// Does not throw an error although $a->b does not exist.
echo $a->b ?? '$a->b does not exist.';  // Writes $a->b does not exist.

// Does not throw an error although $a->b and also $a->b->c does not exist.
echo $a->b->c ?? '$a->b->c does not exist.';  // Writes $a->b->c does not exist.

    Null Coalescing operator performs just two tasks: it checks whether the variable is set and whether it is null. Have a look at the following example:

<?php
# case 1:
$greeting = 'Hola';
echo $greeting ?? 'Hi There'; # outputs: 'Hola'

# case 2:
$greeting = null;
echo $greeting ?? 'Hi There'; # outputs: 'Hi There'

# case 3:
unset($greeting);
echo $greeting ?? 'Hi There'; # outputs: 'Hi There'


The above code example states that Null Coalescing operator treats a non-existing variable and a variable which is set to NULL in the same way.

Null Coalescing operator is an improvement over the ternary operator. Have a look at the following code snippet comparing the two:

<?php /* example: checking for the $_POST field that goes by the name of 'fullname'*/
# in ternary operator
echo ""Welcome "", (isset($_POST['fullname']) && !is_null($_POST['fullname']) ? $_POST['fullname'] : 'Mr. Whosoever.'); # outputs: Welcome Mr. Whosoever.
# in null coalecing operator
echo ""Welcome "", ($_POST['fullname'] ?? 'Mr. Whosoever.'); # outputs: Welcome Mr. Whosoever.


So, the difference between the two is that Null Coalescing operator operator is designed to handle undefined variables better than the ternary operator. Whereas, the ternary operator is a shorthand for if-else.

Null Coalescing operator is not meant to replace ternary operator, but in some use cases like in the above example, it allows you to write clean code with less hassle.

Credits: http://dwellupper.io/post/6/php7-null-coalescing-operator-usage-and-examples
    The other answers goes deep and give great explanations. For those who look for quick answer,

$a ?: 'fallback' is $a ? $a : 'fallback'

while

$a ?? 'fallback' is $a = isset($a) ? $a : 'fallback'



The main difference would be when the left operator is either:


A falsy value that is NOT null (0, '', false, [], ...) 
An undefined variable

    It seems there are pros and cons to using either ?? or ?:. The pro to using ?: is that it evaluates false and null and """" the same. The con is that it reports an E_NOTICE if the preceding argument is null. With ?? the pro is that there is no E_NOTICE, but the con is that it does not evaluate false and null the same. In my experience, I have seen people begin using null and false interchangeably but then they eventually resort to modifying their code to be consistent with using either null or false, but not both. An alternative is to create a more elaborate ternary condition: (isset($something) or !$something) ? $something : $something_else.

The following is an example of the difference of using the ?? operator using both null and false: 

$false = null;
$var = $false ?? ""true"";
echo $var . ""---<br>"";//returns: true---

$false = false;
$var = $false ?? ""true"";
echo $var . ""---<br>""; //returns: ---


By elaborating on the ternary operator however, we can make a false or empty string """" behave as if it were a null without throwing an e_notice:

$false = null;
$var = (isset($false) or !$false) ? $false : ""true"";
echo $var . ""---<br>"";//returns: ---

$false = false;
$var = (isset($false) or !$false) ? $false : ""true"";
echo $var . ""---<br>"";//returns: ---

$false = """";
$var = (isset($false) or !$false) ? $false : ""true"";
echo $var . ""---<br>"";//returns: ---

$false = true;
$var = (isset($false) or !$false) ? $false : ""true"";
echo $var . ""---<br>"";//returns: 1---


Personally, I think it would be really nice if a future rev of PHP included another new operator: :? that replaced the above syntax. ie:
// $var = $false :? ""true""; That syntax would evaluate null, false, and """" equally and not throw an E_NOTICE...
    When using the superglobals like $_GET or $_REQUEST you should be aware that they could be an empty string.
In this specal case this example

$username = $_GET['user'] ?? 'nobody';


will fail because the value of $username now is an empty string.

So when using $_GET or even $_REQUEST you should use the ternary operator instead like this:

$username = (!empty($_GET['user'])?$_GET['user']:'nobody';


Now the value of $username is 'nobody' as expected.
    Practical short answer :
Try:
var_dump('' ?: 'ok');

vs
var_dump('' ?? 'ok');


The first one will return 'ok' if the tested value (or variable *) evaluates to false
whereas
The second one will return 'ok' if the tested value (or variable *) is null or not initialized/set.

*CAUTION : if you want to test a variable with ?:, you must first ensure it is initialized/set, otherwise PHP will raise an E_NOTICE (whereas ?? wont).
    ","[489, 222, 505, 77, 7, 7, 18, 16, 45, 1, 0, 3, 1, 0, 0]",203824,95,2016-01-02T22:23:40,2022-03-15 14:11:43Z,php 
ExpressionChangedAfterItHasBeenCheckedError Explained,"
                
Please explain to me why I keep getting this error: ExpressionChangedAfterItHasBeenCheckedError: Expression has changed after it was checked.

Obviously, I only get it in dev mode, it doesn't happen on my production build, but it's very annoying and I simply don't understand the benefits of having an error in my dev environment that won't show up on prod --probably because of my lack of understanding.

Usually, the fix is easy enough, I just wrap the error causing code in a setTimeout like this:



setTimeout(()=> {
    this.isLoading = true;
}, 0);


Or force detect changes with a constructor like this: constructor(private cd: ChangeDetectorRef) {}:

this.isLoading = true;
this.cd.detectChanges();


But why do I constantly run into this error? I want to understand it so I can avoid these hacky fixes in the future.
    I had a similar issue. Looking at the lifecycle hooks documentation, I changed ngAfterViewInit to ngAfterContentInit and it worked.
    Angular runs change detection and when it finds that some values which has been passed to the child component have been changed, Angular throws the following error:
ExpressionChangedAfterItHasBeenCheckedError click for more
In order to correct this we can use the AfterContentChecked life cycle hook and
import { ChangeDetectorRef, AfterContentChecked} from '@angular/core';

  constructor(
  private cdref: ChangeDetectorRef) { }

  ngAfterContentChecked() {

    this.cdref.detectChanges();

  }

    A lot of understanding came once I understood the Angular Lifecycle Hooks and their relationship with change detection.

I was trying to get Angular to update a global flag bound to the *ngIf of an element, and I was trying to change that flag inside of the ngOnInit() life cycle hook of another component. 

According to the documentation, this method is called after Angular has already detected changes:


  Called once, after the first ngOnChanges().


So updating the flag inside of ngOnChanges() won't initiate change detection. Then, once change detection has naturally triggered again, the flag's value has changed and the error is thrown.

In my case, I changed this:

constructor(private globalEventsService: GlobalEventsService) {

}

ngOnInit() {
    this.globalEventsService.showCheckoutHeader = true;
}


To this:

constructor(private globalEventsService: GlobalEventsService) {
    this.globalEventsService.showCheckoutHeader = true;
}

ngOnInit() {

}


and it fixed the problem :)
    I'm using ng2-carouselamos (Angular 8 and Bootstrap 4)
Taking these steps fixed my problem:

Implement AfterViewChecked
Add constructor(private changeDetector : ChangeDetectorRef ) {}
Then ngAfterViewChecked(){ this.changeDetector.detectChanges(); }

    This error indicates a real problem in your application, therefore it makes sense to throw an exception.

In devMode change detection adds an additional turn after every regular change detection run to check if the model has changed.

If the model has changed between the regular and the additional change detection turn, this indicates that either


change detection itself has caused a change
a method or getter returns a different value every time it is called


which are both bad, because it is not clear how to proceed because the model might never stabilize. 

If Angular runs change detection until the model stabilizes, it might run forever.
If Angular doesn't run change detection, then the view might not reflect the current state of the model.

See also What is difference between production and development mode in Angular2?
    If you are seeing ExpressionChangedAfterItHasBeenCheckedError when triggering an EventEmitter within ngAfterViewInit() then you can pass true when creating the EventEmitter to make it emit asynchronously after the current change detection cycle.
@Component({
  ...
})
export class MyComponent implements AfterViewInit {
  // Emit asynchronously to avoid ExpressionChangedAfterItHasBeenCheckedError
  @Output() valueChange = new EventEmitter<number>(true);

  ...

  ngAfterViewInit(): void {
    ...
    this.valueChange.emit(newValue);
    ...
  }

}

    @HostBinding can be a confusing source of this error.
For example, lets say you have the following host binding in a component
// image-carousel.component.ts
@HostBinding('style.background') 
style_groupBG: string;

For simplicity, lets say this property is updated via the following input property:
@Input('carouselConfig')
public set carouselConfig(carouselConfig: string) 
{
    this.style_groupBG = carouselConfig.bgColor;   
}

In the parent component you are programatically setting it in ngAfterViewInit
@ViewChild(ImageCarousel) carousel: ImageCarousel;

ngAfterViewInit()
{
    this.carousel.carouselConfig = { bgColor: 'red' };
}

Here's what happens :

Your parent component is created
The ImageCarousel component is created, and assigned to carousel (via ViewChild)
We can't access carousel until ngAfterViewInit() (it will be null)
We assign the configuration, which sets style_groupBG = 'red'
This in turn sets background: red on the host ImageCarousel component
This component is 'owned' by your parent component, so when it checks for changes it finds a change on carousel.style.background and isn't clever enough to know that this isn't a problem so it throws the exception.

One solution is to introduce another wrapper div insider ImageCarousel and set the background color on that, but then you don't get some of the benefits of using HostBinding (such as allowing the parent to control the full bounds of the object).
The better solution, in the parent component is to add detectChanges() after setting the config.
ngAfterViewInit()
{
    this.carousel.carouselConfig = { ... };
    this.cdr.detectChanges();
}

This may look quite obvious set out like this, and very similar to other answers but there's a subtle difference.
Consider the case where you don't add @HostBinding until later during development. Suddenly you get this error and it doesn't seem to make any sense.
    Follow the below steps:

1.
Use 'ChangeDetectorRef' by importing it from @angular/core as follows:

import{ ChangeDetectorRef } from '@angular/core';


2.
Implement it in constructor() as follows:

constructor(   private cdRef : ChangeDetectorRef  ) {}


3.
Add the following method to your function which you are calling on an event like click of button. So it look like this: 

functionName() {   
    yourCode;  
    //add this line to get rid of the error  
    this.cdRef.detectChanges();     
}

    There were interesting answers but I didn't seem to find one to match my needs, the closest being from @chittrang-mishra which refers only to one specific function and not several toggles as in my app.

I did not want to use [hidden] to take advantage of *ngIf not even being a part of the DOM so I found the following solution which may not be the best for all as it suppresses the error instead of correcting it, but in my case where I know the final result is correct, it seems ok for my app. 

What I did was implement AfterViewChecked, add constructor(private changeDetector : ChangeDetectorRef  ) {} and then 

ngAfterViewChecked(){
  this.changeDetector.detectChanges();
}


I hope this helps other as many others have helped me.
    Referring to the article https://blog.angularindepth.com/everything-you-need-to-know-about-the-expressionchangedafterithasbeencheckederror-error-e3fd9ce7dbb4

So the mechanics behind change detection actually works in a way that both change detection and verification digests are performed synchronously. That means, if we update properties asynchronously the values will not be updated when the verification loop is running and we will not get ExpressionChanged... error. The reason we get this error is, during the verification process, Angular sees different values then what it recorded during change detection phase. So to avoid that....

1) Use changeDetectorRef

2) use setTimeOut.  This will execute your code in another VM as a macro-task. Angular will not see these changes during verification process and you will not get that error.

 setTimeout(() => {
        this.isLoading = true;
    });


3) If you really want to execute your code on same VM use like 

Promise.resolve(null).then(() => this.isLoading = true);


This will create a micro-task. The micro-task queue is processed after the current synchronous code has finished executing hence the update to the property will happen after the verification step.
    Tried most of the solutions suggested above. Only this worked for me in this scenario. I was using *ngIf to toggle angular material's indeterminate progressive bar based on api calls and it was throwing ExpressionChangedAfterItHasBeenCheckedError.
In the component in question:
constructor(
    private ngZone: NgZone,
    private changeDetectorRef: ChangeDetectorRef,
) {}

ngOnInit() {
    this.ngZone.runOutsideAngular(() => {
        this.appService.appLoader$.subscribe(value => {
            this.loading = value;
            this.changeDetectorRef.detectChanges();
        });
    });
}

The trick is to bypass angular component's change detection using ngzone.
PS: Not sure if this is an elegant solution but using AfterContentChecked and AfterViewChecked lifecycle hook is bound to raise performance issues as your application gets bigger as it is triggered numerous times.
    Update

I highly recommend starting with the OP's self response first: properly think about what can be done in the constructor vs what should be done in ngOnChanges().

Original

This is more a side note than an answer, but it might help someone. I stumbled upon this problem when trying to make the presence of a button depend on the state of the form:

<button *ngIf=""form.pristine"">Yo</button>


As far as I know, this syntax leads to the button being added and removed from the DOM based on the condition. Which in turn leads to the ExpressionChangedAfterItHasBeenCheckedError.

The fix in my case (although I don't claim to grasp the full implications of the difference), was to use display: none instead:

<button [style.display]=""form.pristine ? 'inline' : 'none'"">Yo</button>

    Here's my thoughts on what is happening. I have not read the documentation but am sure this is part of why the error is shown. 

*ngIf=""isProcessing()"" 


When using *ngIf, it physically changes the DOM by adding or removing the element every time the condition changes. So if the condition changes before it is rendered to the view (which is highly possible in Angular's world), the error is thrown. See explanation here between development and production modes.

[hidden]=""isProcessing()""


When using [hidden] it does not physically change the DOM but merely hiding the element from the view, most likely using CSS in the back. The element is still there in the DOM but not visible depending on the condition's value. That is why the error will not occur when using [hidden].
    My issue was manifest when I added *ngIf but that wasn't the cause.  The error was caused by changing the model in {{}} tags then trying to display the changed model in the *ngIf statement later on.  Here's an example:

<div>{{changeMyModelValue()}}</div> <!--don't do this!  or you could get error: ExpressionChangedAfterItHasBeenCheckedError-->
....
<div *ngIf=""true"">{{myModel.value}}</div>


To fix the issue, I changed where I called changeMyModelValue() to a place that made more sense.  

In my situation I wanted changeMyModelValue() called whenever a child component changed the data.  This required I create and emit an event in the child component so the parent could handle it (by calling changeMyModelValue(). see https://angular.io/guide/component-interaction#parent-listens-for-child-event
    Debugging tips
This error can be quite confusing, and it's easy to make a wrong assumption about exactly when it's occuring. I find it helpful to add a lot of debugging statements like this throughout the affected components in the appropriate places. This helps understand the flow.
In the parent put statements like this (the exact string 'EXPRESSIONCHANGED' is important), but other than that these are just examples:
    console.log('EXPRESSIONCHANGED - HomePageComponent: constructor');
    console.log('EXPRESSIONCHANGED - HomePageComponent: setting config', newConfig);
    console.log('EXPRESSIONCHANGED - HomePageComponent: setting config ok');
    console.log('EXPRESSIONCHANGED - HomePageComponent: running detectchanges');

In the child / services / timer callbacks:
    console.log('EXPRESSIONCHANGED - ChildComponent: setting config');
    console.log('EXPRESSIONCHANGED - ChildComponent: setting config ok');

If you run detectChanges manually add logging for that too:
    console.log('EXPRESSIONCHANGED - ChildComponent: running detectchanges');
    this.cdr.detectChanges();

Then in Chrome debugger just filter by 'EXPRESSIONCHANGES'. This will show you exactly the flow and order of everything that gets set, and also exactly at what point Angular throws the error.

You can also click on the gray links to put breakpoints in.
Another thing to watch out if you have similarly named properties throughout your application (such as style.background) make sure you're debugging the one you think you - by setting it to an obscure color value.
    The solution...services and rxjs...event emitters and property binding both use rxjs..you are better of implementing it your self, more control, easier to debug.  Remember that event emitters are using rxjs.  Simply, create a service and within an observable,  have each component subscribe to tha observer and either pass new value or cosume value as needed
    I got this error because i was dispatching redux actions in modal and modal was not opened at that time. I was dispatching actions the moment modal component recieve input. So i put setTimeout there in order to make sure that modal is opened and then actions are dipatched.
    I was facing the same problem as value was changing in one of the array in my component. But instead of detecting the changes on value change, I changed the component change detection strategy to onPush (which will detect changes on object change and not on value change). 

import { Component, OnInit, ChangeDetectionStrategy } from '@angular/core';

@Component({
    changeDetection: ChangeDetectionStrategy.OnPush
    selector: -
    ......
})

    In my case, I had this problem in my spec file, while running my tests. 

I had to change ngIf to [hidden] 



<app-loading *ngIf=""isLoading""></app-loading>


to

<app-loading [hidden]=""!isLoading""></app-loading>

    To anyone struggling with this. Here's a way to debug properly this error : https://blog.angular-university.io/angular-debugging/

In my case, indeed I got rid of this error using this [hidden] hack instead of *ngIf...

But the link I provided enabled me to find THE GUILTY *ngIf :)

Enjoy.
    I had this sort of error in Ionic3 (which uses Angular 4 as part of it's technology stack).

For me it was doing this:

<ion-icon [name]=""getFavIconName()""></ion-icon>

So I was trying to conditionally change the type of an ion-icon from a pin to a remove-circle, per a mode a screen was operating on.

I'm guessing I'll have to add an *ngIf instead.
    For my issue, I was reading github - ""ExpressionChangedAfterItHasBeenCheckedError when changing a component 'non model' value in afterViewInit"" and decided to add the ngModel

<input type=""hidden"" ngModel #clientName />


It fixed my issue, I hope it helps someone.
    In my case, I had an async property in LoadingService with a BehavioralSubject isLoading

Using the [hidden] model works, but *ngIf fails

    <h1 [hidden]=""!(loaderService.isLoading | async)"">
        THIS WORKS FINE
        (Loading Data)
    </h1>

    <h1 *ngIf=""!(loaderService.isLoading | async)"">
        THIS THROWS ERROR
        (Loading Data)
    </h1>

    A solution that worked for me using rxjs

import { startWith, tap, delay } from 'rxjs/operators';

// Data field used to populate on the html
dataSource: any;

....

ngAfterViewInit() {
  this.yourAsyncData.
      .pipe(
          startWith(null),
          delay(0),
          tap((res) => this.dataSource = res)
      ).subscribe();
}

    I hope this helps someone coming here:
We make service calls in ngOnInit in the following manner and use a variable displayMain to control the Mounting of the elements to the DOM.

component.ts

  displayMain: boolean;
  ngOnInit() {
    this.displayMain = false;
    // Service Calls go here
    // Service Call 1
    // Service Call 2
    // ...
    this.displayMain = true;
  }




and component.html

<div *ngIf=""displayMain""> <!-- This is the Root Element -->
 <!-- All the HTML Goes here -->
</div>

    I got this error because i was using a variable in component.html which was not declared in component.ts. Once I removed the part in HTML, this error was gone.
    My issue was I was opening up a Ngbmodal popup on load this the object that was being changed after it was checked. I was able to resolve it by opening the modal popup inside of setTimeout.
setTimeout(() => {
  this.modalReference = this.modalService.open(this.modal, { size: ""lg"" });
});

    I had this issue with between RxJS/Observables and static mock data. At first, my application used static mock data, arrays of data in my case
The html was like this:
*ngFor=""let x of myArray?.splice(0, 10)""

So the idea was only display up to 10 elements from myArray. splice() takes a copy of the original array. To my knowledge this is perfectly fine in Angular.
Then I changed the data flow to Observable pattern as my 'real' data is coming from Akita (a state management library). This means my html became:
*ngFor=""let x of (myArray$ | async)?.splice(0, 10)""

where myArray$ is [was] type of Observable<MyData[]>, and this data manipulation in the template is what caused the error to happen. Don't do it like this with RxJS objects.
    This error occurs when a value changes more than once in the same change detection cycle. I had this problem with a TypeScript getter whose return value was changing very frequently. To fix this, you can restrict a value so that it can only change once per change detection cycle as follows:
import { v4 as uuid } from 'uuid'

private changeDetectionUuid: string
private prevChangeDetectionUuid: string
private value: Date

get frequentlyChangingValue(): any {
  if (this.changeDetectionUuid !== this.prevChangeDetectionUuid) {
    this.prevChangeDetectionUuid = this.changeDetectionUuid
    this.value = new Date()
  }
  return this.value
}

ngAfterContentChecked() {
  this.changeDetectionUuid = uuid()
}

HTML:
<div>{{ frequentlyChangingValue }}</div>

The basic approach here is that each change detection cycle has its own uuid. When the uuid changes, you know that you are on the next cycle. If the cycle has changed then update the value and return it else just return the same value as previously returned on this cycle.
This ensures that each cycle returns only one value. This works fine for frequently updating values given that change detection cycles occur so frequently.
To generate the uuid I've used the uuid npm module but you can use any method that generates a unique random uuid.
    How does setTimeout or delay(0) fix this problem?
Here is why the code above fixes the issue:
The initial value of the flag is false, and so the loading indicator will NOT be displayed initially

ngAfterViewInit() gets called, but the data source is not immediately called, so no modifications of the loading indicator will be made synchronously via ngAfterViewInit()

Angular then finishes rendering the view and reflects the latest data changes on the screen, and the Javascript VM turn completes

One moment later, the setTimeout() call (also used inside delay(0)) is triggered, and only then the data source loads its data

the loading flag is set to true, and the loading indicator will now be displayed

Angular finishes rendering the view, and reflects the latest changes on the screen, which causes the loading indicator to get displayed

No error occurs this time around, and so this fixes the error message.
source: https://blog.angular-university.io/angular-debugging/
    ","[489, 190, 104, 138, 73, 144, 3, 11, 39, 42, 22, 12, 46, 6, 4, 5, -1, 0, 25, 28, 1, 2, 1, 1, 2, 0, 0, 0, 0, 0, 0]",374176,82,2017-04-12T16:59:34,2022-01-27 15:57:13Z,
Optimum way to compare strings in JavaScript? [duplicate],"
                    
            
        
            
                
                    
                        This question already has answers here:
                        
                    
                
            
                    
                        Is there a JavaScript strcmp()?
                            
                                (6 answers)
                            
                    
                Closed 9 years ago.
        

    

I am trying to optimize a function which does binary search of strings in JavaScript.

Binary search requires you to know whether the key is == the pivot or < the pivot.

But this requires two string comparisons in JavaScript, unlike in C like languages which have the strcmp() function that returns three values (-1, 0, +1) for (less than, equal, greater than).

Is there such a native function in JavaScript, that can return a ternary value so that just one comparison is required in each iteration of the binary search?
    You can use the localeCompare() method. 

string_a.localeCompare(string_b);

/* Expected Returns:

 0:  exact match

-1:  string_a < string_b

 1:  string_a > string_b

 */


Further Reading:


MDN: String.prototype.localeCompare
Stack Overflow - Is there a JavaScript strcmp()?
Tutorials Point: JavaScript String - localeCompare() Method

    Well in JavaScript you can check two strings for values same as integers so yo can do this:


""A"" < ""B""
""A"" == ""B""
""A"" > ""B""


And therefore you can make your own function that checks strings the same way as the strcmp().

So this would be the function that does the same:

function strcmp(a, b)
{   
    return (a<b?-1:(a>b?1:0));  
}

    You can use the comparison operators to compare strings. A strcmp function could be defined like this:

function strcmp(a, b) {
    if (a.toString() < b.toString()) return -1;
    if (a.toString() > b.toString()) return 1;
    return 0;
}




Edit    Here’s a string comparison function that takes at most min { length(a), length(b) } comparisons to tell how two strings relate to each other:

function strcmp(a, b) {
    a = a.toString(), b = b.toString();
    for (var i=0,n=Math.max(a.length, b.length); i<n && a.charAt(i) === b.charAt(i); ++i);
    if (i === n) return 0;
    return a.charAt(i) > b.charAt(i) ? -1 : 1;
}

    ","[489, 662, 77, 15]",932235,83,2010-01-30T10:51:05,2018-11-05 10:22:48Z,javascript 
Docker Compose wait for container X before starting Y,"
                
I am using rabbitmq and a simple python sample from here
together with docker-compose. My problem is that I need to wait for rabbitmq to be fully started. From what I searched so far, I don't know how to wait with container x (in my case worker) until y (rabbitmq) is started.
I found this blog post where he checks if the other host is online.
I also found this docker command:

wait
Usage: docker wait CONTAINER [CONTAINER...]
Block until a container stops, then print its exit code.

Waiting for a container to stop is maybe not what I am looking for but if
it is, is it possible to use that command inside the docker-compose.yml?
My solution so far is to wait some seconds and check the port, but is this the way to achieve this? If I don't wait, I get an error.
docker-compose.yml
worker:
    build: myapp/.
    volumes:
    - myapp/.:/usr/src/app:ro

    links:
    - rabbitmq
rabbitmq:
    image: rabbitmq:3-management

python hello sample (rabbit.py):
import pika
import time

import socket

pingcounter = 0
isreachable = False
while isreachable is False and pingcounter < 5:
    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    try:
        s.connect(('rabbitmq', 5672))
        isreachable = True
    except socket.error as e:
        time.sleep(2)
        pingcounter += 1
    s.close()

if isreachable:
    connection = pika.BlockingConnection(pika.ConnectionParameters(
            host=""rabbitmq""))
    channel = connection.channel()

    channel.queue_declare(queue='hello')

    channel.basic_publish(exchange='',
                          routing_key='hello',
                          body='Hello World!')
    print ("" [x] Sent 'Hello World!'"")
    connection.close()

Dockerfile for worker:
FROM python:2-onbuild
RUN [""pip"", ""install"", ""pika""]

CMD [""python"",""rabbit.py""]

Update Nov 2015:
A shell script or waiting inside your program is maybe a possible solution. But after seeing this Issue I am looking for a command or feature of docker/docker-compose itself.
They mention a  solution for implementing a health check, which may be the best option. A open tcp connection does not mean your service is ready or may remain ready. In addition to that I need to change my entrypoint in my dockerfile.
So I am hoping for an answer with docker-compose on board commands, which will hopefully the case if they finish this issue.
Update March 2016
There is a proposal for providing a built-in way to determine if a container is ""alive"". So docker-compose can maybe make use of it in near future.
Update June 2016
It seems that the healthcheck will be integrated into docker in Version 1.12.0
Update January 2017
I found a docker-compose solution see:
Docker Compose wait for container X before starting Y
    Finally found a solution with a docker-compose method. Since docker-compose file format 2.1 you can define healthchecks.
I did it in a example project
you need to install at least docker 1.12.0+.
I also needed to extend the rabbitmq-management Dockerfile, because curl isn't installed on the official image.
Now I test if the management page of the rabbitmq-container is available. If curl finishes with exitcode 0 the container app (python pika) will be started and publish a message to hello queue. Its now working (output).
docker-compose (version 2.1):
version: '2.1'

services:
  app:
    build: app/.
    depends_on:
      rabbit:
        condition: service_healthy
    links: 
        - rabbit

  rabbit:
    build: rabbitmq/.
    ports: 
        - ""15672:15672""
        - ""5672:5672""
    healthcheck:
        test: [""CMD"", ""curl"", ""-f"", ""http://localhost:15672""]
        interval: 30s
        timeout: 10s
        retries: 5

output:
rabbit_1  | =INFO REPORT==== 25-Jan-2017::14:44:21 ===
rabbit_1  | closing AMQP connection <0.718.0> (172.18.0.3:36590 -> 172.18.0.2:5672)
app_1     |  [x] Sent 'Hello World!'
healthcheckcompose_app_1 exited with code 0

Dockerfile (rabbitmq + curl):
FROM rabbitmq:3-management
RUN apt-get update
RUN apt-get install -y curl 
EXPOSE 4369 5671 5672 25672 15671 15672

Version 3 no longer supports the condition form of depends_on.
So i moved from depends_on to restart on-failure. Now my app container will restart 2-3 times until it is working, but it is still a docker-compose feature without overwriting the entrypoint.
docker-compose (version 3):
version: ""3""

services:

  rabbitmq: # login guest:guest
    image: rabbitmq:management
    ports:
    - ""4369:4369""
    - ""5671:5671""
    - ""5672:5672""
    - ""25672:25672""
    - ""15671:15671""
    - ""15672:15672""
    healthcheck:
        test: [""CMD"", ""curl"", ""-f"", ""http://localhost:15672""]
        interval: 30s
        timeout: 10s
        retries: 5

  app:
    build: ./app/
    environment:
      - HOSTNAMERABBIT=rabbitmq
    restart: on-failure
    depends_on:
      - rabbitmq
    links: 
        - rabbitmq

    Quite recently they've added the depends_on feature.
Edit:
As of compose version 2.1+ till version 3 you can use depends_on in conjunction with healthcheck to achieve this:
From the docs:
version: '2.1'
services:
  web:
    build: .
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_started
  redis:
    image: redis
  db:
    image: redis
    healthcheck:
      test: ""exit 0""

Before version 2.1
You can still use depends_on, but it only effects the order in which services are started - not if they are ready before the dependant service is started.
It seems to require at least version 1.6.0.
Usage would look something like this:
version: '2'
services:
  web:
    build: .
    depends_on:
      - db
      - redis
  redis:
    image: redis
  db:
    image: postgres 

From the docs:

Express dependency between services, which has two effects:

docker-compose up will start services in dependency order. In the following example, db and redis will be started before web.
docker-compose up SERVICE will automatically include SERVICE’s dependencies. In the following example, docker-compose up web will also create and start db and redis.


Note: As I understand it, although this does set the order in which containers are loaded. It does not guarantee that the service inside the container has actually loaded.
For example, you postgres container might be up. But the postgres service itself might still be initializing within the container.
    Natively that is not possible, yet. See also this feature request.

So far you need to do that in your containers CMD to wait until all required services are there.

In the Dockerfiles CMD you could refer to your own start script that wraps starting up your container service. Before you start it, you wait for a depending one like:

Dockerfile

FROM python:2-onbuild
RUN [""pip"", ""install"", ""pika""]
ADD start.sh /start.sh
CMD [""/start.sh""]


start.sh

#!/bin/bash
while ! nc -z rabbitmq 5672; do sleep 3; done
python rabbit.py


Probably you need to install netcat in your Dockerfile as well. I do not know what is pre-installed on the python image.

There are a few tools out there that provide easy to use waiting logic, for simple tcp port checks:


wait-for-it 
dockerize


For more complex waits:


goss - Explanation blog

    Using restart: unless-stopped or restart: always may solve this problem.

If worker container stops when rabbitMQ is not ready, it will be restarted until it is.
    If you want to start service only then another service successfully completed (for example migration, data population, etc), docker-compose version 1.29, comes with build in functionality for this - service_completed_successfully.
depends_on:
  <service-name>:
    condition: service_completed_successfully

According to specification:

service_completed_successfully -  specifies that a dependency is expected to run to successful completion before starting a dependent service

    Tried many different ways, but liked the simplicity of this: https://github.com/ufoscout/docker-compose-wait

The idea that you can use ENV vars in the docker compose file to submit a list of services hosts (with ports) which should be ""awaited"" like this: WAIT_HOSTS: postgres:5432, mysql:3306, mongo:27017.

So let's say you have the following docker-compose.yml file (copy/past from repo README):

version: ""3""

services:

  mongo:
    image: mongo:3.4
    hostname: mongo
    ports:
      - ""27017:27017""

  postgres:
    image: ""postgres:9.4""
    hostname: postgres
    ports:
      - ""5432:5432""

  mysql:
    image: ""mysql:5.7""
    hostname: mysql
    ports:
      - ""3306:3306""

  mySuperApp:
    image: ""mySuperApp:latest""
    hostname: mySuperApp
    environment:
      WAIT_HOSTS: postgres:5432, mysql:3306, mongo:27017


Next, in order for services to wait, you need to add the following two lines to your Dockerfiles (into Dockerfile of the services which should await other services to start):

ADD https://github.com/ufoscout/docker-compose-wait/releases/download/2.5.0/wait /wait
RUN chmod +x /wait


The complete example of such sample Dockerfile (again from the project repo README): 

FROM alpine

## Add your application to the docker image
ADD MySuperApp.sh /MySuperApp.sh

## Add the wait script to the image
ADD https://github.com/ufoscout/docker-compose-wait/releases/download/2.5.0/wait /wait
RUN chmod +x /wait

## Launch the wait tool and then your application
CMD /wait && /MySuperApp.sh


For other details about possible usage see README
    For container start ordering use

depends_on:


For waiting previous container start use script

entrypoint: ./wait-for-it.sh db:5432


This article will help you
https://docs.docker.com/compose/startup-order/
    In version 3 of a Docker Compose file, you can use RESTART.

For example:

docker-compose.yml

worker:
    build: myapp/.
    volumes:
    - myapp/.:/usr/src/app:ro
    restart: on-failure
    depends_on:
    - rabbitmq
rabbitmq:
    image: rabbitmq:3-management


Note that I used depends_on instead of links since the latter is deprecated in version 3.

Even though it works, it might not be the ideal solution since you restart the docker container at every failure.

Have a look to RESTART_POLICY as well. it let you fine tune the restart policy.

When you use Compose in production, it is actually best practice to use the restart policy :


  Specifying a restart policy like restart: always to avoid downtime

    you can also just add it to the command option eg.

command: bash -c ""sleep 5; start.sh""


https://github.com/docker/compose/issues/374#issuecomment-156546513

to wait on a port you can also use something like this

command: bash -c ""while ! curl -s rabbitmq:5672 > /dev/null; do echo waiting for xxx; sleep 3; done; start.sh""


to increment the waiting time you can hack a bit more:

command: bash -c ""for i in {1..100} ; do if ! curl -s rabbitmq:5672 > /dev/null ; then echo waiting on rabbitmq for $i seconds; sleep $i; fi; done; start.sh""

    basing on this blog post https://8thlight.com/blog/dariusz-pasciak/2016/10/17/docker-compose-wait-for-dependencies.html

I configured my docker-compose.yml as shown below:

version: ""3.1""

services:
  rabbitmq:
    image: rabbitmq:3.7.2-management-alpine
    restart: always
    environment:
      RABBITMQ_HIPE_COMPILE: 1
      RABBITMQ_MANAGEMENT: 1
      RABBITMQ_VM_MEMORY_HIGH_WATERMARK: 0.2
      RABBITMQ_DEFAULT_USER: ""rabbitmq""
      RABBITMQ_DEFAULT_PASS: ""rabbitmq""
    ports:
      - ""15672:15672""
      - ""5672:5672""
    volumes:
      - data:/var/lib/rabbitmq:rw

  start_dependencies:
    image: alpine:latest
    links:
      - rabbitmq
    command: >
      /bin/sh -c ""
        echo Waiting for rabbitmq service start...;
        while ! nc -z rabbitmq 5672;
        do
          sleep 1;
        done;
        echo Connected!;
      ""

volumes:
  data: {}


Then I do for run =>:

docker-compose up start_dependencies

rabbitmq service will start in daemon mode, start_dependencies will finish the work.
    Not recommended for serious deployments, but here is essentially a ""wait x seconds"" command.

With docker-compose version 3.4 a start_period instruction has been added to healthcheck. This means we can do the following:

docker-compose.yml:

version: ""3.4""
services:
  # your server docker container
  zmq_server:
    build:
      context: ./server_router_router
      dockerfile: Dockerfile

  # container that has to wait
  zmq_client:
    build:
      context: ./client_dealer/
      dockerfile: Dockerfile
    depends_on:
      - zmq_server
    healthcheck:
      test: ""sh status.sh""
      start_period: 5s


status.sh:

#!/bin/sh

exit 0


What happens here is that the healthcheck is invoked after 5 seconds. This calls the status.sh script, which always returns ""No problem"".
We just made zmq_client container wait 5 seconds before starting!

Note: It's important that you have version: ""3.4"". If the .4 is not there, docker-compose complains.
    restart: on-failure
did the trick for me..see below

---
version: '2.1'
services:
  consumer:
    image: golang:alpine
    volumes:
      - ./:/go/src/srv-consumer
    working_dir: /go/src/srv-consumer
    environment:
      AMQP_DSN: ""amqp://guest:guest@rabbitmq:5672""
    command: go run cmd/main.go
    links:
          - rabbitmq
    restart: on-failure

  rabbitmq:
    image: rabbitmq:3.7-management-alpine
    ports:
      - ""15672:15672""
      - ""5672:5672""

    There is a ready to use utility called ""docker-wait"" that can be used for waiting.
    I currently also have that requirement of waiting for some services to be up and running before others start. Also read the suggestions here and on some other places. But most of them require that the docker-compose.yml some how has to be changed a bit.
So I started working on a solution which I consider to be an orchestration layer around docker-compose itself and I finally came up with a shell script which I called docker-compose-profile.
It can wait for tcp connection to a certain container even if the service does not expose any port to the host directy. The trick I am using is to start another docker container inside the stack and from there I can (usually) connect to every service (as long no other network configuration is applied).
There is also waiting method to watch out for a certain log message.
Services can be grouped together to be started in a single step before another step will be triggered to start.
You can also exclude some services without listing all other services to start (like a collection of available services minus some excluded services).
This kind of configuration can be bundled to a profile.
There is a yaml configuration file called dcp.yml which (for now) has to be placed aside your docker-compose.yml file.
For your question this would look like:
command:
  aliases:
    upd:
      command: ""up -d""
      description: |
        Create and start container. Detach afterword.

profiles:
  default:
    description: |
      Wait for rabbitmq before starting worker.
    command: upd
    steps:
      - label: only-rabbitmq
        only: [ rabbitmq ]
        wait:
          - 5@tcp://rabbitmq:5432
      - label: all-others

You could now start your stack by invoking
dcp -p default upd

or even simply by
dcp

as there is only a default profile to run up -d on.
There is a tiny problem. My current version does not (yet) support special waiting condition like the ony
You actually need. So there is no test to send a message to rabbit.
I have been already thinking about a further waiting method to run a certain command on host or as a docker container.
Than we could extend that tool by something like
...
        wait:
          - service: rabbitmq
            method: container
            timeout: 5
            image: python-test-rabbit
...

having a docker image called python-test-rabbit that does your check.
The benefit then would be that there is no need anymore to bring the waiting part to your worker.
It would be isolated and stay inside the orchestration layer.
May be someone finds this helpful to use. Any suggestions are very welcome.
You can find this tool at https://gitlab.com/michapoe/docker-compose-profile
    You can also solve this by setting an endpoint which waits for the service to be up by using netcat (using the docker-wait script). I like this approach as you still have a clean command section in your docker-compose.yml and you don't need to add docker specific code to your application:

version: '2'
services:
  db:
    image: postgres
  django:
    build: .
    command: python manage.py runserver 0.0.0.0:8000
    entrypoint: ./docker-entrypoint.sh db 5432
    volumes:
      - .:/code
    ports:
      - ""8000:8000""
    depends_on:
      - db


Then your docker-entrypoint.sh:

#!/bin/sh

postgres_host=$1
postgres_port=$2
shift 2
cmd=""$@""

# wait for the postgres docker to be running
while ! nc $postgres_host $postgres_port; do
  >&2 echo ""Postgres is unavailable - sleeping""
  sleep 1
done

>&2 echo ""Postgres is up - executing command""

# run the command
exec $cmd


This is nowadays documented in the official docker documentation.

PS: You should install netcat in your docker instance if this is not available. To do so add this to your Docker file :

RUN apt-get update && apt-get install netcat-openbsd -y 

    One of the alternative solution is to use a container orchestration solution like Kubernetes. Kubernetes has support for init containers which run to completion before other containers can start. You can find an example here with SQL Server 2017 Linux container where API container uses init container to initialise a database 

https://www.handsonarchitect.com/2018/08/understand-kubernetes-object-init.html
    I just have 2 compose files and start one first and second one later. My script looks like that:

#!/bin/bash
#before i build my docker files
#when done i start my build docker-compose
docker-compose -f docker-compose.build.yaml up
#now i start other docker-compose which needs the image of the first
docker-compose -f docker-compose.prod.yml up

    Here is the example where main container waits for worker when it start responding for pings:

version: '3'
services:
  main:
    image: bash
    depends_on:
     - worker
    command: bash -c ""sleep 2 && until ping -qc1 worker; do sleep 1; done &>/dev/null""
    networks:
      intra:
        ipv4_address: 172.10.0.254
  worker:
    image: bash
    hostname: test01
    command: bash -c ""ip route && sleep 10""
    networks:
      intra:
        ipv4_address: 172.10.0.11
networks:
  intra:
    driver: bridge
    ipam:
      config:
      - subnet: 172.10.0.0/24


However, the proper way is to use healthcheck (>=2.1).
    ","[489, 440, 80, 82, 58, 8, 10, 13, 4, 22, 5, 3, 15, 5, 1, 7, -1, -6, 0]",392327,167,2015-07-31T12:25:23,2022-03-01 10:42:59Z,
Android basics: running code in the UI thread,"
                
In the viewpoint of running code in the UI thread, is there any difference between:

MainActivity.this.runOnUiThread(new Runnable() {
    public void run() {
        Log.d(""UI thread"", ""I am the UI thread"");
    }
});


or

MainActivity.this.myView.post(new Runnable() {
    public void run() {
        Log.d(""UI thread"", ""I am the UI thread"");
    }
});


and

private class BackgroundTask extends AsyncTask<String, Void, Bitmap> {
    protected void onPostExecute(Bitmap result) {
        Log.d(""UI thread"", ""I am the UI thread"");
    }
}

    use Handler
new Handler(Looper.getMainLooper()).post(new Runnable() {
    @Override
    public void run() {
        // Code here will run in UI thread
    }
});

    I like the one from HPP comment, it can be used anywhere without any parameter:

new Handler(Looper.getMainLooper()).post(new Runnable() {
    @Override
    public void run() {
        Log.d(""UI thread"", ""I am the UI thread"");
    }
});

    None of those are precisely the same, though they will all have the same net effect.

The difference between the first and the second is that if you happen to be on the main application thread when executing the code, the first one (runOnUiThread()) will execute the Runnable immediately. The second one (post()) always puts the Runnable at the end of the event queue, even if you are already on the main application thread.

The third one, assuming you create and execute an instance of BackgroundTask, will waste a lot of time grabbing a thread out of the thread pool, to execute a default no-op doInBackground(), before eventually doing what amounts to a post(). This is by far the least efficient of the three. Use AsyncTask if you actually have work to do in a background thread, not just for the use of onPostExecute().
    As of Android P you can use getMainExecutor():

getMainExecutor().execute(new Runnable() {
  @Override public void run() {
    // Code will run on the main thread
  }
});


From the Android developer docs:


  Return an Executor that will run enqueued tasks on the main thread associated with this context. This is the thread used to dispatch calls to application components (activities, services, etc).


From the CommonsBlog:


  You can call getMainExecutor() on Context to get an Executor that will execute its jobs on the main application thread. There are other ways of accomplishing this, using Looper and a custom Executor implementation, but this is simpler.

    If you need to use in Fragment you should use 

private Context context;

    @Override
    public void onAttach(Context context) {
        super.onAttach(context);
        this.context = context;
    }


    ((MainActivity)context).runOnUiThread(new Runnable() {
        public void run() {
            Log.d(""UI thread"", ""I am the UI thread"");
        }
    });


instead of

getActivity().runOnUiThread(new Runnable() {
    public void run() {
        Log.d(""UI thread"", ""I am the UI thread"");
    }
});


Because There will be null pointer exception in some situation like pager fragment
    The answer by Pomber is acceptable, however I'm not a big fan of creating new objects repeatedly. The best solutions are always the ones that try to mitigate memory hog. Yes, there is auto garbage collection but memory conservation in a mobile device falls within the confines of best practice.
The code below updates a TextView in a service. 

TextViewUpdater textViewUpdater = new TextViewUpdater();
Handler textViewUpdaterHandler = new Handler(Looper.getMainLooper());
private class TextViewUpdater implements Runnable{
    private String txt;
    @Override
    public void run() {
        searchResultTextView.setText(txt);
    }
    public void setText(String txt){
        this.txt = txt;
    }

}


It can be used from anywhere like this:

textViewUpdater.setText(""Hello"");
        textViewUpdaterHandler.post(textViewUpdater);

    There is a fourth way using Handler

new Handler().post(new Runnable() {
    @Override
    public void run() {
        // Code here will run in UI thread
    }
});

    Kotlin version:
Handler(Looper.getMainLooper()).post {
   Toast.makeText(context, ""Running on UI(Main) thread."", Toast.LENGTH_LONG).show()
}

Or if you are using Kotlin coroutines:
inside coroutine scope add this:
withContext(Dispatchers.Main) {
   Toast.makeText(context, ""Running on UI(Main) thread."", Toast.LENGTH_LONG).show()
}

    ","[489, 7, 282, 309, 13, 12, 18, 63, 0]",309170,105,2012-10-11T23:28:55,2021-12-08 13:35:04Z,
"What is the python ""with"" statement designed for?","
                
I came across the Python with statement for the first time today.  I've been using Python lightly for several months and didn't even know of its existence!  Given its somewhat obscure status, I thought it would be worth asking:


What is the Python with statement
designed to be used for?   
What do
you use it for? 
Are there any
gotchas I need to be aware of, or
common anti-patterns associated with
its use?  Any cases where it is better use try..finally than with?
Why isn't it used more widely?
Which standard library classes are compatible with it?

    
I believe this has already been answered by other users before me, so I only add it for the sake of completeness: the with statement simplifies exception handling by encapsulating common preparation and cleanup tasks in so-called context managers. More details can be found in PEP 343. For instance, the open statement is a context manager in itself, which lets you open a file, keep it open as long as the execution is in the context of the with statement where you used it, and close it as soon as you leave the context, no matter whether you have left it because of an exception or during regular control flow. The with statement can thus be used in ways similar to the RAII pattern in C++: some resource is acquired by the with statement and released when you leave the with context.
Some examples are: opening files using with open(filename) as fp:, acquiring locks using with lock: (where lock is an instance of threading.Lock). You can also construct your own context managers using the contextmanager decorator from contextlib. For instance, I often use this when I have to change the current directory temporarily and then return to where I was:

from contextlib import contextmanager
import os

@contextmanager
def working_directory(path):
    current_dir = os.getcwd()
    os.chdir(path)
    try:
        yield
    finally:
        os.chdir(current_dir)

with working_directory(""data/stuff""):
    # do something within data/stuff
# here I am back again in the original working directory


Here's another example that temporarily redirects sys.stdin, sys.stdout and sys.stderr to some other file handle and restores them later:

from contextlib import contextmanager
import sys

@contextmanager
def redirected(**kwds):
    stream_names = [""stdin"", ""stdout"", ""stderr""]
    old_streams = {}
    try:
        for sname in stream_names:
            stream = kwds.get(sname, None)
            if stream is not None and stream != getattr(sys, sname):
                old_streams[sname] = getattr(sys, sname)
                setattr(sys, sname, stream)
        yield
    finally:
        for sname, stream in old_streams.iteritems():
            setattr(sys, sname, stream)

with redirected(stdout=open(""/tmp/log.txt"", ""w"")):
     # these print statements will go to /tmp/log.txt
     print ""Test entry 1""
     print ""Test entry 2""
# back to the normal stdout
print ""Back to normal stdout again""


And finally, another example that creates a temporary folder and cleans it up when leaving the context:

from tempfile import mkdtemp
from shutil import rmtree

@contextmanager
def temporary_dir(*args, **kwds):
    name = mkdtemp(*args, **kwds)
    try:
        yield name
    finally:
        shutil.rmtree(name)

with temporary_dir() as dirname:
    # do whatever you want


    I would suggest two interesting lectures:

PEP 343 The ""with"" Statement
Effbot Understanding Python's
""with"" statement

1.
The with statement is used to wrap the execution of a block with methods defined by a context manager. This allows common try...except...finally usage patterns to be encapsulated for convenient reuse.
2.
You could do something like:
with open(""foo.txt"") as foo_file:
    data = foo_file.read()

OR
from contextlib import nested
with nested(A(), B(), C()) as (X, Y, Z):
   do_something()

OR (Python 3.1)
with open('data') as input_file, open('result', 'w') as output_file:
   for line in input_file:
     output_file.write(parse(line))

OR
lock = threading.Lock()
with lock:
    # Critical section of code

3.
I don't see any Antipattern here.
Quoting Dive into Python:

try..finally is good. with is better.

4.
I guess it's related to programmers's habit to use try..catch..finally statement from other languages.
    The answers here are great, but just to add a simple one that helped me:
with open(""foo.txt"") as file:
    data = file.read()


open returns a file
Since 2.6 python added the methods __enter__ and __exit__ to file.
with is like a for loop that calls __enter__, runs the loop once and then calls __exit__
with works with any instance that has __enter__ and __exit__

a file is locked and not re-usable by other processes until it's closed, __exit__ closes it.
source: http://web.archive.org/web/20180310054708/http://effbot.org/zone/python-with-statement.htm
    The Python with statement is built-in language support of the Resource Acquisition Is Initialization idiom commonly used in C++. It is intended to allow safe acquisition and release of operating system resources.

The with statement creates resources within a scope/block. You write your code using the resources within the block. When the block exits the resources are cleanly released regardless of the outcome of the code in the block (that is whether the block exits normally or because of an exception).

Many resources in the Python library that obey the protocol required by the with statement and so can used with it out-of-the-box. However anyone can make resources that can be used in a with statement by implementing the well documented protocol: PEP 0343

Use it whenever you acquire resources in your application that must be explicitly relinquished such as files, network connections, locks and the like.
    An example of an antipattern might be to use the with inside a loop when it would be more efficient to have the with outside the loop

for example

for row in lines:
    with open(""outfile"",""a"") as f:
        f.write(row)


vs

with open(""outfile"",""a"") as f:
    for row in lines:
        f.write(row)


The first way is opening and closing the file for each row which may cause performance problems compared to the second way with opens and closes the file just once.
    Again for completeness I'll add my most useful use-case for with statements.

I do a lot of scientific computing and for some activities I need the Decimal library for arbitrary precision calculations.  Some part of my code I need high precision and for most other parts I need less precision.

I set my default precision to a low number and then use with to get a more precise answer for some sections:

from decimal import localcontext

with localcontext() as ctx:
    ctx.prec = 42   # Perform a high precision calculation
    s = calculate_something()
s = +s  # Round the final result back to the default precision


I use this a lot with the Hypergeometric Test which requires the division of large numbers resulting form factorials.  When you do genomic scale calculations you have to be careful of round-off and overflow errors.
    points 1, 2, and 3 being reasonably well covered:

4: it is relatively new, only available in python2.6+ (or python2.5 using from __future__ import with_statement)
    Another example for out-of-the-box support, and one that might be a bit baffling at first when you are used to the way built-in open() behaves, are connection objects of popular database modules such as:


sqlite3
psycopg2
cx_oracle


The connection objects are context managers and as such can be used out-of-the-box in a with-statement, however when using the above note that:


  When the with-block is finished, either with an exception or without, the connection is not closed. In case the with-block finishes with an exception, the transaction is rolled back, otherwise the transaction is commited.


This means that the programmer has to take care to close the connection themselves, but allows to acquire a connection, and use it in multiple with-statements, as shown in the psycopg2 docs:

conn = psycopg2.connect(DSN)

with conn:
    with conn.cursor() as curs:
        curs.execute(SQL1)

with conn:
    with conn.cursor() as curs:
        curs.execute(SQL2)

conn.close()


In the example above, you'll note that the cursor objects of psycopg2 also are context managers. From the relevant documentation on the behavior:


  When a cursor exits the with-block it is closed, releasing any resource eventually associated with it. The state of the transaction is not affected.

    In python generally “with” statement is used to open a file, process the data present in the file, and also to close the file without calling a close() method. “with” statement makes the exception handling simpler by providing cleanup activities.
General form of with:
with open(“file name”, “mode”) as file_var:
    processing statements

note: no need to close the file by calling close() upon file_var.close()
    See PEP 343 - The 'with' statement, there is an example section at the end.


  ... new statement ""with"" to the Python
  language to make
      it possible to factor out standard uses of try/finally statements.

    The with statement works with so-called context managers:

http://docs.python.org/release/2.5.2/lib/typecontextmanager.html

The idea is to simplify exception handling by doing the necessary cleanup after leaving the 'with' block. Some of the python built-ins already work as context managers.
    ","[489, 437, 100, 1, 44, 28, 28, 5, 3, 3, 10, 4]",114041,227,2010-06-10T07:35:21,2022-03-26 20:06:52Z,python 
Should import statements always be at the top of a module?,"
                
PEP 8 states:

Imports are always put at the top of the file, just after any module comments and docstrings, and before module globals and constants.

However if the class/method/function that I am importing is only used in rare cases, surely it is more efficient to do the import when it is needed?
Isn't this:
class SomeClass(object):

    def not_often_called(self)
        from datetime import datetime
        self.datetime = datetime.now()

more efficient than this?
from datetime import datetime

class SomeClass(object):

    def not_often_called(self)
        self.datetime = datetime.now()

    Module importing is quite fast, but not instant. This means that:


Putting the imports at the top of the module is fine, because it's a trivial cost that's only paid once.
Putting the imports within a function will cause calls to that function to take longer.


So if you care about efficiency, put the imports at the top. Only move them into a function if your profiling shows that would help (you did profile to see where best to improve performance, right??)



The best reasons I've seen to perform lazy imports are:


Optional library support. If your code has multiple paths that use different libraries, don't break if an optional library is not installed.
In the __init__.py of a plugin, which might be imported but not actually used. Examples are Bazaar plugins, which use bzrlib's lazy-loading framework.

    Here's an updated summary of the answers to this
and
related
questions.

PEP 8 recommends
putting imports at the top.
It's often more convenient
to get ImportErrors when you first run your program rather than when
your program first calls your function.
Imports at the top enhance readability,
since you can see all your dependencies at a glance.
Refactoring
might be easier if the imports are located in the function
where they're used (facilitates moving it to another module).
It can also be argued that this is good for readability.
Putting imports in the function scope can help avoid issues with circular imports.
Putting imports in the function scope helps keep the module namespace clean,
so that it does not appear among tab-completion suggestions.
Start-up time:
imports in a function won't run until (if) that function is called.
Might get significant with heavy-weight libraries.
Even though import statements are super fast on subsequent runs,
they still incur a speed penalty
which can be significant if the function is trivial but frequently in use.
Imports under the __name__ == ""__main__"" guard seems very reasonable.
It seems unclear if dynamic or conditional imports favour one style over another.

    I have adopted the practice of putting all imports in the functions that use them, rather than at the top of the module.

The benefit I get is the ability to refactor more reliably. When I move a function from one module to another, I know that the function will continue to work with all of its legacy of testing intact. If I have my imports at the top of the module, when I move a function, I find that I end up spending a lot of time getting the new module's imports complete and minimal. A refactoring IDE might make this irrelevant.

There is a speed penalty as mentioned elsewhere. I have measured this in my application and found it to be insignificant for my purposes. 

It is also nice to be able to see all module dependencies up front without resorting to search (e.g. grep). However, the reason I care about module dependencies is generally because I'm installing, refactoring, or moving an entire system comprising multiple files, not just a single module. In that case, I'm going to perform a global search anyway to make sure I have the system-level dependencies. So I have not found global imports to aid my understanding of a system in practice.

I usually put the import of sys inside the if __name__=='__main__' check and then pass arguments (like sys.argv[1:]) to a main() function. This allows me to use main in a context where sys has not been imported.
    Putting the import statement inside of a function can prevent circular dependencies.
For example, if you have 2 modules, X.py and Y.py, and they both need to import each other, this will cause a circular dependency when you import one of the modules causing an infinite loop. If you move the import statement in one of the modules then it won't try to import the other module till the function is called, and that module will already be imported, so no infinite loop. Read here for more - effbot.org/zone/import-confusion.htm
    While PEP encourages importing at the top of a module, it isn't an error to import at other levels. That indicates imports should be at the top, however there are exceptions.
It is a micro-optimization to load modules when they are used. Code that is sluggish importing can be optimized later if it makes a sizable difference.
Still, you might introduce flags to conditionally import at as near to the top as possible, allowing a user to use configuration to import the modules they need while still importing everything immediately.
Importing as soon as possible means the program will fail if any imports (or imports of imports) are missing or have syntax errors. If all imports occur at the top of all modules then python works in two steps. Compile. Run.
Built in modules work anywhere they are imported because they are well designed. Modules you write should be the same. Moving around your imports to the top or to their first use can help ensure there are no side effects and the code is injecting dependencies.
Whether you put imports at the top or not, your code should still work when the imports are at the top. So start by importing immediately then optimize as needed.
    Most of the time this would be useful for clarity and sensible to do but it's not always the case.  Below are a couple of examples of circumstances where module imports might live elsewhere.

Firstly, you could have a module with a unit test of the form:

if __name__ == '__main__':
    import foo
    aa = foo.xyz()         # initiate something for the test


Secondly, you might have a requirement to conditionally import some different module at runtime.

if [condition]:
    import foo as plugin_api
else:
    import bar as plugin_api
xx = plugin_api.Plugin()
[...]


There are probably other situations where you might place imports in other parts in the code.
    Module initialization only occurs once - on the first import.  If the module in question is from the standard library, then you will likely import it from other modules in your program as well.  For a module as prevalent as datetime, it is also likely a dependency for a slew of other standard libraries.  The import statement would cost very little then since the module intialization would have happened already.  All it is doing at this point is binding the existing module object to the local scope.

Couple that information with the argument for readability and I would say that it is best to have the import statement at module scope.  
    I was surprised not to see actual cost numbers for the repeated load-checks posted already, although there are many good explanations of what to expect.

If you import at the top, you take the load hit no matter what. That's pretty small, but commonly in the milliseconds, not nanoseconds.

If you import within a function(s), then you only take the hit for loading if and when one of those functions is first called. As many have pointed out, if that doesn't happen at all, you save the load time. But if the function(s) get called a lot, you take a repeated though much smaller hit (for checking that it has been loaded; not for actually re-loading). On the other hand, as @aaronasterling pointed out you also save a little because importing within a function lets the function use slightly-faster local variable lookups to identify the name later (http://stackoverflow.com/questions/477096/python-import-coding-style/4789963#4789963).

Here are the results of a simple test that imports a few things from inside a function. The times reported (in Python 2.7.14 on a 2.3 GHz Intel Core i7) are shown below (the 2nd call taking more than later calls seems consistent, though I don't know why).

 0 foo:   14429.0924 µs
 1 foo:      63.8962 µs
 2 foo:      10.0136 µs
 3 foo:       7.1526 µs
 4 foo:       7.8678 µs
 0 bar:       9.0599 µs
 1 bar:       6.9141 µs
 2 bar:       7.1526 µs
 3 bar:       7.8678 µs
 4 bar:       7.1526 µs


The code:

from __future__ import print_function
from time import time

def foo():
    import collections
    import re
    import string
    import math
    import subprocess
    return

def bar():
    import collections
    import re
    import string
    import math
    import subprocess
    return

t0 = time()
for i in xrange(5):
    foo()
    t1 = time()
    print(""    %2d foo: %12.4f \xC2\xB5s"" % (i, (t1-t0)*1E6))
    t0 = t1
for i in xrange(5):
    bar()
    t1 = time()
    print(""    %2d bar: %12.4f \xC2\xB5s"" % (i, (t1-t0)*1E6))
    t0 = t1

    The first variant is indeed more efficient than the second when the function is called either zero or one times.  With the second and subsequent invocations, however, the ""import every call"" approach is actually less efficient.  See this link for a lazy-loading technique that combines the best of both approaches by doing a ""lazy import"".

But there are reasons other than efficiency why you might prefer one over the other.  One approach is makes it much more clear to someone reading the code as to the dependencies that this module has.  They also have very different failure characteristics -- the first will fail at load time if there's no ""datetime"" module while the second won't fail until the method is called.

Added Note: In IronPython, imports can be quite a bit more expensive than in CPython because the code is basically being compiled as it's being imported.
    It's interesting that not a single answer mentioned parallel processing so far, where it might be REQUIRED that the imports are in the function, when the serialized function code is what is being pushed around to other cores, e.g. like in the case of ipyparallel.
    Curt makes a good point: the second version is clearer and will fail at load time rather than later, and unexpectedly.

Normally I don't worry about the efficiency of loading modules, since it's (a) pretty fast, and (b) mostly only happens at startup.

If you have to load heavyweight modules at unexpected times, it probably makes more sense to load them dynamically with the __import__ function, and be sure to catch ImportError exceptions, and handle them in a reasonable manner.
    This is like many other optimizations - you sacrifice some readability for speed.  As John mentioned, if you've done your profiling homework and found this to be a significantly useful enough change and you need the extra speed, then go for it.  It'd probably be good to put a note up with all the other imports:

from foo import bar
from baz import qux
# Note: datetime is imported in SomeClass below

    Just to complete Moe's answer and the original question:

When we have to deal with circular dependences we can do some ""tricks"". Assuming we're working with modules a.py and b.py that contain x() and b y(), respectively. Then:


We can move one of the from imports at the bottom of the module.
We can move one of the from imports inside the function or method that is actually requiring the import (this isn't always possible, as you may use it from several places).
We can change one of the two from imports to be an import that looks like: import a


So, to conclude. If you aren't dealing with circular dependencies and doing some kind of trick to avoid them, then it's better to put all your imports at the top because of the reasons already explained in other answers to this question. And please, when doing this ""tricks"" include a comment, it's always welcome! :)
    I wouldn't worry about the efficiency of loading the module up front too much.  The memory taken up by the module won't be very big (assuming it's modular enough) and the startup cost will be negligible.

In most cases you want to load the modules at the top of the source file.  For somebody reading your code, it makes it much easier to tell what function or object came from what module.

One good reason to import a module elsewhere in the code is if it's used in a debugging statement.

For example:

do_something_with_x(x)


I could debug this with:

from pprint import pprint
pprint(x)
do_something_with_x(x)


Of course, the other reason to import modules elsewhere in the code is if you need to dynamically import them.  This is because you pretty much don't have any choice.

I wouldn't worry about the efficiency of loading the module up front too much.  The memory taken up by the module won't be very big (assuming it's modular enough) and the startup cost will be negligible.
    There can be a performance gain by importing variables/local scoping inside of a function. This depends on the usage of the imported thing inside the function. If you are looping many times and accessing a module global object, importing it as local can help. 

test.py

X=10
Y=11
Z=12
def add(i):
  i = i + 10


runlocal.py

from test import add, X, Y, Z

    def callme():
      x=X
      y=Y
      z=Z
      ladd=add 
      for i  in range(100000000):
        ladd(i)
        x+y+z

    callme()


run.py

from test import add, X, Y, Z

def callme():
  for i in range(100000000):
    add(i)
    X+Y+Z

callme()


A time on Linux shows a small gain

/usr/bin/time -f ""\t%E real,\t%U user,\t%S sys"" python run.py 
    0:17.80 real,   17.77 user, 0.01 sys
/tmp/test$ /usr/bin/time -f ""\t%E real,\t%U user,\t%S sys"" python runlocal.py 
    0:14.23 real,   14.22 user, 0.01 sys


real is wall clock. user is time in program. sys is time for system calls.

https://docs.python.org/3.5/reference/executionmodel.html#resolution-of-names
    I do not aspire to provide complete answer, because others have already done this very well. I just want to mention one use case when I find especially useful to import modules inside functions. My application uses python packages and modules stored in certain location as plugins. During application startup, the application walks through all the modules in the location and imports them, then it looks inside the modules and if it finds some mounting points for the plugins (in my case it is a subclass of a certain base class having a unique ID) it registers them. The number of plugins is large (now dozens, but maybe hundreds in the future) and each of them is used quite rarely. Having imports of third party libraries at the top of my plugin modules was a bit penalty during application startup. Especially some thirdparty libraries are heavy to import (e.g. import of plotly even tries to connect to internet and download something which was adding about one second to startup). By optimizing imports (calling them only in the functions where they are used) in the plugins I managed to shrink the startup from 10 seconds to some 2 seconds. That is a big difference for my users.

So my answer is no, do not always put the imports at the top of your modules.
    In addition to the excellent answers already given, it's worth noting that the placement of imports is not merely a matter of style. Sometimes a module has implicit dependencies that need to be imported or initialized first, and a top-level import could lead to violations of the required order of execution. 

This issue often comes up in Apache Spark's Python API, where you need to initialize the SparkContext before importing any pyspark packages or modules. It's best to place pyspark imports in a scope where the SparkContext is guaranteed to be available.
    It's a tradeoff, that only the programmer can decide to make. 

Case 1 saves some memory and startup time by not importing the datetime module (and doing whatever initialization it might require) until needed.  Note that doing the import 'only when called' also means doing it 'every time when called', so each call after the first one is still incurring the additional overhead of doing the import. 

Case 2 save some execution time and latency by importing datetime beforehand so that not_often_called() will return more quickly when it is called, and also by not incurring the overhead of an import on every call.

Besides efficiency, it's easier to see module dependencies up front if the import statements are ... up front. Hiding them down in the code can make it more difficult to easily find what modules something depends on.

Personally I generally follow the PEP except for things like unit tests and such that I don't want always loaded because I know they aren't going to be used except for test code.
    Here's an example where all the imports are at the very top (this is the only time I've needed to do this).  I want to be able to terminate a subprocess on both Un*x and Windows.

import os
# ...
try:
    kill = os.kill  # will raise AttributeError on Windows
    from signal import SIGTERM
    def terminate(process):
        kill(process.pid, SIGTERM)
except (AttributeError, ImportError):
    try:
        from win32api import TerminateProcess  # use win32api if available
        def terminate(process):
            TerminateProcess(int(process._handle), -1)
    except ImportError:
        def terminate(process):
            raise NotImplementedError  # define a dummy function


(On review: what John Millikin said.)
    Readability
In addition to startup performance, there is a readability argument to be made for localizing import statements. For example take python line numbers 1283 through 1296 in my current first python project:
listdata.append(['tk font version', font_version])
listdata.append(['Gtk version', str(Gtk.get_major_version())+"".""+
                 str(Gtk.get_minor_version())+"".""+
                 str(Gtk.get_micro_version())])

import xml.etree.ElementTree as ET

xmltree = ET.parse('/usr/share/gnome/gnome-version.xml')
xmlroot = xmltree.getroot()
result = []
for child in xmlroot:
    result.append(child.text)
listdata.append(['Gnome version', result[0]+"".""+result[1]+"".""+
                 result[2]+"" ""+result[3]])

If the import statement was at the top of file I would have to scroll up a long way, or press Home, to find out what ET was. Then I would have to navigate back to line 1283 to continue reading code.
Indeed even if the import statement was at the top of the function (or class) as many would place it, paging up and back down would be required.
Displaying the Gnome version number will rarely be done so the import at top of file introduces unnecessary startup lag.
    This is a fascinating discussion. Like many others I had never even considered this topic. I got cornered into having to have the imports in the functions because of wanting to use the Django ORM in one of my libraries. I was having to call django.setup() before importing my model classes and because this was at the top of the file it was being dragged into completely non-Django library code because of the IoC injector construction.

I kind of hacked around a bit and ended up putting the django.setup() in the singleton constructor and the relevant import at the top of each class method. Now this worked fine but made me uneasy because the imports weren't at the top and also I started worrying about the extra time hit of the imports. Then I came here and read with great interest everybody's take on this.

I have a long C++ background and now use Python/Cython. My take on this is that why not put the imports in the function unless it causes you a profiled bottleneck. It's only like declaring space for variables just before you need them. The trouble is I have thousands of lines of code with all the imports at the top! So I think I will do it from now on and change the odd file here and there when I'm passing through and have the time.
    I would like to mention a usecase of mine, very similar to those mentioned by @John Millikin and @V.K.:
Optional Imports
I do data analysis with Jupyter Notebook, and I use the same IPython notebook as a template for all analyses. In some occasions, I need to import Tensorflow to do some quick model runs, but sometimes I work in places where tensorflow isn't set up / is slow to import. In those cases, I encapsulate my Tensorflow-dependent operations in a helper function, import tensorflow inside that function, and bind it to a button.
This way, I could do ""restart-and-run-all"" without having to wait for the import, or having to resume the rest of the cells when it fails.
    ","[489, 347, 4, 74, 93, 1, 43, 5, 5, 15, 3, 9, 6, 4, 8, 1, 3, 4, 6, 6, 2, 0, 0]",151119,119,2008-09-24T17:21:47,2021-11-11 13:37:26Z,python 
"What's the difference between ""git reset"" and ""git checkout""?","
                
I've always thought of git reset and git checkout as the same, in the sense that both bring the project back to a specific commit. However, I feel they can't be exactly the same, as that would be redundant. What is the actual difference between the two? I'm a bit confused, as the svn only has svn co to revert the commit. 

ADDED

VonC and Charles explained the differences between git reset and git checkout really well. My current understanding is that git reset reverts all of the changes back to a specific commit, whereas git checkout more or less prepares for a branch. I found the following two diagrams quite useful in coming to this understanding:




ADDED 3

From http://think-like-a-git.net/sections/rebase-from-the-ground-up/using-git-cherry-pick-to-simulate-git-rebase.html, checkout and reset can emulate the rebase. 



git checkout bar 
git reset --hard newbar 
git branch -d newbar 



    
git reset is specifically about updating the index, moving the HEAD.
git checkout is about updating the working tree (to the index or the specified tree). It will update the HEAD only if you checkout a branch (if not, you end up with a detached HEAD).
(actually, with Git 2.23 Q3 2019, this will be git restore, not necessarily git checkout)

By comparison, since svn has no index, only a working tree, svn checkout will copy a given revision on a separate directory.
The closer equivalent for git checkout would:

svn update (if you are in the same branch, meaning the same SVN URL)
svn switch (if you checkout for instance the same branch, but from another SVN repo URL)

All those three working tree modifications (svn checkout, update, switch) have only one command in git: git checkout.
But since git has also the notion of index (that ""staging area"" between the repo and the working tree), you also have git reset.

Thinkeye mentions in the comments the article ""Reset Demystified "".

For instance, if we have two branches, 'master' and 'develop' pointing at different commits, and we're currently on 'develop' (so HEAD points to it) and we run git reset master, 'develop' itself will now point to the same commit that 'master' does.
On the other hand, if we instead run git checkout master, 'develop' will not move, HEAD itself will. HEAD will now point to 'master'.
So, in both cases we're moving HEAD to point to commit A, but how we do so is very different. reset will move the branch HEAD points to, checkout moves HEAD itself to point to another branch.


On those points, though:
LarsH adds in the comments:

The first paragraph of this answer, though, is misleading: ""git checkout ... will update the HEAD only if you checkout a branch (if not, you end up with a detached HEAD)"".
Not true: git checkout will update the HEAD even if you checkout a commit that's not a branch (and yes, you end up with a detached HEAD, but it still got updated).
git checkout a839e8f updates HEAD to point to commit a839e8f.


De Novo concurs in the comments:

@LarsH is correct.
The second bullet has a misconception about what HEAD is in will update the HEAD only if you checkout a branch.
HEAD goes wherever you are, like a shadow.
Checking out some non-branch ref (e.g., a tag), or a commit directly, will move HEAD. Detached head doesn't mean you've detached from the HEAD, it means the head is detached from a branch ref, which you can see from, e.g., git log --pretty=format:""%d"" -1.

Attached head states will start with (HEAD ->,
detached will still show (HEAD, but will not have an arrow to a branch ref.


    The key difference in a nutshell is that reset moves the current branch reference, while checkout does not (it moves HEAD).

As the Pro Git book explains under Reset Demystified,


  The first thing reset will do is move what HEAD points to. This isn’t
  the same as changing HEAD itself (which is what checkout does); reset
  moves the branch that HEAD is pointing to. This means if HEAD is set
  to the master branch (i.e. you’re currently on the master branch),
  running git reset 9e5e6a4 will start by making master point to
  9e5e6a4. [emphasis added]


See also VonC's answer for a very helpful text and diagram excerpt from the same article, which I won't duplicate here.

Of course there are a lot more details about what effects checkout and reset can have on the index and the working tree, depending on what parameters are used. There can be lots of similarities and differences between the two commands. But as I see it, the most crucial difference is whether they move the tip of the current branch.
    One simple use case when reverting change:
1. Use reset if you want to undo staging of a modified file.
2. Use checkout if you want to discard changes to unstaged file/s.
    brief mnemonics:

git reset HEAD           :             index = HEAD
git checkout             : file_tree = index
git reset --hard HEAD    : file_tree = index = HEAD

    In their simplest form, reset resets the index without touching the working tree, while checkout changes the working tree without touching the index.

Resets the index to match HEAD, working tree left alone:

git reset


Conceptually, this checks out the index into the working tree. To get it to actually do anything you would have to use -f to force it to overwrite any local changes. This is a safety feature to make sure that the ""no argument"" form isn't destructive:

git checkout


Once you start adding parameters it is true that there is some overlap.

checkout is usually used with a branch, tag or commit. In this case it will reset HEAD and the index to the given commit as well as performing the checkout of the index into the working tree.

Also, if you supply --hard to reset you can ask reset to overwrite the working tree as well as resetting the index.

If you current have a branch checked out out there is a crucial different between reset and checkout when you supply an alternative branch or commit. reset will change the current branch to point at the selected commit whereas checkout will leave the current branch alone but will checkout the supplied branch or commit instead.

Other forms of reset and commit involve supplying paths.

If you supply paths to reset you cannot supply --hard and reset will only change the index version of the supplied paths to the version in the supplied commit (or HEAD if you don't specify a commit).

If you supply paths to checkout, like reset it will update the index version of the supplied paths to match the supplied commit (or HEAD) but it will always checkout the index version of the supplied paths into the working tree.
    The two commands (reset and checkout) are completely different. 

checkout X IS NOT reset --hard X

If X is a branch name, 
checkout X will change the current branch 
while reset --hard X will not. 
    Here's a clarification of the ambiguity:

git checkout will move the HEAD to another commit(could be a change using a branchname too), but:

on whatever branch you are, the pointer to the tip of that branch(e.g., ""main"") will remain unchanged (so you might end up in a detached head state).

Also, the staging area and the working directory will remain unchanged(in the similar state they were before the checkout).




Examples:
git checkout 3ad2bcf <--- checkout to another commit
git checkout another-branch <--- checkout to another commit using a branchname


git reset also moves the HEAD, however again, with two differences:

It moves the pointer that points to the commit at the tip of the current branch too. For instance, let's say the pointer to the current branch is named ""main"", then you perform a git-reset, now, the main pointer will point to another commit, and the HEAD will point to that commit as well(well basically, HEAD points to that commit indirectly through pointing to the main pointer, it is still an attached head(!), but it doesn't make any difference here).

Git-reset doesn't necessarily leave the staging area and the working directory on the same state they were in before the reset was performed. As you know, there are three types of reset: soft, mixed(default) and hard:

With the soft reset, the staging area and the working directory both remain in the state they've been on before the reset(similar to checkout in this regard, but don't forget the difference #1).
With the mixed reset which is the default type of reset, in addition to difference #1, the staging area's proposed next commit(what you've git-added basically), will also be set to the newly pointed-to-by-HEAD commit. BUT in the working directory, all the files will still have your latest edits to them (that's why this type of reset is the default one, so that you don't lose your work).
With the hard reset, in addition to difference #1, all the three trees HEAD, staging-area and ALSO the working-directory will change to the newly pointed-to-by-HEAD commit.





Examples:
git reset --soft 3ad2bcf
git reset da3b47

    ","[489, 221, 15, 59, 5, 73, 3, 0]",151108,272,2010-09-03T20:21:43,2021-10-02 05:46:52Z,
Freeze screen in chrome debugger / DevTools panel for popover inspection?,"
                
I'm using the chrome inspector to try and analyze the z-index of a twitter bootstrap popover, and finding it extremely frustrating... 

Is there a way to freeze the popover (while shown) so that I can assess and modify the associated CSS?

Placing a fixed 'hover' on the associated link does not cause the popover to appear. 
    Got it working. Here was my procedure:


Browse to the desired page
Open the dev console - F12 on Windows/Linux or option + ⌘ + J on macOS
Select the Sources tab in chrome inspector
In the web browser window, hover over the desired element to initiate the popover
Hit F8 on Windows/Linux (or fn + F8 on macOS) while the popover is showing. If you have clicked anywhere on the actual page F8 will do nothing. Your last click needs to be somewhere in the inspector, like the sources tab
Go to the Elements tab in inspector
Find your popover (it will be nested in the trigger element's HTML)
Have fun modifying the CSS

    To be able to inspect any element do the following. This should work even if it's hard to duplicate the hover state:


Run the following javascript in the console. This will break into the debugger in 5 seconds.

setTimeout(function(){debugger;}, 5000)
Go show your element (by hovering or however) and wait until Chrome breaks into the Debugger. 
Now click on the Elements tab in the Chrome Inspector, and you can look for your element there. 
You may also be able to click on the Find Element icon (looks like a magnifying glass) and Chrome will let you go and inspect and find your element on the page by right clicking on it, then choosing Inspect Element


Note that this approach is a slight variation to this other great answer on this page.
    UPDATE:
As Brad Parks wrote in his comment there is a much better and easier solution with only one line of JS code:


  run setTimeout(function(){debugger;},5000);, then go show your element and wait until it breaks into the Debugger




Original answer:

I just had the same problem, and I think I found an ""universal"" solution. (assuming the site uses jQuery) 
Hope it helps someone!


Go to elements tab in inspector
Right click <body> and click ""Edit as HTML""
Add the following element after <body> then press Ctrl+Enter: <div id=""debugFreeze"" data-rand=""0""></div>
Right click this new element, and select ""Break on..."" -> ""Attributes modifications""
Now go to Console view and run the following command: setTimeout(function(){$(""#debugFreeze"").attr(""data-rand"",Math.random())},5000);
Now go back to the browser window and you have 5 seconds to find your element and click/hover/focus/etc it, before the breakpoint will be hit and the browser will ""freeze"".
Now you can inspect your clicked/hovered/focused/etc element in peace.


Of course you can modify the javascript and the timing, if you get the idea.
    
Right click anywhere inside Elements Tab
Choose Breakon... > subtree modifications
Trigger the popup you want to see and it will freeze if it see changes in the DOM
If you still don't see the popup, click Step over the next function(F10) button beside Resume(F8) in the upper top center of the chrome until you freeze the popup you want to see. 

    I tried the other solutions here, they work but I'm lazy so this is my solution


hover over the element to trigger expanded state
ctrl+shift+c
hover over element again
right click
navigate to the debugger


by right clicking it no longer registers mouse event since a context menu pops up, so you can move the mouse away safely
    I found that this works really well in Chrome.

Right click on the element that you'd like to inspect, then click Force Element State > Hover. Screenshot attached.


    Previously My Chrome Freeze feature was not working by pressing f8 shortcut Key , i use this walk around and goto Source Tab and just clicked on Pause / play on Script Execution button in right panel of chrome Dev tools in Source Tab, My short cut key that got fixed and started to work from then, Really thank full , Fixed my problem
    ","[488, 836, 383, 97, 51, 3, 17, 0]",205618,182,2013-07-29T18:32:24,2021-12-23 12:26:40Z,css 
Wait 5 seconds before executing next line,"
                
This function below doesn’t work like I want it to; being a JS novice I can’t figure out why.

I need it to wait 5 seconds before checking whether the newState is -1.

Currently, it doesn’t wait, it just checks straight away.

function stateChange(newState) {
  setTimeout('', 5000);

  if(newState == -1) {
    alert('VIDEO HAS STOPPED');
  }
}

    Here's a solution using the new async/await syntax.
Be sure to check browser support as this is a language feature introduced with ECMAScript 6.
Utility function:
const delay = ms => new Promise(res => setTimeout(res, ms));

Usage:
const yourFunction = async () => {
  await delay(5000);
  console.log(""Waited 5s"");

  await delay(5000);
  console.log(""Waited an additional 5s"");
};

The advantage of this approach is that it makes your code look and behave like synchronous code.
    You have to put your code in the callback function you supply to setTimeout:

function stateChange(newState) {
    setTimeout(function () {
        if (newState == -1) {
            alert('VIDEO HAS STOPPED');
        }
    }, 5000);
}


Any other code will execute immediately.
    If you're in an async function you can simply do it in one line:
console.log(1);
await new Promise(resolve => setTimeout(resolve, 3000)); // 3 sec
console.log(2);

FYI, if target is NodeJS you can use this if you want (it's a predefined promisified setTimeout function):
await setTimeout[Object.getOwnPropertySymbols(setTimeout)[0]](3000) // 3 sec

    You really shouldn't be doing this, the correct use of timeout is the right tool for the OP's problem and any other occasion where you just want to run something after a period of time. Joseph Silber has demonstrated that well in his answer. However, if in some non-production case you really want to hang the main thread for a period of time, this will do it.

function wait(ms){
   var start = new Date().getTime();
   var end = start;
   while(end < start + ms) {
     end = new Date().getTime();
  }
}


With execution in the form:

console.log('before');
wait(7000);  //7 seconds in milliseconds
console.log('after');


I've arrived here because I was building a simple test case for sequencing a mix of asynchronous operations around long-running blocking operations (i.e. expensive DOM manipulation) and this is my simulated blocking operation. It suits that job fine, so I thought I post it for anyone else who arrives here with a similar use case. Even so, it's creating a Date() object in a while loop, which might very overwhelm the GC if it runs long enough. But I can't emphasize enough, this is only suitable for testing, for building any actual functionality you should refer to Joseph Silber's answer.
    Use a delay function like this:

var delay = ( function() {
    var timer = 0;
    return function(callback, ms) {
        clearTimeout (timer);
        timer = setTimeout(callback, ms);
    };
})();


Usage: 

delay(function(){
    // do stuff
}, 5000 ); // end delay


Credits: How to delay the .keyup() handler until the user stops typing?
    setTimeout(function() {
     $('.message').hide();
}, 5000);

This will hide the '.message' div after 5 seconds.
    This solution comes from React Native's documentation for a refresh control:

function wait(timeout) {
    return new Promise(resolve => {
        setTimeout(resolve, timeout);
    });
}


To apply this to the OP's question, you could use this function in coordination with await:

await wait(5000);
if (newState == -1) {
    alert('Done');
}

    You should not just try to pause 5 seconds in javascript.  It doesn't work that way.  You can schedule a function of code to run 5 seconds from now, but you have to put the code that you want to run later into a function and the rest of your code after that function will continue to run immediately.

For example:

function stateChange(newState) {
    setTimeout(function(){
        if(newState == -1){alert('VIDEO HAS STOPPED');}
    }, 5000);
}


But, if you have code like this:

stateChange(-1);
console.log(""Hello"");


The console.log() statement will run immediately.  It will not wait until after the timeout fires in the stateChange() function.  You cannot just pause javascript execution for a predetermined amount of time.

Instead, any code that you want to run delays must be inside the setTimeout() callback function (or called from that function).

If you did try to ""pause"" by looping, then you'd essentially ""hang"" the Javascript interpreter for a period of time.  Because Javascript runs your code in only a single thread, when you're looping nothing else can run (no other event handlers can get called).  So, looping waiting for some variable to change will never work because no other code can run to change that variable.
    Based on Joseph Silber's answer, I would do it like that, a bit more generic.

You would have your function (let's create one based on the question):

function videoStopped(newState){
   if (newState == -1) {
       alert('VIDEO HAS STOPPED');
   }
}


And you could have a wait function:

function wait(milliseconds, foo, arg){
    setTimeout(function () {
        foo(arg); // will be executed after the specified time
    }, milliseconds);
}


At the end you would have:

wait(5000, videoStopped, newState);


That's a solution, I would rather not use arguments in the wait function (to have only foo(); instead of foo(arg);) but that's for the example.
    You can add delay by making small changes to your function ( async and await ).
const addNSecondsDelay = (n) => {
  return new Promise(resolve => {
    setTimeout(() => {
      resolve();
    }, n * 1000);
  });
}

const asyncFunctionCall = async () {

  console.log(""stpe-1""); 
  await addNSecondsDelay(5);
  console.log(""step-2 after 5 seconds delay""); 

}

asyncFunctionCall();

    Best way to create a function like this for wait in milli seconds, this function will wait for milliseconds provided in the argument:

function waitSeconds(iMilliSeconds) {
    var counter= 0
        , start = new Date().getTime()
        , end = 0;
    while (counter < iMilliSeconds) {
        end = new Date().getTime();
        counter = end - start;
    }
}

    Try this:

//the code will execute in 1 3 5 7 9 seconds later
function exec() {
    for(var i=0;i<5;i++) {
        setTimeout(function() {
            console.log(new Date());   //It's you code
        },(i+i+1)*1000);
    }
}

    using angularjs:

$timeout(function(){
if(yourvariable===-1){
doSomeThingAfter5Seconds();
}
},5000)

    Create new Js function

function sleep(delay) {
        var start = new Date().getTime();
        while (new Date().getTime() < start + delay);
      }


Call the function when you want to delay execution. Use milliseconds in int for delay value.

####Some code
 sleep(1000);
####Next line

    ","[488, 405, 455, 115, 236, 53, 9, 12, 46, 6, 6, 8, 10, -2, -5]",1481849,81,2013-01-09T01:11:08,2022-02-24 14:21:39Z,javascript 
Add border-bottom to table row <tr>,"
                
I have a table of 3 by 3. I need a way to add a border for the bottom of every row tr and give it a specific color.

First I tried the direct way, i.e.:

<tr style=""border-bottom:1pt solid black;"">


But that didn't work. So I added CSS like this:

tr {
border-bottom: 1pt solid black;
}


That still didn't work.

I would prefer to use CSS because then I don't need to add a style attribute to every row.
I haven't added a border attribute to the <table>. I hope that that is not affecting my CSS.
    Add border-collapse:collapse to your table rule:
table { 
    border-collapse: collapse; 
}

Example
table {
  border-collapse: collapse;
}

tr {
  border-bottom: 1pt solid black;
}<table>
  <tr><td>A1</td><td>B1</td><td>C1</td></tr>
  <tr><td>A2</td><td>B2</td><td>C2</td></tr>
  <tr><td>A2</td><td>B2</td><td>C2</td></tr>
</table>

Link
    There are lot of incomplete answers here. Since you cannot apply a border to tr tag, you need to apply it to the td or th tags like so:

td {
  border-bottom: 1pt solid black;
}


Doing this will leave a small space between each td, which is likely not desirable if you want the border to appear as though it is the tr tag. In order to ""fill in the gaps"" so to speak, you need to utilize the border-collapse property on the table element and set its value to collapse, like so:

table {
  border-collapse: collapse;
}

    I had a problem like this before. I don't think tr can take a border styling directly. My workaround was to style the tds in the row:
<tr class=""border_bottom"">

CSS:
tr.border_bottom td {
  border-bottom: 1px solid black;
}

    Another solution to this is border-spacing property:

table td {
  border-bottom: 2px solid black;
}

table {
  border-spacing: 0px;
}<table>
 <tr>
   <td>ABC</td>
   <td>XYZ</td>
</table>

    Use border-collapse:collapse on table and border-bottom: 1pt solid black; on the tr
    You can use the box-shadow property to fake a border of a tr element. Adjust Y position of box-shadow (below represented as 2px) to adjust thickness.

tr {
  -webkit-box-shadow: 0px 2px 0px 0px rgba(0,0,0,0.99);
  -moz-box-shadow: 0px 2px 0px 0px rgba(0,0,0,0.99);
  box-shadow: 0px 2px 0px 0px rgba(0,0,0,0.99);
}

    Use 

border-collapse:collapse as Nathan wrote and you need to set

td { border-bottom: 1px solid #000; }
    I tried adding

    table {
      border-collapse: collapse;
    }   


alongside the 

    tr {
      bottom-border: 2pt solid #color;
    }


and then commented out border-collapse to see what worked.  Just having the tr selector with bottom-border property worked for me!

No Border CSS ex.



No Border Photo live



CSS Border ex.



Table with Border photo live


    Several interesting answers. Since you just want a border bottom (or top) here are two more. Assuming you want a blue border 3px thick. In the style section you could add

.blueB {background-color:blue; height:3px} or
hr {background-color:blue; color:blue height:3px}


In the table code either

<tr><td colspan='3' class='blueB></td></tr> or
<tr><td colspan='3'><hr></td></tr>

    <td style=""border-bottom-style: solid; border-bottom: thick dotted #ff0000; "">

You can do the same to the whole row as well.

There is border-bottom-style, border-top-style,border-left-style,border-right-style. Or simply border-style that apply to all four borders at once.

You can see (and TRY YOURSELF online) more details here
    Use 

table{border-collapse:collapse}
tr{border-top:thin solid}


Replace ""thin solid"" with CSS properties.
    No CSS border bottom:

<table>
    <thead>
        <tr>
            <th>Title</th>
        </tr>
        <tr>
            <th>
                <hr>
            </th>
        </tr>
    </thead>
</table>

    HTML

<tr class=""bottom-border"">
</tr>


CSS

tr.bottom-border {
  border-bottom: 1px solid #222;
}

    You can't put a border on a tr element. This worked for me in firefox and IE 11:

<td style='border-bottom:1pt solid black'>

    Display the row as a block.

tr {
    display: block;
    border-bottom: 1px solid #000;
}


and to display alternate colors simply:

tr.oddrow {
    display: block;
    border-bottom: 1px solid #F00;
}

    I found when using this method that the space between the td elements caused a gap to form in the border, but have no fear...

One way around this:

<tr>
    <td>
        Example of normal table data
    </td>

    <td class=""end"" colspan=""/* total number of columns in entire table*/"">
        /* insert nothing in here */ 
    </td>
</tr>


With the CSS:

td.end{
    border:2px solid black;
}

    If you don't want to

enforce border collapse on the table
use the TD elements styling

You can use the ::after selector to add borders to TR :
table tbody tr {
    position : relative; # to contain the ::after element within the table-row
}

table tbody tr td {
    position : relative; # needed to apply a z-index
    z-index : 2; # needs to be higher than the z-index on the tr::after element
}

table tbody tr::after {
    content : '';
    position : absolute;
    z-index : 1; # Add a z-index below z-index on TD so you can still select data from your table rows :)
    top : 0px;
    left : 0px;
    width : 100%;
    height : 100%;
    border : 1px solid green; # Style your border here, choose if you want a border bottom, top, left, etc ...
}

It is a simple trick that I used in a scenario where I had to put spaces between table-rows so I wasn't able to add a border collapse on the table, the end result :

Hope it helps :)
    ","[488, 659, 39, 464, 4, 78, 16, 54, 11, 2, 2, 8, 1, -3, 0, 6, 2, 0]",933562,56,2012-04-06T08:09:47,2021-06-15 13:54:02Z,html css 
How can I get my Twitter Bootstrap buttons to right align?,"
                
I have a simple demo here:
<ul>
    <li>One <input class=""btn pull-right"" value=""test""></li>
    <li>Two <input class=""btn pull-right"" value=""test2""></li>
</ul>

I have an unordered list and for each list item I wish to have text on the left and then a right aligned button.  I have tried to use pull-right but this completely messes up the alignment.  What am I doing wrong?
<link href=""http://twitter.github.com/bootstrap/assets/css/bootstrap.css"" rel=""stylesheet"" />
<ul>
  <li>One <input class=""btn pull-right"" value=""test""></li>
  <li>Two <input class=""btn  pull-right"" value=""test2"" </li>
</ul>

    Insert pull-right into the class attribute and let bootstrap arrange the buttons.
For Bootstrap 2.3, see: http://getbootstrap.com/2.3.2/components.html#misc > Helper classes > .pull-right.

For Bootstrap 3, see: https://getbootstrap.com/docs/3.3/css/#helper-classes > Helper classes.

For Bootstrap 4, see: https://getbootstrap.com/docs/4.0/utilities/float/#responsive
The pull-right command was removed and replaced with float-right or in general to float-{sm,md,lg,xl}-{left,right,none}

For Boostrap 5, see: https://getbootstrap.com/docs/5.0/utilities/float/
The closest solution would be float-end.
    ""pull-right"" class may not be the right way because in uses ""float: right"" instead of text-align.

Checking the bootstrap 3 css file i found ""text-right"" class on line 457. This class should be the right way to align the text to the right.

Some code:

<div class=""row"">
    <div class=""col-xs-12"">
        <div class=""text-right"">
            <button type=""button"" class=""btn btn-default"">Default</button>
        </div>
    </div>
</div>



    For Bootstrap 5:
Documentation: https://getbootstrap.com/docs/5.0/utilities/float/
use .float-end in the element for right alignment.
You possibly have to add .clearfix in the parent element if you move ex a button to the right and don't want the following element to slide up.
    Update 2019 - Bootstrap 4.0.0

The pull-right class is now float-right in Bootstrap 4...

    <div class=""row"">
        <div class=""col-12"">One <input type=""button"" class=""btn float-right"" value=""test""></div>
        <div class=""col-12"">Two <input type=""button"" class=""btn float-right"" value=""test""></div>
    </div>


http://www.codeply.com/go/nTobetXAwb

It's also better to not align the ul list and use block elements for the rows.

Is float-right still not working?

Remember that Bootstrap 4 is now flexbox, and many elements are display:flex which can prevent float-right from working. In some cases, the util classes like align-self-end or ml-auto work to right align elements that are inside a flexbox container like a Bootstrap 4 .row, Card or Nav.

Also remember that text-right still works on inline elements.

Bootstrap 4 align right examples



Bootstrap 3

Use the pull-right class.
    In twitter bootstrap 3 try the class pull-right

class=""btn pull-right""

    <p align=""right"">
<button type=""button"" class=""btn btn-primary"">Submit</button>
</p>

    In Bootstrap 4: Try this way with Flexbox. See documentation in getbootstrap

<div class=""row"">
  <div class=""col-md"">
    <div class=""d-flex justify-content-end"">
      <button type=""button"" class=""btn btn-default"">Example 1</button>
      <button type=""button"" class=""btn btn-default"">Example 2</button>
    </div>
  </div>
</div>

    Adding to the accepted answer, when working within containers and columns that have built in padding from bootstrap, I sometimes have a full stretched column with a child div that does the pulling to be the way to go.



<div class=""row"">
  <div class=""col-sm-12"">
      <div class=""pull-right"">
            <p>I am right aligned, factoring in container column padding</p>
      </div>
  </div>
</div>


Alternately, have all your columns add up to your total number of grid columns (12 by default) along with  having the first column be offset.



<div class=""row"">
  <div class=""col-sm-4 col-sm-offset-4"">
        This content and its sibling..
  </div>
  <div class=""col-sm-4"">
        are right aligned as a whole thanks to the offset on the first column and the sum of the columns used is the total available (12).
  </div>
</div>

    Pull right was depreciated as of v3.1.0 .
Just a heads up.

http://getbootstrap.com/components/#callout-dropdown-pull-right
    Now you need to add .dropdown-menu-right to the existing .dropdown-menu element. pull-right is not supported anymore.
More info here http://getbootstrap.com/components/#btn-dropdowns
    Apply pull-right class for the button.
http://getbootstrap.com/css/#helper-classes-floats -> Helper classes

This link will help
    Using the Bootstrap pull-right helper didn't work for us because it uses float: right, which forces inline-block elements to become block.  And when the .btns become block, they lose the natural margin that inline-block was providing them as quasi-textual elements.

So instead we used direction: rtl; on the parent element, which causes the text inside that element to layout from right to left, and that causes inline-block elements to layout from right to left, too.  You can use LESS like the following to prevent children from being laid out rtl too:

/* Flow the inline-block .btn starting from the right. */
.btn-container-right {
  direction: rtl;

  * {
    direction: ltr;
  }
}


and use it like:

<div class=""btn-container-right"">
    <button class=""btn"">Click Me</button>
</div>

    From Bootstrap V3.3.1 the following CSS style will solve this issue

.modal-open{
    padding-right: 0 !important;
}


Note: I tried all the suggestions in posts above and all addresses older versions and do not provide a fix to newset bootstrap versions. 
    you can also use blank columns to give spaces on left 

like 

<div class=""row"">
    <div class=""col-md-8""></div>  <!-- blank space increase or decrease it by column # -->
        <div class=""col-md-4"">
            <button id=""saveedit"" name=""saveedit"" class=""btn btn-success"">Save</button>
        </div>
</div>


Demo ::
Jsfiddle demo 
    Sorry for replying to an older already answered question, but I thought I'd point out a couple of reasons that your jsfiddle does not work, in case others check it out and wonder why the pull-right class as described in the accepted answer doesn't work there.  


the url to the bootstrap.css file is invalid. (perhaps it worked when you asked the question).
you should add the attribute: type=""button"" to your input element, or it won't be rendered as a button - it will be rendered as an input box.  Better yet, use the <button> element instead.
Additionally, because pull-right uses floats, you will get some staggering of the button layout because each LI does not have enough height to accommodate the height of the button. Adding some line-height or min-height css to the LI would address that.


working fiddle: http://jsfiddle.net/3ejqufp6/

<ul>
  <li>One <input type=""button"" class=""btn pull-right"" value=""test""/></li>
  <li>Two <input type=""button"" class=""btn pull-right"" value=""test2""/></li>
</ul>


(I also added a min-width to the buttons as I couldn't stand the look of a ragged right-justified look to the buttons because of varying widths :) )
    Use button tag instead of input and use pull-right class.

pull-right class totally messes up both of your buttons, but you can fix this by defining custom margin on the right side.

<button class=""btn btn-primary pull-right btn-sm RbtnMargin"" type=""button"">Save</button>
<button class=""btn btn-primary pull-right btn-sm""  type=""button"">Cancel</button>


Then use the following CSS for the class

.RbtnMargin { margin-left: 5px; }

    <ul>
    <li class=""span4"">One <input class=""btn btn-small"" value=""test""></li>
    <li class=""span4"">Two <input class=""btn btn-small"" value=""test2""></li>
</ul>

One way would be to apply this style to your list items in order to keep them inline
or
<ul>
    <li>One <input class=""btn"" value=""test""></li>
    <li>Two <input class=""btn"" value=""test2""></li>
</ul>

in CSS
li {
    line-height: 20px;
    margin: 5px;
    padding: 2px;
}

    Can you try a custom CSS aside the bootstrap CSS to see if any changes. Try

.move-rigth{
    display: block;
    float: right;
}


If it works then you can try manipulating what you have or adding other formatting to this and achieving what you desire. Because you are using bootstrap doesn't mean if it doesn't offer you what you want then you just manage it. You are working with your codes and so you command it to do as you say. 
Cheers!
    for bootstrap 4 documentation

  <div class=""row justify-content-end"">
    <div class=""col-4"">
      Start of the row
    </div>
    <div class=""col-4"">
      End of the row
    </div>
  </div>

    The problem is that you're using the buttons as part of your lists. And because the vertical margin between list items is too low to place the buttons in between it messes the alignments up. I would place one of the buttons on top of the list and another one beneath them so that it would look like what you expect!
<ul>
<input class=""btn pull-right"" value=""test"">
<li>One</li> 
<li>Two</li>
<input class=""btn pull-right"" value=""test2""> 
</ul>

    ","[488, 758, 151, 8, 79, 256, 1, 9, 19, 4, 3, 4, 11, 1, 2, 12, 19, 2, 2, -1, 0]",1208301,43,2013-03-16T06:11:57,2022-03-31 14:58:11Z,
Android: How to handle right to left swipe gestures,"
                
I want my app to recognize when a user swipes from right to left on the phone screen.

How to do this?
    OnSwipeTouchListener.java:

import android.content.Context;
import android.view.GestureDetector;
import android.view.GestureDetector.SimpleOnGestureListener;
import android.view.MotionEvent;
import android.view.View;
import android.view.View.OnTouchListener;

public class OnSwipeTouchListener implements OnTouchListener {

    private final GestureDetector gestureDetector;

    public OnSwipeTouchListener (Context ctx){
        gestureDetector = new GestureDetector(ctx, new GestureListener());
    }

    @Override
    public boolean onTouch(View v, MotionEvent event) {
        return gestureDetector.onTouchEvent(event);
    }

    private final class GestureListener extends SimpleOnGestureListener {

        private static final int SWIPE_THRESHOLD = 100;
        private static final int SWIPE_VELOCITY_THRESHOLD = 100;

        @Override
        public boolean onDown(MotionEvent e) {
            return true;
        }

        @Override
        public boolean onFling(MotionEvent e1, MotionEvent e2, float velocityX, float velocityY) {
            boolean result = false;
            try {
                float diffY = e2.getY() - e1.getY();
                float diffX = e2.getX() - e1.getX();
                if (Math.abs(diffX) > Math.abs(diffY)) {
                    if (Math.abs(diffX) > SWIPE_THRESHOLD && Math.abs(velocityX) > SWIPE_VELOCITY_THRESHOLD) {
                        if (diffX > 0) {
                            onSwipeRight();
                        } else {
                            onSwipeLeft();
                        }
                        result = true;
                    }
                }
                else if (Math.abs(diffY) > SWIPE_THRESHOLD && Math.abs(velocityY) > SWIPE_VELOCITY_THRESHOLD) {
                    if (diffY > 0) {
                        onSwipeBottom();
                    } else {
                        onSwipeTop();
                    }
                    result = true;
                }
            } catch (Exception exception) {
                exception.printStackTrace();
            }
            return result;
        }
    }

    public void onSwipeRight() {
    }

    public void onSwipeLeft() {
    }

    public void onSwipeTop() {
    }

    public void onSwipeBottom() {
    }
}


Usage:

imageView.setOnTouchListener(new OnSwipeTouchListener(MyActivity.this) {
    public void onSwipeTop() {
        Toast.makeText(MyActivity.this, ""top"", Toast.LENGTH_SHORT).show();
    }
    public void onSwipeRight() {
        Toast.makeText(MyActivity.this, ""right"", Toast.LENGTH_SHORT).show();
    }
    public void onSwipeLeft() {
        Toast.makeText(MyActivity.this, ""left"", Toast.LENGTH_SHORT).show();
    }
    public void onSwipeBottom() {
        Toast.makeText(MyActivity.this, ""bottom"", Toast.LENGTH_SHORT).show();
    }

});

    Kotlin version of @Mirek Rusin is here:

OnSwipeTouchListener.kt :

open class OnSwipeTouchListener(ctx: Context) : OnTouchListener {

    private val gestureDetector: GestureDetector

    companion object {

        private val SWIPE_THRESHOLD = 100
        private val SWIPE_VELOCITY_THRESHOLD = 100
    }

    init {
        gestureDetector = GestureDetector(ctx, GestureListener())
    }

    override fun onTouch(v: View, event: MotionEvent): Boolean {
        return gestureDetector.onTouchEvent(event)
    }

    private inner class GestureListener : SimpleOnGestureListener() {


        override fun onDown(e: MotionEvent): Boolean {
            return true
        }

        override fun onFling(e1: MotionEvent, e2: MotionEvent, velocityX: Float, velocityY: Float): Boolean {
            var result = false
            try {
                val diffY = e2.y - e1.y
                val diffX = e2.x - e1.x
                if (Math.abs(diffX) > Math.abs(diffY)) {
                    if (Math.abs(diffX) > SWIPE_THRESHOLD && Math.abs(velocityX) > SWIPE_VELOCITY_THRESHOLD) {
                        if (diffX > 0) {
                            onSwipeRight()
                        } else {
                            onSwipeLeft()
                        }
                        result = true
                    }
                } else if (Math.abs(diffY) > SWIPE_THRESHOLD && Math.abs(velocityY) > SWIPE_VELOCITY_THRESHOLD) {
                    if (diffY > 0) {
                        onSwipeBottom()
                    } else {
                        onSwipeTop()
                    }
                    result = true
                }
            } catch (exception: Exception) {
                exception.printStackTrace()
            }

            return result
        }


    }

    open fun onSwipeRight() {}

    open fun onSwipeLeft() {}

    open fun onSwipeTop() {}

    open fun onSwipeBottom() {}
}


Usage:

view.setOnTouchListener(object : OnSwipeTouchListener(context) {

    override fun onSwipeTop() {
        super.onSwipeTop()
    }

    override fun onSwipeBottom() {
        super.onSwipeBottom()
    }

    override fun onSwipeLeft() {
        super.onSwipeLeft()
    }

    override fun onSwipeRight() {
        super.onSwipeRight()
    }
})


the open keyword was the point for me...
    This code detects left and right swipes, avoids deprecated API calls, and has other miscellaneous improvements over earlier answers.

/**
 * Detects left and right swipes across a view.
 */
public class OnSwipeTouchListener implements OnTouchListener {

    private final GestureDetector gestureDetector;

    public OnSwipeTouchListener(Context context) {
        gestureDetector = new GestureDetector(context, new GestureListener());
    }

    public void onSwipeLeft() {
    }

    public void onSwipeRight() {
    }

    public boolean onTouch(View v, MotionEvent event) {
        return gestureDetector.onTouchEvent(event);
    }

    private final class GestureListener extends SimpleOnGestureListener {

        private static final int SWIPE_DISTANCE_THRESHOLD = 100;
        private static final int SWIPE_VELOCITY_THRESHOLD = 100;

        @Override
        public boolean onDown(MotionEvent e) {
            return true;
        }

        @Override
        public boolean onFling(MotionEvent e1, MotionEvent e2, float velocityX, float velocityY) {
            float distanceX = e2.getX() - e1.getX();
            float distanceY = e2.getY() - e1.getY();
            if (Math.abs(distanceX) > Math.abs(distanceY) && Math.abs(distanceX) > SWIPE_DISTANCE_THRESHOLD && Math.abs(velocityX) > SWIPE_VELOCITY_THRESHOLD) {
                if (distanceX > 0)
                    onSwipeRight();
                else
                    onSwipeLeft();
                return true;
            }
            return false;
        }
    }
}


Use it like this:

view.setOnTouchListener(new OnSwipeTouchListener(context) {
    @Override
    public void onSwipeLeft() {
        // Whatever
    }
});

    I've been doing similar things, but for horizontal swipes only

import android.content.Context
import android.view.GestureDetector
import android.view.MotionEvent
import android.view.View

abstract class OnHorizontalSwipeListener(val context: Context) : View.OnTouchListener {    

    companion object {
         const val SWIPE_MIN = 50
         const val SWIPE_VELOCITY_MIN = 100
    }

    private val detector = GestureDetector(context, GestureListener())

    override fun onTouch(view: View, event: MotionEvent) = detector.onTouchEvent(event)    

    abstract fun onRightSwipe()

    abstract fun onLeftSwipe()

    private inner class GestureListener : GestureDetector.SimpleOnGestureListener() {    

        override fun onDown(e: MotionEvent) = true

        override fun onFling(e1: MotionEvent, e2: MotionEvent, velocityX: Float, velocityY: Float)
            : Boolean {

            val deltaY = e2.y - e1.y
            val deltaX = e2.x - e1.x

            if (Math.abs(deltaX) < Math.abs(deltaY)) return false

            if (Math.abs(deltaX) < SWIPE_MIN
                    && Math.abs(velocityX) < SWIPE_VELOCITY_MIN) return false

            if (deltaX > 0) onRightSwipe() else onLeftSwipe()

            return true
        }
    }
}


And then it can be used for view components 

private fun listenHorizontalSwipe(view: View) {
    view.setOnTouchListener(object : OnHorizontalSwipeListener(context!!) {
            override fun onRightSwipe() {
                Log.d(TAG, ""Swipe right"")
            }

            override fun onLeftSwipe() {
                Log.d(TAG, ""Swipe left"")
            }

        }
    )
}

    If you also need to process click events here some modifications:

public class OnSwipeTouchListener implements OnTouchListener {

    private final GestureDetector gestureDetector = new GestureDetector(new GestureListener());

    public boolean onTouch(final View v, final MotionEvent event) {
        return gestureDetector.onTouchEvent(event);
    }

    private final class GestureListener extends SimpleOnGestureListener {

        private static final int SWIPE_THRESHOLD = 100;
        private static final int SWIPE_VELOCITY_THRESHOLD = 100;


        @Override
        public boolean onFling(MotionEvent e1, MotionEvent e2, float velocityX, float velocityY) {
            boolean result = false;
            try {
                float diffY = e2.getY() - e1.getY();
                float diffX = e2.getX() - e1.getX();
                if (Math.abs(diffX) > Math.abs(diffY)) {
                    if (Math.abs(diffX) > SWIPE_THRESHOLD && Math.abs(velocityX) > SWIPE_VELOCITY_THRESHOLD) {
                        if (diffX > 0) {
                            result = onSwipeRight();
                        } else {
                            result = onSwipeLeft();
                        }
                    }
                } else {
                    if (Math.abs(diffY) > SWIPE_THRESHOLD && Math.abs(velocityY) > SWIPE_VELOCITY_THRESHOLD) {
                        if (diffY > 0) {
                            result = onSwipeBottom();
                        } else {
                            result = onSwipeTop();
                        }
                    }
                }
            } catch (Exception exception) {
                exception.printStackTrace();
            }
            return result;
        }
    }

    public boolean onSwipeRight() {
        return false;
    }

    public boolean onSwipeLeft() {
        return false;
    }

    public boolean onSwipeTop() {
        return false;
    }

    public boolean onSwipeBottom() {
        return false;
    }
}


And sample usage:

    background.setOnClickListener(new View.OnClickListener() {
        @Override
        public void onClick(View arg0) {
            toggleSomething();
        }
    });
    background.setOnTouchListener(new OnSwipeTouchListener() {
        public boolean onSwipeTop() {
            Toast.makeText(MainActivity.this, ""top"", Toast.LENGTH_SHORT).show();
            return true;
        }
        public boolean onSwipeRight() {
            Toast.makeText(MainActivity.this, ""right"", Toast.LENGTH_SHORT).show();
            return true;
        }
        public boolean onSwipeLeft() {
            Toast.makeText(MainActivity.this, ""left"", Toast.LENGTH_SHORT).show();
            return true;
        }
        public boolean onSwipeBottom() {
            Toast.makeText(MainActivity.this, ""bottom"", Toast.LENGTH_SHORT).show();
            return true;
        }
    });

    Expanding on Mirek's answer, for the case when you want to use the swipe gestures inside a scroll view. By default the touch listener for the scroll view get disabled and therefore scroll action does not happen. In order to fix this you need to override the dispatchTouchEvent method of the Activity and return the inherited version of this method after you're done with your own listener.

In order to do a few modifications to Mirek's code:
I add a getter for the gestureDetector in the OnSwipeTouchListener.

public GestureDetector getGestureDetector(){
    return  gestureDetector;
}


Declare the OnSwipeTouchListener inside the Activity as a class-wide field.

OnSwipeTouchListener onSwipeTouchListener;


Modify the usage code accordingly:

onSwipeTouchListener = new OnSwipeTouchListener(MyActivity.this) {
    public void onSwipeTop() {
        Toast.makeText(MyActivity.this, ""top"", Toast.LENGTH_SHORT).show();
    }
    public void onSwipeRight() {
        Toast.makeText(MyActivity.this, ""right"", Toast.LENGTH_SHORT).show();
    }
    public void onSwipeLeft() {
        Toast.makeText(MyActivity.this, ""left"", Toast.LENGTH_SHORT).show();
    }
    public void onSwipeBottom() {
        Toast.makeText(MyActivity.this, ""bottom"", Toast.LENGTH_SHORT).show();
    }
});

imageView.setOnTouchListener(onSwipeTouchListener);


And override the dispatchTouchEvent method inside Activity:

@Override
    public boolean dispatchTouchEvent(MotionEvent ev){
        swipeListener.getGestureDetector().onTouchEvent(ev); 
            return super.dispatchTouchEvent(ev);   
    }


Now both scroll and swipe actions should work.
    You don't need complicated calculations.
It can be done just by using OnGestureListener interface from GestureDetector class.

Inside onFling method you can detect all four directions like this:

MyGestureListener.java:

import android.util.Log;
import android.view.GestureDetector;
import android.view.MotionEvent;

public class MyGestureListener implements GestureDetector.OnGestureListener{

    private static final long VELOCITY_THRESHOLD = 3000;

    @Override
    public boolean onDown(final MotionEvent e){ return false; }

    @Override
    public void onShowPress(final MotionEvent e){ }

    @Override
    public boolean onSingleTapUp(final MotionEvent e){ return false; }

    @Override
    public boolean onScroll(final MotionEvent e1, final MotionEvent e2, final float distanceX,
                        final float distanceY){ return false; }

    @Override
    public void onLongPress(final MotionEvent e){ }

    @Override
    public boolean onFling(final MotionEvent e1, final MotionEvent e2,
                       final float velocityX,
                       final float velocityY){

        if(Math.abs(velocityX) < VELOCITY_THRESHOLD 
                    && Math.abs(velocityY) < VELOCITY_THRESHOLD){
            return false;//if the fling is not fast enough then it's just like drag
        }

        //if velocity in X direction is higher than velocity in Y direction,
        //then the fling is horizontal, else->vertical
        if(Math.abs(velocityX) > Math.abs(velocityY)){
            if(velocityX >= 0){
                Log.i(""TAG"", ""swipe right"");
            }else{//if velocityX is negative, then it's towards left
                Log.i(""TAG"", ""swipe left"");
            }
        }else{
            if(velocityY >= 0){
                Log.i(""TAG"", ""swipe down"");
            }else{
                Log.i(""TAG"", ""swipe up"");
            }
        }

        return true;
    }
}


usage:

GestureDetector mDetector = new GestureDetector(MainActivity.this, new MyGestureListener());

view.setOnTouchListener(new View.OnTouchListener(){
    @Override
    public boolean onTouch(final View v, final MotionEvent event){
        return mDetector.onTouchEvent(event);
    }
});

    In order to have Click Listener, DoubleClick Listener, OnLongPress Listener, Swipe Left, Swipe Right, Swipe Up, Swipe Down on Single View you need to setOnTouchListener. i.e,

view.setOnTouchListener(new OnSwipeTouchListener(MainActivity.this) {

            @Override
            public void onClick() {
                super.onClick();
                // your on click here
            }

            @Override
            public void onDoubleClick() {
                super.onDoubleClick();
                // your on onDoubleClick here
            }

            @Override
            public void onLongClick() {
                super.onLongClick();
                // your on onLongClick here
            }

            @Override
            public void onSwipeUp() {
                super.onSwipeUp();
                // your swipe up here
            }

            @Override
            public void onSwipeDown() {
                super.onSwipeDown();
                // your swipe down here.
            }

            @Override
            public void onSwipeLeft() {
                super.onSwipeLeft();
                // your swipe left here.
            }

            @Override
            public void onSwipeRight() {
                super.onSwipeRight();
                // your swipe right here.
            }
        });

}


For this you need OnSwipeTouchListener class that implements OnTouchListener.

public class OnSwipeTouchListener implements View.OnTouchListener {

private GestureDetector gestureDetector;

public OnSwipeTouchListener(Context c) {
    gestureDetector = new GestureDetector(c, new GestureListener());
}

public boolean onTouch(final View view, final MotionEvent motionEvent) {
    return gestureDetector.onTouchEvent(motionEvent);
}

private final class GestureListener extends GestureDetector.SimpleOnGestureListener {

    private static final int SWIPE_THRESHOLD = 100;
    private static final int SWIPE_VELOCITY_THRESHOLD = 100;

    @Override
    public boolean onDown(MotionEvent e) {
        return true;
    }

    @Override
    public boolean onSingleTapUp(MotionEvent e) {
        onClick();
        return super.onSingleTapUp(e);
    }

    @Override
    public boolean onDoubleTap(MotionEvent e) {
        onDoubleClick();
        return super.onDoubleTap(e);
    }

    @Override
    public void onLongPress(MotionEvent e) {
        onLongClick();
        super.onLongPress(e);
    }

    // Determines the fling velocity and then fires the appropriate swipe event accordingly
    @Override
    public boolean onFling(MotionEvent e1, MotionEvent e2, float velocityX, float velocityY) {
        boolean result = false;
        try {
            float diffY = e2.getY() - e1.getY();
            float diffX = e2.getX() - e1.getX();
            if (Math.abs(diffX) > Math.abs(diffY)) {
                if (Math.abs(diffX) > SWIPE_THRESHOLD && Math.abs(velocityX) > SWIPE_VELOCITY_THRESHOLD) {
                    if (diffX > 0) {
                        onSwipeRight();
                    } else {
                        onSwipeLeft();
                    }
                }
            } else {
                if (Math.abs(diffY) > SWIPE_THRESHOLD && Math.abs(velocityY) > SWIPE_VELOCITY_THRESHOLD) {
                    if (diffY > 0) {
                        onSwipeDown();
                    } else {
                        onSwipeUp();
                    }
                }
            }
        } catch (Exception exception) {
            exception.printStackTrace();
        }
        return result;
    }
}

public void onSwipeRight() {
}

public void onSwipeLeft() {
}

public void onSwipeUp() {
}

public void onSwipeDown() {
}

public void onClick() {

}

public void onDoubleClick() {

}

public void onLongClick() {

}
}

    My solution is similar to those above but I have abstracted the gesture handling into an abstract class OnGestureRegisterListener.java, which includes swipe, click and long click gestures. 

OnGestureRegisterListener.java

public abstract class OnGestureRegisterListener implements View.OnTouchListener {

    private final GestureDetector gestureDetector;
    private View view;

    public OnGestureRegisterListener(Context context) {
        gestureDetector = new GestureDetector(context, new GestureListener());
    }

    @Override
    public boolean onTouch(View view, MotionEvent event) {
        this.view = view;
        return gestureDetector.onTouchEvent(event);
    }

    public abstract void onSwipeRight(View view);
    public abstract void onSwipeLeft(View view);
    public abstract void onSwipeBottom(View view);
    public abstract void onSwipeTop(View view);
    public abstract void onClick(View view);
    public abstract boolean onLongClick(View view);

    private final class GestureListener extends GestureDetector.SimpleOnGestureListener {

        private static final int SWIPE_THRESHOLD = 100;
        private static final int SWIPE_VELOCITY_THRESHOLD = 100;

        @Override
        public boolean onDown(MotionEvent e) {
            return true;
        }

        @Override
        public void onLongPress(MotionEvent e) {
            onLongClick(view);
            super.onLongPress(e);
        }

        @Override
        public boolean onSingleTapUp(MotionEvent e) {
            onClick(view);
            return super.onSingleTapUp(e);
        }

        @Override
        public boolean onFling(MotionEvent e1, MotionEvent e2, float velocityX, float velocityY) {
            boolean result = false;
            try {
                float diffY = e2.getY() - e1.getY();
                float diffX = e2.getX() - e1.getX();
                if (Math.abs(diffX) > Math.abs(diffY)) {
                    if (Math.abs(diffX) > SWIPE_THRESHOLD && Math.abs(velocityX) > SWIPE_VELOCITY_THRESHOLD) {
                        if (diffX > 0) {
                            onSwipeRight(view);
                        } else {
                            onSwipeLeft(view);
                        }
                        result = true;
                    }
                }
                else if (Math.abs(diffY) > SWIPE_THRESHOLD && Math.abs(velocityY) > SWIPE_VELOCITY_THRESHOLD) {
                    if (diffY > 0) {
                        onSwipeBottom(view);
                    } else {
                        onSwipeTop(view);
                    }
                    result = true;
                }
            } catch (Exception exception) {
                exception.printStackTrace();
            }
            return result;
        }

    }
}


And use it like so. Note that you can also easily pass in your View parameter.

OnGestureRegisterListener onGestureRegisterListener = new OnGestureRegisterListener(this) {
    public void onSwipeRight(View view) {
        // Do something
    }
    public void onSwipeLeft(View view) {
        // Do something
    }
    public void onSwipeBottom(View view) {
        // Do something
    }
    public void onSwipeTop(View view) {
        // Do something
    }
    public void onClick(View view) {
        // Do something
    }
    public boolean onLongClick(View view) { 
        // Do something
        return true;
    }
};

Button button = findViewById(R.id.my_button);
button.setOnTouchListener(onGestureRegisterListener);

    This issue still exists. Add the following classes:
private class SwipeFirstTouchListener implements View.OnTouchListener {

    private final DirtyOnSwipeTouchListener swipe;
    private final View.OnTouchListener delegate;

    private SwipeFirstTouchListener(DirtyOnSwipeTouchListener swipe, View.OnTouchListener delegate) {
        this.swipe = swipe;
        this.delegate = delegate;
    }

    @Override
    public boolean onTouch(View v, MotionEvent event) {
        if (!swipe.onTouch(v, event)) {
            // no a swipe, so lets try with the rest of the events
            return delegate.onTouch(v, event);
        }
        return false;
    }
}

and
private class DirtyOnSwipeTouchListener extends OnSwipeTouchListener {
    private boolean dirty = false;
    private OnSwipeTouchListener delegate;

    public DirtyOnSwipeTouchListener(Context ctx, OnSwipeTouchListener delegate) {
        super(ctx);

        this.delegate = delegate;
    }

    private void reset() {
        dirty = false;
    }

    public void onSwipeTop() {
        dirty = true;

        delegate.onSwipeTop();
    }

    public void onSwipeRight() {
        dirty = true;
        delegate.onSwipeRight();
    }

    public void onSwipeLeft() {
        dirty = true;
        delegate.onSwipeLeft();
    }

    public void onSwipeBottom() {
        dirty = true;
        delegate.onSwipeBottom();
    }

    @Override
    public boolean onTouch(View v, MotionEvent event) {
        try {
            super.onTouch(v, event);

            return dirty;
        } finally {
            dirty = false;
        }

    }
};

and a class found on the internet:
public class OnSwipeTouchListener implements OnTouchListener {
    
    private static final String TAG = OnSwipeTouchListener.class.getName();

    private final GestureDetector gestureDetector;

    public OnSwipeTouchListener(Context ctx) {
        gestureDetector = new GestureDetector(ctx, new GestureListener());
    }

    @Override
    public boolean onTouch(View v, MotionEvent event) {
        return gestureDetector.onTouchEvent(event);
    }

    private final class GestureListener extends GestureDetector.SimpleOnGestureListener {

        private static final int SWIPE_THRESHOLD = 100;
        private static final int SWIPE_VELOCITY_THRESHOLD = 100;

        @Override
        public boolean onDown(MotionEvent e) {
            return true;
        }

        @Override
        public boolean onFling(MotionEvent e1, MotionEvent e2, float velocityX, float velocityY) {
            boolean result = false;
            try {
                float diffY = e2.getY() - e1.getY();
                float diffX = e2.getX() - e1.getX();
                if (Math.abs(diffX) > Math.abs(diffY)) {
                    if (Math.abs(diffX) > SWIPE_THRESHOLD && Math.abs(velocityX) > SWIPE_VELOCITY_THRESHOLD) {
                        if (diffX > 0) {
                            onSwipeRight();
                        } else {
                            onSwipeLeft();
                        }
                        result = true;
                    }
                } else if (Math.abs(diffY) > SWIPE_THRESHOLD && Math.abs(velocityY) > SWIPE_VELOCITY_THRESHOLD) {
                    if (diffY > 0) {
                        onSwipeBottom();
                    } else {
                        onSwipeTop();
                    }
                    result = true;
                }
            } catch (Exception exception) {
                Log.d(TAG, ""Unexpected problem handling swipes, ignoring."", exception);
            }
            return result;
        }
    }

    public void onSwipeRight() {
        // Do nothing
    }

    public void onSwipeLeft() {
        // Do nothing
    }

    public void onSwipeTop() {
        // Do nothing
    }

    public void onSwipeBottom() {
        // Do nothing
    }
}

then add your own OnTouchListener and OnSwipeTouchListener like so:
    DirtyOnSwipeTouchListener swipe = new DirtyOnSwipeTouchListener(this, new OnSwipeTouchListener(this) {
        public void onSwipeTop() {
            // your code here
        }

        public void onSwipeRight() {
            // your code here
        }

        public void onSwipeLeft() {
            // your code here
        }

        public void onSwipeBottom() {
            // your code here
        }
    });


    View.OnTouchListener toggleListener = new View.OnTouchListener() {
        public boolean onTouch(View v, MotionEvent event) {
            if (event.getAction() == MotionEvent.ACTION_UP) {
                // your code here

                return true;
            } else if (event.getAction() == MotionEvent.ACTION_DOWN) {
                // your code here

                return true;
            }
            return false;
        }
    };

    SwipeFirstTouchListener swipeFirstTouchListener = new SwipeFirstTouchListener(swipe, toggleListener);

    myView.setOnTouchListener(swipeFirstTouchListener);

    Use SwipeListView and let it handle the gesture detection for you.


    To add an onClick as well, here's what I did.

....
// in OnSwipeTouchListener class

private final class GestureListener extends SimpleOnGestureListener {

    .... // normal GestureListener  code

   @Override
    public boolean onSingleTapConfirmed(MotionEvent e) {
        onClick(); // my method
        return super.onSingleTapConfirmed(e);
    }

} // end GestureListener class

    public void onSwipeRight() {
    }

    public void onSwipeLeft() {
    }

    public void onSwipeTop() {
    }

    public void onSwipeBottom() {
    }

    public void onClick(){ 
    }


    // as normal
    @Override
    public boolean onTouch(View v, MotionEvent event) {
        return gestureDetector.onTouchEvent(event);
}

} // end OnSwipeTouchListener class




I'm using Fragments, so using getActivity() for context. This is how I implemented it - and it works.



myLayout.setOnTouchListener(new OnSwipeTouchListener(getActivity()) {
            public void onSwipeTop() {
                Toast.makeText(getActivity(), ""top"", Toast.LENGTH_SHORT).show();
            }
            public void onSwipeRight() {
                Toast.makeText(getActivity(), ""right"", Toast.LENGTH_SHORT).show();
            }
            public void onSwipeLeft() {
                Toast.makeText(getActivity(), ""left"", Toast.LENGTH_SHORT).show();
            }
            public void onSwipeBottom() {
                Toast.makeText(getActivity(), ""bottom"", Toast.LENGTH_SHORT).show();
            }

            public void onClick(){
                Toast.makeText(getActivity(), ""clicked"", Toast.LENGTH_SHORT).show();
            }
        });

    @Edward Brey's method works great. If someone would also like to copy & paste the imports for the OnSwipeTouchListener, here they are:

 import android.content.Context;
 import android.view.GestureDetector;
 import android.view.GestureDetector.SimpleOnGestureListener;
 import android.view.MotionEvent;
 import android.view.View;
 import android.view.View.OnTouchListener;

    A little modification of @Mirek Rusin answer and now you can detect multitouch swipes. This code is on Kotlin:

class OnSwipeTouchListener(ctx: Context, val onGesture: (gestureCode: Int) -> Unit) : OnTouchListener {

private val SWIPE_THRESHOLD = 200
private val SWIPE_VELOCITY_THRESHOLD = 200

private val gestureDetector: GestureDetector

var fingersCount = 0

fun resetFingers() {
    fingersCount = 0
}

init {
    gestureDetector = GestureDetector(ctx, GestureListener())
}

override fun onTouch(v: View, event: MotionEvent): Boolean {
    if (event.pointerCount > fingersCount) {
        fingersCount = event.pointerCount
    }
    return gestureDetector.onTouchEvent(event)
}

private inner class GestureListener : SimpleOnGestureListener() {

    override fun onDown(e: MotionEvent): Boolean {
        return true
    }

    override fun onFling(e1: MotionEvent, e2: MotionEvent, velocityX: Float, velocityY: Float): Boolean {
        var result = false
        try {
            val diffY = e2.y - e1.y
            val diffX = e2.x - e1.x
            if (Math.abs(diffX) > Math.abs(diffY)) {
                if (Math.abs(diffX) > SWIPE_THRESHOLD && Math.abs(velocityX) > SWIPE_VELOCITY_THRESHOLD) {
                    if (diffX > 0) {
                        val gesture = when (fingersCount) {
                            1 -> Gesture.SWIPE_RIGHT
                            2 -> Gesture.TWO_FINGER_SWIPE_RIGHT
                            3 -> Gesture.THREE_FINGER_SWIPE_RIGHT
                            else -> -1
                        }
                        if (gesture > 0) {
                            onGesture.invoke(gesture)
                        }
                    } else {
                        val gesture = when (fingersCount) {
                            1 -> Gesture.SWIPE_LEFT
                            2 -> Gesture.TWO_FINGER_SWIPE_LEFT
                            3 -> Gesture.THREE_FINGER_SWIPE_LEFT
                            else -> -1
                        }
                        if (gesture > 0) {
                            onGesture.invoke(gesture)
                        }
                    }
                    resetFingers()
                }
            } else if (Math.abs(diffY) > SWIPE_THRESHOLD && Math.abs(velocityY) > SWIPE_VELOCITY_THRESHOLD) {
                if (diffY > 0) {
                    val gesture = when (fingersCount) {
                        1 ->  Gesture.SWIPE_DOWN
                        2 -> Gesture.TWO_FINGER_SWIPE_DOWN
                        3 -> Gesture.THREE_FINGER_SWIPE_DOWN
                        else -> -1
                    }
                    if (gesture > 0) {
                        onGesture.invoke(gesture)
                    }
                } else {
                    val gesture = when (fingersCount) {
                        1 ->  Gesture.SWIPE_UP
                        2 -> Gesture.TWO_FINGER_SWIPE_UP
                        3 -> Gesture.THREE_FINGER_SWIPE_UP
                        else -> -1
                    }
                    if (gesture > 0) {
                        onGesture.invoke(gesture)
                    }
                }
                resetFingers()
            }
            result = true

        } catch (exception: Exception) {
            exception.printStackTrace()
        }

        return result
    }
}}


Where Gesture.SWIPE_RIGHT and others are unique integer indentificator of gesture that I`m using to detect kind of gesture later in my activity:

rootView?.setOnTouchListener(OnSwipeTouchListener(this, {
    gesture -> log(Gesture.parseName(this, gesture))
}))


So you see gesture here is an integer variable that holds value I have passed before.
    This question was asked many years ago. Now, there is a better solution: SmartSwipe: https://github.com/luckybilly/SmartSwipe

code looks like this:

SmartSwipe.wrap(contentView)
        .addConsumer(new StayConsumer()) //contentView stay while swiping with StayConsumer
        .enableAllDirections() //enable directions as needed
        .addListener(new SimpleSwipeListener() {
            @Override
            public void onSwipeOpened(SmartSwipeWrapper wrapper, SwipeConsumer consumer, int direction) {
                //direction: 
                //  1: left
                //  2: right
                //  4: top
                //  8: bottom
            }
        })
;

    import android.content.Context
import android.view.GestureDetector
import android.view.GestureDetector.SimpleOnGestureListener
import android.view.MotionEvent
import android.view.View
import android.view.View.OnTouchListener

/**
 * Detects left and right swipes across a view.
 */
class OnSwipeTouchListener(context: Context, onSwipeCallBack: OnSwipeCallBack?) : OnTouchListener {

    private var gestureDetector : GestureDetector
    private var onSwipeCallBack: OnSwipeCallBack?=null

    init {

        gestureDetector = GestureDetector(context, GestureListener())
        this.onSwipeCallBack = onSwipeCallBack!!
    }
    companion object {

        private val SWIPE_DISTANCE_THRESHOLD = 100
        private val SWIPE_VELOCITY_THRESHOLD = 100
    }

   /* fun onSwipeLeft() {}

    fun onSwipeRight() {}*/

    override fun onTouch(v: View, event: MotionEvent): Boolean {


        return gestureDetector.onTouchEvent(event)
    }

    private inner class GestureListener : SimpleOnGestureListener() {

        override fun onDown(e: MotionEvent): Boolean {
            return true
        }

        override fun onFling(eve1: MotionEvent?, eve2: MotionEvent?, velocityX: Float, velocityY: Float): Boolean {
            try {
                if(eve1 != null&& eve2!= null) {
                    val distanceX = eve2?.x - eve1?.x
                    val distanceY = eve2?.y - eve1?.y
                    if (Math.abs(distanceX) > Math.abs(distanceY) && Math.abs(distanceX) > SWIPE_DISTANCE_THRESHOLD && Math.abs(velocityX) > SWIPE_VELOCITY_THRESHOLD) {
                        if (distanceX > 0)
                            onSwipeCallBack!!.onSwipeLeftCallback()
                        else
                            onSwipeCallBack!!.onSwipeRightCallback()
                        return true
                    }
                }
            }catch (exception:Exception){
                exception.printStackTrace()
            }

            return false
        }


    }
}

    @Mirek Rusin answeir is very good.
But, there is small bug, and fix is requried -

public boolean onFling(MotionEvent e1, MotionEvent e2, float velocityX, float velocityY) {
            boolean result = false;
            try {
                float diffY = e2.getY() - e1.getY();
                float diffX = e2.getX() - e1.getX();
                if (Math.abs(diffX) > Math.abs(diffY)) {
                    if (Math.abs(diffX) > SWIPE_THRESHOLD && Math.abs(velocityX) > SWIPE_VELOCITY_THRESHOLD) {
                        if (diffX > 0) {
                            if (getOnSwipeListener() != null) {
                                getOnSwipeListener().onSwipeRight();
                            }
                        } else {
                            if (getOnSwipeListener() != null) {
                                getOnSwipeListener().onSwipeLeft();
                            }
                        }
                        result = true;
                    }
                }
                else if (Math.abs(diffY) > SWIPE_THRESHOLD && Math.abs(velocityY) > SWIPE_VELOCITY_THRESHOLD) {
                    if (diffY > 0) {
                        if (getOnSwipeListener() != null) {
                            getOnSwipeListener().onSwipeBottom();
                        }
                    } else {
                        if (getOnSwipeListener() != null) {
                            getOnSwipeListener().onSwipeTop();
                        }
                    }
                    result = true;
                }


What the difference? We set result = true, only if we have checked that all requrinments (both SWIPE_THRESHOLD  and SWIPE_VELOCITY_THRESHOLD are Ok ). This is important if we discard swipe if some of requrinments are not achieved, and we have to do smth in onTouchEvent method of OnSwipeTouchListener!
    Here is simple Android Code for detecting gesture direction

In MainActivity.java and activity_main.xml, write the following code:


  MainActivity.java


import java.util.ArrayList;

import android.app.Activity;
import android.gesture.Gesture;
import android.gesture.GestureLibraries;
import android.gesture.GestureLibrary;
import android.gesture.GestureOverlayView;
import android.gesture.GestureOverlayView.OnGesturePerformedListener;
import android.gesture.GestureStroke;
import android.gesture.Prediction;
import android.os.Bundle;
import android.widget.Toast;

public class MainActivity extends Activity implements
        OnGesturePerformedListener {

    GestureOverlayView gesture;
    GestureLibrary lib;
    ArrayList<Prediction> prediction;

    @Override
    protected void onCreate(Bundle savedInstanceState) {
        super.onCreate(savedInstanceState);
        setContentView(R.layout.activity_main);

        lib = GestureLibraries.fromRawResource(MainActivity.this,
                R.id.gestureOverlayView1);
        gesture = (GestureOverlayView) findViewById(R.id.gestureOverlayView1);
        gesture.addOnGesturePerformedListener(this);
    }

    @Override
    public void onGesturePerformed(GestureOverlayView overlay, Gesture gesture) {
        ArrayList<GestureStroke> strokeList = gesture.getStrokes();
        // prediction = lib.recognize(gesture);
        float f[] = strokeList.get(0).points;
        String str = """";

        if (f[0] < f[f.length - 2]) {
            str = ""Right gesture"";
        } else if (f[0] > f[f.length - 2]) {
            str = ""Left gesture"";
        } else {
            str = ""no direction"";
        }
        Toast.makeText(getApplicationContext(), str, Toast.LENGTH_LONG).show();

    }

}



  activity_main.xml


<android.gesture.GestureOverlayView xmlns:android=""http://schemas.android.com/apk/res/android""
    xmlns:tools=""http://schemas.android.com/tools""
    xmlns:android1=""http://schemas.android.com/apk/res/android""
    xmlns:android2=""http://schemas.android.com/apk/res/android""
    android:id=""@+id/gestureOverlayView1""
    android:layout_width=""match_parent""
    android:layout_height=""match_parent""
    android1:orientation=""vertical"" >

    <TextView
        android:id=""@+id/textView1""
        android:layout_width=""wrap_content""
        android:layout_height=""wrap_content""
        android:text=""Draw gesture""
        android:textAppearance=""?android:attr/textAppearanceMedium"" />

</android.gesture.GestureOverlayView>

    If you want to display some buttons with actions when an list item is swipe are a lot of libraries on the internet that have this behavior.
I implemented the library that I found on the internet and I am very satisfied. It is very simple to use and very quick. I improved the original library and I added a new click listener for item click. Also I added font awesome library (http://fortawesome.github.io/Font-Awesome/) and now you can simply add a new item title and specify the icon name from font awesome.

Here is the github link
    public class TranslatorSwipeTouch implements OnTouchListener
{
   private String TAG=""TranslatorSwipeTouch"";

   @SuppressWarnings(""deprecation"")
   private GestureDetector detector=new GestureDetector(new TranslatorGestureListener());

   @Override
   public boolean onTouch(View view, MotionEvent event)
   {
     return detector.onTouchEvent(event);
   }

private class TranslatorGestureListener extends SimpleOnGestureListener 
{
    private final int GESTURE_THRESHOULD=100;
    private final int GESTURE_VELOCITY_THRESHOULD=100;

    @Override
    public boolean onDown(MotionEvent e) {
        return true;
    }

    @Override
    public boolean onFling(MotionEvent event1,MotionEvent event2,float velocityx,float velocityy)
    {
        try
        {
            float diffx=event2.getX()-event1.getX();
            float diffy=event2.getY()-event1.getY();

            if(Math.abs(diffx)>Math.abs(diffy))
            {
                if(Math.abs(diffx)>GESTURE_THRESHOULD && Math.abs(velocityx)>GESTURE_VELOCITY_THRESHOULD)
                {
                    if(diffx>0)
                    {
                        onSwipeRight();
                    }
                    else
                    {
                        onSwipeLeft();
                    }
                }
            }
            else
            {
                if(Math.abs(diffy)>GESTURE_THRESHOULD && Math.abs(velocityy)>GESTURE_VELOCITY_THRESHOULD)
                {
                    if(diffy>0)
                    {
                         onSwipeBottom();
                    }
                    else
                    {
                        onSwipeTop();
                    }
                }
            }
        }
        catch(Exception e)
        {
            Log.d(TAG, """"+e.getMessage());
        }
        return false;           
    }

    public void onSwipeRight()
    {
        //Toast.makeText(this.getClass().get, ""swipe right"", Toast.LENGTH_SHORT).show();
        Log.i(TAG, ""Right"");
    }
    public void onSwipeLeft()
    {
        Log.i(TAG, ""Left"");
        //Toast.makeText(MyActivity.this, ""swipe left"", Toast.LENGTH_SHORT).show();
    }

    public void onSwipeTop()
    {
        Log.i(TAG, ""Top"");
        //Toast.makeText(MyActivity.this, ""swipe top"", Toast.LENGTH_SHORT).show();
    }

    public void onSwipeBottom()
    {
        Log.i(TAG, ""Bottom"");
        //Toast.makeText(MyActivity.this, ""swipe bottom"", Toast.LENGTH_SHORT).show();
    }   

  }

 }

    the usage of Edward Brey's answer in Kotlin

 view.setOnTouchListener(object: OnSwipeTouchListener(this) {
      override fun onSwipeLeft() {
        super.onSwipeLeft()
      }
      override fun onSwipeRight() {
        super.onSwipeRight()
      }
    }
 )

    I know its a bit late since 2012 but I hope it will help someone since I think it's a shorter and cleaner code than most of the answers:
view.setOnTouchListener((v, event) -> {
        
int action = MotionEventCompat.getActionMasked(event);

switch(action) {
    case (MotionEvent.ACTION_DOWN) :
        Log.d(DEBUG_TAG,""Action was DOWN"");
        return true;

    case (MotionEvent.ACTION_MOVE) :
        Log.d(DEBUG_TAG,""Action was MOVE"");
        return true;

    case (MotionEvent.ACTION_UP) :
        Log.d(DEBUG_TAG,""Action was UP"");
        return true;

    case (MotionEvent.ACTION_CANCEL) :
        Log.d(DEBUG_TAG,""Action was CANCEL"");
        return true;

    case (MotionEvent.ACTION_OUTSIDE) :
        Log.d(DEBUG_TAG,""Movement occurred outside bounds "" +
                ""of current screen element"");
        return true;

    default :
        return super.onTouchEvent(event);
}
    });

of course you can leave only the relevant gestures to you.
src: https://developer.android.com/training/gestures/detector
    ","[488, 902, 20, 217, 4, 56, 32, 15, 27, 5, 1, 11, 10, 6, 3, 3, 1, 1, 1, 0, 0, 0, 0]",463602,285,2010-11-09T22:22:40,2021-06-04 10:26:59Z,
Could not load file or assembly ... An attempt was made to load a program with an incorrect format (System.BadImageFormatException),"
                
I have two projects, ProjectA and ProjectB.  ProjectB is a console application, which depends on ProjectA.  Yesterday, everything was working fine, but suddenly today when I run ProjectB I get this:


  BadImageFormatException was unhandled:
  Could not load file or assembly 'ProjectA, Version=1.0.0.0, Culture=neutral, PublicKeyToken=null' or one of its dependencies. An attempt was made to load a program with an incorrect format.


Both are just regular projects, with no dependencies on any other non-.Net projects.  Both are fully .Net - there is no native code, and no P/Invoke.  I have other projects which depend on ProjectA and still work just fine.

Things I have tried:


Make sure both projects are set to ""Any CPU,"" with the build checkbox checked.  They are.
Make sure both projects are for the same Target Framework (.Net 4.0 Client Profile).
Under ProjectB --> References --> ProjectA --> Properties, make sure ""Copy Local"" is set to ""True"" _ (I verified that ProjectA.dll is being copied correctly)
Clean/Rebuild the solution.  I even tried manually deleting the /bin and /obj folders in both projects.
Restart Visual Studio.  Restart my computer.
Check out an entirely new copy of the repository.


But I still get the same error.  I have no idea what I did to cause this, nor how to fix it.  Any ideas?
    I am pretty sure you're having a 32-bit / 64-bit conflict. It sounds like your main project might be set to 32-bit while the class its referencing is set to 64-bit. Try looking at this SO question and this one too. Between the two of them, you should be able to figure out your problem.
    I just had this error message running IIS Express in Visual Studio 2015. In my case I needed to be running the 64 bit version of IIS Express:


  Tools → Options → Projects and Solutions → Web Projects
  Check the box
  that says ""Use the 64 bit version of IIS Express for web sites and
  projects"".


Screenshot:


    Might be you are facing the problem with your website after deploying on server.

Then you need to adjust your application pool to Enable 32-Bit Applications.

Steps


Open IIS Manager
Click on Application Pools
Select whatever application pool you are using
From right pane, click Advanced Settings...
Set Enable 32-Bit Applications to True




    First of all I got this in VS2017 with an old project I needed to make a tiny change to and upraded all the projects to framework 4.7.



Several others have mentioned selecting Any CPU can fix this issue.

There's a couple places you need to do it, and it might not just be as simple as selecting from the dropdown. This fixed it for me:

1) You need to do it both here:



2) And also in Configuration Manager (right click on solution)



But what if it isn't there???

Then click New and choose these settings: (thanks @RckLN)


    For the newer version of visual studio (v16.10 for this answer), it can be fixed by manually changing the solution platform. For me it worked after changing from ""Any CPU"" to ""x86"".

Click on solutions platform dropdown, the one in which any CPU is appearing in image below.


Go to configuration manager.


Click on new and add platform x86 or x64 (32 or 64 bits) based on what is working for you.


Restart the project.


    You may need to change the Appication Pool setting ""Enable 32bit Applications"" to TRUE in IIS7 if you have at least 1 32bit dll\exe in your project.
    I also had this problem. As mention before the problem was related to a 32-bit / 64-bit conflict, but with the site hosted in Azure. To change the plattform in Azure App Service, go to Configuration -> General settings.

    I had this problem running unit tests (xunit) in Visual Studio 2015 and came across the following fix:

Menu Bar -> Test -> Test Settings -> Default Processor Architecture -> X64

    None of these solutions worked for me - but by deleting the contents of bin and obj folders everything was cool again.
    I had this same problem. I had set Project A's ""Platform Target"" (""Project A""(Right Click)->Properties->Build->""Platform Target"") to x86 but kept Project B's at ""Any CPU"". Setting Project B's to ""x86"" fixed this. 
    The following solved the issue for me, uncheck 'Prefer 
32-bit' :

    Shoot! I knew about this problem. I thought I was doing everything right until I accidentally saw 'x86' in the VS output window and that's when I got hold of the cause. Wasted a few mins on it today.

The configuration under 'Publish' window was set to 'x86'; whereas, everywhere else, it was 'x64'.

Please make sure it's in-sync across configuration manager, publish settings, solution configurations, and IIS settings (if that's your web server). 

Also, please keep in mind - VS is a 32-bit app and IIS is 64 bit. 32-bit apps are disabled by default in IIS.


    I got this when building a project via Visual Studio Online (VSTS) Build using Visual Studio Build Steps.

The solution was:


Delete the existing source folder
Explicitly set 'Any CPU' in the platform for all Visual Studio Builds including dependencies (see screenshot below).
Re-run the build



    I had the same issue with multiple projects in the same solution, i ended up setting all of the target frameworks to .NET Framework 4 and x86 for the target CPU and it finally successfully compiled.
    The Chilkat .NET 4.5 assembly requires the VC++ 2012 or 2013 runtime to be installed on any computer where your application runs. Most computers will already have it installed. Your development computer will have it because Visual Studio has been installed. However, if deploying to a computer where the required VC++ runtime is not available, the above error will occur:

Install all of the bellow packages

Visual C++ Redistributable Packages for Visual Studio 2013 - vcredist_x64

Visual C++ Redistributable Packages for Visual Studio 2013 - vcredist_x86

Visual C++ Redistributable Packages for Visual Studio 2012 - vcredist_x64

Visual C++ Redistributable Packages for Visual Studio 2012 - vcredist_x86
    I also had this problem running unit tests by using ReSharper on Visual Studio 2017 and fixed it with following config:



Also you can change the ReSharper's run test setting:
https://resharper-support.jetbrains.com/hc/en-us/articles/207242715-How-to-run-MSTest-tests-using-x64-configuration
    Are you trying to run your .exe file from the cmd? This was my mistake. Just run the .exe file by double clicking it. If it's a .NET Core SCD for Windows 8.1/Windows Server 2012 R2 x64.
    In my case the error was System.BadImageFormatException: Could not load file or assembly 'vjslib, Version=2.0.0.0, Culture=neutral, PublicKeyToken=b03f5f7f11d50a3a' or one of its dependencies.
It was solved by installing vjredist 64 from here.
    My machine showed me a BIOS update and I wondered if that has something to do with the sudden popping-up of this error. And after I did the update, the error was resolved and the solution built fine.
    You might also see this issue if you're trying to package a 64bit project with an MSI installer in VS. (""The reason is because the native shim packaged with the .msi file is a 32-bit executable."")

See here for more details: http://blogs.msdn.com/b/heaths/archive/2006/02/01/64-bit-managed-custom-actions-with-visual-studio.aspx 
    I encountered the same issue.  It popped up out of the blue and that seemed strange to me.

In the Exception snapshot, for the FusionLog, I saw the following within its message:

... C:\Windows\Microsoft.NET\Framework64 ...

More about the fusion log: http://msdn.microsoft.com/en-us/library/e74a18c4(v=vs.110).aspx

All the projects had a Target CPU of AnyCPU.  I changed the application project (the project that references all the other projects) to a Target CPU of x86.  It now works.

Not sure how the Target CPU mix up occurred for no apparent reason, but it did.
    I also face this problem in a project, after a few minutes i found the solution, 
this problem is due to CPU configuration,
If you are using Visual Studio 2010 or VS 2013, just goto project 's properties and then select Compile from side bar and there will be 5 drop-down, 5th Drop-down will be Target CPU:, you should set it to x86 or x64 according to your requirements instead of Any CPU. 

My problem was solved after changing it to x86. 
    This also can happen just by having multiple supported frameworks defined in the app.config file and, forcing the app to run in a different .NET framework other than the one mentioned first in the app.config file.

And also this fires when you have both of the mentioned frameworks available in your system.

As a workaround, bring up the target framework you are going to use for the debugging up in the app.config

ex: if you trying to run in .NET 4, config file should have something similar to this,

<supportedRuntime version=""v4.0""/>
<supportedRuntime version=""v2.0.50727""/>

    In my project for C#, project property->[Build]->Platform target: Any CPU,
and uncheck the Prefer 32-bit to let compiler to choose automatically.
    It can be a little funny, but I had the same problem with normal working code. I added StreamWriter and StreamReader and it gave that error.
The solution was I took that code into comment brackets then did debug and it started to work again
    If you use LibreOffice from your program via cli .net integration like me, I got the same error. I use the older version of LibreOffice on the production environment on my PC I installed a newer version that was in conflict. Just uninstall LibreOffice. I found the solution here .NET CLI: Could not load file or assembly 'cli_cppuhelper'
    In my case a dependency was missing in the dll that threw this exception. I checked with Dependency Walker, added the missing dll and the problem was resolved.

More specifically, I somehow corrupted my opencv_core340.dll by accidentally adding SVN keywords to it, and thus my dll could no longer use it. However I don't believe that the solution to this problem depends on whether the dll is corrupted or missing. I'm just adding this for the sake of giving complete information.
    I have detected something different from the other answers. Reaching this exception in my project was the result of a corrupt compilation. Without making any changes, just forcing rebuild, it was fixed.
    I had the same issue. Project B in my case was a .Net Core Class Library which has a Nuget ""Microsoft.Management.Infrastructure"" installed. The error was that i called my project B ""MI"". I changed the project name to something else and suddenly everything worked again.
    Interesting as it goes, this can also happen if the folder path is long, which can cause build issues, oddly enough with this cryptic error message.
Just moving the folder up the path, solved the problem!
    ","[488, 757, 173, 234, 8, 3, 10, 3, 22, 3, 37, 4, 1, 3, 3, 3, 1, -1, -1, -2, 2, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]",570142,67,2012-07-06T22:14:38,2022-04-08 00:15:16Z,c 
How to parse float with two decimal places in javascript?,"
                
I have the following code. I would like to have it such that if price_result equals an integer, let's say 10, then I would like to add two decimal places. So 10 would be 10.00.
Or if it equals 10.6 would be 10.60. Not sure how to do this.

price_result = parseFloat(test_var.split('$')[1].slice(0,-1));

    You can use toFixed() to do that

var twoPlacedFloat = parseFloat(yourString).toFixed(2)

    If you need performance (like in games):

Math.round(number * 100) / 100


It's about 100 times as fast as parseFloat(number.toFixed(2))

http://jsperf.com/parsefloat-tofixed-vs-math-round
    You can use .toFixed() to for float value 2 digits

Exampale


let newValue = parseFloat(9.990000).toFixed(2)

//output
9.99


    When you use toFixed, it always returns the value as a string. This sometimes complicates the code. To avoid that, you can make an alternative method for Number.

Number.prototype.round = function(p) {
  p = p || 10;
  return parseFloat( this.toFixed(p) );
};


and use:

var n = 22 / 7; // 3.142857142857143
n.round(3); // 3.143


or simply:

(22/7).round(3); // 3.143

    ceil from lodash is probably the best 

_.ceil(""315.9250488"",2) 
_.ceil(315.9250488,2) 
_.ceil(undefined,2)
_.ceil(null,2)
_.ceil("""",2)


will work also with a number and it's safe
    I have tried this for my case and it'll work fine.
var multiplied_value = parseFloat(given_quantity*given_price).toFixed(3);

Sample output:

9.007

    To return a number, add another layer of parentheses. Keeps it clean.

var twoPlacedFloat = parseFloat((10.02745).toFixed(2));

    If your objective is to parse, and your input might be a literal, then you'd expect a float and toFixed won't provide that, so here are two simple functions to provide this:

function parseFloat2Decimals(value) {
    return parseFloat(parseFloat(value).toFixed(2));
}

function parseFloat2Decimals(value,decimalPlaces) {
    return parseFloat(parseFloat(value).toFixed(decimalPlaces));
}

    Please use below function if you don't want to round off.

function ConvertToDecimal(num) {
    num = num.toString(); //If it's not already a String
    num = num.slice(0, (num.indexOf(""."")) + 3); //With 3 exposing the hundredths place
   alert('M : ' +  Number(num)); //If you need it back as a Number    
}

    Solution for FormArray controllers 


Initialize FormArray form Builder

  formInitilize() {
    this.Form = this._formBuilder.group({
      formArray: this._formBuilder.array([this.createForm()])
    });
  }


Create Form

  createForm() {
    return (this.Form = this._formBuilder.group({
      convertodecimal: ['']
    }));
  }


Set Form Values into Form Controller

  setFormvalues() {
    this.Form.setControl('formArray', this._formBuilder.array([]));
    const control = <FormArray>this.resourceBalanceForm.controls['formArray'];
    this.ListArrayValues.forEach((x) => {
      control.push(this.buildForm(x));
    });
  }

  private buildForm(x): FormGroup {
    const bindvalues= this._formBuilder.group({
      convertodecimal: x.ArrayCollection1? parseFloat(x.ArrayCollection1[0].name).toFixed(2) : '' // Option for array collection
// convertodecimal: x.number.toFixed(2)    --- option for two decimal value 
    });

    return bindvalues;
  }

    @sd
Short Answer:  There is no way in JS to have Number datatype value with trailing zeros after a decimal.

Long Answer: Its the property of toFixed or toPrecision function of JavaScript, to return the String. The reason for this is that the Number datatype cannot have value like a = 2.00, it will always remove the trailing zeros after the decimal,  This is the inbuilt property of Number Datatype. So to achieve the above in JS we have 2 options


Either use data as a string or
Agree to have truncated value with case '0' at the end ex 2.50 -> 2.5.


    Try this (see comments in code):

function fixInteger(el) {
    // this is element's value selector, you should use your own
    value = $(el).val();
    if (value == '') {
        value = 0;
    }
    newValue = parseInt(value);
    // if new value is Nan (when input is a string with no integers in it)
    if (isNaN(newValue)) {
        value = 0;
        newValue = parseInt(value);
    }
    // apply new value to element
    $(el).val(newValue);
}

function fixPrice(el) {
    // this is element's value selector, you should use your own
    value = $(el).val();
    if (value == '') {
        value = 0;
    }
    newValue = parseFloat(value.replace(',', '.')).toFixed(2);
    // if new value is Nan (when input is a string with no integers in it)
    if (isNaN(newValue)) {
        value = 0;
        newValue = parseFloat(value).toFixed(2);
    }
    // apply new value to element
    $(el).val(newValue);
}

    I've got other solution.

You can use round() to do that instead toFixed()

var twoPlacedFloat = parseFloat(yourString).round(2)

    The solution that work for me is the following

parseFloat(value)

    You can store your price as a string
You can use
Number(string)
for your calculations.
example
Number(""34.50"") == 34.5

also
Number(""35.65"") == 35.65

If you're comfortable with the Number function , you can go with it.
    Simple JavaScript, string to float:

var it_price = chief_double($(""#ContentPlaceHolder1_txt_it_price"").val());

function chief_double(num){
    var n = parseFloat(num);
    if (isNaN(n)) {
        return ""0"";
    }
    else {
        return parseFloat(num);
    }
}

    For what its worth: A decimal number, is a decimal number, you either round it to some other value or not. Internally, it will approximate a decimal fraction according to the rule of floating point arthmetic and handling. It stays a decimal number (floating point, in JS a double) internally, no matter how you many digits you want to display it with.

To present it for display, you can choose the precision of the display to whatever you want by string conversion. Presentation is a display issue, not a storage thing.
    ","[488, 1069, 77, 3, 59, 6, 1, 19, 9, 1, -2, 0, -2, -4, -4, -1, -2, 0]",786260,83,2010-12-14T01:41:30,2021-03-16 15:25:46Z,javascript 
"Error when trying to inject a service into an angular component ""EXCEPTION: Can't resolve all parameters for component"", why?","
                
I've built a basic app in Angular, but I have encountered a strange issue where I cannot inject a service into one of my components. It injects fine into any of the three other components I have created, however.
For starters, this is the service:

import { Injectable } from '@angular/core';

@Injectable()
export class MobileService {
  screenWidth: number;
  screenHeight: number;

  constructor() {
    this.screenWidth = window.outerWidth;
    this.screenHeight = window.outerHeight;

    window.addEventListener(""resize"", this.onWindowResize.bind(this) )
  }
  
  onWindowResize(ev: Event) {
    var win = (ev.currentTarget as Window);
    this.screenWidth = win.outerWidth;
    this.screenHeight = win.outerHeight;
  }
  
}

And the component that it refuses to work with:
import { Component, } from '@angular/core';
import { NgClass } from '@angular/common';
import { ROUTER_DIRECTIVES } from '@angular/router';

import {MobileService} from '../';

@Component({
  moduleId: module.id,
  selector: 'pm-header',
  templateUrl: 'header.component.html',
  styleUrls: ['header.component.css'],
  directives: [ROUTER_DIRECTIVES, NgClass],
})
export class HeaderComponent {
  mobileNav: boolean = false;

  constructor(public ms: MobileService) {
    console.log(ms);
  }

}

The error I get in the browser console is this:

EXCEPTION: Can't resolve all parameters for HeaderComponent: (?).

I have the service in the bootstrap function so it has a provider. And I seem to be able to inject it into the constructor of any of my other components without issue.
    In addition to the previous answers given, it seems this error is thrown as well when your injectable service is missing the actual @Injectable() decorator. So before you debug the cyclic dependency thing and the order of your imports/exports, do a simple check whether your service actually has @Injectable() defined.

This applies to the current Angular latest, Angular 2.1.0.

I opened an issue on this matter.
    Import it from the file where it is declared directly instead of the barrel.

I don't know what exactly causes the issue but I saw it mentioned several times (probably some kind of circular dependency).

It should also be fixable by changing the order of the exports in the barrel (don't know details, but was mentioned as well)
    for angular 6 and newer versions, try

@Injectable({
  providedIn: 'root'
})


..right above your service class with no other lines in between

advantages


no need to add the service to any module (will be ""auto-discovered"")
service will be a singleton (since it will be injected into root)


[angular docs]
    Adding Injectable solved my problem:
Error code
import { Observable } from 'rxjs';
import { io } from 'socket.io-client';
import { HttpClient } from '@angular/common/http';

export class Chat {

After fix
import { Injectable } from '@angular/core';
import { Observable } from 'rxjs';
import { io } from 'socket.io-client';
import { HttpClient } from '@angular/common/http';

@Injectable()
export class Chat {

    As of Angular 2.2.3 there is now a forwardRef() utility function that allows you to inject providers that have not yet been defined.

By not defined, I mean that the dependency injection map doesn't know the identifier. This is what happens during circular dependencies. You can have circular dependencies in Angular that are very difficult to untangle and see.

export class HeaderComponent {
  mobileNav: boolean = false;

  constructor(@Inject(forwardRef(() => MobileService)) public ms: MobileService) {
    console.log(ms);
  }

}


Adding @Inject(forwardRef(() => MobileService)) to the parameter of the constructor in the original question's source code will fix the problem.

References

Angular 2 Manual: ForwardRef

Forward references in Angular 2
    Im my case, add ""emitDecoratorMetadata"" and ""esModuleInterop"" solved the problem.
https://github.com/thymikee/jest-preset-angular/issues/288
    Another possibility is not having emitDecoratorMetadata set to true in tsconfig.json

{
  ""compilerOptions"": {

     ...

    ""emitDecoratorMetadata"": true,

     ...

    }

}

    WRONG #1: Forgetting Decorator:

//Uncaught Error: Can't resolve all parameters for MyFooService: (?).
export class MyFooService { ... }


WRONG #2: Omitting ""@"" Symbol:

//Uncaught Error: Can't resolve all parameters for MyFooService: (?).
Injectable()
export class MyFooService { ... }


WRONG #3: Omitting ""()"" Symbols:

//Uncaught Error: Can't resolve all parameters for TypeDecorator: (?).
@Injectable
export class MyFooService { ... }


WRONG #4: Lowercase ""i"":

//Uncaught ReferenceError: injectable is not defined
@injectable
export class MyFooService { ... }


WRONG #5: You forgot:
import { Injectable } from '@angular/core';

//Uncaught ReferenceError: Injectable is not defined
@Injectable
export class MyFooService { ... }


CORRECT:

@Injectable()
export class MyFooService { ... }

    Anuglar import paths are case sensitive.Check if your service paths are correct everywhere you use service and also check the letter cases to be correct and identical everywhere.
    This can be a really difficult issue to debug due to the lack of feedback in the error. If you are concerned about an actual cyclic dependency, here's the most important thing to look at in the stack trace a) the name of the service b) the constructor parameter in that service that has a question mark e.g. if it looks like this:


  can't resolve all parameters for AuthService: ([object Object],
  [object Object], [object Object], [object Object], ?)


then it means the 5th parameter is a service that also depend on AuthService. i.e. question mark, means it wasn't resolved by DI.

From there, you just need to decouple the 2 services by restructuring the code.
    This answer might be very helpful for this problem. In addition, for my case, exporting the service as default was the cause.

WRONG:

@Inject()
export default class MobileService { ... }


CORRECT:

@Inject()
export class MobileService { ... }

    import {Injector} from '@angular/core';
import {ServiceA} from './service-a';

@Component({
  // ... 
})
class MyComp {
  constructor(private injector: Injector) {
     const serviceA = injector.get(ServiceA);
  }
}

    In addition to the missing @Injectable() decorator

Missing @Injectable() decorator in abstract class produced the Can't resolve all parameters for service: (?)
The decorator needs be present in MyService as well as in the derived class BaseService

//abstract class
@Injectable()
abstract class BaseService { ... }

//MyService    
@Injectable()
export class MyService extends BaseService {
.....
}

    I also encountered this by injecting service A into service B and vice versa.

I think it's a good thing that this fails fast as it should probably be avoided anyway. If you want your services to be more modular and re-usable, it's best to avoid circular references as much as possible. This post highlights the pitfalls surrounding that. 

Therefore, I have the following recommendations:


If you feel the classes are interacting too often (I'm talking about feature envy), you might want to consider merging the 2 services into 1 class.
If the above doesn't work for you, consider using a 3rd service, (an EventService) which both services can inject in order to exchange messages.

    In my case, I needed to add import ""core-js/es7/reflect""; to my application to make @Injectable work.
    For the benefit of searchers; I got this error. It was simply a missing @ symbol.

I.e. This produces the Can't resolve all parameters for MyHttpService error.

Injectable()
export class MyHttpService{
}


Adding the missing @ symbol fixes it.

@Injectable()
export class MyHttpService{
}

    As already stated, the issue is caused by the export ordering within the barrel which is caused by circular dependencies.

A more detailed explanation is here: https://stackoverflow.com/a/37907696/893630
    In my case, it happened because I didn't declare the type for a constructor parameter.

I had something like this:

constructor(private URL, private http: Http) { }


and then changing it to the code below solved my problem.

constructor(private URL : string, private http: Http) {}

    for me it was just lack of () in @Injectable. Proper is @Injectable()
    You get this error if you have service A that depends on a static property / method of service B and the service B itself depends on service A trough dependency injection. So it's a kind of a circular dependency, although it isn't since the property / method is static. Probably a bug that occurs in combination with AOT.
    In my case it was because of the plugin Augury, disable it will work fine. Alternative option is aot, also works.

all credits to @Boboss74 , he posted the answer here: https://github.com/angular/angular/issues/23958
    Well for me the issue was even more annoying, I was using a service within a service and forgot to add it as dependency in the appModule!
Hope this helps someone save several hours breaking the app down only to build it back up again
    Removing parameters from injectable constructor() method solved it for my case.
    Gotcha!

If none of the above answers helped you, maybe you are importing some element from the same file where a component is injecting the service.

I explain better:

This is the service file:

// your-service-file.ts
import { helloWorld } from 'your-component-file.ts'

@Injectable()
export class CustomService() {
  helloWorld()
}


This is the component file:

@Component({..})
export class CustomComponent {
  constructor(service: CustomService) { }
}

export function helloWorld() {
  console.log('hello world');
}


So it causes problems even if the symbol isn't inside the same component, but just inside the same file. Move the symbol (it can be a function, a constant, a class and so on...) elsewhere and the error will fade away
    I have encountered this error by mistyping the service's name, i.e.  constructor (private myService: MyService).

For misspelled services, I was able to determine which service was the problem (I had several listed in the constructor) by inspecting the page in Chrome->Console. You will see as part of the message a ""parameter"" array list by displaying object Object, object Object, ? (or something like that). Notice where the ""?"" is and that is the position of the service that is causing the problem.  
    In my case I was trying to extend ""NativeDateAdapter"" in order to override ""format(date: Date, displayFormat: Object)"" method. 

In AngularMaterial-2 DatePicker .

So basically I forgot to add @Injectable anotation.

After I add this to my ""CustomDateAdapter"" class:

@Injectable({
  providedIn: 'root'
})


Error has gone.
    In my case it was a circular reference.
I had MyService calling Myservice2
And MyService2 calling MyService.

Not good :(
    In my case, I was exporting a Class and an Enum from the same component file:

mComponent.component.ts:

export class MyComponentClass{...}
export enum MyEnum{...}


Then, I was trying to use MyEnum from a child of MyComponentClass. That was causing the Can't resolve all parameters error.

By moving MyEnum in a separate folder from MyComponentClass, that solved my issue!

As Günter Zöchbauer mentioned, this is happening because of a service or component is circularly dependent.
    If your service is defined in the same file as a component (that consumes it) and the service is defined after the component in the file you may get this error. This is due to the same 'forwardRef' issue others have mentioned. At this time VSCode isn't great about showing you this error and the build compiles successfully.

Running the build with --aot can mask this problem due to the way the compiler works (probably related to tree shaking). 

Solution: Make sure the service is defined in another file or before the component definition. (I'm not sure if forwardRef can be used in this case, but it seems clumsy to do so).

If I have a very simple service that is very strongly tied to a component (sort of like a view model) - eg. ImageCarouselComponent, I may name it ImageCarouselComponent.service.ts so it doesn't get all mixed up with my other services.
    For me this was because i stopped using the -aot flag whilst trying to make the compile time faster.

 ng serve -aot

    ","[488, 364, 479, 2, 3, 119, 1, 14, 81, 1, 3, 7, 1, 12, 24, 12, 19, 28, 8, 6, 9, 5, 3, 5, 2, 2, 2, 1, 1, 1, 0]",434030,69,2016-06-23T17:07:45,2022-03-14 11:37:15Z,typescript 
Iteration over std::vector: unsigned vs signed index variable,"
                
What is the correct way of iterating over a vector in C++?

Consider these two code fragments, this one works fine:

for (unsigned i=0; i < polygon.size(); i++) {
    sum += polygon[i];
}


and this one:

for (int i=0; i < polygon.size(); i++) {
    sum += polygon[i];
}


which generates warning: comparison between signed and unsigned integer expressions.

I'm new in the world of C++, so the unsigned variable looks a bit frightening to me and I know unsigned variables can be dangerous if not used correctly, so - is this correct?
    Four years passed, Google gave me this answer. With the standard C++11 (aka C++0x) there is actually a new pleasant way of doing this (at the price of breaking backward compatibility): the new auto keyword. It saves you the pain of having to explicitly specify the type of the iterator to use (repeating the vector type again), when it is obvious (to the compiler), which type to use. With v being your vector, you can do something like this:

for ( auto i = v.begin(); i != v.end(); i++ ) {
    std::cout << *i << std::endl;
}


C++11 goes even further and gives you a special syntax for iterating over collections like vectors. It removes the necessity of writing things that are always the same:

for ( auto &i : v ) {
    std::cout << i << std::endl;
}


To see it in a working program, build a file auto.cpp:

#include <vector>
#include <iostream>

int main(void) {
    std::vector<int> v = std::vector<int>();
    v.push_back(17);
    v.push_back(12);
    v.push_back(23);
    v.push_back(42);
    for ( auto &i : v ) {
        std::cout << i << std::endl;
    }
    return 0;
}


As of writing this, when you compile this with g++, you normally need to set it to work with the new standard by giving an extra flag:

g++ -std=c++0x -o auto auto.cpp


Now you can run the example:

$ ./auto
17
12
23
42


Please note that the instructions on compiling and running are specific to gnu c++ compiler on Linux, the program should be platform (and compiler) independent.
    Adding this as I couldn't find it mentioned in any answer: for index-based iteration, we can use decltype(vec_name.size()) which would evaluate to std::vector<T>::size_type
Example
for(decltype(v.size()) i{ 0 }; i < v.size(); i++) {
    /* std::cout << v[i]; ... */
}

    For iterating backwards see this answer. 

Iterating forwards is almost identical. Just change the iterators / swap decrement by increment. You should prefer iterators. Some people tell you to use std::size_t as the index variable type. However, that is not portable. Always use the size_type typedef of the container (While you could get away with only a conversion in the forward iterating case, it could actually go wrong all the way in the backward iterating case when using std::size_t, in case std::size_t is wider than what is the typedef of size_type):



Using std::vector

Using iterators

for(std::vector<T>::iterator it = v.begin(); it != v.end(); ++it) {
    /* std::cout << *it; ... */
}


Important is, always use the prefix increment form for iterators whose definitions you don't know. That will ensure your code runs as generic as possible. 

Using Range C++11

for(auto const& value: a) {
     /* std::cout << value; ... */


Using indices

for(std::vector<int>::size_type i = 0; i != v.size(); i++) {
    /* std::cout << v[i]; ... */
}




Using arrays

Using iterators

for(element_type* it = a; it != (a + (sizeof a / sizeof *a)); it++) {
    /* std::cout << *it; ... */
}


Using Range C++11

for(auto const& value: a) {
     /* std::cout << value; ... */


Using indices

for(std::size_t i = 0; i != (sizeof a / sizeof *a); i++) {
    /* std::cout << a[i]; ... */
}


Read in the backward iterating answer what problem the sizeof approach can yield to, though.
    Use size_t :
for (size_t i=0; i < polygon.size(); i++)

Quoting Wikipedia:

The stdlib.h and stddef.h header files define a datatype called size_t which is used to represent the size of an object. Library functions that take sizes expect them to be of type size_t, and the sizeof operator evaluates to size_t.
The actual type of size_t is platform-dependent; a common mistake is to assume size_t is the same as unsigned int, which can lead to programming errors, particularly as 64-bit architectures become more prevalent.

    If your compiler supports it, you could use a range based for to access the vector elements:

vector<float> vertices{ 1.0, 2.0, 3.0 };

for(float vertex: vertices){
    std::cout << vertex << "" "";
}


Prints: 1 2 3 . Note, you can't use this technique for changing the elements of the vector.
    A call to vector<T>::size() returns a value of type std::vector<T>::size_type, not int, unsigned int or otherwise.

Also generally iteration over a container in C++ is done using iterators, like this.

std::vector<T>::iterator i = polygon.begin();
std::vector<T>::iterator end = polygon.end();

for(; i != end; i++){
    sum += *i;
}


Where T is the type of data you store in the vector.

Or using the different iteration algorithms (std::transform, std::copy, std::fill, std::for_each et cetera).
    A bit of history:

To represent whether a number is negative or not computer use a 'sign' bit.  int is a signed data type meaning it can hold positive and negative values (about -2billion to 2billion).  Unsigned can only store positive numbers (and since it doesn't waste a bit on metadata it can store more: 0 to about 4billion).

std::vector::size() returns an unsigned, for how could a vector have negative length?

The warning is telling you that the right operand of your inequality statement can hold more data then the left.

Essentially if you have a vector with more then 2 billion entries and you use an integer to index into you'll hit overflow problems (the int will wrap back around to negative 2 billion).
    Obscure but important detail: if you say ""for(auto it)"" as follows, you get a copy of the object, not the actual element:

struct Xs{int i} x;
x.i = 0;
vector <Xs> v;
v.push_back(x);
for(auto it : v)
    it.i = 1;         // doesn't change the element v[0]


To modify the elements of the vector, you need to define the iterator as a reference:

for(auto &it : v)

    In the specific case in your example, I'd use the STL algorithms to accomplish this. 

#include <numeric> 

sum = std::accumulate( polygon.begin(), polygon.end(), 0 );


For a more general, but still fairly simple case, I'd go with:

#include <boost/lambda/lambda.hpp>
#include <boost/lambda/bind.hpp>

using namespace boost::lambda;
std::for_each( polygon.begin(), polygon.end(), sum += _1 );

    Consider whether you need to iterate at all

The <algorithm> standard header provides us with facilities for this:

using std::begin;  // allows argument-dependent lookup even
using std::end;    // if the container type is unknown here
auto sum = std::accumulate(begin(polygon), end(polygon), 0);


Other functions in the algorithm library perform common tasks - make sure you know what's available if you want to save yourself effort.
    Regarding Johannes Schaub's answer:

for(std::vector<T*>::iterator it = v.begin(); it != v.end(); ++it) { 
...
}


That may work with some compilers but not with gcc. The problem here is the question if std::vector::iterator is a type, a variable (member) or a function (method). We get the following error with gcc:

In member function ‘void MyClass<T>::myMethod()’:
error: expected `;' before ‘it’
error: ‘it’ was not declared in this scope
In member function ‘void MyClass<T>::sort() [with T = MyClass]’:
instantiated from ‘void MyClass<T>::run() [with T = MyClass]’
instantiated from here
dependent-name ‘std::vector<T*,std::allocator<T*> >::iterator’ is parsed as a non-type, but instantiation yields a type
note: say ‘typename std::vector<T*,std::allocator<T*> >::iterator’ if a type is meant


The solution is using the keyword 'typename' as told:

typename std::vector<T*>::iterator it = v.begin();
for( ; it != v.end(); ++it) {
...

    I usually use BOOST_FOREACH:

#include <boost/foreach.hpp>

BOOST_FOREACH( vector_type::value_type& value, v ) {
    // do something with 'value'
}


It works on STL containers, arrays, C-style strings, etc.
    To be complete, C++11 syntax enables just one another version for iterators (ref):

for(auto it=std::begin(polygon); it!=std::end(polygon); ++it) {
  // do something with *it
}


Which is also comfortable for reverse iteration

for(auto it=std::end(polygon)-1; it!=std::begin(polygon)-1; --it) {
  // do something with *it
}

    In C++11
I would use general algorithms like for_each to avoid searching for the right type of iterator and lambda expression to avoid extra named functions/objects.
The short ""pretty"" example for your particular case (assuming polygon is a vector of integers):
for_each(polygon.begin(), polygon.end(), [&sum](int i){ sum += i; });

tested on: http://ideone.com/i6Ethd
Dont' forget to include: algorithm and, of course, vector :)
Microsoft has actually also a nice example on this:
source: http://msdn.microsoft.com/en-us/library/dd293608.aspx
#include <algorithm>
#include <iostream>
#include <vector>
using namespace std;

int main() 
{
   // Create a vector object that contains 10 elements.
   vector<int> v;
   for (int i = 1; i < 10; ++i) {
      v.push_back(i);
   }

   // Count the number of even numbers in the vector by 
   // using the for_each function and a lambda.
   int evenCount = 0;
   for_each(v.begin(), v.end(), [&evenCount] (int n) {
      cout << n;
      if (n % 2 == 0) {
         cout << "" is even "" << endl;
         ++evenCount;
      } else {
         cout << "" is odd "" << endl;
      }
   });

   // Print the count of even numbers to the console.
   cout << ""There are "" << evenCount 
        << "" even numbers in the vector."" << endl;
}

    for (vector<int>::iterator it = polygon.begin(); it != polygon.end(); it++)
    sum += *it; 

    The first is type correct, and correct in some strict sense.  (If you think about is, size can never be less than zero.)  That warning strikes me as one of the good candidates for being ignored, though.
    The two code segments work the same. However, unsigned int"" route is correct. Using unsigned int types will work better with the vector in the instance you used it. Calling the size() member function on a vector returns an unsigned integer value, so you want to be comparing the variable ""i"" to a value of its own type.

Also, if you are still a little uneasy about how ""unsigned int"" looks in your code, try ""uint"". This is basically a shortened version of ""unsigned int"" and it works exactly the same. You also don't need to include other headers to use it.
    auto polygonsize = polygon.size(), i=polygonsize;
for (i=0; i < polygonsize; i++) {
    sum += polygon[i];
}

This

uses auto to avoid us worrying about types.
It takes any function calls e.g. the size() function call out of the loop to avoid unnecessary repeated function calls.
It makes the loop counter available. Purists will want to work with the n'th element with no knowledge of the value of n, and see this as bad.
It appears to have an unecessary statement i=polygonsize initializing the loop variable when it's declared, but this should disappear if there is a half decent code optimizer, and is merely to ensure i has the correct type.

I am not saying anyone should code anything the way I just did.
I am merely offering it as another alternative which avoids worrying about types, takes function calls out of the loop, and makes the loop counter available for practical things like debugging information in more complex scenarios.
    ","[488, 179, 1, 854, 12, 1, 17, 7, 1, 43, 2, 38, 6, 5, 5, 4, 2, 0, 0]",856552,250,2009-01-03T16:52:24,2021-07-07 12:04:18Z,c 
Can't bind to 'formControl' since it isn't a known property of 'input' - Angular2 Material Autocomplete issue,"
                
I am trying to use Angular Material Autocomplete component in my Angular 2 project. I added the following to my template.

<md-input-container>
   <input mdInput placeholder=""Category"" [mdAutocomplete]=""auto"" [formControl]=""stateCtrl"">
</md-input-container>

<md-autocomplete #auto=""mdAutocomplete"">
   <md-option *ngFor=""let state of filteredStates | async"" [value]=""state"">
      {{ state }}
   </md-option>
</md-autocomplete>


Following is my component.

import {Component, OnInit} from ""@angular/core"";
import {ActivatedRoute, Router} from ""@angular/router"";
import {FormControl} from ""@angular/forms"";

@Component({
    templateUrl: './edit_item.component.html',
    styleUrls: ['./edit_item.component.scss']
})
export class EditItemComponent implements OnInit {
    stateCtrl: FormControl;
    states = [....some data....];

    constructor(private route: ActivatedRoute, private router: Router) {
        this.stateCtrl = new FormControl();
        this.filteredStates = this.stateCtrl.valueChanges.startWith(null).map(name => this.filterStates(name));
    }
    ngOnInit(): void {
    }
    filterStates(val: string) {
        return val ? this.states.filter((s) => new RegExp(val, 'gi').test(s)) : this.states;
    }
}


I'm getting the following error. It looks like the formControl directive is not being found.


  Can't bind to 'formControl' since it isn't a known property of 'input'


What is the issue here?
    While using formControl, you have to import ReactiveFormsModule to your imports array.

Example:

import {FormsModule, ReactiveFormsModule} from '@angular/forms';

@NgModule({
  imports: [
    BrowserModule,
    FormsModule,
    ReactiveFormsModule,
    MaterialModule,
  ],
  ...
})
export class AppModule {}

    Forget trying to decipher the example .ts - as others have said it is often incomplete.

Instead just click on the 'pop-out' icon circled here and you'll get a fully working StackBlitz example.



You can quickly confirm the required modules:



Comment out any instances of ReactiveFormsModule, and sure enough you'll get the error:

Template parse errors:
Can't bind to 'formControl' since it isn't a known property of 'input'. 

    Another reason this can happen:
The component you are using formControl in is not declared in a module that imports the ReactiveFormsModule.
So check the module that declares the component that throws this error.
    In angular 12 the imports path for matautocompleteModule is changed and it
solved my problem.... Now it look like this

    From version 9.1.4 you only need to import ReactiveFormsModule

https://angular.io/guide/reactive-forms
    Start by adding a regular matInput to your template. Let's assume you're using the formControl directive from ReactiveFormsModule to track the value of the input.

Reactive forms provide a model-driven approach to handling form inputs whose values change over time. This guide shows you how to create and update a simple form control, progress to using multiple controls in a group, validate form values, and implement more advanced forms.

import { FormsModule, ReactiveFormsModule } from ""@angular/forms""; //this to use ngModule


...

imports: [
    BrowserModule,
    AppRoutingModule,
    HttpModule,
    FormsModule,
    RouterModule,
    ReactiveFormsModule,
    BrowserAnimationsModule,
    MaterialModule],

    Well what worked for me was to build the form within the template `` in the @component({}), for example--

import { Component, OnInit } from '@angular/core';
import { FormControl } from '@angular/forms';

@Component({
  selector: 'app-contact-form',
  template:`
  <form class=""validation-form"" validate method=""createUserWithEmailAndPassword"">
  <div class=""form-row"">
    <div class=""col-md-6 mb-3"">
      <label for=""firstName"">First name</label>
      <input type=""text"" [formControl]=""firstName"" id=""firstName"" placeholder=""Please enter your first name"" required>
      <div class=""valid-feedback"">
        Looks good!
      </div>
    </div>
    <div class=""col-md-6 mb-3"">
      <label for=""lastName"">Last name</label>
      <input type=""text"" [formControl]=""lastName"" id=""lastName"" placeholder=""Please enter your last name"" required>
      <div class=""valid-feedback"">
        Looks good!
      </div>
    </div>
  </div>
    <div class=""form-row"">
      <div class=""col-md-6 mb-3"">
        <label for=""email"">Email address</label>
        <input type=""email"" [formControl]=""email"" id=""email"" aria-describedby=""emailHelp"" placeholder=""Please enter your last name"" required>
        <small id=""emailHelp"" class=""form-text text-muted"">We'll never share your email with anyone else.</small>
        <div class=""valid-feedback"">
          Looks good!
        </div>
      </div>
    </div>
    <div class=""col-md-6 mb-3"">
      <label for=""password"">Password</label>
      <input type=""password"" [formControl]=""password"" id=""password"" placeholder=""Please enter your password"" required>
      <div class=""valid-feedback"">
        Looks good!
      </div>
    </div>
    <div class=""col-md-3 mb-3"">
      <label for=""zip"">Zip</label>
      <input type=""text"" [formControl]=""zip"" id=""zip"" required>
      <div class=""invalid-feedback"">
        Please provide a valid zip.
      </div>
    </div>
  </div>
  <div class=""form-group"">
    <div class=""form-check"">
      <input class=""form-check-input"" type=""checkbox"" value="""" id=""invalidCheck"" required>
      <label class=""form-check-label"" for=""invalidCheck"">
        Agree to terms and conditions
      </label>
      <div class=""invalid-feedback"">
        You must agree before submitting.
      </div>
    </div>
  </div>
  <button class=""btn btn-primary"" type=""submit"">Submit form</button>
</form>`,

  templateUrl: './contact-form.component.html',
  styleUrls: ['./contact-form.component.scss']
})
export class ContactFormComponent implements OnInit {

  firstName =  new FormControl('');
  lastName =  new FormControl('');
  email =  new FormControl('');
  password =  new FormControl('');

  constructor() { }

  ngOnInit(): void {
  }

}

This stopped showing errors. If the error persists then this could work out for you
    ","[488, 1012, 59, 19, 2, 4, 0, 0]",282237,40,2017-04-05T01:32:57,2021-07-29 13:52:15Z,typescript 
How can I remove an entry in global configuration with git config?,"
                
I ran a global configuration command in git to exclude certain files using a .gitignore_global file:
git config --global core.excludesfile ~/.gitignore_global

Is there a way to undo the creation of this setting globally?
    I'm not sure what you mean by ""undo"" the change.  You can remove the core.excludesfile setting like this:

git config --global --unset core.excludesfile


And of course you can simply edit the config file:

git config --global --edit


...and then remove the setting by hand.
    You can use the --unset flag of git config to do this like so:

git config --global --unset user.name
git config --global --unset user.email


If you have more variables for one config you can use:

git config --global --unset-all user.name

    If someone just wanna delete the user object entirely, then he should use:
git config --global --remove-section user

This is useful when a user accidentally adds more properties that are not required just like user.password etc.
    In order to complement the larsk anwser, is possible remove an entry line while editing with vim using the dd command:
git config --global --edit

then:

Press the Esc key to go to normal mode.
Place the cursor on the line you want to delete.
Type dd and hit Enter to remove the line.

when you finish, type ESQ and :wq
    Try these commands to remove all users' usernames and emails.
git config --global --unset-all user.name
git config --global --unset-all user.email

    Open config file to edit :

git config --global --edit


Press Insert and remove the setting

and finally type :wq and Enter to save.
    You can check all the config settings using

git config --global --list


You can remove the setting for example username

git config --global --unset user.name


You can edit the configuration or remove the config setting manually by hand using:

git config --global --edit 

    Try this from the command line to change the git config details.

git config --global --replace-all user.name ""Your New Name""

git config --global --replace-all user.email ""Your new email""

    git config information will stored in ~/.gitconfig in unix platform.

In Windows it will be stored in C:/users/<NAME>/.gitconfig.

You can edit it manually by opening this files and deleting the fields which you are interested. 
    You can edit the ~/.gitconfig file in your home folder. This is where all --global settings are saved.
    ","[488, 865, 79, 7, 8, 14, 28, 21, 27, 5, 4]",504558,124,2012-08-08T15:55:38,2021-12-31 07:56:28Z,
Custom domain for GitHub project pages,"
                
I have a gh-pages branch in one of my http://github.com repos. The GitHub project pages works fine if I go to http://myuser.github.com/myrepo

I want to setup a custom domain (myexample.com) that will serve up this project pages.  I want both myexample.com and www.myexample.com to serve up these project pages.

GitHub pages help says to make an A record and a CNAME record in your DNS.  The A record makes sense, but I do not know what CNAME record to make in my DNS.

The gh-pages docs say to make a CNAME record for 'charlie.github.com' which is a user page repository.  I do not have a user page repository - I only have a project repository and a gh-pages branch that I want to use for myexample.com and www.myexample.com.

Do I need to make a user page repository just so I can use my project page for www.myexample.com and myexample.com?

I would just try it, but I want to make sure this will work as I already have www.myexample.com live and don't want to make a mistake.

I emailed GitHub support and their response was


  You can't have both point to the same gh-pages as far as I know.  


I find it hard to believe they would only support A records for project pages.

Has anyone successfully done this before?
    1/23/19 UPDATE:
Things have changed quite a bit (for the better) since my last answer.  This updated answer will show you how to configure:

Root apex (example.com)
Sub-domain (www.example.com)
HTTPS (optional but strongly encouraged)

In the end, all requests to example.com will be re-directed to https://www.example.com (or http:// if you choose NOT to use HTTPS).  I always use www as my final landing.  Why(1,2), is for another discussion.
This answer is long but it is not complicated.  I was verbose for clarity as the GitHub docs on this topic are not clear or linear.
Step 1: Enable GitHub pages in GitHub settings

From your repo, click on the  tab
Scroll down to the GitHub Pages section.  You have two options: 
Choosing master branch will treat /README.md as your web index.html.  Choosing master branch /docs folder will treat /docs/README.md as your web index.html.
Choose a theme.
Wait a minute while GitHub publishes your site.  Verify it works by clicking on the link next to Your site is ready to be published at

Step 2: Specify custom domain in GitHub settings
Enter your custom domain name here and hit save:

This is a subtle, but important step.

If the custom domain you added to your GitHub Pages site is example.com, then www.example.com will redirect to example.com
If the custom domain you added to your GitHub Pages site is www.example.com, then example.com will redirect to www.example.com.

As mentioned before, I recommend always landing at www so I entered www.example.com as pictured above.
Step 3: Create DNS entries
In your DNS provider's web console, create four A records and one CNAME.

A Records for @ (aka root apex):

Some DNS providers will have you specify @, others (like AWS Route 53) you will leave the sub-domain blank to indicate @.  In either case, these are the A records to create:
185.199.108.153
185.199.109.153
185.199.110.153
185.199.111.153

Check the Github docs to confirm these are the most up-to-date IPs.

Create a CNAME record to point www.example.com to YOUR-GITHUB-USERNAME.github.io.

This is the most confusing part.
Note the YOUR-GITHUB-USERNAME NOT the GitHub repo name!  The value of YOUR-GITHUB-USERNAME is determined by this chart.
For a User pages site (most likely what you are), CNAME entry will be username.github.io, ex:

For a Organization  pages site, CNAME entry will be orgname.github.io, ex:

Step 5: Confirm DNS entries

Confirm your A records by running dig +noall +answer example.com.  It should return the four 185.x.x.x IP addresses you entered.

Confirm your CNAME record by running dig www.example.com +nostats +nocomments +nocmd.  It should return a CNAME   YOUR-GITHUB-USERNAME.github.io


It may take an hour or so for these DNS entries to resolve/propagate.  Once they do, open up your browser to http://example.com and it should re-direct to http://www.example.com
Step 6: SSL (HTTPS) Configuration. Optional, but highly recommended
After you have the custom domain working, go back to the repo settings.  If you already have the settings page open, hard refresh the page.
If there is a message under the Enforce HTTPS checkbox, stating that it is still processing you will need to wait.  You may also need to hit the save button in the Custom domain section to kick off the Enforce HTTPS processing.
Once processing is completed, it should look like this:

Just click on the Enforce HTTPS checkbox, and point your browser to https://example.com.  It should re-direct and open https://www.example.com
THATS IT!
GitHub will automatically keep your HTTPS cert up-to-date AND should handle the apex to www redirect over HTTPS.
Hope this helps!!
    Overview

The documentation is a little confusing when it comes to project pages, as opposed to user pages. It feels like you should have to do more, but actually the process is very easy.

It involves:


Setting up 2 static A records for the naked (no www) domain. 
Creating one CNAME record for www which will point to a GitHub URL. This will handle www redirection for you. 
Creating a file called CNAME (capitalised) in your project root on the gh-pages branch. This will tell Github what URL to respond to.
Wait for everything to propagate.


What you will get

Your content will be served from a URL of the form http://nicholasjohnson.com.

Visiting http://www.nicholasjohnson.com will return a 301 redirect to the naked domain. 

The path will be respected by the redirect, so traffic to http://www.nicholasjohnson.com/angular will be redirected to http://nicholasjohnson.com/angular. 

You can have one project page per repository, so if your repos are open you can have as many as you like.

Here's the process:

1. Create A records

For the A records, point @ to the following ip addresses:

@: 185.199.108.153
@: 185.199.109.153
@: 185.199.110.153
@: 185.199.111.153


These are the static Github IP addresses from which your content will be served.

2. Create a CNAME Record

For the CNAME record, point www to yourusername.github.io. Note the trailing full stop. Note also, this is the username, not the project name. You don't need to specify the project name yet. Github will use the CNAME file to determine which project to serve content from.

e.g.

www: forwardadvance.github.io.


The purpose of the CNAME is to redirect all www subdomain traffic to a GitHub page which will 301 redirect to the naked domain.

Here's a screenshot of the configuration I use for my own site http://nicholasjohnson.com:



3. Create a CNAME file

Add a file called CNAME to your project root in the gh-pages branch. This should contain the domain you want to serve. Make sure you commit and push.

e.g.

nicholasjohnson.com


This file tells GitHub to use this repo to handle traffic to this domain. 

4. Wait

Now wait 5 minutes, your project page should now be live.
    Short answer
These detailed explanations are great, but the OP's (and my) confusion could be resolved with one sentence: ""Direct DNS to your GitHub username or organization, ignoring the specific project, and add the appropriate CNAME files in your project repositories: GitHub will send the right DNS to the right project based on files in the repository.""
    The selected answer is the good one, but is long, so you might not read the key point:
I got an error with the SSL when accesign www.example.com but it worked fine if I go to example.com
If it happens the same to you, probably your error is that in the DNS configuration you have set:
CNAME www.example.com --> example.com  (WRONG)

But, what you have to do is:
CNAME www.example.com --> username.github.io  (GOOD)

or
CNAME www.example.com --> organization.github.io  (GOOD)

That was my error
    As of Aug 29, 2013, Github's documentation claim that:


  Warning: Project pages subpaths like http://username.github.io/projectname will not be redirected to a project's custom domain.

    I just discovered, after a bit of frustration, that if you're using PairNIC, all you have to do is enable the ""Web Forwarding"" setting under ""Custom DNS"" and supply the username.github.io/project address and it will automatically set up both the apex and subdomain records for you. It appears to do exactly what's suggested in the accepted answer. However, it won't let you do the exact same thing by manually adding records. Very strange. Anyway, it took me a while to figure that out, so I thought I'd share to save everyone else the trouble.
    
  If you are wondering how to get your domain to appear as www.mydomain.com instead of redirecting the www request to
  mydomain.com, try this:


CNAME file on gh-pages branch will have one line:

www.mydomain.com (instead of mydomain.com)

No matter your preference on redirection (in other words, no matter what is in your CNAME file on the gs-pages branch), with your DNS provider, you should set it up like this:

A      @    192.30.252.154
A      @    192.30.252.153
CNAME  www  username.github.io

    Things are lot easier nowadays! 


Update your Apex domain (@) record to point



  192.30.252.154 
  
  192.30.252.153



Edit your Custome domain field in your github repo settings.








www and other subdomains can be updated as CNAME to apex domain.

    I'd like to share my steps which is a bit different to what offered by rynop and superluminary.

for A Record is exactly the same but
instead of creating CNAME for www I would prefer to redirect it to my blank domain (non-www)

This configuration is referring to guidance of preferred domain. The domain setting of www to non www or vise versa can be different on each of the domain providers. Since my domain is under GoDaddy, so under the  Domain Setting I set it using the Subdomain Forwarding (301).
As the result of pointing the domain to Github repository, it will then give all the URLs for both of master and gh-pages.
As addition to the CNAME file above, you may need to completely bypass Jekyll processing on GitHub Pages by creating a file named .nojekyll in the root of your pages repo.
    ","[488, 611, 250, 24, 2, 14, 3, 21, 3, 0]",118776,300,2012-01-31T15:50:13,2022-03-18 11:37:38Z,
What is an index in SQL?,"
                
Also, when is it appropriate to use one?
    An index is used to speed up searching in the database. MySQL have some good documentation on the subject (which is relevant for other SQL servers as well):
http://dev.mysql.com/doc/refman/5.0/en/mysql-indexes.html

An index can be used to efficiently find all rows matching some column in your query and then walk through only that subset of the table to find exact matches. If you don't have indexes on any column in the WHERE clause, the SQL server has to walk through the whole table and check every row to see if it matches, which may be a slow operation on big tables.

The index can also be a UNIQUE index, which means that you cannot have duplicate values in that column, or a PRIMARY KEY which in some storage engines defines where in the database file the value is stored.

In MySQL you can use EXPLAIN in front of your SELECT statement to see if your query will make use of any index. This is a good start for troubleshooting performance problems. Read more here:
http://dev.mysql.com/doc/refman/5.0/en/explain.html
    First we need to understand how normal (without indexing) query runs. It basically traverse each rows one by one and when it finds the data it returns. Refer the following image. (This image has been taken from this video.) 


So suppose query is to find 50 , it will have to read  49 records as a linear search. 

Refer the following image. (This image has been taken from this video)

 

When we apply indexing, the query will quickly find out the data without reading each one of them just by eliminating half of the data in each traversal like a binary search. The mysql indexes are stored as B-tree where all the data are in leaf node.
    Well in general index is a B-tree. There are two types of indexes: clustered and nonclustered. 

Clustered index creates a physical order of rows (it can be only one and in most cases it is also a primary key - if you create primary key on table you create clustered index on this table also).

Nonclustered index is also a binary tree but it doesn't create a physical order of rows. So the leaf nodes of nonclustered index contain PK (if it exists) or row index. 

Indexes are used to increase the speed of search. Because the complexity is of O(log N). Indexes is very large and interesting topic. I can say that creating indexes on large database is some kind of art sometimes.
    So, How indexing actually works?
Well, first off, the database table does not reorder itself when we put index on a column to optimize the query performance.
An index is a data structure, (most commonly its B-tree {Its balanced tree, not binary tree}) that stores the value for a specific column in a table.

The major advantage of B-tree is that the data in it is sortable. Along with it, B-Tree data structure is time efficient and operations such as searching, insertion, deletion can be done in logarithmic time.
So the index would look like this -

Here for each column, it would be mapped with a database internal identifier (pointer) which points to the exact location of the row. And, now if we run the same query.
Visual Representation of the Query execution

So, indexing just cuts down the time complexity from o(n) to o(log n).
A detailed info - https://pankajtanwar.in/blog/what-is-the-sorting-algorithm-behind-order-by-query-in-mysql
    Indexes are all about finding data quickly.

Indexes in a database are analogous to indexes that you find in a book. If a book has an index, and I ask you to find a chapter in that book, you can quickly find that with the help of the index. On the other hand, if the book does not have an index, you will have to spend more time looking for the chapter by looking at every page from the start to the end of the book.

In a similar fashion, indexes in a database can help queries find data quickly. If you are new to indexes, the following videos, can be very useful. In fact, I have learned a lot from them.

Index Basics
Clustered and Non-Clustered Indexes 
Unique and Non-Unique Indexes 
Advantages and disadvantages of indexes
    INDEXES - to find data easily 

UNIQUE INDEX - duplicate values are not allowed 

Syntax for INDEX

CREATE INDEX INDEX_NAME ON TABLE_NAME(COLUMN);


Syntax for UNIQUE INDEX

CREATE UNIQUE INDEX INDEX_NAME ON TABLE_NAME(COLUMN);

    INDEX is a performance optimization technique that speeds up the data retrieval process. It is a persistent data structure that is associated with a Table (or View) in order to increase performance during retrieving the data from that table (or View).
Index based search is applied more particularly when your queries include WHERE filter. Otherwise, i.e, a query without WHERE-filter selects whole data and process. Searching whole table without INDEX is called Table-scan.
You will find exact information for Sql-Indexes in clear and reliable way:
follow these links:

For cocnept-wise understanding:
http://dotnetauthorities.blogspot.in/2013/12/Microsoft-SQL-Server-Training-Online-Learning-Classes-INDEX-Overview-and-Optimizations.html
For implementation-wise understanding:
http://dotnetauthorities.blogspot.in/2013/12/Microsoft-SQL-Server-Training-Online-Learning-Classes-INDEX-Creation-Deletetion-Optimizations.html

    A clustered index is like the contents of a phone book. You can open the book at 'Hilditch, David' and find all the information for all of the 'Hilditch's right next to each other. Here the keys for the clustered index are (lastname, firstname).

This makes clustered indexes great for retrieving lots of data based on range based queries since all the data is located next to each other.

Since the clustered index is actually related to how the data is stored, there is only one of them possible per table (although you can cheat to simulate multiple clustered indexes).

A non-clustered index is different in that you can have many of them and they then point at the data in the clustered index. You could have e.g. a non-clustered index at the back of a phone book which is keyed on (town, address)

Imagine if you had to search through the phone book for all the people who live in 'London' - with only the clustered index you would have to search every single item in the phone book since the key on the clustered index is on (lastname, firstname) and as a result the people living in London are scattered randomly throughout the index.

If you have a non-clustered index on (town) then these queries can be performed much more quickly.

Hope that helps!
    An index is used to speed up the performance of queries. It does this by reducing the number of database data pages that have to be visited/scanned.

In SQL Server, a clustered index determines the physical order of data in a table. There can be only one clustered index per table (the clustered index IS the table). All other indexes on a table are termed non-clustered.


SQL Server Index Basics
SQL Server Indexes: The Basics
SQL Server Indexes 
Index Basics
Index (wiki)

    If you're using SQL Server, one of the best resources is its own Books Online that comes with the install!  It's the 1st place I would refer to for ANY SQL Server related topics.

If it's practical ""how should I do this?"" kind of questions, then StackOverflow would be a better place to ask.

Also, I haven't been back for a while but sqlservercentral.com used to be one of the top SQL Server related sites out there.
    An index is used for several different reasons. The main reason is to speed up querying so that you can get rows or sort rows faster. Another reason is to define a primary-key or unique index which will guarantee that no other columns have the same values.
    An index is an on-disk structure associated with a table or view that speeds retrieval of rows from the table or view. An index contains keys built from one or more columns in the table or view. These keys are stored in a structure (B-tree) that enables SQL Server to find the row or rows associated with the key values quickly and efficiently.

Indexes are automatically created when PRIMARY KEY and UNIQUE constraints are defined on table columns. For example, when you create a table with a UNIQUE constraint, Database Engine automatically creates a nonclustered index. 

If you configure a PRIMARY KEY, Database Engine automatically creates a clustered index, unless a clustered index already exists. When you try to enforce a PRIMARY KEY constraint on an existing table and a clustered index already exists on that table, SQL Server enforces the primary key using a nonclustered index.

Please refer to this for more information about indexes (clustered and non clustered):
https://docs.microsoft.com/en-us/sql/relational-databases/indexes/clustered-and-nonclustered-indexes-described?view=sql-server-ver15

Hope this helps!
    INDEX is not part of SQL. INDEX creates a Balanced Tree on physical level to accelerate CRUD.
SQL is a language which describe the Conceptual Level Schema and External Level Schema. SQL doesn't describe Physical Level Schema.
The statement which creates an INDEX is defined by DBMS, not by SQL standard.
    ","[488, 421, 20, 25, 2, 61, 22, 14, 183, 86, 6, 5, 0, 0]",712888,154,2010-06-02T06:26:54,2021-10-17 04:58:28Z,sql 
Explaining Python's '__enter__' and '__exit__',"
                
I saw this in someone's code. What does it mean?

    def __enter__(self):
        return self

    def __exit__(self, type, value, tb):
        self.stream.close()




from __future__ import with_statement#for python2.5 

class a(object):
    def __enter__(self):
        print 'sss'
        return 'sss111'
    def __exit__(self ,type, value, traceback):
        print 'ok'
        return False

with a() as s:
    print s


print s

    Using these magic methods (__enter__, __exit__) allows you to implement objects which can be used easily with the with statement. 

The idea is that it makes it easy to build code which needs some 'cleandown' code executed (think of it as a try-finally block). Some more explanation here.

A useful example could be a database connection object (which then automagically closes the connection once the corresponding 'with'-statement goes out of scope):

class DatabaseConnection(object):

    def __enter__(self):
        # make a database connection and return it
        ...
        return self.dbconn

    def __exit__(self, exc_type, exc_val, exc_tb):
        # make sure the dbconnection gets closed
        self.dbconn.close()
        ...


As explained above, use this object with the with statement (you may need to do from __future__ import with_statement at the top of the file if you're on Python 2.5).

with DatabaseConnection() as mydbconn:
    # do stuff


PEP343 -- The 'with' statement' has a nice writeup as well.
    If you know what context managers are then you need nothing more to understand __enter__ and __exit__ magic methods. Lets see a very simple example.
In this example I am opening the myfile.txt file with help of open function. The try/finally block ensures that even if an unexpected exception occurs myfile.txt will be closed.
fp=open(r""C:\Users\SharpEl\Desktop\myfile.txt"")
try:
    for line in fp:
        print(line)
finally:
    fp.close()

Now I am opening same file with with statement:
with open(r""C:\Users\SharpEl\Desktop\myfile.txt"") as fp:
    for line in fp:
        print(line) 

If you look at the code, I  didn't close the file & there is no try/finally block. Because with statement automatically closes  myfile.txt . You can even check it by calling print(fp.closed) attribute -- which returns True.
This is because the file objects (fp in my example) returned by open function has two built-in methods __enter__ and __exit__. It is  also known as context manager. __enter__ method is called at the start of with block and __exit__  method is called at the end.
Note: with statement only works with objects that support the context management protocol (i.e. they have __enter__ and __exit__ methods). A class which implement both methods is known as context manager class.
Now lets define our own context manager class.
 class Log:
    def __init__(self,filename):
        self.filename=filename
        self.fp=None    
    def logging(self,text):
        self.fp.write(text+'\n')
    def __enter__(self):
        print(""__enter__"")
        self.fp=open(self.filename,""a+"")
        return self    
    def __exit__(self, exc_type, exc_val, exc_tb):
        print(""__exit__"")
        self.fp.close()

with Log(r""C:\Users\SharpEl\Desktop\myfile.txt"") as logfile:
    print(""Main"")
    logfile.logging(""Test1"")
    logfile.logging(""Test2"")

I hope now you have basic understanding of both __enter__ and __exit__ magic methods.
    In addition to the above answers to exemplify invocation order, a simple run example


class myclass:
    def __init__(self):
        print(""__init__"")

    def __enter__(self): 
        print(""__enter__"")

    def __exit__(self, type, value, traceback):
        print(""__exit__"")

    def __del__(self):
        print(""__del__"")

with myclass(): 
    print(""body"")


Produces the output: 

__init__
__enter__
body
__exit__
__del__


A reminder: when using the syntax with myclass() as mc, variable mc gets the value returned by __enter__(), in the above case None! For such use, need to define return value, such as: 

def __enter__(self): 
    print('__enter__')
    return self

    I found it strangely difficult to locate the python docs for __enter__ and __exit__ methods by Googling, so to help others here is the link:

https://docs.python.org/2/reference/datamodel.html#with-statement-context-managers
https://docs.python.org/3/reference/datamodel.html#with-statement-context-managers
(detail is the same for both versions)


  object.__enter__(self)
  Enter the runtime context related to this object. The with statement will bind this method’s return value to the target(s) specified in the as clause of the statement, if any.
  
  object.__exit__(self, exc_type, exc_value, traceback)
  Exit the runtime context related to this object. The parameters describe the exception that caused the context to be exited. If the context was exited without an exception, all three arguments will be None.
  
  If an exception is supplied, and the method wishes to suppress the exception (i.e., prevent it from being propagated), it should return a true value. Otherwise, the exception will be processed normally upon exit from this method.
  
  Note that __exit__() methods should not reraise the passed-in exception; this is the caller’s responsibility.


I was hoping for a clear description of the __exit__ method arguments. This is lacking but we can deduce them...

Presumably exc_type is the class of the exception.

It says you should not re-raise the passed-in exception. This suggests to us that one of the arguments might be an actual Exception instance ...or maybe you're supposed to instantiate it yourself from the type and value?

We can answer by looking at this article:
http://effbot.org/zone/python-with-statement.htm


  For example, the following __exit__ method swallows any TypeError, but lets all other exceptions through:


def __exit__(self, type, value, traceback):
    return isinstance(value, TypeError)


...so clearly value is an Exception instance.

And presumably traceback is a Python traceback object.
    This is called context manager and I just want to add that similar approaches exist for other programming languages. Comparing them could be helpful in understanding the context manager in python.
Basically, a context manager is used when we are dealing with some resources (file, network, database) that need to be initialized and at some point, tear downed (disposed). In Java 7 and above we have automatic resource management that takes the form of:

//Java code
try (Session session = new Session())
{
  // do stuff
}


Note that Session needs to implement AutoClosable or one of its (many) sub-interfaces.

In C#, we have using statements for managing resources that takes the form of:

//C# code
using(Session session = new Session())
{
  ... do stuff.
}


In which Session should implement IDisposable. 

In python, the class that we use should implement __enter__ and __exit__. So it takes the form of:

#Python code
with Session() as session:
    #do stuff


And as others pointed out, you can always use try/finally statement in all the languages to implement the same mechanism. This is just syntactic sugar.
    Python calls __enter__ when execution enters the context of the with statement and it’s time to acquire the resource. When execution leaves the context again, Python calls __exit__ to free up the resource
Let's consider Context Managers and the “with” Statement in Python. Context Manager is a simple “protocol” (or interface) that your object needs to follow so it can be used with the with statement. Basically all you need to do is add enter and exit methods to an object if you want it to function as a context manager. Python will call these two methods at the appropriate times in the resource management cycle.
Let’s take a look at what this would look like in practical terms. Here’s how a simple implementation of the open() context manager might look like:
class ManagedFile:
    def __init__(self, name):
        self.name = name

    def __enter__(self):
        self.file = open(self.name, 'w')
        return self.file

    def __exit__(self, exc_type, exc_val, exc_tb):
        if self.file:
            self.file.close()

Our ManagedFile class follows the context manager protocol and now supports the with statement.
>>> with ManagedFile('hello.txt') as f:
...    f.write('hello, world!')
...    f.write('bye now')`enter code here`

Python calls enter when execution enters the context of the with statement and it’s time to acquire the resource. When execution leaves the context again, Python calls exit to free up the resource.
Writing a class-based context manager isn’t the only way to support the with statement in Python. The contextlib utility module in the standard library provides a few more abstractions built on top of the basic context manager protocol. This can make your life a little easier if your use cases matches what’s offered by contextlib.
    try adding my answers (my thought of learning) :

__enter__ and [__exit__] both are methods that are invoked on entry to and exit from the body of ""the with statement"" (PEP 343) and implementation of both is called context manager.

the with statement is intend to hiding flow control of try finally clause and make the code inscrutable.

the syntax of the with statement is :

with EXPR as VAR:
    BLOCK


which translate to (as mention in PEP 343) :

mgr = (EXPR)
exit = type(mgr).__exit__  # Not calling it yet
value = type(mgr).__enter__(mgr)
exc = True
try:
    try:
        VAR = value  # Only if ""as VAR"" is present
        BLOCK
    except:
        # The exceptional case is handled here
        exc = False
        if not exit(mgr, *sys.exc_info()):
            raise
        # The exception is swallowed if exit() returns true
finally:
    # The normal and non-local-goto cases are handled here
    if exc:
        exit(mgr, None, None, None)


try some code:

>>> import logging
>>> import socket
>>> import sys

#server socket on another terminal / python interpreter
>>> s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
>>> s.listen(5)
>>> s.bind((socket.gethostname(), 999))
>>> while True:
>>>    (clientsocket, addr) = s.accept()
>>>    print('get connection from %r' % addr[0])
>>>    msg = clientsocket.recv(1024)
>>>    print('received %r' % msg)
>>>    clientsocket.send(b'connected')
>>>    continue

#the client side
>>> class MyConnectionManager:
>>>     def __init__(self, sock, addrs):
>>>         logging.basicConfig(level=logging.DEBUG, format='%(asctime)s \
>>>         : %(levelname)s --> %(message)s')
>>>         logging.info('Initiating My connection')
>>>         self.sock = sock
>>>         self.addrs = addrs
>>>     def __enter__(self):
>>>         try:
>>>             self.sock.connect(addrs)
>>>             logging.info('connection success')
>>>             return self.sock
>>>         except:
>>>             logging.warning('Connection refused')
>>>             raise
>>>     def __exit__(self, type, value, tb):
>>>             logging.info('CM suppress exception')
>>>             return False
>>> addrs = (socket.gethostname())
>>> s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
>>> with MyConnectionManager(s, addrs) as CM:
>>>     try:
>>>         CM.send(b'establishing connection')
>>>         msg = CM.recv(1024)
>>>         print(msg)
>>>     except:
>>>         raise
#will result (client side) :
2018-12-18 14:44:05,863         : INFO --> Initiating My connection
2018-12-18 14:44:05,863         : INFO --> connection success
b'connected'
2018-12-18 14:44:05,864         : INFO --> CM suppress exception

#result of server side
get connection from '127.0.0.1'
received b'establishing connection'


and now try manually (following translate syntax):

>>> s = socket.socket(socket.AF_INET, socket.SOCK_STREAM) #make new socket object
>>> mgr = MyConnection(s, addrs)
2018-12-18 14:53:19,331         : INFO --> Initiating My connection
>>> ext = mgr.__exit__
>>> value = mgr.__enter__()
2018-12-18 14:55:55,491         : INFO --> connection success
>>> exc = True
>>> try:
>>>     try:
>>>         VAR = value
>>>         VAR.send(b'establishing connection')
>>>         msg = VAR.recv(1024)
>>>         print(msg)
>>>     except:
>>>         exc = False
>>>         if not ext(*sys.exc_info()):
>>>             raise
>>> finally:
>>>     if exc:
>>>         ext(None, None, None)
#the result:
b'connected'
2018-12-18 15:01:54,208         : INFO --> CM suppress exception


the result of the server side same as before

sorry for my bad english and my unclear explanations, thank you....
    ","[488, 562, 101, 71, 80, 6, 2, 5]",366224,135,2009-12-31T07:07:18,2022-01-25 21:35:31Z,python 
What's the best UML diagramming tool? [closed],"
                    
            
        
            
                    
                        
                    
                
                    
                        As it currently stands, this question is not a good fit for our Q&A format. We expect answers to be supported by facts, references,  or expertise, but this question will likely solicit debate, arguments, polling, or extended discussion. If you feel that this question  can be improved and possibly reopened, visit the help center for guidance.
                        
                    
                
            
                Closed 9 years ago.
        

            
        
            
                    
                        
                    
                
                    
                        Locked. This question and its answers are locked because the question is off-topic but has historical significance. It is not currently accepting new answers or interactions.
                        
                    
                
            
        

    

I'm trying to choose a tool for creating UML diagrams of all flavours. Usability is a major criteria for me, but I'd still take more power with a steeper learning curve and be happy. Free (as in beer) would be nice, but I'd be willing to pay if the tool's worth it. What should I be using?
    Some context: Recently for graduate school I researched UML tools for usability and UML comprehension in general for an independent project.  I also model/architect for a living.

The previous posts have too many answers and not enough questions.  A common misunderstanding is that UML is about creating diagrams.  Sure, diagrams are important, but really you are creating a model.  Here are the questions that should be answered as each vendor product/solution does some things better than others.  Note:  The listed answers are my view as the best even if other products support a given feature or need.


Are you modeling or drawing? (Drawing - ArgoUML, free implementations, and Visio)
Will you be modeling in the future? (For basic modeling - Community editions of pay products)
Do you want to formalize your modeling through profiles or meta-models? OCL? (Sparx, RSM, Visual Paradigm)
Are you concerned about model portability, XMI support? (GenMyModel, Sparx, Visual Paradigm, Altova)
Do you have an existing set of documents that you need to work with? (Depends on the documents)
Would you want to generate code stubs or full functioning code?(GenMyModel, Visual Paradigm, Sparx, Altova)
Do you need more mature processes such as use case management, pattern creation, asset creation, RUP integration, etc? (RSA/RSM/IBM Rational Products) 


Detailed Examples:  IBM Rational Software Architect did not implement UML 2.0 all the way when it comes to realizes type relationships when creating a UML profile, but Visual Paradigm and Sparx got it right. 
Ok, that was way too detailed, so a simpler example would be ArgoUML, which has no code generation features and focuses on drawing more than the modeling aspect of UML.  Sparx and Visual Paradigm do UML really well and generate code well, however, hooking into project lifecycles and other process is where RSM/RSA is strong. 
Watch out for closed or product specific code generation processes or frameworks as you could end up stuck with that product.

This is a straight brain dump so a couple details may not be perfect, however, this should provide a general map to the questions and solutions to looking into.

NEW - Found a good list of many UML tools with descriptions.  Wiki UML Tool List
    For sequence diagrams, only, try websequencediagrams.com. It's a freemium (free for the basic tasks, paid for advanced features) product, and lets you quickly bang out a diagram without any fussing around with lines and stencils.


Alice->Bob: Authentication Request
note left of Bob: Bob thinks about it
Bob->Alice: Authentication Response



    For me it's Enterprise Architect from Sparx Systems. A very rounded UML tool for a very reasonable price. 

Very strong feature list including: integrated project management, baselining, export/import (including export to html), documentation generation from the model, various templates (Zachman, TOGAF, etc.), IDE plugins, code generation (with IDE plugins available for Visual Studio, Eclipse & others), automation API - the list goes on. 

Oh yeah, don't forget support for source control directly from inside the tool (SVN, CVS, TFS & SCC).

I would also stay away from Visio - you only get diagrams, not a model. Rename a class in one place in a UML modelling tool and you rename in all places. This is not the case in Visio!
    For my simple & short UML working,
I've used this tool:

StarUML - http://staruml.sourceforge.net/en/

Great free software for UML drawing.



Although the original Star UML is no longer maintained, there's now a fork called White Star UML, which is actively developed.
    As I usually use UML more as a communication tool rather than a modeling tool I sometimes have the need to flex the language a bit, which makes the strict modeling tools quite unwieldy. Also, they tend to have a large overhead for the occasional drawing. This also means I don't give tools that handle round-trip modeling well any bonus points. With this in mind... 

When using Visio, I tend to use these stencils for my UMLing needs (the built in kind of suck). It could be that I have grown used to it as it is the primary diagramming tool at my current assignment.

OmniGraffle also has some UML stencils built in and more are available at Graffletopia, but I wouldn't recommend that as a diagramming tool as it has too many quirks (quirks that are good for many things, but not UML). Free trial though, so by all means... :)

I've been trying out MagicDraw a bit, but while functional, I found the user interface distracting. 

Otherwise i find the Topcased an interesting project (or group of projects). Last I used it it still had some bugs, but it worked, and seems to have evolved nicely since. Works great on any Eclipse-enabled platform. Free as in speech and beer :)

As for the diagramming tool Dia, it's quite ugly (interface and resulting drawings), but it does get the job done. An interesting modeling tool free alternative is Umbrello, but I haven't really used it much.

I definitely agree with mashi that whiteboards are great (together with a digital camera or cellphone).

Probably some of the nicest tools I've used belong to the Rational family of tools.
    You may be looking for an automated tool that will automatically generate a lot of stuff for you. But here's a free, generally powerful diagramming tool useful not only for UML but for all kinds of diagramming tasks. It accepts as input and outputs to a wide variety of commonly used file formats. It's called yEd, and it's worth a look
    Visual Paradigm for UML http://content.usa.visual-paradigm.com/websiteimages/images/products/vpuml60/vpumltitle.gif

I'm very fond of Visual Paradigm for UML It's very powerful and has a free Community Edition and cheap Personal Edition as well.

Agilian http://content.usa.visual-paradigm.com/websiteimages/images/products/ag10/agtitle.gif

For Agile modeling there's also Agilian which is a bit more flexible, adds extra features to support smartboards and knows mind-mapping as well.

The thing I like most about their products is the flexibility. I'm using Enterprise Architect at work nowadays but I think it's not smart enough. I want to be able to quick-brainstorm some sequence diagrams and have the application keep my model up-to-date in the background, something VPUML does a very good job at.

In my opinion it's way better than Enterprise Architect, though that is a great tool as well :)
    Take a look at BOUML: multiplatform (QT), works pretty well and supports colaborative work.

BOUML is a free UML 2 tool box (under development) allowing you to specify and generate code in C++, Java, Idl, Php and Python.
BOUML runs under Unix/Linux/Solaris, MacOS X(Power PC and Intel) and Windows.

From Wikipedia:

The releases prior to version 4.23 are free software licensed under GPL. BOUML 5 and later is proprietary software.

    If you're looking to get out the door and working on UML without having to learn a complex new tool I would check out Violet UML.  I've used it to some pretty great success in the past.
    PlantUML is an open-source markup-language-to-UML-diagram tool in Java that deserves to be mentioned here. It ranks high on the usability scale  because of its intuitive syntax for the various diagrams and diagram components. 
    Dia is a possible choice. It's definitely not the best tool, but it is functional.
    Enterprise Architect from Sparx systems is the best tool I've used. A bit expensive at $199 (professional edition), but IMO it's worth it.
    I will add UMLet which I haven't tried yet, but have been selected at my office to start doing diagrams.
Looks simple, diagrams aren't sexy, but it seems quite complete with regard to the kind of diagrams you can do. Seems to have good export capabilities too (important!), is flexible can support custom components) and can be used as Eclipse plugin.
    Astah UML (ex-JUDE) is pretty good.
    I haven't been able to find a top-notch free UML diagramming tool, but if you're interested in pure diagramming, as opposed to round-trip-engineering, I'd go with Microsoft Visio. If you want full round-trip engineering, Rational Rose.

This list of UML tools on Wikipedia might also come in handy.
    Pen and paper. If you can get the scan into a vector format, that may be useful when making minor amendments.
    You should try Creately. Runs in your browser and can do team collaboration.

supports sequence diagrams, class, ER, usecase etc. works great and has a free version available.

Creately.com
    You can also check out Lucid Chart for uml and other types of diagramming.
    Don't forget yuml.me, I love it.
    http://plantuml.sourceforge.net/index.html
    In my practice i use Sequence Diagram Editor. it is really fast and helpful tool. the one thing i don't like about it is that it is commercial product, not free.
    I like VisualParadigm mentioned before in this thread. It's powerful and easy to use I think it gives most power comparing to other tools.

If you need something simple, quick and easy (and free) there is a great tool called UMLet - I highly recommend this. I've tried many of UML diagramming tools and this the simplest one (and it still allows to do great diagrams). This is my choice:)
    Obviously if you are serious about UML in the long run you need to use a software UML tool like the ones suggested in the other answers, but I've found that a whiteboard is one of the best tools for UML diagramming, especially during the design phase, or when you are exploring different alternatives.  Nothing beats a whiteboard for speed/flexibility in my mind.  They are also great for collaboration assuming you are collocated physically. 
    In my opinion StarUML is the best.
    I can't believe no one has mentioned NetBeans UML Editor, it's great and satisfied all of my Java based UML requirments.

This after I tested JDeveloper UML, ArgoUML and StarUML.
    I recently conducted a poll ""What UML Tools do you use?"" in my blog. NetBeans UML was was the top opensource choice and Enterprise Architect was the top commercial choice.
    You can create UML class, sequence, component, use case, and activity diagrams in Visual Studio 2010 Ultimate. You can link these diagrams to Team Foundation work items so you can plan and track development and test work. You can also create sequence, dependency graphs, and layer diagrams from code and use Architecture Explorer to browse and explore your solution. 

I've posted more links on my profile for more info.
    You might want to take a look at MagicDraw or Visual Paradigm for UML. Both offer community editions that, of course, don't span the full feature range, but may well be sufficient if you want to create diagrams only and not generate code or do full round-trip engineering.
    Rational and Together/J are best-of-breed products, but expensive.

In my experience, I've enjoyed Eclipse Omondo and Sparx Enterprise Architect.  Omondo integrates nicely with Eclipse for code generation, and has a very intuitive feel.  However, it is strongly tied to Java.  Sparx is a good tool for the price point, but lacks the full range of UML 2.0 diagrams.

Do NOT bother with Poseidon.  It is buggy, bloated, and unusuable for all intents and purposes.
    For sequence diagrams you can also try Trace Modeler. It's not free but it has a great interface, very friendly and productive. You can use it on any platform. 
    ",,1055595,688,2008-08-18T23:29:17,2013-08-14 16:46:32Z,
How does the compilation/linking process work?,"
                
How does the compilation and linking process work?

(Note: This is meant to be an entry to Stack Overflow's C++ FAQ. If you want to critique the idea of providing an FAQ in this form, then the posting on meta that started all this would be the place to do that. Answers to that question are monitored in the C++ chatroom, where the FAQ idea started out in the first place, so your answer is very likely to get read by those who came up with the idea.)

    The compilation of a C++ program involves three steps:


Preprocessing: the preprocessor takes a C++ source code file and deals with the #includes, #defines and other preprocessor directives. The output of this step is a ""pure"" C++ file without pre-processor directives.
Compilation: the compiler takes the pre-processor's output and produces an object file from it.
Linking: the linker takes the object files produced by the compiler and produces either a library or an executable file.


Preprocessing

The preprocessor handles the preprocessor directives, like #include and #define. It is agnostic of the syntax of C++, which is why it must be used with care.

It works on one C++ source file at a time by replacing #include directives with the content of the respective files (which is usually just declarations), doing replacement of macros (#define), and selecting different portions of text depending of #if, #ifdef and #ifndef directives.

The preprocessor works on a stream of preprocessing tokens. Macro substitution is defined as replacing tokens with other tokens (the operator ## enables merging two tokens when it makes sense).

After all this, the preprocessor produces a single output that is a stream of tokens resulting from the transformations described above. It also adds some special markers that tell the compiler where each line came from so that it can use those to produce sensible error messages.

Some errors can be produced at this stage with clever use of the #if and #error directives.

Compilation

The compilation step is performed on each output of the preprocessor. The compiler parses the pure C++ source code (now without any preprocessor directives) and converts it into assembly code. Then invokes underlying back-end(assembler in toolchain) that assembles that code into machine code producing actual binary file in some format(ELF, COFF, a.out, ...). This object file contains the compiled code (in binary form) of the symbols defined in the input. Symbols in object files are referred to by name.

Object files can refer to symbols that are not defined. This is the case when you use a declaration, and don't provide a definition for it. The compiler doesn't mind this, and will happily produce the object file as long as the source code is well-formed.

Compilers usually let you stop compilation at this point. This is very useful because with it you can compile each source code file separately. The advantage this provides is that you don't need to recompile everything if you only change a single file.

The produced object files can be put in special archives called static libraries, for easier reusing later on.

It's at this stage that ""regular"" compiler errors, like syntax errors or failed overload resolution errors, are reported.

Linking

The linker is what produces the final compilation output from the object files the compiler produced. This output can be either a shared (or dynamic) library (and while the name is similar, they haven't got much in common with static libraries mentioned earlier) or an executable.

It links all the object files by replacing the references to undefined symbols with the correct addresses. Each of these symbols can be defined in other object files or in libraries. If they are defined in libraries other than the standard library, you need to tell the linker about them.

At this stage the most common errors are missing definitions or duplicate definitions. The former means that either the definitions don't exist (i.e. they are not written), or that the object files or libraries where they reside were not given to the linker. The latter is obvious: the same symbol was defined in two different object files or libraries.
    This topic is discussed at CProgramming.com:
https://www.cprogramming.com/compilingandlinking.html
Here is what the author there wrote:

Compiling isn't quite the same as creating an executable file!
Instead, creating an executable is a multistage process divided into
two components: compilation and linking. In reality, even if a program
""compiles fine"" it might not actually work because of errors during
the linking phase. The total process of going from source code files
to an executable might better be referred to as a build.
Compilation
Compilation refers to the processing of source code files (.c, .cc, or
.cpp) and the creation of an 'object' file. This step doesn't create
anything the user can actually run. Instead, the compiler merely
produces the machine language instructions that correspond to the
source code file that was compiled. For instance, if you compile (but
don't link) three separate files, you will have three object files
created as output, each with the name .o or .obj
(the extension will depend on your compiler). Each of these files
contains a translation of your source code file into a machine
language file -- but you can't run them yet! You need to turn them
into executables your operating system can use. That's where the
linker comes in.
Linking
Linking refers to the creation of a single executable file from
multiple object files. In this step, it is common that the linker will
complain about undefined functions (commonly, main itself). During
compilation, if the compiler could not find the definition for a
particular function, it would just assume that the function was
defined in another file. If this isn't the case, there's no way the
compiler would know -- it doesn't look at the contents of more than
one file at a time. The linker, on the other hand, may look at
multiple files and try to find references for the functions that
weren't mentioned.
You might ask why there are separate compilation and linking steps.
First, it's probably easier to implement things that way. The compiler
does its thing, and the linker does its thing -- by keeping the
functions separate, the complexity of the program is reduced. Another
(more obvious) advantage is that this allows the creation of large
programs without having to redo the compilation step every time a file
is changed. Instead, using so called ""conditional compilation"", it is
necessary to compile only those source files that have changed; for
the rest, the object files are sufficient input for the linker.
Finally, this makes it simple to implement libraries of pre-compiled
code: just create object files and link them just like any other
object file. (The fact that each file is compiled separately from
information contained in other files, incidentally, is called the
""separate compilation model"".)
To get the full benefits of condition compilation, it's probably
easier to get a program to help you than to try and remember which
files you've changed since you last compiled. (You could, of course,
just recompile every file that has a timestamp greater than the
timestamp of the corresponding object file.) If you're working with an
integrated development environment (IDE) it may already take care of
this for you. If you're using command line tools, there's a nifty
utility called make that comes with most *nix distributions. Along
with conditional compilation, it has several other nice features for
programming, such as allowing different compilations of your program
-- for instance, if you have a version producing verbose output for debugging.
Knowing the difference between the compilation phase and the link
phase can make it easier to hunt for bugs. Compiler errors are usually
syntactic in nature -- a missing semicolon, an extra parenthesis.
Linking errors usually have to do with missing or multiple
definitions. If you get an error that a function or variable is
defined multiple times from the linker, that's a good indication that
the error is that two of your source code files have the same function
or variable.

    GCC compiles a C/C++ program into executable in 4 steps. 

For example, gcc -o hello hello.c is carried out as follows:

1. Pre-processing

Preprocessing via the GNU C Preprocessor (cpp.exe), which includes
    the headers (#include) and expands the macros (#define).


cpp hello.c > hello.i



The resultant intermediate file ""hello.i"" contains the expanded source code.

2. Compilation

The compiler compiles the pre-processed source code into assembly code for a specific processor.


gcc -S hello.i



The -S option specifies to produce assembly code, instead of object code. The resultant assembly file is ""hello.s"".

3. Assembly

The assembler (as.exe) converts the assembly code into machine code in the object file ""hello.o"".


as -o hello.o hello.s



4. Linker

Finally, the linker (ld.exe) links the object code with the library code to produce an executable file ""hello"".



    ld -o hello hello.o ...libraries...


    On the standard front:


a translation unit is the combination of a source files, included headers and source files less any source lines skipped by conditional inclusion preprocessor directive.
the standard defines 9 phases in the translation.  The first four correspond to preprocessing, the next three are the compilation, the next one is the instantiation of templates (producing instantiation units) and the last one is the linking.


In practice the eighth phase (the instantiation of templates) is often done during the compilation process but some compilers delay it to the linking phase and some spread it in the two.
    The skinny is that a CPU loads data from memory addresses, stores data to memory addresses, and execute instructions sequentially out of memory addresses, with some conditional jumps in the sequence of instructions processed. Each of these three categories of instructions involves computing an address to a memory cell to be used in the machine instruction.  Because machine instructions are of a variable length depending on the particular instruction involved, and because we string a variable length of them together as we build our machine code, there is a two step process involved in calculating and building any addresses.

First we laying out the allocation of memory as best we can before we can know what exactly goes in each cell.  We figure out the bytes, or words, or whatever that form the instructions and literals and any data.  We just start allocating memory and building the values that will create the program as we go, and note down anyplace we need to go back and fix an address.  In that place we put a dummy to just pad the location so we can continue to calculate memory size.  For example our first machine code might take one cell.  The next machine code might take 3 cells, involving one machine code cell and two address cells.  Now our address pointer is 4.  We know what goes in the machine cell, which is the op code, but we have to wait to calculate what goes in the address cells till we know where that data will be located, i.e. what will be the machine address of that data.

If there were just one source file a compiler could theoretically produce fully executable machine code without a linker.  In a two pass process it could calculate all of the actual addresses to all of the data cells referenced by any machine load or store instructions.  And it could calculate all of the absolute addresses referenced by any absolute jump instructions.  This is how simpler compilers, like the one in Forth work, with no linker.

A linker is something that allows blocks of code to be compiled separately.  This can speed up the overall process of building code, and allows some flexibility with how the blocks are later used, in other words they can be relocated in memory, for example adding 1000 to every address to scoot the block up by 1000 address cells.

So what the compiler outputs is rough machine code that is not yet fully built, but is laid out so we know the size of everything, in other words so we can start to calculate  where all of the absolute addresses will be located.  the compiler also  outputs a list of symbols which are name/address pairs.  The symbols relate a memory offset in the machine code in the module with a name.  The offset being the absolute distance to the memory location of the symbol in the module.

That's where we get to the linker.  The linker first slaps all of these blocks of machine code together end to end and notes down where each one starts.  Then it calculates the addresses to be fixed by adding together the relative offset within a module and the absolute position of the module in the bigger layout.

Obviously I've oversimplified this so you can try to grasp it, and I have deliberately not used the jargon of object files, symbol tables, etc. which to me is part of the confusion.
    ","[488, 649, 56, 48, 25, 22]",254202,406,2011-06-07T11:04:33,2021-03-26 13:00:39Z,c 
"What's the difference between ""STL"" and ""C++ Standard Library""?","
                
Someone brought this article to my attention that claims (I'm paraphrasing) the STL term is misused to refer to the entire C++ Standard Library instead of the parts that were taken from SGI STL.

(...) it refers to the ""STL"", despite the fact that very few people still use the STL (which was designed at SGI).
Parts of the C++ Standard Library were based on parts of the STL, and it is these parts that many people (including several authors and the notoriously error-ridden cplusplus.com) still refer to as ""the STL"". However, this is inaccurate; indeed, the C++ standard never mentions ""STL"", and there are content differences between the two.
(...) ""STL"" is rarely used to refer to the bits of the stdlib that happen to be based on the SGI STL. People think it's the entire standard library. It gets put on CVs. And it is misleading.

I hardly know anything about C++'s history so I can't judge the article's correctness. Should I refrain from using the term STL? Or is this an isolated opinion?
    The ""STL"" was written by Alexander Stepanov in the days long before C++ was standardised. C++ existed through the 80s, but what we now call ""C++"" is the language standardised in ISO/IEC 14882:2014 (and earlier versions, such as ISO/IEC 14882:2011).

The STL was already widely used as a library for C++, giving programmers access to containers, iterators and algorithms. When the standardisation happened, the language committee designed parts of the C++ Standard Library (which is part of the language standard) to very closely match the STL.

Over the years, many people — including prominent book authors, and various websites — have continued to refer to the C++ Standard Library as ""the STL"", despite the fact that the two entities are separate and that there are some differences. These differences are even more pronounced in the upcoming new C++ standard, which includes various features and significantly alters some classes.

The original STL is now often called ""an implementation of the C++ Standard Template Library"" (rather backwards to actual history!), in the same way that your Microsoft Visual Studio or GCC ships an implementation of the C++ Standard Library. But the ""Standard Template Library"" and the ""Standard Library"" are not the same thing.

The battle is about whether the current Standard Library should be called ""the STL"" in whole or in part, and/or whether it matters what it's called.

For ""STL""

There is a school of thought that says that everybody knows now that ""STL"" means the standard library, just as everybody now knows that ""C++"" is the ISO-standardised language.

It also includes those who believe that it doesn't really matter as long as all parties understand what is being talked about.

It's a term made even more prevalent by the nature of the beast, much of which makes heavy use of the C++ feature known as ""templates"".

For ""C++ Standard Library"" (or stdlib)

However, there is another school of thought — to which I subscribe — that says that this is confusing. People learning C++ for the first time do not know this distinction, and may not notice small language differences.

The author of that article has numerous times encountered people who believe that the entire C++ Standard Library is the STL, including features that were never part of the STL itself. Most vocal proponents of ""the STL"", in contrast, know exactly what they mean by it and refuse to believe that not everybody ""gets it"". Clearly, the term's usage is not uniform.

In addition, there are some STL-like libraries that are in fact implementations of the original STL, not the C++ Standard Library. Until recently, STLPort was one of them (and even there, the confusion abounds!).

Further, the C++ Standard does not contain the text ""STL"" anywhere, and some people habitually employ phrases like ""the STL is included in the C++ Standard Library"", which is plain incorrect. 

It's my belief that continuing to propagate the usage of the term in this way will just lead to the misunderstanding going on forever. Alas, it may be entirely counter-productive to attempt to change things, even if it's supposed to be for the better. We may just be stuck with double-meanings forever.

Conclusion

I appreciate that this post has been a little biased: I wrote the article you linked to. :) Anyway, I hope this helps to explain the battle a bit better.

Update 13/04/2011

Here are three perfect examples of someone who is using ""the STL"" to refer to the entire C++ Standard Library. It continues to baffle me that so many people swear blind that nobody ever does this, when it's plain to see almost on a daily basis.
    There is no one answer that's really correct. Alexander Stepanov developed a library he called STL (working for HP at the time). That library was then proposed for inclusion in the C++ standard.

That basically ""forked"" development. The committee included some parts, rejected others completely, and redesigned a few (with Alexander's participation). Development of the original library was later moved to Silicon Graphics, but continued separately from the C++ standard library.

After those pieces were added to the standard library, some other parts of the standard library were modified to fit better with what was added (e.g., begin, end, rbegin and rend were added to std::string so it could be used like a container). Around the same time, most of the library (even pieces that were completely unrelated) were made into templates to accommodate different types (e.g., standard streams).

Some people also use STL as just a short form of ""STandard Library"".

That means when somebody uses the term ""STL"" they could be referring to any of about half a dozen different things. For better or worse, most people who use it seem to ignore the multiplicity of meanings, and assume that everybody else will recognize what they're referring to. This leads to many misunderstandings, and at least a few serious flame-wars that made most of the participants look foolish because they were simply talking about entirely different things.

Unfortunately, the confusion is likely to continue unabated. It's much more convenient to refer to ""STL"" than something like ""the containers, iterators, and algorithms in the C++ standard library, but not including std::string, even though it can act like a container."" Even though ""C++ standard library"" isn't quite as long and clumsy as that, ""STL"" is still a lot shorter and simpler still. Until or unless somebody invents terms that are more precise (when necessary), and just as convenient, ""STL"" will continue to be used and confusion will continue to result.
    From the GNU Standard C++ Library (libstdc++) FAQ:

The STL (Standard Template Library) was the inspiration for large chunks of the C++ Standard Library, but the terms are not interchangeable and they don't mean the same thing. The C++ Standard Library includes lots of things that didn't come from the STL, and some of them aren't even templates, such as std::locale and std::thread.
Libstdc++-v3 incorporates a lot of code from the SGI STL (the final merge was from release
3.3). The code in libstdc++ contains many fixes and changes compared to the original SGI code.
In particular, string is not from SGI and makes no use of their ""rope"" class (although that is included as an optional extension), neither is valarray nor some others. Classes like vector<> were from SGI, but have been extensively modified.
More information on the evolution of libstdc++ can be found at the API evolution and backwards compatibility documentation.
The FAQ for SGI's STL is still recommended reading.

FYI, as of March 2018 even the official STL web site www.sgi.com/tech/stl/  is gone.
    The term ""STL"" or ""Standard Template Library"" does not show up anywhere in the ISO 14882 C++ standard. So referring to the C++ standard library as STL is wrong. The term ""C++ Standard Library"" or ""standard library"" is what's officially used by ISO 14882:


  ISO 14882 C++ Standard:
  
  17 - Library introduction [lib.library]:
  
  
  This clauses describes the contents of the C++ Standard Library, how
  a well-formed C++ program makes use of
  the library, and how a conforming
  implementation may provide the
  entities in the library.
  
  
  ...


STL is a library originally designed by Alexander Stepanov, independent of the C++ standard. However, some components of the C++ standard library include STL components like vector, list and algorithms like copy and swap.

But of course the C++ standard includes much more things outside the STL, so the term ""C++ standard library"" is more correct (and is what's actually used by the standards documents).
    I've made this same argument recently, but I believe a little tolerance can be allowed. If Scott Meyers makes the same mistake, you're in good company.
    C++ Standard Library includes C++ STL
The contents of the C++ standard library are:

C++ version of C language header file
C++ IO header file
C++ STL

So please don’t confuse the C++ standard library with STL.
    In layman words: STL is part of Standard Library.
C++ Standard Library is group into:

Standard Functional Library
-I/O,
-String and character handling,
-Mathematical,
-Time, date, and localization,
-Dynamic allocation,
-Miscellaneous,
-Wide-character functions

Standard OOP and Generics Library
-The Standard C++ I/O Classes
-The String Class
-The Numeric Classes
-The STL Container Classes
-The STL Algorithms
-The STL Function Objects
-The STL Iterators
-The STL Allocators
-The Localization library
-Exception Handling Classes
-Miscellaneous Support Library


So if you are talking about STL as Standard Library, it is OK and just remember that STL implementations allow for generics and others are more specific to one type.
Please refer to https://www.tutorialspoint.com/cplusplus/cpp_standard_library.htm
    ","[488, 618, 89, 9, 57, 23, -1, -1]",105786,205,2011-03-05T17:32:14,2021-01-25 12:05:05Z,c 
enum to string in modern C++11 / C++14 / C++17 and future C++20,"
                
Contrary to all other similar questions, this question is about using the new C++ features.

2008 c Is there a simple way to convert C++ enum to string?
2008 c Easy way to use variables of enum types as string in C?
2008 c++ How to easily map c++ enums to strings
2008 c++ Making something both a C identifier and a string?
2008 c++ Is there a simple script to convert C++ enum to string?
2009 c++ How to use enums as flags in C++?
2011 c++ How to convert an enum type variable to a string?
2011 c++ Enum to String C++
2011 c++ How to convert an enum type variable to a string?
2012 c How to convert enum names to string in c
2013 c Stringifying an conditionally compiled enum in C

After reading many answers, I did not yet find any:

Elegant way using C++11, C++14 or C++17 new features
Or something ready-to-use in Boost
Else something planned for C++20

Example
An example is often better than a long explanation.
You can compile and run this snippet on Coliru.
(Another former example is also available)
#include <map>
#include <iostream>

struct MyClass
{
    enum class MyEnum : char {
        AAA = -8,
        BBB = '8',
        CCC = AAA + BBB
    };
};

// Replace magic() by some faster compile-time generated code
// (you're allowed to replace the return type with std::string
// if that's easier for you)
const char* magic (MyClass::MyEnum e)
{
    const std::map<MyClass::MyEnum,const char*> MyEnumStrings {
        { MyClass::MyEnum::AAA, ""MyClass::MyEnum::AAA"" },
        { MyClass::MyEnum::BBB, ""MyClass::MyEnum::BBB"" },
        { MyClass::MyEnum::CCC, ""MyClass::MyEnum::CCC"" }
    };
    auto   it  = MyEnumStrings.find(e);
    return it == MyEnumStrings.end() ? ""Out of range"" : it->second;
}

int main()
{
   std::cout << magic(MyClass::MyEnum::AAA) <<'\n';
   std::cout << magic(MyClass::MyEnum::BBB) <<'\n';
   std::cout << magic(MyClass::MyEnum::CCC) <<'\n';
}

Constraints

Please no valueless duplication of other answers or basic link.
Please avoid bloat macro-based answer, or try to reduce the #define overhead as minimum as possible.
Please no manual enum -> string mapping.

Nice to have

Support enum values starting from a number different from zero
Support negative enum values
Support fragmented enum values
Support class enum (C++11)
Support class enum : <type> having any allowed <type> (C++11)
Compile-time (not run-time) conversions to a string,
or at least fast execution at run-time (e.g. std::map is not a great idea...)
constexpr (C++11, then relaxed in C++14/17/20)
noexcept (C++11)
C++17/C++20 friendly snippet

One possible idea could be using the C++ compiler capabilities to generate C++ code at compilation-time using meta-programming tricks based on variadic template class and constexpr functions...
    Magic Enum header-only library provides static reflection for enums (to string, from string, iteration) for C++17.

#include <magic_enum.hpp>

enum Color { RED = 2, BLUE = 4, GREEN = 8 };

Color color = Color::RED;
auto color_name = magic_enum::enum_name(color);
// color_name -> ""RED""

std::string color_name{""GREEN""};
auto color = magic_enum::enum_cast<Color>(color_name)
if (color.has_value()) {
  // color.value() -> Color::GREEN
};


For more examples check home repository https://github.com/Neargye/magic_enum.

Where is the drawback?

This library uses a compiler-specific hack (based on __PRETTY_FUNCTION__ / __FUNCSIG__), which works on Clang >= 5, MSVC >= 15.3 and GCC >= 9.

Enum value must be in range [MAGIC_ENUM_RANGE_MIN, MAGIC_ENUM_RANGE_MAX].


By default MAGIC_ENUM_RANGE_MIN = -128, MAGIC_ENUM_RANGE_MAX = 128.
If need another range for all enum types by default, redefine the macro MAGIC_ENUM_RANGE_MIN and MAGIC_ENUM_RANGE_MAX.
MAGIC_ENUM_RANGE_MIN must be less or equals than 0 and must be greater than INT16_MIN.
MAGIC_ENUM_RANGE_MAX must be greater than 0 and must be less than INT16_MAX.
If need another range for specific enum type, add specialization enum_range for necessary enum type.

#include <magic_enum.hpp>

enum number { one = 100, two = 200, three = 300 };

namespace magic_enum {
template <>
  struct enum_range<number> {
    static constexpr int min = 100;
    static constexpr int max = 300;
};
}


    (The approach of the better_enums library)

There is a way to do enum to string in current C++ that looks like this:

ENUM(Channel, char, Red = 1, Green, Blue)

// ""Same as"":
// enum class Channel : char { Red = 1, Green, Blue };


Usage:

Channel     c = Channel::_from_string(""Green"");  // Channel::Green (2)
c._to_string();                                  // string ""Green""

for (Channel c : Channel::_values())
    std::cout << c << std::endl;

// And so on...


All operations can be made constexpr. You can also implement the C++17 reflection proposal mentioned in the answer by @ecatmur.


There is only one macro. I believe this is the minimum possible, because preprocessor stringization (#) is the only way to convert a token to a string in current C++.
The macro is pretty unobtrusive – the constant declarations, including initializers, are pasted into a built-in enum declaration. This means they have the same syntax and meaning as in a built-in enum.
Repetition is eliminated.
The implementation is most natural and useful in at least C++11, due to constexpr. It can also be made to work with C++98 + __VA_ARGS__. It is definitely modern C++.




The macro's definition is somewhat involved, so I'm answering this in several ways.


The bulk of this answer is an implementation that I think is suitable for the space constraints on StackOverflow.
There is also a CodeProject article describing the basics of the implementation in a long-form tutorial. [Should I move it here? I think it's too much for a SO answer].
There is a full-featured library ""Better Enums"" that implements the macro in a single header file. It also implements N4428 Type Property Queries, the current revision of the C++17 reflection proposal N4113. So, at least for enums declared through this macro, you can have the proposed C++17 enum reflection now, in C++11/C++14.


It is straightforward to extend this answer to the features of the library – nothing ""important"" is left out here. It is, however, quite tedious, and there are compiler portability concerns.

Disclaimer: I am the author of both the CodeProject article and the library.

You can try the code in this answer, the library, and the implementation of N4428 live online in Wandbox. The library documentation also contains an overview of how to use it as N4428, which explains the enums portion of that proposal.



Explanation

The code below implements conversions between enums and strings. However, it can be extended to do other things as well, such as iteration. This answer wraps an enum in a struct. You can also generate a traits struct alongside an enum instead.

The strategy is to generate something like this:

struct Channel {
    enum _enum : char { __VA_ARGS__ };
    constexpr static const Channel          _values[] = { __VA_ARGS__ };
    constexpr static const char * const     _names[] = { #__VA_ARGS__ };

    static const char* _to_string(Channel v) { /* easy */ }
    constexpr static Channel _from_string(const char *s) { /* easy */ }
};


The problems are:


We will end up with something like {Red = 1, Green, Blue} as the initializer for the values array. This is not valid C++, because Red is not an assignable expression. This is solved by casting each constant to a type T that has an assignment operator, but will drop the assignment: {(T)Red = 1, (T)Green, (T)Blue}.
Similarly, we will end up with {""Red = 1"", ""Green"", ""Blue""} as the initializer for the names array. We will need to trim off the "" = 1"". I am not aware of a great way to do this at compile time, so we will defer this to run time. As a result, _to_string won't be constexpr, but _from_string can still be constexpr, because we can treat whitespace and equals signs as terminators when comparing with untrimmed strings.
Both the above need a ""mapping"" macro that can apply another macro to each element in __VA_ARGS__. This is pretty standard. This answer includes a simple version that can handle up to 8 elements.
If the macro is to be truly self-contained, it needs to declare no static data that requires a separate definition. In practice, this means arrays need special treatment. There are two possible solutions: constexpr (or just const) arrays at namespace scope, or regular arrays in non-constexpr static inline functions. The code in this answer is for C++11 and takes the former approach. The CodeProject article is for C++98 and takes the latter.




Code

#include <cstddef>      // For size_t.
#include <cstring>      // For strcspn, strncpy.
#include <stdexcept>    // For runtime_error.



// A ""typical"" mapping macro. MAP(macro, a, b, c, ...) expands to
// macro(a) macro(b) macro(c) ...
// The helper macro COUNT(a, b, c, ...) expands to the number of
// arguments, and IDENTITY(x) is needed to control the order of
// expansion of __VA_ARGS__ on Visual C++ compilers.
#define MAP(macro, ...) \
    IDENTITY( \
        APPLY(CHOOSE_MAP_START, COUNT(__VA_ARGS__)) \
            (macro, __VA_ARGS__))

#define CHOOSE_MAP_START(count) MAP ## count

#define APPLY(macro, ...) IDENTITY(macro(__VA_ARGS__))

#define IDENTITY(x) x

#define MAP1(m, x)      m(x)
#define MAP2(m, x, ...) m(x) IDENTITY(MAP1(m, __VA_ARGS__))
#define MAP3(m, x, ...) m(x) IDENTITY(MAP2(m, __VA_ARGS__))
#define MAP4(m, x, ...) m(x) IDENTITY(MAP3(m, __VA_ARGS__))
#define MAP5(m, x, ...) m(x) IDENTITY(MAP4(m, __VA_ARGS__))
#define MAP6(m, x, ...) m(x) IDENTITY(MAP5(m, __VA_ARGS__))
#define MAP7(m, x, ...) m(x) IDENTITY(MAP6(m, __VA_ARGS__))
#define MAP8(m, x, ...) m(x) IDENTITY(MAP7(m, __VA_ARGS__))

#define EVALUATE_COUNT(_1, _2, _3, _4, _5, _6, _7, _8, count, ...) \
    count

#define COUNT(...) \
    IDENTITY(EVALUATE_COUNT(__VA_ARGS__, 8, 7, 6, 5, 4, 3, 2, 1))



// The type ""T"" mentioned above that drops assignment operations.
template <typename U>
struct ignore_assign {
    constexpr explicit ignore_assign(U value) : _value(value) { }
    constexpr operator U() const { return _value; }

    constexpr const ignore_assign& operator =(int dummy) const
        { return *this; }

    U   _value;
};



// Prepends ""(ignore_assign<_underlying>)"" to each argument.
#define IGNORE_ASSIGN_SINGLE(e) (ignore_assign<_underlying>)e,
#define IGNORE_ASSIGN(...) \
    IDENTITY(MAP(IGNORE_ASSIGN_SINGLE, __VA_ARGS__))

// Stringizes each argument.
#define STRINGIZE_SINGLE(e) #e,
#define STRINGIZE(...) IDENTITY(MAP(STRINGIZE_SINGLE, __VA_ARGS__))



// Some helpers needed for _from_string.
constexpr const char    terminators[] = "" =\t\r\n"";

// The size of terminators includes the implicit '\0'.
constexpr bool is_terminator(char c, size_t index = 0)
{
    return
        index >= sizeof(terminators) ? false :
        c == terminators[index] ? true :
        is_terminator(c, index + 1);
}

constexpr bool matches_untrimmed(const char *untrimmed, const char *s,
                                 size_t index = 0)
{
    return
        is_terminator(untrimmed[index]) ? s[index] == '\0' :
        s[index] != untrimmed[index] ? false :
        matches_untrimmed(untrimmed, s, index + 1);
}



// The macro proper.
//
// There are several ""simplifications"" in this implementation, for the
// sake of brevity. First, we have only one viable option for declaring
// constexpr arrays: at namespace scope. This probably should be done
// two namespaces deep: one namespace that is likely to be unique for
// our little enum ""library"", then inside it a namespace whose name is
// based on the name of the enum to avoid collisions with other enums.
// I am using only one level of nesting.
//
// Declaring constexpr arrays inside the struct is not viable because
// they will need out-of-line definitions, which will result in
// duplicate symbols when linking. This can be solved with weak
// symbols, but that is compiler- and system-specific. It is not
// possible to declare constexpr arrays as static variables in
// constexpr functions due to the restrictions on such functions.
//
// Note that this prevents the use of this macro anywhere except at
// namespace scope. Ironically, the C++98 version of this, which can
// declare static arrays inside static member functions, is actually
// more flexible in this regard. It is shown in the CodeProject
// article.
//
// Second, for compilation performance reasons, it is best to separate
// the macro into a ""parametric"" portion, and the portion that depends
// on knowing __VA_ARGS__, and factor the former out into a template.
//
// Third, this code uses a default parameter in _from_string that may
// be better not exposed in the public interface.

#define ENUM(EnumName, Underlying, ...)                               \
namespace data_ ## EnumName {                                         \
    using _underlying = Underlying;                                   \
    enum { __VA_ARGS__ };                                             \
                                                                      \
    constexpr const size_t           _size =                          \
        IDENTITY(COUNT(__VA_ARGS__));                                 \
                                                                      \
    constexpr const _underlying      _values[] =                      \
        { IDENTITY(IGNORE_ASSIGN(__VA_ARGS__)) };                     \
                                                                      \
    constexpr const char * const     _raw_names[] =                   \
        { IDENTITY(STRINGIZE(__VA_ARGS__)) };                         \
}                                                                     \
                                                                      \
struct EnumName {                                                     \
    using _underlying = Underlying;                                   \
    enum _enum : _underlying { __VA_ARGS__ };                         \
                                                                      \
    const char * _to_string() const                                   \
    {                                                                 \
        for (size_t index = 0; index < data_ ## EnumName::_size;      \
             ++index) {                                               \
                                                                      \
            if (data_ ## EnumName::_values[index] == _value)          \
                return _trimmed_names()[index];                       \
        }                                                             \
                                                                      \
        throw std::runtime_error(""invalid value"");                    \
    }                                                                 \
                                                                      \
    constexpr static EnumName _from_string(const char *s,             \
                                           size_t index = 0)          \
    {                                                                 \
        return                                                        \
            index >= data_ ## EnumName::_size ?                       \
                    throw std::runtime_error(""invalid identifier"") :  \
            matches_untrimmed(                                        \
                data_ ## EnumName::_raw_names[index], s) ?            \
                    (EnumName)(_enum)data_ ## EnumName::_values[      \
                                                            index] :  \
            _from_string(s, index + 1);                               \
    }                                                                 \
                                                                      \
    EnumName() = delete;                                              \
    constexpr EnumName(_enum value) : _value(value) { }               \
    constexpr operator _enum() const { return (_enum)_value; }        \
                                                                      \
  private:                                                            \
    _underlying     _value;                                           \
                                                                      \
    static const char * const * _trimmed_names()                      \
    {                                                                 \
        static char     *the_names[data_ ## EnumName::_size];         \
        static bool     initialized = false;                          \
                                                                      \
        if (!initialized) {                                           \
            for (size_t index = 0; index < data_ ## EnumName::_size;  \
                 ++index) {                                           \
                                                                      \
                size_t  length =                                      \
                    std::strcspn(data_ ## EnumName::_raw_names[index],\
                                 terminators);                        \
                                                                      \
                the_names[index] = new char[length + 1];              \
                                                                      \
                std::strncpy(the_names[index],                        \
                             data_ ## EnumName::_raw_names[index],    \
                             length);                                 \
                the_names[index][length] = '\0';                      \
            }                                                         \
                                                                      \
            initialized = true;                                       \
        }                                                             \
                                                                      \
        return the_names;                                             \
    }                                                                 \
};


and

// The code above was a ""header file"". This is a program that uses it.
#include <iostream>
#include ""the_file_above.h""

ENUM(Channel, char, Red = 1, Green, Blue)

constexpr Channel   channel = Channel::_from_string(""Red"");

int main()
{
    std::cout << channel._to_string() << std::endl;

    switch (channel) {
        case Channel::Red:   return 0;
        case Channel::Green: return 1;
        case Channel::Blue:  return 2;
    }
}

static_assert(sizeof(Channel) == sizeof(char), """");


The program above prints Red, as you would expect. There is a degree of type safety, since you can't create an enum without initializing it, and deleting one of the cases from the switch will result in a warning from the compiler (depending on your compiler and flags). Also, note that ""Red"" was converted to an enum during compilation.
    I don't know if you're going to like this or not, I'm not pretty happy with this solution but it is a C++14 friendly approach because it is using template variables and abusing template specialization:
enum class MyEnum : std::uint_fast8_t {
   AAA,
   BBB,
   CCC,
};

template<MyEnum> const char MyEnumName[] = ""Invalid MyEnum value"";
template<> const char MyEnumName<MyEnum::AAA>[] = ""AAA"";
template<> const char MyEnumName<MyEnum::BBB>[] = ""BBB"";
template<> const char MyEnumName<MyEnum::CCC>[] = ""CCC"";

int main()
{
    // Prints ""AAA""
    std::cout << MyEnumName<MyEnum::AAA> << '\n';
    // Prints ""Invalid MyEnum value""
    std::cout << MyEnumName<static_cast<MyEnum>(0x12345678)> << '\n';
    // Well... in fact it prints ""Invalid MyEnum value"" for any value
    // different of MyEnum::AAA, MyEnum::BBB or MyEnum::CCC.

    return 0;
}

The worst about this approach is that is a pain to maintain, but it is also a pain to maintain some of other similar aproaches, aren't they?
Good points about this aproach:

Using variable tempates (C++14 feature)
With template specialization we can ""detect"" when an invalid value is used (but I'm not sure if this could be useful at all).
It looks neat.
The name lookup is done at compile time.

Live example
Edit
Misterious user673679 you're right; the C++14 variable template approach doesn't handles the runtime case, it was my fault to forget it :(
But we can still use some modern C++ features and variable template plus variadic template trickery to achieve a runtime translation from enum value to string... it is as bothersome as the others but still worth to mention.
Let's start using a template alias to shorten the access to a enum-to-string map:
// enum_map contains pairs of enum value and value string for each enum
// this shortcut allows us to use enum_map<whatever>.
template <typename ENUM>
using enum_map = std::map<ENUM, const std::string>;

// This variable template will create a map for each enum type which is
// instantiated with.
template <typename ENUM>
enum_map<ENUM> enum_values{};

Then, the variadic template trickery:
template <typename ENUM>
void initialize() {}

template <typename ENUM, typename ... args>
void initialize(const ENUM value, const char *name, args ... tail)
{
    enum_values<ENUM>.emplace(value, name);
    initialize<ENUM>(tail ...);
}

The ""best trick"" here is the use of variable template for the map which contains the values and names of each enum entry; this map will be the same in each translation unit and have the same name everywhere so is pretty straightforward and neat, if we call the initialize function like this:
initialize
(
    MyEnum::AAA, ""AAA"",
    MyEnum::BBB, ""BBB"",
    MyEnum::CCC, ""CCC""
);

We are asigning names to each MyEnum entry and can be used in runtime:
std::cout << enum_values<MyEnum>[MyEnum::AAA] << '\n';

But can be improved with SFINAE and overloading << operator:
template<typename ENUM, class = typename std::enable_if<std::is_enum<ENUM>::value>::type>
std::ostream &operator <<(std::ostream &o, const ENUM value)
{
    static const std::string Unknown{std::string{typeid(ENUM).name()} + "" unknown value""};
    auto found = enum_values<ENUM>.find(value);

    return o << (found == enum_values<ENUM>.end() ? Unknown : found->second);
}

With the correct operator << now we can use the enum this way:
std::cout << MyEnum::AAA << '\n';

This is also bothersome to maintain and can be improved, but hope you get the idea.
Live example
    Back in 2011 I spent a weekend fine-tuning a macro-based solution and ended up never using it.

My current procedure is to start Vim, copy the enumerators in an empty switch body, start a new macro, transform the first enumerator into a case statement, move the cursor to the beginning of the next line, stop the macro and generate the remaining case statements by running the macro on the other enumerators. 

Vim macros are more fun than C++ macros.

Real-life example:

enum class EtherType : uint16_t
{
    ARP   = 0x0806,
    IPv4  = 0x0800,
    VLAN  = 0x8100,
    IPv6  = 0x86DD
};


I will create this:

std::ostream& operator<< (std::ostream& os, EtherType ethertype)
{
    switch (ethertype)
    {
        case EtherType::ARP : return os << ""ARP"" ;
        case EtherType::IPv4: return os << ""IPv4"";
        case EtherType::VLAN: return os << ""VLAN"";
        case EtherType::IPv6: return os << ""IPv6"";
        // omit default case to trigger compiler warning for missing cases
    };
    return os << static_cast<std::uint16_t>(ethertype);
}


And that's how I get by.

Native support for enum stringification would be much better though. I'm very interested to see the results of the reflection workgroup in C++17.

An alternative way to do it was posted by @sehe in the comments.
    For C++17 C++20, you will be interested in the work of the Reflection Study Group (SG7). There is a parallel series of papers covering wording (P0194) and rationale, design and evolution (P0385). (Links resolve to the latest paper in each series.)

As of P0194r2 (2016-10-15), the syntax would use the proposed reflexpr keyword:

meta::get_base_name_v<
  meta::get_element_m<
    meta::get_enumerators_m<reflexpr(MyEnum)>,
    0>
  >


For example (adapted from Matus Choclik's reflexpr branch of clang):

#include <reflexpr>
#include <iostream>

enum MyEnum { AAA = 1, BBB, CCC = 99 };

int main()
{
  auto name_of_MyEnum_0 = 
    std::meta::get_base_name_v<
      std::meta::get_element_m<
        std::meta::get_enumerators_m<reflexpr(MyEnum)>,
        0>
    >;

  // prints ""AAA""
  std::cout << name_of_MyEnum_0 << std::endl;
}


Static reflection failed to make it into C++17 (rather, into the probably-final draft presented at the November 2016 standards meeting in Issaquah) but there is confidence that it will make it into C++20; from Herb Sutter's trip report:


  In particular, the Reflection study group reviewed the latest merged static reflection proposal and found it ready to enter the main Evolution groups at our next meeting to start considering the unified static reflection proposal for a TS or for the next standard.

    This is similar to Yuri Finkelstein; but does not required boost. I am using a map so you can assign any value to the enums, any order.

Declaration of enum class as:

DECLARE_ENUM_WITH_TYPE(TestEnumClass, int32_t, ZERO = 0x00, TWO = 0x02, ONE = 0x01, THREE = 0x03, FOUR);


The following code will automatically create the enum class and overload:


'+' '+=' for std::string
'<<' for streams
'~' just to convert to string (Any unary operator will do, but I personally don't like it for clarity)
'*' to get the count of enums


No boost required, all required functions provided.

Code:

#include <algorithm>
#include <iostream>
#include <map>
#include <sstream>
#include <string>
#include <vector>

#define STRING_REMOVE_CHAR(str, ch) str.erase(std::remove(str.begin(), str.end(), ch), str.end())

std::vector<std::string> splitString(std::string str, char sep = ',') {
    std::vector<std::string> vecString;
    std::string item;

    std::stringstream stringStream(str);

    while (std::getline(stringStream, item, sep))
    {
        vecString.push_back(item);
    }

    return vecString;
}

#define DECLARE_ENUM_WITH_TYPE(E, T, ...)                                                                     \
    enum class E : T                                                                                          \
    {                                                                                                         \
        __VA_ARGS__                                                                                           \
    };                                                                                                        \
    std::map<T, std::string> E##MapName(generateEnumMap<T>(#__VA_ARGS__));                                    \
    std::ostream &operator<<(std::ostream &os, E enumTmp)                                                     \
    {                                                                                                         \
        os << E##MapName[static_cast<T>(enumTmp)];                                                            \
        return os;                                                                                            \
    }                                                                                                         \
    size_t operator*(E enumTmp) { (void) enumTmp; return E##MapName.size(); }                                 \
    std::string operator~(E enumTmp) { return E##MapName[static_cast<T>(enumTmp)]; }                          \
    std::string operator+(std::string &&str, E enumTmp) { return str + E##MapName[static_cast<T>(enumTmp)]; } \
    std::string operator+(E enumTmp, std::string &&str) { return E##MapName[static_cast<T>(enumTmp)] + str; } \
    std::string &operator+=(std::string &str, E enumTmp)                                                      \
    {                                                                                                         \
        str += E##MapName[static_cast<T>(enumTmp)];                                                           \
        return str;                                                                                           \
    }                                                                                                         \
    E operator++(E &enumTmp)                                                                                  \
    {                                                                                                         \
        auto iter = E##MapName.find(static_cast<T>(enumTmp));                                                 \
        if (iter == E##MapName.end() || std::next(iter) == E##MapName.end())                                  \
            iter = E##MapName.begin();                                                                        \
        else                                                                                                  \
        {                                                                                                     \
            ++iter;                                                                                           \
        }                                                                                                     \
        enumTmp = static_cast<E>(iter->first);                                                                \
        return enumTmp;                                                                                       \
    }                                                                                                         \
    bool valid##E(T value) { return (E##MapName.find(value) != E##MapName.end()); }

#define DECLARE_ENUM(E, ...) DECLARE_ENUM_WITH_TYPE(E, int32_t, __VA_ARGS__)
template <typename T>
std::map<T, std::string> generateEnumMap(std::string strMap)
{
    STRING_REMOVE_CHAR(strMap, ' ');
    STRING_REMOVE_CHAR(strMap, '(');

    std::vector<std::string> enumTokens(splitString(strMap));
    std::map<T, std::string> retMap;
    T inxMap;

    inxMap = 0;
    for (auto iter = enumTokens.begin(); iter != enumTokens.end(); ++iter)
    {
        // Token: [EnumName | EnumName=EnumValue]
        std::string enumName;
        T enumValue;
        if (iter->find('=') == std::string::npos)
        {
            enumName = *iter;
        }
        else
        {
            std::vector<std::string> enumNameValue(splitString(*iter, '='));
            enumName = enumNameValue[0];
            //inxMap = static_cast<T>(enumNameValue[1]);
            if (std::is_unsigned<T>::value)
            {
                inxMap = static_cast<T>(std::stoull(enumNameValue[1], 0, 0));
            }
            else
            {
                inxMap = static_cast<T>(std::stoll(enumNameValue[1], 0, 0));
            }
        }
        retMap[inxMap++] = enumName;
    }

    return retMap;
}


Example:

DECLARE_ENUM_WITH_TYPE(TestEnumClass, int32_t, ZERO = 0x00, TWO = 0x02, ONE = 0x01, THREE = 0x03, FOUR);

int main(void) {
    TestEnumClass first, second;
    first = TestEnumClass::FOUR;
    second = TestEnumClass::TWO;

    std::cout << first << ""("" << static_cast<uint32_t>(first) << "")"" << std::endl; // FOUR(4)

    std::string strOne;
    strOne = ~first;
    std::cout << strOne << std::endl; // FOUR

    std::string strTwo;
    strTwo = (""Enum-"" + second) + (TestEnumClass::THREE + ""-test"");
    std::cout << strTwo << std::endl; // Enum-TWOTHREE-test

    std::string strThree(""TestEnumClass: "");
    strThree += second;
    std::cout << strThree << std::endl; // TestEnumClass: TWO
    std::cout << ""Enum count="" << *first << std::endl;
}


You can run the code here
    My solution, using a preprocessor define.
You can check this code on https://repl.it/@JomaCorpFX/nameof#main.cpp
#include <iostream>
#include <stdexcept>
#include <regex>

typedef std::string String;
using namespace std::literals::string_literals;

class Strings
{
public:
    static String TrimStart(const std::string& data)
    {
        String s = data;
        s.erase(s.begin(), std::find_if(s.begin(), s.end(), [](unsigned char ch) {
            return !std::isspace(ch);
        }));
        return s;
    }

    static String TrimEnd(const std::string& data)
    {
        String s = data;
        s.erase(std::find_if(s.rbegin(), s.rend(), [](unsigned char ch) {
            return !std::isspace(ch);
        }).base(),
            s.end());
        return s;
    }

    static String Trim(const std::string& data)
    {
        return TrimEnd(TrimStart(data));
    }

    static String Replace(const String& data, const String& toFind, const String& toReplace)
    {
        String result = data;
        size_t pos = 0;
        while ((pos = result.find(toFind, pos)) != String::npos)
        {
            result.replace(pos, toFind.length(), toReplace);
            pos += toReplace.length();
            pos = result.find(toFind, pos);
        }
        return result;
    }

};

static String Nameof(const String& name)
{
    std::smatch groups;
    String str = Strings::Trim(name);
    if (std::regex_match(str, groups, std::regex(u8R""(^&?([_a-zA-Z]\w*(->|\.|::))*([_a-zA-Z]\w*)$)"")))
    {
        if (groups.size() == 4)
        {
            return groups[3];
        }
    }
    throw std::invalid_argument(Strings::Replace(u8R""(nameof(#). Invalid identifier ""#"".)"", u8""#"", name));
}

#define nameof(name) Nameof(u8## #name ## s)
#define cnameof(name) Nameof(u8## #name ## s).c_str()

enum TokenType {
    COMMA,
    PERIOD,
    Q_MARK
};

struct MyClass
{
    enum class MyEnum : char {
        AAA = -8,
        BBB = '8',
        CCC = AAA + BBB
    };
};

int main() {
    String greetings = u8""Hello""s;
    std::cout << nameof(COMMA) << std::endl;
    std::cout << nameof(TokenType::PERIOD) << std::endl;
    std::cout << nameof(TokenType::Q_MARK) << std::endl;
    std::cout << nameof(int) << std::endl;
    std::cout << nameof(std::string) << std::endl;
    std::cout << nameof(Strings) << std::endl;
    std::cout << nameof(String) << std::endl;
    std::cout << nameof(greetings) << std::endl;
    std::cout << nameof(&greetings) << std::endl;
    std::cout << nameof(greetings.c_str) << std::endl;
    std::cout << nameof(std::string::npos) << std::endl;
    std::cout << nameof(MyClass::MyEnum::AAA) << std::endl;
    std::cout << nameof(MyClass::MyEnum::BBB) << std::endl;
    std::cout << nameof(MyClass::MyEnum::CCC) << std::endl;


    std::cin.get();
    return 0;
}

Output
COMMA
PERIOD
Q_MARK
int
string
Strings
String
greetings
greetings
c_str
npos
AAA
BBB
CCC

Clang

Visual C++

    I have been frustrated by this problem for a long time too, along with the problem of getting a type converted to string in a proper way. However, for the last problem, I was surprised by the solution explained in Is it possible to print a variable's type in standard C++?, using the idea from Can I obtain C++ type names in a constexpr way?. Using this technique, an analogous function can be constructed for getting an enum value as string:

#include <iostream>
using namespace std;

class static_string
{
    const char* const p_;
    const std::size_t sz_;

public:
    typedef const char* const_iterator;

    template <std::size_t N>
    constexpr static_string(const char(&a)[N]) noexcept
        : p_(a)
        , sz_(N - 1)
    {}

    constexpr static_string(const char* p, std::size_t N) noexcept
        : p_(p)
        , sz_(N)
    {}

    constexpr const char* data() const noexcept { return p_; }
    constexpr std::size_t size() const noexcept { return sz_; }

    constexpr const_iterator begin() const noexcept { return p_; }
    constexpr const_iterator end()   const noexcept { return p_ + sz_; }

    constexpr char operator[](std::size_t n) const
    {
        return n < sz_ ? p_[n] : throw std::out_of_range(""static_string"");
    }
};

inline std::ostream& operator<<(std::ostream& os, static_string const& s)
{
    return os.write(s.data(), s.size());
}

/// \brief Get the name of a type
template <class T>
static_string typeName()
{
#ifdef __clang__
    static_string p = __PRETTY_FUNCTION__;
    return static_string(p.data() + 30, p.size() - 30 - 1);
#elif defined(_MSC_VER)
    static_string p = __FUNCSIG__;
    return static_string(p.data() + 37, p.size() - 37 - 7);
#endif

}

namespace details
{
    template <class Enum>
    struct EnumWrapper
    {
        template < Enum enu >
        static static_string name()
        {
#ifdef __clang__
            static_string p = __PRETTY_FUNCTION__;
            static_string enumType = typeName<Enum>();
            return static_string(p.data() + 73 + enumType.size(), p.size() - 73 - enumType.size() - 1);
#elif defined(_MSC_VER)
            static_string p = __FUNCSIG__;
            static_string enumType = typeName<Enum>();
            return static_string(p.data() + 57 + enumType.size(), p.size() - 57 - enumType.size() - 7);
#endif
        }
    };
}

/// \brief Get the name of an enum value
template <typename Enum, Enum enu>
static_string enumName()
{
    return details::EnumWrapper<Enum>::template name<enu>();
}

enum class Color
{
    Blue = 0,
    Yellow = 1
};


int main() 
{
    std::cout << ""_"" << typeName<Color>() << ""_""  << std::endl;
    std::cout << ""_"" << enumName<Color, Color::Blue>() << ""_""  << std::endl;
    return 0;
}


The code above has only been tested on Clang (see https://ideone.com/je5Quv) and VS2015, but should be adaptable to other compilers by fiddling a bit with the integer constants. Of course, it still uses macros under the hood, but at least one doesn't need access to the enum implementation.
    Very simple solution with one big constraint: you can't assign custom values to enum values, but with the right regex, you could. you could also add a map to translate them back to enum values without much more effort:

#include <vector>
#include <string>
#include <regex>
#include <iterator>

std::vector<std::string> split(const std::string& s, 
                               const std::regex& delim = std::regex("",\\s*""))
{
    using namespace std;
    vector<string> cont;
    copy(regex_token_iterator<string::const_iterator>(s.begin(), s.end(), delim, -1), 
         regex_token_iterator<string::const_iterator>(),
         back_inserter(cont));
    return cont;
}

#define EnumType(Type, ...)     enum class Type { __VA_ARGS__ }

#define EnumStrings(Type, ...)  static const std::vector<std::string> \
                                Type##Strings = split(#__VA_ARGS__);

#define EnumToString(Type, ...) EnumType(Type, __VA_ARGS__); \
                                EnumStrings(Type, __VA_ARGS__)


Usage example:

EnumToString(MyEnum, Red, Green, Blue);

    I took the idea from @antron and implemented it differently: generating a true enum class. 

This implementation meets all the requirements listed in original question but currently has only one real limitation: it assumes the enum values are either not provided or, if provided, must start with 0 and go up sequentially without gaps. 

This is not an intrinsic limitation - simply that I don't use ad-hoc enum values. If this is needed, one can replace vector lookup with traditional switch/case implementation. 

The solution uses some c++17 for inline variables but this can be easily avoided if needed. It also uses boost:trim because of simplicity. 

Most importantly, it takes only 30 lines of code and no black magic macros.
The code is below. It's meant to be put in header and included in multiple compilation modules.

It can be used the same way as was suggested earlier in this thread:

ENUM(Channel, int, Red, Green = 1, Blue)
std::out << ""My name is "" << Channel::Green;
//prints My name is Green


Pls let me know if this is useful and how it can be improved further.



#include <boost/algorithm/string.hpp>   
struct EnumSupportBase {
  static std::vector<std::string> split(const std::string s, char delim) {
    std::stringstream ss(s);
    std::string item;
    std::vector<std::string> tokens;
    while (std::getline(ss, item, delim)) {
        auto pos = item.find_first_of ('=');
        if (pos != std::string::npos)
            item.erase (pos);
        boost::trim (item);
        tokens.push_back(item);
    }
    return tokens;
  }
};
#define ENUM(EnumName, Underlying, ...) \
    enum class EnumName : Underlying { __VA_ARGS__, _count }; \
    struct EnumName ## Support : EnumSupportBase { \
        static inline std::vector<std::string> _token_names = split(#__VA_ARGS__, ','); \
        static constexpr const char* get_name(EnumName enum_value) { \
            int index = (int)enum_value; \
            if (index >= (int)EnumName::_count || index < 0) \
               return ""???""; \
            else \
               return _token_names[index].c_str(); \
        } \
    }; \
    inline std::ostream& operator<<(std::ostream& os, const EnumName & es) { \
        return os << EnumName##Support::get_name(es); \
    } 

    If your enum looks  like

enum MyEnum
{
  AAA = -8,
  BBB = '8',
  CCC = AAA + BBB
};


You can move the content of the enum to a new file:

AAA = -8,
BBB = '8',
CCC = AAA + BBB


And then the values can be surrounded by a macro:

// default definition
#ifned ITEM(X,Y)
#define ITEM(X,Y)
#endif

// Items list
ITEM(AAA,-8)
ITEM(BBB,'8')
ITEM(CCC,AAA+BBB)

// clean up
#undef ITEM


Next step may be include the items in the enum again:

enum MyEnum
{
  #define ITEM(X,Y) X=Y,
  #include ""enum_definition_file""
};


And finally you can generate utility functions about this enum:

std::string ToString(MyEnum value)
{
  switch( value )
  {
    #define ITEM(X,Y) case X: return #X;
    #include ""enum_definition_file""
  }

  return """";
}

MyEnum FromString(std::string const& value)
{
  static std::map<std::string,MyEnum> converter
  {
    #define ITEM(X,Y) { #X, X },
    #include ""enum_definition_file""
  };

  auto it = converter.find(value);
  if( it != converter.end() )
    return it->second;
  else
    throw std::runtime_error(""Value is missing"");
}


The solution can be applied to older C++ standards and it does not use modern C++ elements but it can be used to generate lot of code without too much effort and maintenance.
    You can abuse user-defined literals to achieve the desired result:
enum
{
  AAA = ""AAA""_h8,
  BB = ""BB""_h8,
};
   
std::cout << h8::to_string(AAA) << std::endl;
std::cout << h8::to_string(BB) << std::endl;

This packs a string into an integer, which is reversible. Check out the example here.
    I had the same problem a couple of days ago. I couldn't find any C++ solution without some weird macro magic, so I decided to write a CMake code generator to generate simple switch case statements.

Usage:

enum2str_generate(
  PATH          <path to place the files in>
  CLASS_NAME    <name of the class (also prefix for the files)>
  FUNC_NAME     <name of the (static) member function>
  NAMESPACE     <the class will be inside this namespace>
  INCLUDES      <LIST of files where the enums are defined>
  ENUMS         <LIST of enums to process>
  BLACKLIST     <LIST of constants to ignore>
  USE_CONSTEXPR <whether to use constexpr or not (default: off)>
  USE_C_STRINGS <whether to use c strings instead of std::string or not (default: off)>
)


The function searches the include files in the filesystem (uses the include directories provided with the include_directories command), reads them and does some regex to generate the class and the function(s).

NOTE: constexpr implies inline in C++, so using the USE_CONSTEXPR option will generate a header only class!

Example:

./includes/a.h:

enum AAA : char { A1, A2 };

typedef enum {
   VAL1          = 0,
   VAL2          = 1,
   VAL3          = 2,
   VAL_FIRST     = VAL1,    // Ignored
   VAL_LAST      = VAL3,    // Ignored
   VAL_DUPLICATE = 1,       // Ignored
   VAL_STRANGE   = VAL2 + 1 // Must be blacklisted
} BBB;


./CMakeLists.txt:

include_directories( ${PROJECT_SOURCE_DIR}/includes ...)

enum2str_generate(
   PATH       ""${PROJECT_SOURCE_DIR}""
   CLASS_NAME ""enum2Str""
   NAMESPACE  ""abc""
   FUNC_NAME  ""toStr""
   INCLUDES   ""a.h"" # WITHOUT directory
   ENUMS      ""AAA"" ""BBB""
   BLACKLIST  ""VAL_STRANGE"")


Generates:

./enum2Str.hpp:

/*!
  * \file enum2Str.hpp
  * \warning This is an automatically generated file!
  */

#ifndef ENUM2STR_HPP
#define ENUM2STR_HPP

#include <string>
#include <a.h>

namespace abc {

class enum2Str {
 public:
   static std::string toStr( AAA _var ) noexcept;
   static std::string toStr( BBB _var ) noexcept;
};

}

#endif // ENUM2STR_HPP


./enum2Str.cpp:

/*!
  * \file enum2Str.cpp
  * \warning This is an automatically generated file!
  */

#include ""enum2Str.hpp""

namespace abc {

/*!
 * \brief Converts the enum AAA to a std::string
 * \param _var The enum value to convert
 * \returns _var converted to a std::string
 */
std::string enum2Str::toStr( AAA _var ) noexcept {
   switch ( _var ) {
      case A1: return ""A1"";
      case A2: return ""A2"";
      default: return ""<UNKNOWN>"";
   }
}

/*!
 * \brief Converts the enum BBB to a std::string
 * \param _var The enum value to convert
 * \returns _var converted to a std::string
 */
std::string enum2Str::toStr( BBB _var ) noexcept {
   switch ( _var ) {
      case VAL1: return ""VAL1"";
      case VAL2: return ""VAL2"";
      case VAL3: return ""VAL3"";
      default: return ""<UNKNOWN>"";
   }
}
}


Update:

The script now also supports scoped enumerations (enum class|struct) and
I moved it to a seperate repo with some other scripts I often use: https://github.com/mensinda/cmakeBuildTools
    As per request from the OP, here a stripped down version of the ugly macro solution based on Boost Preprosessor and Variadic Macros. 

It allows for a simple list like syntax of the enumerator elements along with setting values for specific elements so that

XXX_ENUM(foo,(a,b,(c,42)));


expands to

enum foo {
    a,
    b,
    c=42
};


Alongside with the necessary functions to output and do some conversion back. This macro has been around here for ages, and I am not totally sure that its the most efficient way, or that it is a conforming way, but it has ever since been working

The complete code can be seen in action at both Ideone and Coliru. 

Its gargantuan ugliness is above; I would have put it behind spoilers to protect your eyes, if I knew how, but markdown doesn't like me.

The library (merged within one single header file)

#include <boost/preprocessor.hpp>
#include <string>
#include <unordered_map>

namespace xxx
{

template<class T>
struct enum_cast_adl_helper { };

template<class E>
E enum_cast( const std::string& s )
{
    return do_enum_cast(s,enum_cast_adl_helper<E>());
}

template<class E>
E enum_cast( const char* cs )
{
    std::string s(cs);
    return enum_cast<E>(s);
}

} // namespace xxx

#define XXX_PP_ARG_N(                             \
          _1, _2, _3, _4, _5, _6, _7, _8, _9,_10, \
         _11,_12,_13,_14,_15,_16,_17,_18,_19,_20, \
         _21,_22,_23,_24,_25,_26,_27,_28,_29,_30, \
         _31,_32,_33,_34,_35,_36,_37,_38,_39,_40, \
         _41,_42,_43,_44,_45,_46,_47,_48,_49,_50, \
         _51,_52,_53,_54,_55,_56,_57,_58,_59,_60, \
         _61,_62,_63,N,...) N

#define XXX_PP_RSEQ_N()                 \
         63,62,61,60,                   \
         59,58,57,56,55,54,53,52,51,50, \
         49,48,47,46,45,44,43,42,41,40, \
         39,38,37,36,35,34,33,32,31,30, \
         29,28,27,26,25,24,23,22,21,20, \
         19,18,17,16,15,14,13,12,11,10, \
         9,8,7,6,5,4,3,2,1,0 

#define XXX_PP_NARG_(...) XXX_PP_ARG_N(__VA_ARGS__)
#define XXX_PP_NARG(...)  XXX_PP_NARG_(__VA_ARGS__,XXX_PP_RSEQ_N())
#define XXX_TUPLE_SIZE_INTERNAL(TUPLE) XXX_PP_NARG TUPLE

#define XXX_TUPLE_CHOICE(i)                            \
  BOOST_PP_APPLY(                                      \
    BOOST_PP_TUPLE_ELEM(                               \
      25, i, (                                         \
        (0), (1), (2), (3), (4), (5), (6), (7), (8),   \
        (9), (10), (11), (12), (13), (14), (15), (16), \
        (17), (18), (19), (20), (21), (22), (23), (24) \
  ) ) )

#define BOOST_PP_BOOL_00  BOOST_PP_BOOL_0
#define BOOST_PP_BOOL_01  BOOST_PP_BOOL_1
#define BOOST_PP_BOOL_02  BOOST_PP_BOOL_2
#define BOOST_PP_BOOL_03  BOOST_PP_BOOL_3
#define BOOST_PP_BOOL_04  BOOST_PP_BOOL_4
#define BOOST_PP_BOOL_05  BOOST_PP_BOOL_5
#define BOOST_PP_BOOL_06  BOOST_PP_BOOL_6
#define BOOST_PP_BOOL_07  BOOST_PP_BOOL_7
#define BOOST_PP_BOOL_08  BOOST_PP_BOOL_8
#define BOOST_PP_BOOL_09  BOOST_PP_BOOL_9
#define BOOST_PP_BOOL_010 BOOST_PP_BOOL_10
#define BOOST_PP_BOOL_011 BOOST_PP_BOOL_11
#define BOOST_PP_BOOL_012 BOOST_PP_BOOL_12
#define BOOST_PP_BOOL_013 BOOST_PP_BOOL_13
#define BOOST_PP_BOOL_014 BOOST_PP_BOOL_14
#define BOOST_PP_BOOL_015 BOOST_PP_BOOL_15
#define BOOST_PP_BOOL_016 BOOST_PP_BOOL_16
#define BOOST_PP_BOOL_017 BOOST_PP_BOOL_17
#define BOOST_PP_BOOL_018 BOOST_PP_BOOL_18
#define BOOST_PP_BOOL_019 BOOST_PP_BOOL_19
#define BOOST_PP_BOOL_020 BOOST_PP_BOOL_20
#define BOOST_PP_BOOL_021 BOOST_PP_BOOL_21
#define BOOST_PP_BOOL_022 BOOST_PP_BOOL_22
#define BOOST_PP_BOOL_023 BOOST_PP_BOOL_23
#define BOOST_PP_BOOL_024 BOOST_PP_BOOL_24
#define BOOST_PP_BOOL_025 BOOST_PP_BOOL_25
#define BOOST_PP_BOOL_026 BOOST_PP_BOOL_26
#define BOOST_PP_BOOL_027 BOOST_PP_BOOL_27
#define BOOST_PP_BOOL_028 BOOST_PP_BOOL_28
#define BOOST_PP_BOOL_029 BOOST_PP_BOOL_29
#define BOOST_PP_BOOL_030 BOOST_PP_BOOL_30
#define BOOST_PP_BOOL_031 BOOST_PP_BOOL_31
#define BOOST_PP_BOOL_032 BOOST_PP_BOOL_32
#define BOOST_PP_BOOL_033 BOOST_PP_BOOL_33
#define BOOST_PP_BOOL_034 BOOST_PP_BOOL_34
#define BOOST_PP_BOOL_035 BOOST_PP_BOOL_35
#define BOOST_PP_BOOL_036 BOOST_PP_BOOL_36
#define BOOST_PP_BOOL_037 BOOST_PP_BOOL_37
#define BOOST_PP_BOOL_038 BOOST_PP_BOOL_38
#define BOOST_PP_BOOL_039 BOOST_PP_BOOL_39
#define BOOST_PP_BOOL_040 BOOST_PP_BOOL_40
#define BOOST_PP_BOOL_041 BOOST_PP_BOOL_41
#define BOOST_PP_BOOL_042 BOOST_PP_BOOL_42
#define BOOST_PP_BOOL_043 BOOST_PP_BOOL_43
#define BOOST_PP_BOOL_044 BOOST_PP_BOOL_44
#define BOOST_PP_BOOL_045 BOOST_PP_BOOL_45
#define BOOST_PP_BOOL_046 BOOST_PP_BOOL_46
#define BOOST_PP_BOOL_047 BOOST_PP_BOOL_47
#define BOOST_PP_BOOL_048 BOOST_PP_BOOL_48
#define BOOST_PP_BOOL_049 BOOST_PP_BOOL_49
#define BOOST_PP_BOOL_050 BOOST_PP_BOOL_50
#define BOOST_PP_BOOL_051 BOOST_PP_BOOL_51
#define BOOST_PP_BOOL_052 BOOST_PP_BOOL_52
#define BOOST_PP_BOOL_053 BOOST_PP_BOOL_53
#define BOOST_PP_BOOL_054 BOOST_PP_BOOL_54
#define BOOST_PP_BOOL_055 BOOST_PP_BOOL_55
#define BOOST_PP_BOOL_056 BOOST_PP_BOOL_56
#define BOOST_PP_BOOL_057 BOOST_PP_BOOL_57
#define BOOST_PP_BOOL_058 BOOST_PP_BOOL_58
#define BOOST_PP_BOOL_059 BOOST_PP_BOOL_59
#define BOOST_PP_BOOL_060 BOOST_PP_BOOL_60
#define BOOST_PP_BOOL_061 BOOST_PP_BOOL_61
#define BOOST_PP_BOOL_062 BOOST_PP_BOOL_62
#define BOOST_PP_BOOL_063 BOOST_PP_BOOL_63

#define BOOST_PP_DEC_00  BOOST_PP_DEC_0
#define BOOST_PP_DEC_01  BOOST_PP_DEC_1
#define BOOST_PP_DEC_02  BOOST_PP_DEC_2
#define BOOST_PP_DEC_03  BOOST_PP_DEC_3
#define BOOST_PP_DEC_04  BOOST_PP_DEC_4
#define BOOST_PP_DEC_05  BOOST_PP_DEC_5
#define BOOST_PP_DEC_06  BOOST_PP_DEC_6
#define BOOST_PP_DEC_07  BOOST_PP_DEC_7
#define BOOST_PP_DEC_08  BOOST_PP_DEC_8
#define BOOST_PP_DEC_09  BOOST_PP_DEC_9
#define BOOST_PP_DEC_010 BOOST_PP_DEC_10
#define BOOST_PP_DEC_011 BOOST_PP_DEC_11
#define BOOST_PP_DEC_012 BOOST_PP_DEC_12
#define BOOST_PP_DEC_013 BOOST_PP_DEC_13
#define BOOST_PP_DEC_014 BOOST_PP_DEC_14
#define BOOST_PP_DEC_015 BOOST_PP_DEC_15
#define BOOST_PP_DEC_016 BOOST_PP_DEC_16
#define BOOST_PP_DEC_017 BOOST_PP_DEC_17
#define BOOST_PP_DEC_018 BOOST_PP_DEC_18
#define BOOST_PP_DEC_019 BOOST_PP_DEC_19
#define BOOST_PP_DEC_020 BOOST_PP_DEC_20
#define BOOST_PP_DEC_021 BOOST_PP_DEC_21
#define BOOST_PP_DEC_022 BOOST_PP_DEC_22
#define BOOST_PP_DEC_023 BOOST_PP_DEC_23
#define BOOST_PP_DEC_024 BOOST_PP_DEC_24
#define BOOST_PP_DEC_025 BOOST_PP_DEC_25
#define BOOST_PP_DEC_026 BOOST_PP_DEC_26
#define BOOST_PP_DEC_027 BOOST_PP_DEC_27
#define BOOST_PP_DEC_028 BOOST_PP_DEC_28
#define BOOST_PP_DEC_029 BOOST_PP_DEC_29
#define BOOST_PP_DEC_030 BOOST_PP_DEC_30
#define BOOST_PP_DEC_031 BOOST_PP_DEC_31
#define BOOST_PP_DEC_032 BOOST_PP_DEC_32
#define BOOST_PP_DEC_033 BOOST_PP_DEC_33
#define BOOST_PP_DEC_034 BOOST_PP_DEC_34
#define BOOST_PP_DEC_035 BOOST_PP_DEC_35
#define BOOST_PP_DEC_036 BOOST_PP_DEC_36
#define BOOST_PP_DEC_037 BOOST_PP_DEC_37
#define BOOST_PP_DEC_038 BOOST_PP_DEC_38
#define BOOST_PP_DEC_039 BOOST_PP_DEC_39
#define BOOST_PP_DEC_040 BOOST_PP_DEC_40
#define BOOST_PP_DEC_041 BOOST_PP_DEC_41
#define BOOST_PP_DEC_042 BOOST_PP_DEC_42
#define BOOST_PP_DEC_043 BOOST_PP_DEC_43
#define BOOST_PP_DEC_044 BOOST_PP_DEC_44
#define BOOST_PP_DEC_045 BOOST_PP_DEC_45
#define BOOST_PP_DEC_046 BOOST_PP_DEC_46
#define BOOST_PP_DEC_047 BOOST_PP_DEC_47
#define BOOST_PP_DEC_048 BOOST_PP_DEC_48
#define BOOST_PP_DEC_049 BOOST_PP_DEC_49
#define BOOST_PP_DEC_050 BOOST_PP_DEC_50
#define BOOST_PP_DEC_051 BOOST_PP_DEC_51
#define BOOST_PP_DEC_052 BOOST_PP_DEC_52
#define BOOST_PP_DEC_053 BOOST_PP_DEC_53
#define BOOST_PP_DEC_054 BOOST_PP_DEC_54
#define BOOST_PP_DEC_055 BOOST_PP_DEC_55
#define BOOST_PP_DEC_056 BOOST_PP_DEC_56
#define BOOST_PP_DEC_057 BOOST_PP_DEC_57
#define BOOST_PP_DEC_058 BOOST_PP_DEC_58
#define BOOST_PP_DEC_059 BOOST_PP_DEC_59
#define BOOST_PP_DEC_060 BOOST_PP_DEC_60
#define BOOST_PP_DEC_061 BOOST_PP_DEC_61
#define BOOST_PP_DEC_062 BOOST_PP_DEC_62
#define BOOST_PP_DEC_063 BOOST_PP_DEC_63

#define XXX_TO_NUMx(x) 0 ## x
#define XXX_TO_NUM(x) BOOST_PP_ADD(0,XXX_TO_NUMx(x))
#define XXX_STRINGIZEX(x) # x
#define XXX_VSTRINGIZE_SINGLE(a,b,x) XXX_STRINGIZE(x)
#define XXX_VSTRINGIZE_TUPLE(tpl) XXX_TUPLE_FOR_EACH(XXX_VSTRINGIZE_SINGLE,,tpl)
#define XXX_TUPLE_SIZE(TUPLE) XXX_TO_NUM(XXX_TUPLE_CHOICE(XXX_TUPLE_SIZE_INTERNAL(TUPLE)))
#define XXX_TUPLE_FOR_EACH(MACRO,DATA,TUPLE) BOOST_PP_LIST_FOR_EACH(MACRO,DATA,BOOST_PP_TUPLE_TO_LIST(XXX_TUPLE_SIZE(TUPLE),TUPLE))
#define XXX_STRINGIZE(x) XXX_STRINGIZEX(x)
#define XXX_VSTRINGIZE(...) XXX_VSTRINGIZE_TUPLE((__VA_ARGS__))
#define XXX_CAST_TO_VOID_ELEMENT(r,data,elem) (void)(elem);
#define XXX_CAST_TO_VOID_INTERNAL(TUPLE) XXX_TUPLE_FOR_EACH(XXX_CAST_TO_VOID_ELEMENT,,TUPLE)    
#define XXX_CAST_TO_VOID(...) XXX_CAST_TO_VOID_INTERNAL((__VA_ARGS__))
#define XXX_ENUM_EXTRACT_SP(en) BOOST_PP_TUPLE_ELEM(XXX_TUPLE_SIZE(en),0,en) = BOOST_PP_TUPLE_ELEM(XXX_TUPLE_SIZE(en),1,en)
#define XXX_ENUM_ELEMENT(r,data,elem) BOOST_PP_IF( XXX_TUPLE_SIZE(elem), XXX_ENUM_EXTRACT_SP(elem), elem) ,
#define XXX_ENUM_EXTRACT_ELEMENT(en) BOOST_PP_TUPLE_ELEM(XXX_TUPLE_SIZE(en),0,en)
#define XXX_ENUM_CASE_ELEMENT(en) BOOST_PP_IF( XXX_TUPLE_SIZE(en), XXX_ENUM_EXTRACT_ELEMENT(en), en )
#define XXX_ENUM_CASE(r,data,elem) case data :: XXX_ENUM_CASE_ELEMENT(elem) : return #data ""::"" XXX_STRINGIZE(XXX_ENUM_CASE_ELEMENT(elem));
#define XXX_ENUM_IFELSE(r,data,elem) else if( en == data :: XXX_ENUM_CASE_ELEMENT(elem)) { return #data ""::"" XXX_STRINGIZE(XXX_ENUM_CASE_ELEMENT(elem)); }
#define XXX_ENUM_CASTLIST(r,data,elem) { XXX_STRINGIZE(XXX_ENUM_CASE_ELEMENT(elem)), data :: XXX_ENUM_CASE_ELEMENT(elem) },
#define XXX_ENUM_QUALIFIED_CASTLIST(r,data,elem) { #data ""::"" XXX_STRINGIZE(XXX_ENUM_CASE_ELEMENT(elem)), data :: XXX_ENUM_CASE_ELEMENT(elem) },

#define XXX_ENUM_INTERNAL(TYPE,NAME,TUPLE)                       \
enum TYPE                                                        \
{                                                                \
   XXX_TUPLE_FOR_EACH(XXX_ENUM_ELEMENT,,TUPLE)                   \
   BOOST_PP_CAT(last_enum_,NAME)                                 \
};                                                               \
                                                                 \
inline                                                           \
const char* to_string( NAME en )                                 \
{                                                                \
   if(false)                                                     \
   {                                                             \
   }                                                             \
   XXX_TUPLE_FOR_EACH(XXX_ENUM_IFELSE,NAME,TUPLE)                \
   else if( en == NAME :: BOOST_PP_CAT(last_enum_,NAME) )        \
   {                                                             \
     return XXX_VSTRINGIZE(NAME,::,BOOST_PP_CAT(last_enum_,NAME));  \
   }                                                             \
   else                                                          \
   {                                                             \
     return ""Invalid enum value specified for "" # NAME;          \
   }                                                             \
}                                                                \
                                                                 \
inline                                                           \
std::ostream& operator<<( std::ostream& os, const NAME& en )     \
{                                                                \
   os << to_string(en);                                          \
   return os;                                                    \
}                                                                \
                                                                 \
inline                                                           \
NAME do_enum_cast( const std::string& s, const ::xxx::enum_cast_adl_helper<NAME>& ) \
{                                                                \
  static const std::unordered_map<std::string,NAME> map =        \
  {                                                              \
    XXX_TUPLE_FOR_EACH(XXX_ENUM_CASTLIST,NAME,TUPLE)             \
    XXX_TUPLE_FOR_EACH(XXX_ENUM_QUALIFIED_CASTLIST,NAME,TUPLE)   \
  };                                                             \
                                                                 \
  auto cit = map.find(s);                                        \
  if( cit == map.end() )                                         \
  {                                                              \
    throw std::runtime_error(""Invalid value to cast to enum"");   \
  }                                                              \
  return cit->second;                                            \
}

#define XXX_ENUM(NAME,TUPLE) XXX_ENUM_INTERNAL(NAME,NAME,TUPLE)
#define XXX_ENUM_CLASS(NAME,TUPLE) XXX_ENUM_INTERNAL(class NAME,NAME,TUPLE)
#define XXX_ENUM_CLASS_TYPE(NAME,TYPE,TUPLE) XXX_ENUM_INTERNAL(class NAME : TYPE,NAME,TUPLE)
#define XXX_ENUM_TYPE(NAME,TYPE,TUPLE) XXX_ENUM_INTERNAL(NAME : TYPE,NAME,TUPLE)


Usage

#include ""xxx_enum.h""  // the above lib
#include <iostream>

XXX_ENUM(foo,(a,b,(c,42)));

int main()
{
  std::cout << ""foo::a = ""            << foo::a            <<'\n';
  std::cout << ""(int)foo::c = ""       << (int)foo::c       <<'\n';
  std::cout << ""to_string(foo::b) = "" << to_string(foo::b) <<'\n';
  std::cout << ""xxx::enum_cast<foo>(\""b\"") = "" << xxx::enum_cast<foo>(""b"") <<'\n';
}


Compilation (copy paste header within main.cpp)

> g++ --version | sed 1q
g++ (GCC) 4.9.2

> g++ -std=c++14 -pedantic -Wall -Wextra main.cpp
main.cpp:268:31: warning: extra ';' [-Wpedantic]
     XXX_ENUM(foo,(a,b,(c,42)));
                               ^


Output

foo::a = foo::a
(int)foo::c = 42
to_string(foo::b) = foo::b
xxx::enum_cast<foo>(""b"") = foo::b

    As long as you are okay with writing a separate .h/.cpp pair for each queryable enum, this solution works with nearly the same syntax and capabilities as a regular c++ enum:

// MyEnum.h
#include <EnumTraits.h>
#ifndef ENUM_INCLUDE_MULTI
#pragma once
#end if

enum MyEnum : int ETRAITS
{
    EDECL(AAA) = -8,
    EDECL(BBB) = '8',
    EDECL(CCC) = AAA + BBB
};


The .cpp file is 3 lines of boilerplate:

// MyEnum.cpp
#define ENUM_DEFINE MyEnum
#define ENUM_INCLUDE <MyEnum.h>
#include <EnumTraits.inl>


Example usage:

for (MyEnum value : EnumTraits<MyEnum>::GetValues())
    std::cout << EnumTraits<MyEnum>::GetName(value) << std::endl;


Code

This solution requires 2 source files:

// EnumTraits.h
#pragma once
#include <string>
#include <unordered_map>
#include <vector>

#define ETRAITS
#define EDECL(x) x

template <class ENUM>
class EnumTraits
{
public:
    static const std::vector<ENUM>& GetValues()
    {
        return values;
    }

    static ENUM GetValue(const char* name)
    {
        auto match = valueMap.find(name);
        return (match == valueMap.end() ? ENUM() : match->second);
    }

    static const char* GetName(ENUM value)
    {
        auto match = nameMap.find(value);
        return (match == nameMap.end() ? nullptr : match->second);
    }

public:
    EnumTraits() = delete;

    using vector_type = std::vector<ENUM>;
    using name_map_type = std::unordered_map<ENUM, const char*>;
    using value_map_type = std::unordered_map<std::string, ENUM>;

private:
    static const vector_type values;
    static const name_map_type nameMap;
    static const value_map_type valueMap;
};

struct EnumInitGuard{ constexpr const EnumInitGuard& operator=(int) const { return *this; } };
template <class T> constexpr T& operator<<=(T&& x, const EnumInitGuard&) { return x; }


...and

// EnumTraits.inl
#define ENUM_INCLUDE_MULTI

#include ENUM_INCLUDE
#undef ETRAITS
#undef EDECL

using EnumType = ENUM_DEFINE;
using TraitsType = EnumTraits<EnumType>;
using VectorType = typename TraitsType::vector_type;
using NameMapType = typename TraitsType::name_map_type;
using ValueMapType = typename TraitsType::value_map_type;
using NamePairType = typename NameMapType::value_type;
using ValuePairType = typename ValueMapType::value_type;

#define ETRAITS ; const VectorType TraitsType::values
#define EDECL(x) EnumType::x <<= EnumInitGuard()
#include ENUM_INCLUDE
#undef ETRAITS
#undef EDECL

#define ETRAITS ; const NameMapType TraitsType::nameMap
#define EDECL(x) NamePairType(EnumType::x, #x) <<= EnumInitGuard()
#include ENUM_INCLUDE
#undef ETRAITS
#undef EDECL

#define ETRAITS ; const ValueMapType TraitsType::valueMap
#define EDECL(x) ValuePairType(#x, EnumType::x) <<= EnumInitGuard()
#include ENUM_INCLUDE
#undef ETRAITS
#undef EDECL


Explanation

This implementation exploits the fact that the braced list of elements of an enum definition can also be used as a braced initializer list for class member initialization.

When ETRAITS is evaluated in the context of EnumTraits.inl, 
it expands out to a static member definition for the EnumTraits<> class. 

The EDECL macro transforms each enum member into initializer list values which subsequently get passed into the member constructor in order to populate the enum info. 

The EnumInitGuard class is designed to consume the enum initializer values and then collapse - leaving a pure list of enum data.

Benefits


c++-like syntax
Works identically for both enum and enum class (*almost)
Works for enum types with any numeric underlying type
Works for enum types with automatic, explicit, and fragmented initializer values
Works for mass renaming (intellisense linking preserved)
Only 5 preprocessor symbols (3 global)


* In contrast to enums, initializers in enum class types that reference other values from the same enum must have those values fully qualified

Disbenefits


Requires a separate .h/.cpp pair for each queryable enum
Depends on convoluted macro and include magic
Minor syntax errors explode into much larger errors
Defining class or namespace scoped enums is nontrivial
No compile time initialization


Comments

Intellisense will complain a bit about private member access when opening up EnumTraits.inl, but since the expanded macros are actually defining class members, that isn't actually a problem.

The #ifndef ENUM_INCLUDE_MULTI block at the top of the header file is a minor annoyance that could probably be shrunken down into a macro or something, but it's small enough to live with at its current size.

Declaring a namespace scoped enum requires that the enum first be forward declared inside its namespace scope, then defined in the global namespace. Additionally, any enum initializers using values of the same enum must have those values fully qualified.

namespace ns { enum MyEnum : int; }
enum ns::MyEnum : int ETRAITS
{
    EDECL(AAA) = -8,
    EDECL(BBB) = '8',
    EDECL(CCC) = ns::MyEnum::AAA + ns::MyEnum::BBB
}

    (Analogue of https://stackoverflow.com/a/54967187/2338477, slightly modified).

Here is my own solution with minimum define magic and support of individual enum assignments.

Here is header file:

#pragma once
#include <string>
#include <map>
#include <regex>

template <class Enum>
class EnumReflect
{
public:
    static const char* getEnums() { return """"; }
};

//
//  Just a container for each enumeration type.
//
template <class Enum>
class EnumReflectBase
{
public:
    static std::map<std::string, int> enum2int;
    static std::map<int, std::string> int2enum;

    static void EnsureEnumMapReady( const char* enumsInfo )
    {
        if (*enumsInfo == 0 || enum2int.size() != 0 )
            return;

        // Should be called once per each enumeration.
        std::string senumsInfo(enumsInfo);
        std::regex re(""^([a-zA-Z_][a-zA-Z0-9_]+) *=? *([^,]*)(,|$) *"");     // C++ identifier to optional "" = <value>""
        std::smatch sm;
        int value = 0;

        for (; regex_search(senumsInfo, sm, re); senumsInfo = sm.suffix(), value++)
        {
            string enumName = sm[1].str();
            string enumValue = sm[2].str();

            if (enumValue.length() != 0)
                value = atoi(enumValue.c_str());

            enum2int[enumName] = value;
            int2enum[value] = enumName;
        }
    }
};

template <class Enum>
std::map<std::string, int> EnumReflectBase<Enum>::enum2int;

template <class Enum>
std::map<int, std::string> EnumReflectBase<Enum>::int2enum;


#define DECLARE_ENUM(name, ...)                                         \
    enum name { __VA_ARGS__ };                                          \
    template <>                                                         \
    class EnumReflect<##name>: public EnumReflectBase<##name> {         \
    public:                                                             \
        static const char* getEnums() { return #__VA_ARGS__; }          \
    };




/*
    Basic usage:

    Declare enumeration:

DECLARE_ENUM( enumName,

    enumValue1,
    enumValue2,
    enumValue3 = 5,

    // comment
    enumValue4
);

    Conversion logic:

    From enumeration to string:

        printf( EnumToString(enumValue3).c_str() );

    From string to enumeration:

       enumName value;

       if( !StringToEnum(""enumValue4"", value) )
            printf(""Conversion failed..."");
*/

//
//  Converts enumeration to string, if not found - empty string is returned.
//
template <class T>
std::string EnumToString(T t)
{
    EnumReflect<T>::EnsureEnumMapReady(EnumReflect<T>::getEnums());
    auto& int2enum = EnumReflect<T>::int2enum;
    auto it = int2enum.find(t);

    if (it == int2enum.end())
        return """";

    return it->second;
}

//
//  Converts string to enumeration, if not found - false is returned.
//
template <class T>
bool StringToEnum(const char* enumName, T& t)
{
    EnumReflect<T>::EnsureEnumMapReady(EnumReflect<T>::getEnums());
    auto& enum2int = EnumReflect<T>::enum2int;
    auto it = enum2int.find(enumName);

    if (it == enum2int.end())
        return false;

    t = (T) it->second;
    return true;
}


And here is example test application:

DECLARE_ENUM(TestEnum,
    ValueOne,
    ValueTwo,
    ValueThree = 5,
    ValueFour = 7
);

DECLARE_ENUM(TestEnum2,
    ValueOne2 = -1,
    ValueTwo2,
    ValueThree2 = -4,
    ValueFour2
);

void main(void)
{
    string sName1 = EnumToString(ValueOne);
    string sName2 = EnumToString(ValueTwo);
    string sName3 = EnumToString(ValueThree);
    string sName4 = EnumToString(ValueFour);

    TestEnum t1, t2, t3, t4, t5 = ValueOne;
    bool b1 = StringToEnum(sName1.c_str(), t1);
    bool b2 = StringToEnum(sName2.c_str(), t2);
    bool b3 = StringToEnum(sName3.c_str(), t3);
    bool b4 = StringToEnum(sName4.c_str(), t4);
    bool b5 = StringToEnum(""Unknown"", t5);

    string sName2_1 = EnumToString(ValueOne2);
    string sName2_2 = EnumToString(ValueTwo2);
    string sName2_3 = EnumToString(ValueThree2);
    string sName2_4 = EnumToString(ValueFour2);

    TestEnum2 t2_1, t2_2, t2_3, t2_4, t2_5 = ValueOne2;
    bool b2_1 = StringToEnum(sName2_1.c_str(), t2_1);
    bool b2_2 = StringToEnum(sName2_2.c_str(), t2_2);
    bool b2_3 = StringToEnum(sName2_3.c_str(), t2_3);
    bool b2_4 = StringToEnum(sName2_4.c_str(), t2_4);
    bool b2_5 = StringToEnum(""Unknown"", t2_5);


Updated version of same header file will be kept here:

https://github.com/tapika/cppscriptcore/blob/master/SolutionProjectModel/EnumReflect.h
    You could use a reflection library, like Ponder: 

enum class MyEnum
{
    Zero = 0,
    One  = 1,
    Two  = 2
};

ponder::Enum::declare<MyEnum>()
    .value(""Zero"", MyEnum::Zero)
    .value(""One"",  MyEnum::One)
    .value(""Two"",  MyEnum::Two);

ponder::EnumObject zero(MyEnum::Zero);

zero.name(); // -> ""Zero""

    Well, yet another option. A typical use case is where you need constants for the HTTP verbs as well as using its string version values.

The example:

int main () {

  VERB a = VERB::GET;
  VERB b = VERB::GET;
  VERB c = VERB::POST;
  VERB d = VERB::PUT;
  VERB e = VERB::DELETE;


  std::cout << a.toString() << std::endl;

  std::cout << a << std::endl;

  if ( a == VERB::GET ) {
    std::cout << ""yes"" << std::endl;
  }

  if ( a == b ) {
    std::cout << ""yes"" << std::endl;
  }

  if ( a != c ) {
    std::cout << ""no"" << std::endl;
  }

}


The VERB class:

// -----------------------------------------------------------
// -----------------------------------------------------------
class VERB {

private:

  // private constants
  enum Verb {GET_=0, POST_, PUT_, DELETE_};

  // private string values
  static const std::string theStrings[];

  // private value
  const Verb value;
  const std::string text;

  // private constructor
  VERB (Verb v) :
  value(v), text (theStrings[v])
  {
    // std::cout << "" constructor \n"";
  }

public:

  operator const char * ()  const { return text.c_str(); }

  operator const std::string ()  const { return text; }

  const std::string toString () const { return text; }

  bool operator == (const VERB & other) const { return (*this).value == other.value; }

  bool operator != (const VERB & other) const { return ! ( (*this) == other); }

  // ---

  static const VERB GET;
  static const VERB POST;
  static const VERB PUT;
  static const VERB DELETE;

};

const std::string VERB::theStrings[] = {""GET"", ""POST"", ""PUT"", ""DELETE""};

const VERB VERB::GET = VERB ( VERB::Verb::GET_ );
const VERB VERB::POST = VERB ( VERB::Verb::POST_ );
const VERB VERB::PUT = VERB ( VERB::Verb::PUT_ );
const VERB VERB::DELETE = VERB ( VERB::Verb::DELETE_ );
// end of file

    I am not sure if this approach is already covered in one of the other answers (actually it is, see below). I encountered the problem many times and didnt find a solution that did not use obfuscated macros or third party libraries. Hence I decided to write my own obfuscated macro version. 

What I want to enable is the equivalent of

enum class test1 { ONE, TWO = 13, SIX };

std::string toString(const test1& e) { ... }

int main() {
    test1 x;
    std::cout << toString(x) << ""\n"";
    std::cout << toString(test1::TWO) << ""\n"";
    std::cout << static_cast<std::underlying_type<test1>::type>(test1::TWO) << ""\n"";
    //std::cout << toString(123);// invalid
}


which should print

ONE
TWO
13


I am not a fan of macros. However, unless c++ natively supports converting enums to strings one has to use some sort of code generation and/or macros (and I doubt this will happen too soon). I am using a X-macro: 

// x_enum.h
#include <string>
#include <map>
#include <type_traits>
#define x_begin enum class x_name {
#define x_val(X) X
#define x_value(X,Y) X = Y
#define x_end };
x_enum_def
#undef x_begin
#undef x_val
#undef x_value
#undef x_end

#define x_begin inline std::string toString(const x_name& e) { \
                static std::map<x_name,std::string> names = { 
#define x_val(X)      { x_name::X , #X }
#define x_value(X,Y)  { x_name::X , #X }
#define x_end }; return names[e]; }
x_enum_def
#undef x_begin
#undef x_val
#undef x_value
#undef x_end
#undef x_name
#undef x_enum_def


Most of it is defining and undefining symbols that the user will pass as parameter to the X-marco via an include. The usage is like this

#define x_name test1
#define x_enum_def x_begin x_val(ONE) , \
                           x_value(TWO,13) , \
                           x_val(SIX) \
                   x_end
#include ""x_enum.h""


Live Demo

Note that I didnt include choosing the underlying type yet. I didnt need it so far, but it should be straight forward to modify to code to enable that. 

Only after writing this I realized that it is rather similar to eferions answer. Maybe I read it before and maybe it was the main source of inspiration. I was always failing in understanding X-macros until I wrote my own ;). 
    Solutions using enum within class/struct (struct defaults with public members) and overloaded operators:

struct Color
{
    enum Enum { RED, GREEN, BLUE };
    Enum e;

    Color() {}
    Color(Enum e) : e(e) {}

    Color operator=(Enum o) { e = o; return *this; }
    Color operator=(Color o) { e = o.e; return *this; }
    bool operator==(Enum o) { return e == o; }
    bool operator==(Color o) { return e == o.e; }
    operator Enum() const { return e; }

    std::string toString() const
    {
        switch (e)
        {
        case Color::RED:
            return ""red"";
        case Color::GREEN:
            return ""green"";
        case Color::BLUE:
            return ""blue"";
        default:
            return ""unknown"";
        }
    }
};


From the outside it looks nearly exactly like a class enum:

Color red;
red = Color::RED;
Color blue = Color::BLUE;

cout << red.toString() << "" "" << Color::GREEN << "" "" << blue << endl;


This will output ""red 1 2"". You could possibly overload << to make blue output a string (although it might cause ambiguity so not possible), but it wouldn't work with Color::GREEN since it doesn't automatically convert to Color.

The purpose of having an implicit convert to Enum (which implicitly converts to int or type given) is to be able to do:

Color color;
switch (color) ...


This works, but it also means that this work too:

int i = color;


With an enum class it wouldn't compile.
You ought to be careful if you overload two functions taking the enum and an integer, or remove the implicit conversion...

Another solution would involve using an actual enum class and static members:

struct Color
{
    enum class Enum { RED, GREEN, BLUE };
    static const Enum RED = Enum::RED, GREEN = Enum::GREEN, BLUE = Enum::BLUE;

    //same as previous...
};


It possibly takes more space, and is longer to make, but causes a compile error for implicit int conversions. I'd use this one because of that!

There's surely overhead with this though, but I think it's just simpler and looks better than other code I've seen. There's also potential for adding functionality, which could all be scoped within the class.

Edit: this works and most can be compiled before execution:

class Color
{
public:
    enum class Enum { RED, GREEN, BLUE };
    static const Enum RED = Enum::RED, GREEN = Enum::GREEN, BLUE = Enum::BLUE;

    constexpr Color() : e(Enum::RED) {}
    constexpr Color(Enum e) : e(e) {}

    constexpr bool operator==(Enum o) const { return e == o; }
    constexpr bool operator==(Color o) const { return e == o.e; }
    constexpr operator Enum() const { return e; }

    Color& operator=(Enum o) { const_cast<Enum>(this->e) = o; return *this; }
    Color& operator=(Color o) { const_cast<Enum>(this->e) = o.e; return *this; }

    std::string toString() const
    {
        switch (e)
        {
        case Enum::RED:
            return ""red"";
        case Enum::GREEN:
            return ""green"";
        case Enum::BLUE:
            return ""blue"";
        default:
            return ""unknown"";
        }
    }
private:
    const Enum e;
};

    EDIT: check below for a newer version

As mentioned above, N4113 is the final solution to this matter, but we'll have to wait more than a year to see it coming out.  

Meanwhile, if you want such feature, you'll need to resort to ""simple"" templates and some preprocessor magic.  

Enumerator

template<typename T>
class Enum final
{
    const char* m_name;
    const T m_value;
    static T m_counter;

public:
    Enum(const char* str, T init = m_counter) : m_name(str), m_value(init) {m_counter = (init + 1);}

    const T value() const {return m_value;}
    const char* name() const {return m_name;}
};

template<typename T>
T Enum<T>::m_counter = 0;

#define ENUM_TYPE(x)      using Enum = Enum<x>;
#define ENUM_DECL(x,...)  x(#x,##__VA_ARGS__)
#define ENUM(...)         const Enum ENUM_DECL(__VA_ARGS__);


Usage

#include <iostream>

//the initialization order should be correct in all scenarios
namespace Level
{
    ENUM_TYPE(std::uint8)
    ENUM(OFF)
    ENUM(SEVERE)
    ENUM(WARNING)
    ENUM(INFO, 10)
    ENUM(DEBUG)
    ENUM(ALL)
}

namespace Example
{
    ENUM_TYPE(long)
    ENUM(A)
    ENUM(B)
    ENUM(C, 20)
    ENUM(D)
    ENUM(E)
    ENUM(F)
}

int main(int argc, char** argv)
{
    Level::Enum lvl = Level::WARNING;
    Example::Enum ex = Example::C;
    std::cout << lvl.value() << std::endl; //2
    std::cout << ex.value() << std::endl; //20
}


Simple explaination

Enum<T>::m_counter is set to 0 inside each namespace declaration.
(Could someone point me out where ^^this behaviour^^ is mentioned on the standard?)
The preprocessor magic automates the declaration of enumerators.

Disadvantages


It's not a true enum type, therefore not promotable to int
Cannot be used in switch cases




Alternative solution

This one sacrifices line numbering (not really) but can be used on switch cases.

#define ENUM_TYPE(x) using type = Enum<x>
#define ENUM(x)      constexpr type x{__LINE__,#x}

template<typename T>
struct Enum final
{
    const T value;
    const char* name;

    constexpr operator const T() const noexcept {return value;}
    constexpr const char* operator&() const noexcept {return name;}
};


Errata

#line 0 conflicts with -pedantic on GCC and clang.

Workaround

Either start at #line 1 and subtract 1 from __LINE__.
Or, don't use -pedantic.
And while we're at it, avoid VC++ at all costs, it has always been a joke of a compiler.

Usage

#include <iostream>

namespace Level
{
    ENUM_TYPE(short);
    #line 0
    ENUM(OFF);
    ENUM(SEVERE);
    ENUM(WARNING);
    #line 10
    ENUM(INFO);
    ENUM(DEBUG);
    ENUM(ALL);
    #line <next line number> //restore the line numbering
};

int main(int argc, char** argv)
{
    std::cout << Level::OFF << std::endl;   // 0
    std::cout << &Level::OFF << std::endl;  // OFF

    std::cout << Level::INFO << std::endl;  // 10
    std::cout << &Level::INFO << std::endl; // INFO

    switch(/* any integer or integer-convertible type */)
    {
    case Level::OFF:
        //...
        break;

    case Level::SEVERE:
        //...
        break;

    //...
    }

    return 0;
}


Real-life implementation and use

r3dVoxel - Enum
r3dVoxel - ELoggingLevel

Quick Reference

#line lineno -- cppreference.com
    The following solution is based on a std::array<std::string,N> for a given enum.

For enum to std::string conversion we can just cast the enum to size_t and lookup the string from the array. The operation is O(1) and requires no heap allocation.

#include <boost/preprocessor/seq/transform.hpp>
#include <boost/preprocessor/seq/enum.hpp>
#include <boost/preprocessor/stringize.hpp>

#include <string>
#include <array>
#include <iostream>

#define STRINGIZE(s, data, elem) BOOST_PP_STRINGIZE(elem)

// ENUM
// ============================================================================
#define ENUM(X, SEQ) \
struct X {   \
    enum Enum {BOOST_PP_SEQ_ENUM(SEQ)}; \
    static const std::array<std::string,BOOST_PP_SEQ_SIZE(SEQ)> array_of_strings() { \
        return {{BOOST_PP_SEQ_ENUM(BOOST_PP_SEQ_TRANSFORM(STRINGIZE, 0, SEQ))}}; \
    } \
    static std::string to_string(Enum e) { \
        auto a = array_of_strings(); \
        return a[static_cast<size_t>(e)]; \
    } \
}


For std::string to enum conversion we would have to make a linear search over the array and cast the array index to enum.

Try it here with usage examples: http://coliru.stacked-crooked.com/a/e4212f93bee65076

Edit: Reworked my solution so the custom Enum can be used inside a class.
    This gist provides a simple mapping based on C++ variadic templates.

This is a C++17-simplified version of the type-based map from the gist:

#include <cstring> // http://stackoverflow.com/q/24520781

template<typename KeyValue, typename ... RestOfKeyValues>
struct map {
  static constexpr typename KeyValue::key_t get(const char* val) noexcept {
    if constexpr (sizeof...(RestOfKeyValues)==0)  // C++17 if constexpr
      return KeyValue::key; // Returns last element
    else {
      static_assert(KeyValue::val != nullptr,
                  ""Only last element may have null name"");
      return strcmp(val, KeyValue::val()) 
            ? map<RestOfKeyValues...>::get(val) : KeyValue::key;
    }
  }
  static constexpr const char* get(typename KeyValue::key_t key) noexcept {
    if constexpr (sizeof...(RestOfKeyValues)==0)
      return (KeyValue::val != nullptr) && (key == KeyValue::key)
            ? KeyValue::val() : """";
    else
      return (key == KeyValue::key) 
            ? KeyValue::val() : map<RestOfKeyValues...>::get(key);
  }
};

template<typename Enum, typename ... KeyValues>
class names {
  typedef map<KeyValues...> Map;
public:
  static constexpr Enum get(const char* nam) noexcept {
    return Map::get(nam);
  }
  static constexpr const char* get(Enum key) noexcept {
    return Map::get(key);
  }
};


An example usage: 

enum class fasion {
    fancy,
    classic,
    sporty,
    emo,
    __last__ = emo,
    __unknown__ = -1
};

#define NAME(s) static inline constexpr const char* s() noexcept {return #s;}
namespace name {
    NAME(fancy)
    NAME(classic)
    NAME(sporty)
    NAME(emo)
}

template<auto K, const char* (*V)()>  // C++17 template<auto>
struct _ {
    typedef decltype(K) key_t;
    typedef decltype(V) name_t;
    static constexpr key_t  key = K; // enum id value
    static constexpr name_t val = V; // enum id name
};

typedef names<fasion,
    _<fasion::fancy, name::fancy>,
    _<fasion::classic, name::classic>,
    _<fasion::sporty, name::sporty>,
    _<fasion::emo, name::emo>,
    _<fasion::__unknown__, nullptr>
> fasion_names;


The map<KeyValues...> can be used in both directions:


fasion_names::get(fasion::emo)
fasion_names::get(""emo"")


This example is available on godbolt.org

int main ()
{
  constexpr auto str = fasion_names::get(fasion::emo);
  constexpr auto fsn = fasion_names::get(str);
  return (int) fsn;
}


Result from gcc-7 -std=c++1z -Ofast -S

main:
        mov     eax, 3
        ret

    Just generate your enums. Writing a generator for that purpose is about five minutes' work.

Generator code in java and python, super easy to port to any language you like, including C++.

Also super easy to extend by whatever functionality you want.

example input:

First = 5
Second
Third = 7
Fourth
Fifth=11


generated header:

#include <iosfwd>

enum class Hallo
{
    First = 5,
    Second = 6,
    Third = 7,
    Fourth = 8,
    Fifth = 11
};

std::ostream & operator << (std::ostream &, const Hallo&);


generated cpp file

#include <ostream>

#include ""Hallo.h""

std::ostream & operator << (std::ostream &out, const Hallo&value)
{
    switch(value)
    {
    case Hallo::First:
        out << ""First"";
        break;
    case Hallo::Second:
        out << ""Second"";
        break;
    case Hallo::Third:
        out << ""Third"";
        break;
    case Hallo::Fourth:
        out << ""Fourth"";
        break;
    case Hallo::Fifth:
        out << ""Fifth"";
        break;
    default:
        out << ""<unknown>"";
    }

    return out;
}


And the generator, in a very terse form as a template for porting and extension. This example code really tries to avoid overwriting any files but still use it at your own risk.

package cppgen;

import java.io.BufferedReader;
import java.io.File;
import java.io.FileInputStream;
import java.io.FileOutputStream;
import java.io.InputStreamReader;
import java.io.OutputStreamWriter;
import java.io.PrintWriter;
import java.nio.charset.Charset;
import java.util.LinkedHashMap;
import java.util.Map;
import java.util.Map.Entry;
import java.util.regex.Matcher;
import java.util.regex.Pattern;

public class EnumGenerator
{
    static void fail(String message)
    {
        System.err.println(message);
        System.exit(1);
    }

    static void run(String[] args)
    throws Exception
    {
        Pattern pattern = Pattern.compile(""\\s*(\\w+)\\s*(?:=\\s*(\\d+))?\\s*"", Pattern.UNICODE_CHARACTER_CLASS);
        Charset charset = Charset.forName(""UTF8"");
        String tab = ""    "";

        if (args.length != 3)
        {
            fail(""Required arguments: <enum name> <input file> <output dir>"");
        }

        String enumName = args[0];

        File inputFile = new File(args[1]);

        if (inputFile.isFile() == false)
        {
            fail(""Not a file: ["" + inputFile.getCanonicalPath() + ""]"");
        }

        File outputDir = new File(args[2]);

        if (outputDir.isDirectory() == false)
        {
            fail(""Not a directory: ["" + outputDir.getCanonicalPath() + ""]"");
        }

        File headerFile = new File(outputDir, enumName + "".h"");
        File codeFile = new File(outputDir, enumName + "".cpp"");

        for (File file : new File[] { headerFile, codeFile })
        {
            if (file.exists())
            {
                fail(""Will not overwrite file ["" + file.getCanonicalPath() + ""]"");
            }
        }

        int nextValue = 0;

        Map<String, Integer> fields = new LinkedHashMap<>();

        try
        (
            BufferedReader reader = new BufferedReader(new InputStreamReader(new FileInputStream(inputFile), charset));
        )
        {
            while (true)
            {
                String line = reader.readLine();

                if (line == null)
                {
                    break;
                }

                if (line.trim().length() == 0)
                {
                    continue;
                }

                Matcher matcher = pattern.matcher(line);

                if (matcher.matches() == false)
                {
                    fail(""Syntax error: ["" + line + ""]"");
                }

                String fieldName = matcher.group(1);

                if (fields.containsKey(fieldName))
                {
                    fail(""Double fiend name: "" + fieldName);
                }

                String valueString = matcher.group(2);

                if (valueString != null)
                {
                    int value = Integer.parseInt(valueString);

                    if (value < nextValue)
                    {
                        fail(""Not a monotonous progression from "" + nextValue + "" to "" + value + "" for enum field "" + fieldName);
                    }

                    nextValue = value;
                }

                fields.put(fieldName, nextValue);

                ++nextValue;
            }
        }

        try
        (
            PrintWriter headerWriter = new PrintWriter(new OutputStreamWriter(new FileOutputStream(headerFile), charset));
            PrintWriter codeWriter = new PrintWriter(new OutputStreamWriter(new FileOutputStream(codeFile), charset));
        )
        {
            headerWriter.println();
            headerWriter.println(""#include <iosfwd>"");
            headerWriter.println();
            headerWriter.println(""enum class "" + enumName);
            headerWriter.println('{');
            boolean first = true;
            for (Entry<String, Integer> entry : fields.entrySet())
            {
                if (first == false)
                {
                    headerWriter.println("","");
                }

                headerWriter.print(tab + entry.getKey() + "" = "" + entry.getValue());

                first = false;
            }
            if (first == false)
            {
                headerWriter.println();
            }
            headerWriter.println(""};"");
            headerWriter.println();
            headerWriter.println(""std::ostream & operator << (std::ostream &, const "" + enumName + ""&);"");
            headerWriter.println();

            codeWriter.println();
            codeWriter.println(""#include <ostream>"");
            codeWriter.println();
            codeWriter.println(""#include \"""" + enumName + "".h\"""");
            codeWriter.println();
            codeWriter.println(""std::ostream & operator << (std::ostream &out, const "" + enumName + ""&value)"");
            codeWriter.println('{');
            codeWriter.println(tab + ""switch(value)"");
            codeWriter.println(tab + '{');
            first = true;
            for (Entry<String, Integer> entry : fields.entrySet())
            {
                codeWriter.println(tab + ""case "" + enumName + ""::"" + entry.getKey() + ':');
                codeWriter.println(tab + tab + ""out << \"""" + entry.getKey() + ""\"";"");
                codeWriter.println(tab + tab + ""break;"");

                first = false;
            }
            codeWriter.println(tab + ""default:"");
            codeWriter.println(tab + tab + ""out << \""<unknown>\"";"");
            codeWriter.println(tab + '}');
            codeWriter.println();
            codeWriter.println(tab + ""return out;"");
            codeWriter.println('}');
            codeWriter.println();
        }
    }

    public static void main(String[] args)
    {
        try
        {
            run(args);
        }
        catch(Exception exc)
        {
            exc.printStackTrace();
            System.exit(1);
        }
    }
}


And a port to Python 3.5 because different enough to be potentially helpful

import re
import collections
import sys
import io
import os

def fail(*args):
    print(*args)
    exit(1)

pattern = re.compile(r'\s*(\w+)\s*(?:=\s*(\d+))?\s*')
tab = ""    ""

if len(sys.argv) != 4:
    n=0
    for arg in sys.argv:
        print(""arg"", n, "":"", arg, "" / "", sys.argv[n])
        n += 1
    fail(""Required arguments: <enum name> <input file> <output dir>"")

enumName = sys.argv[1]

inputFile = sys.argv[2]

if not os.path.isfile(inputFile):
    fail(""Not a file: ["" + os.path.abspath(inputFile) + ""]"")

outputDir = sys.argv[3]

if not os.path.isdir(outputDir):
    fail(""Not a directory: ["" + os.path.abspath(outputDir) + ""]"")

headerFile = os.path.join(outputDir, enumName + "".h"")
codeFile = os.path.join(outputDir, enumName + "".cpp"")

for file in [ headerFile, codeFile ]:
    if os.path.exists(file):
        fail(""Will not overwrite file ["" + os.path.abspath(file) + ""]"")

nextValue = 0

fields = collections.OrderedDict()

for line in open(inputFile, 'r'):
    line = line.strip()

    if len(line) == 0:
        continue

    match = pattern.match(line)

    if match == None:
        fail(""Syntax error: ["" + line + ""]"")

    fieldName = match.group(1)

    if fieldName in fields:
        fail(""Double field name: "" + fieldName)

    valueString = match.group(2)

    if valueString != None:
        value = int(valueString)

        if value < nextValue:
            fail(""Not a monotonous progression from "" + nextValue + "" to "" + value + "" for enum field "" + fieldName)

        nextValue = value

    fields[fieldName] = nextValue

    nextValue += 1

headerWriter = open(headerFile, 'w')
codeWriter = open(codeFile, 'w')

try:
    headerWriter.write(""\n"")
    headerWriter.write(""#include <iosfwd>\n"")
    headerWriter.write(""\n"")
    headerWriter.write(""enum class "" + enumName + ""\n"")
    headerWriter.write(""{\n"")
    first = True
    for fieldName, fieldValue in fields.items():
        if not first:
            headerWriter.write("",\n"")

        headerWriter.write(tab + fieldName + "" = "" + str(fieldValue))

        first = False
    if not first:
        headerWriter.write(""\n"")
    headerWriter.write(""};\n"")
    headerWriter.write(""\n"")
    headerWriter.write(""std::ostream & operator << (std::ostream &, const "" + enumName + ""&);\n"")
    headerWriter.write(""\n"")

    codeWriter.write(""\n"")
    codeWriter.write(""#include <ostream>\n"")
    codeWriter.write(""\n"")
    codeWriter.write(""#include \"""" + enumName + "".h\""\n"")
    codeWriter.write(""\n"")
    codeWriter.write(""std::ostream & operator << (std::ostream &out, const "" + enumName + ""&value)\n"")
    codeWriter.write(""{\n"")
    codeWriter.write(tab + ""switch(value)\n"")
    codeWriter.write(tab + ""{\n"")
    for fieldName in fields.keys():
        codeWriter.write(tab + ""case "" + enumName + ""::"" + fieldName + "":\n"")
        codeWriter.write(tab + tab + ""out << \"""" + fieldName + ""\"";\n"")
        codeWriter.write(tab + tab + ""break;\n"")
    codeWriter.write(tab + ""default:\n"")
    codeWriter.write(tab + tab + ""out << \""<unknown>\"";\n"")
    codeWriter.write(tab + ""}\n"")
    codeWriter.write(""\n"")
    codeWriter.write(tab + ""return out;\n"")
    codeWriter.write(""}\n"")
    codeWriter.write(""\n"")
finally:
    headerWriter.close()
    codeWriter.close()

    You can use a select() function, which is really just a short-hand switch; it is not a solution in the true sense of the word, but it makes life easier:
enum
{
  NORMAL,
  INVALID
} state(NORMAL);

//std::cout << (state ? ""INVALID"" : ""NORMAL"") << std::endl;
std::cout << select(state, ""NORMAL"", ""INVALID"") << std::endl;

select() functions are common in SIMD/GPU programming. They are generalizations of the ternary ?: operator. You can also view select() as a functional array (a function implementing an array data structure).
Here's a full example.
    I wrote a library for solving this problem, everything happens in compiling time, except for getting the message.

Usage:

Use macro DEF_MSG to define a macro and message pair:

DEF_MSG(CODE_OK,   ""OK!"")
DEF_MSG(CODE_FAIL, ""Fail!"")


CODE_OK is the macro to use, and ""OK!"" is the corresponding message.

Use get_message() or just gm() to get the message:

get_message(CODE_FAIL);  // will return ""Fail!""
gm(CODE_FAIL);           // works exactly the same as above


Use MSG_NUM to find out how many macros have been defined. This will automatically increse, you don't need to do anything.

Predefined messages:

MSG_OK:     OK
MSG_BOTTOM: Message bottom


Project: libcodemsg



The library doesn't create extra data. Everything happens in compiling time. In message_def.h, it generates an enum called MSG_CODE; in message_def.c, it generates a variable holds all the strings in static const char* _g_messages[].

In such case, the library is limited to create one enum only. This is ideal for return values, for example:

MSG_CODE foo(void) {
    return MSG_OK; // or something else
}

MSG_CODE ret = foo();

if (MSG_OK != ret) {
    printf(""%s\n"", gm(ret););
}


Another thing I like this design is you can manage message definitions in different files.



I found the solution to this question looks much better.
    #define ENUM_MAKE(TYPE, ...) \
        enum class TYPE {__VA_ARGS__};\
        struct Helper_ ## TYPE { \
            static const String& toName(TYPE type) {\
                int index = static_cast<int>(type);\
                return splitStringVec()[index];}\
            static const TYPE toType(const String& name){\
                static std::unordered_map<String,TYPE> typeNameMap;\
                if( typeNameMap.empty() )\
                {\
                    const StringVector& ssVec = splitStringVec();\
                    for (size_t i = 0; i < ssVec.size(); ++i)\
                        typeNameMap.insert(std::make_pair(ssVec[i], static_cast<TYPE>(i)));\
                }\
                return typeNameMap[name];}\
            static const StringVector& splitStringVec() {\
                static StringVector typeNameVector;\
                if(typeNameVector.empty()) \
                {\
                    typeNameVector = StringUtil::split(#__VA_ARGS__, "","");\
                    for (auto& name : typeNameVector)\
                    {\
                        name.erase(std::remove(name.begin(), name.end(), ' '),name.end()); \
                        name = String(#TYPE) + ""::"" + name;\
                    }\
                }\
                return typeNameVector;\
            }\
        };


using String = std::string;
using StringVector = std::vector<String>;

   StringVector StringUtil::split( const String& str, const String& delims, unsigned int maxSplits, bool preserveDelims)
    {
        StringVector ret;
        // Pre-allocate some space for performance
        ret.reserve(maxSplits ? maxSplits+1 : 10);    // 10 is guessed capacity for most case

        unsigned int numSplits = 0;

        // Use STL methods 
        size_t start, pos;
        start = 0;
        do 
        {
            pos = str.find_first_of(delims, start);
            if (pos == start)
            {
                // Do nothing
                start = pos + 1;
            }
            else if (pos == String::npos || (maxSplits && numSplits == maxSplits))
            {
                // Copy the rest of the string
                ret.push_back( str.substr(start) );
                break;
            }
            else
            {
                // Copy up to delimiter
                ret.push_back( str.substr(start, pos - start) );

                if(preserveDelims)
                {
                    // Sometimes there could be more than one delimiter in a row.
                    // Loop until we don't find any more delims
                    size_t delimStart = pos, delimPos;
                    delimPos = str.find_first_not_of(delims, delimStart);
                    if (delimPos == String::npos)
                    {
                        // Copy the rest of the string
                        ret.push_back( str.substr(delimStart) );
                    }
                    else
                    {
                        ret.push_back( str.substr(delimStart, delimPos - delimStart) );
                    }
                }

                start = pos + 1;
            }
            // parse up to next real data
            start = str.find_first_not_of(delims, start);
            ++numSplits;

        } while (pos != String::npos);



        return ret;
    }


example

ENUM_MAKE(MY_TEST, MY_1, MY_2, MY_3)


    MY_TEST s1 = MY_TEST::MY_1;
    MY_TEST s2 = MY_TEST::MY_2;
    MY_TEST s3 = MY_TEST::MY_3;

    String z1 = Helper_MY_TEST::toName(s1);
    String z2 = Helper_MY_TEST::toName(s2);
    String z3 = Helper_MY_TEST::toName(s3);

    MY_TEST q1 = Helper_MY_TEST::toType(z1);
    MY_TEST q2 = Helper_MY_TEST::toType(z2);
    MY_TEST q3 = Helper_MY_TEST::toType(z3);


automatically ENUM_MAKE macro generate 'enum class' and helper class with 'enum reflection function'. 

In order to reduce mistakes, at once Everything is defined with only one ENUM_MAKE. 

The advantage of this code is automatically created for reflection and a close look at macro code ,easy-to-understand code. 'enum to string' , 'string to enum' performance both is algorithm O(1).

Disadvantages is when first use , helper class for enum relection 's string vector and map is initialized.
but If you want you'll also be pre-initialized. –
    my solution is without macro usage.

advantages:


you see exactly what you do
access is with hash maps, so good for many valued enums
no need to consider order or non-consecutive values
both enum to string and string to enum translation, while added enum value must be added in one additional place only


disadvantages:


you need to replicate all the enums values as text 
access in hash map must consider string case
maintenance if adding values is painful - must add in both enum and direct translate map


so... until the day that C++ implements the C# Enum.Parse functionality, I will be stuck with this:

            #include <unordered_map>

            enum class Language
            { unknown, 
                Chinese, 
                English, 
                French, 
                German
                // etc etc
            };

            class Enumerations
            {
            public:
                static void fnInit(void);

                static std::unordered_map <std::wstring, Language> m_Language;
                static std::unordered_map <Language, std::wstring> m_invLanguage;

            private:
                static void fnClear();
                static void fnSetValues(void);
                static void fnInvertValues(void);

                static bool m_init_done;
            };

            std::unordered_map <std::wstring, Language> Enumerations::m_Language = std::unordered_map <std::wstring, Language>();
            std::unordered_map <Language, std::wstring> Enumerations::m_invLanguage = std::unordered_map <Language, std::wstring>();

            void Enumerations::fnInit()
            {
                fnClear();
                fnSetValues();
                fnInvertValues();
            }

            void Enumerations::fnClear()
            {
                m_Language.clear();
                m_invLanguage.clear();
            }

            void Enumerations::fnSetValues(void)
            {   
                m_Language[L""unknown""] = Language::unknown;
                m_Language[L""Chinese""] = Language::Chinese;
                m_Language[L""English""] = Language::English;
                m_Language[L""French""] = Language::French;
                m_Language[L""German""] = Language::German;
                // and more etc etc
            }

            void Enumerations::fnInvertValues(void)
            {
                for (auto it = m_Language.begin(); it != m_Language.end(); it++)
                {
                    m_invLanguage[it->second] = it->first;
                }
            }

            // usage -
            //Language aLanguage = Language::English;
            //wstring sLanguage = Enumerations::m_invLanguage[aLanguage];

            //wstring sLanguage = L""French"" ;
            //Language aLanguage = Enumerations::m_Language[sLanguage];

    My answer is here. 

You can get enum value names and these indices simultaneously as deque of string. 

This method only needs little copy and paste and edit.

Obtained result needs type-casting from size_t to enum class type when you need enum class type value, but I think it is a very portable and powerful way to treat enum class.

enum class myenum
{
  one = 0,
  two,
  three,
};

deque<string> ssplit(const string &_src, boost::regex &_re)
{
  boost::sregex_token_iterator it(_src.begin(), _src.end(), _re, -1);
  boost::sregex_token_iterator e;
  deque<string> tokens;
  while (it != e)
    tokens.push_back(*it++);
  return std::move(tokens);
}

int main()
{
  regex re("","");
  deque<string> tokens = ssplit(""one,two,three"", re);
  for (auto &t : tokens) cout << t << endl;
    getchar();
  return 0;
}

    My 3 cents, though this is not a complete match to what the op wants. Here is the relevant reference.
namespace enums
{

template <typename T, T I, char ...Chars>
struct enums : std::integral_constant<T, I>
{
  static constexpr char const chars[sizeof...(Chars)]{Chars...};
};

template <typename T, T X, typename S, std::size_t ...I>
constexpr auto make(std::index_sequence<I...>) noexcept
{
  return enums<T, X, S().chars[I]...>();
}

#define ENUM(s, n) []() noexcept{\
  struct S { char const (&chars)[sizeof(s)]{s}; };\
  return enums::make<decltype(n), n, S>(\
    std::make_index_sequence<sizeof(s)>());}()

#define ENUM_T(s, n)\
  static constexpr auto s ## _tmp{ENUM(#s, n)};\
  using s ## _enum_t = decltype(s ## _tmp)

template <typename T, typename ...A, std::size_t N>
inline auto map(char const (&s)[N]) noexcept
{
  constexpr auto invalid(~T{});

  auto r{invalid};

  return
    (
      (
        invalid == r ?
          r = std::strncmp(A::chars, s, N) ? invalid : A{} :
          r
      ),
      ...
    );
}

}

int main()
{
  ENUM_T(echo, 0);
  ENUM_T(cat, 1);
  ENUM_T(ls, 2);

  std::cout << echo_enum_t{} << "" "" << echo_enum_t::chars << std::endl;

  std::cout << enums::map<int, echo_enum_t, cat_enum_t, ls_enum_t>(""ls"")) << std::endl;

  return 0;
}

So you generate a type, that you can convert to an integer and/or a string.
    ","[488, 95, 103, 21, 27, 86, 30, 2, 3, 2, 3, 10, 1, 7, 4, 3, 1, 1, 0, 2, 1, 1, 1, 1, 3, -2, 0, 0, 0, 0, 0]",276547,231,2015-03-03T10:05:45,2021-11-29 16:34:04Z,c c c c c c c c c c c 
Set the maximum character length of a UITextField,"
                
How can I set the maximum amount of characters in a UITextField on the iPhone SDK when I load up a UIView?
    Swift 4
import UIKit

private var kAssociationKeyMaxLength: Int = 0

extension UITextField {
    
    @IBInspectable var maxLength: Int {
        get {
            if let length = objc_getAssociatedObject(self, &kAssociationKeyMaxLength) as? Int {
                return length
            } else {
                return Int.max
            }
        }
        set {
            objc_setAssociatedObject(self, &kAssociationKeyMaxLength, newValue, .OBJC_ASSOCIATION_RETAIN)
            addTarget(self, action: #selector(checkMaxLength), for: .editingChanged)
        }
    }
    
    @objc func checkMaxLength(textField: UITextField) {
        guard let prospectiveText = self.text,
            prospectiveText.count > maxLength
            else {
                return
        }
        
        let selection = selectedTextRange
        
        let indexEndOfText = prospectiveText.index(prospectiveText.startIndex, offsetBy: maxLength)
        let substring = prospectiveText[..<indexEndOfText]
        text = String(substring)
        
        selectedTextRange = selection
    }
}

Edit: memory leak issue fixed.

    Use below extension to set the maximum character length of a UITextField and UITextView.

Swift 4.0

    private var kAssociationKeyMaxLength: Int = 0
    private var kAssociationKeyMaxLengthTextView: Int = 0
    extension UITextField {


        @IBInspectable var maxLength: Int {
            get {
                if let length = objc_getAssociatedObject(self, &kAssociationKeyMaxLength) as? Int {
                    return length
                } else {
                    return Int.max
                }
            }
            set {
                objc_setAssociatedObject(self, &kAssociationKeyMaxLength, newValue, .OBJC_ASSOCIATION_RETAIN)
                addTarget(self, action: #selector(checkMaxLength), for: .editingChanged)
            }
        }

        @objc func checkMaxLength(textField: UITextField) {
            guard let prospectiveText = self.text,
                prospectiveText.count > maxLength
                else {
                    return
            }

            let selection = selectedTextRange

            let indexEndOfText = prospectiveText.index(prospectiveText.startIndex, offsetBy: maxLength)
            let substring = prospectiveText[..<indexEndOfText]
            text = String(substring)

            selectedTextRange = selection
        }
    }


UITextView

extension UITextView:UITextViewDelegate {


        @IBInspectable var maxLength: Int {
            get {
                if let length = objc_getAssociatedObject(self, &kAssociationKeyMaxLengthTextView) as? Int {
                    return length
                } else {
                    return Int.max
                }
            }
            set {
                self.delegate = self

                objc_setAssociatedObject(self, &kAssociationKeyMaxLengthTextView, newValue, .OBJC_ASSOCIATION_RETAIN)
            }
        }

        public func textViewDidChange(_ textView: UITextView) {
            checkMaxLength(textField: self)
        }
        @objc func checkMaxLength(textField: UITextView) {
            guard let prospectiveText = self.text,
                prospectiveText.count > maxLength
                else {
                    return
            }

            let selection = selectedTextRange

            let indexEndOfText = prospectiveText.index(prospectiveText.startIndex, offsetBy: maxLength)
            let substring = prospectiveText[..<indexEndOfText]
            text = String(substring)

            selectedTextRange = selection
        }
    }


You can set limit below.


    There is generic solution for setting max length in Swift.
By IBInspectable you can add new Attribute in Xcode Attribute Inspector.

import UIKit
private var maxLengths = [UITextField: Int]()
extension UITextField {

    @IBInspectable var maxLength: Int {
        get {
            guard let length = maxLengths[self]
            else {
                return Int.max
            }
            return length
        }
        set {
            maxLengths[self] = newValue
            addTarget(
                self,
                action: Selector(""limitLength:""),
                forControlEvents: UIControlEvents.EditingChanged
            )
        }
    }

    func limitLength(textField: UITextField) {
        guard let prospectiveText = textField.text
            where prospectiveText.characters.count > maxLength else {
                return
        }
        let selection = selectedTextRange
        text = prospectiveText.substringWithRange(
            Range<String.Index>(prospectiveText.startIndex ..< prospectiveText.startIndex.advancedBy(maxLength))
        )
        selectedTextRange = selection
    }

}

    Often you have multiple input fields with a different length.

- (BOOL)textField:(UITextField *)textField shouldChangeCharactersInRange:(NSRange)range replacementString:(NSString *)string {
    int allowedLength;
    switch(textField.tag) {
        case 1: 
            allowedLength = MAXLENGTHNAME;      // triggered for input fields with tag = 1
            break;
        case 2:
            allowedLength = MAXLENGTHADDRESS;   // triggered for input fields with tag = 2
            break;
        default:
            allowedLength = MAXLENGTHDEFAULT;   // length default when no tag (=0) value =255
            break;
    }

    if (textField.text.length >= allowedLength && range.length == 0) {
        return NO; // Change not allowed
    } else {
        return YES; // Change allowed
    }
}

    What about this simple approach. Its working fine for me.

extension UITextField {

    func  charactersLimit(to:Int) {

        if (self.text!.count > to) {
            self.deleteBackward()
        }
    }
}


Then:

someTextField.charactersLimit(to:16)

    Swift 4

func textField(_ textField: UITextField, shouldChangeCharactersIn range: NSRange, replacementString string: String) -> Bool {
    guard let text = textField.text else { return true }
    let newLength = text.count + string.count - range.length
    return newLength <= 10
}

    To complete August answer, an possible implementation of the proposed function  (see UITextField's delegate).

I did not test domness code, but mine do not get stuck if the user reached the limit, and it is compatible with a new string that comes replace a smaller or equal one.

-(BOOL)textField:(UITextField *)textField shouldChangeCharactersInRange:(NSRange)range replacementString:(NSString *)string {
    //limit the size :
    int limit = 20;
    return !([textField.text length]>limit && [string length] > range.length);
}

    I give a supplementary answer based on @Frouo.  I think his answer is the most beautiful way. Becuase it's a common control we can reuse. 

private var kAssociationKeyMaxLength: Int = 0

extension UITextField {

    @IBInspectable var maxLength: Int {
        get {
            if let length = objc_getAssociatedObject(self, &kAssociationKeyMaxLength) as? Int {
                return length
            } else {
                return Int.max
            }
        }
        set {
            objc_setAssociatedObject(self, &kAssociationKeyMaxLength, newValue, .OBJC_ASSOCIATION_RETAIN)
            self.addTarget(self, action: #selector(checkMaxLength), for: .editingChanged)
        }
    }

    func checkMaxLength(textField: UITextField) {

        guard !self.isInputMethod(), let prospectiveText = self.text,
            prospectiveText.count > maxLength
            else {
                return
        }

        let selection = selectedTextRange
        let maxCharIndex = prospectiveText.index(prospectiveText.startIndex, offsetBy: maxLength)
        text = prospectiveText.substring(to: maxCharIndex)
        selectedTextRange = selection
    }

    //The method is used to cancel the check when use Chinese Pinyin input method.
    //Becuase the alphabet also appears in the textfield when inputting, we should cancel the check.
    func isInputMethod() -> Bool {
        if let positionRange = self.markedTextRange {
            if let _ = self.position(from: positionRange.start, offset: 0) {
                return true
            }
        }
        return false
    }

}

    You can also do this using NotificationCenter in Swift 4  

NotificationCenter.default.addObserver(self, selector: #selector(self.handleTextChange(recognizer:)), name: NSNotification.Name.UITextFieldTextDidChange, object: yourTextField)

    @objc func handleTextChange(recognizer: NSNotification) {
            //max length is 50 charater max
            let textField = recognizer.object as! UITextField

            if((textField.text?.count)! > 50) {
                let newString: String? = (textField.text as NSString?)?.substring(to: 50)
                textField.text = newString

            }         
        }

    Swift 4.2 and UITextFieldDelegate method

This works for me and limits the textfield to have a max input of 8 characters. Hopefully NSRange will eventually be changed to Range but for now I am happy to use NSString as creating a Range from NSRange involves dealing with another optional.

func textField(_ textField: UITextField, shouldChangeCharactersIn range: NSRange, replacementString string: String) -> Bool {
    let text = textField.text ?? """"
    let nsString = text as NSString
    let newText = nsString.replacingCharacters(in: range, with: string)
    return newText.count <= 8
}

    If your purpose of limiting text count is to ensure that text will fit into a UILabel elsewhere, I'd avoid using character count. It breaks down with some emoji (trying to truncate a double size emoji will likely crash your app). It's also an issue with some languages like Japanese and Chinese, which have a two-step input process where a simple count just won't work. 

I built out a UITextField drop-in subclass (MPC_CharacterLimitedTextField on github). You feed it the expected output label width and it will handle all languages, emoji, and pasting issues. It will harvest only as many full characters that will fit into the label, regardless of the character count. There's a demo in the project so you can test it to see if it's what you need. Hope it will help anybody who was having the same problems with output length that I was. 
    This should be enough to solve the problem (replace 4 by the limit u want). Just make sure to add delegate in IB.

- (BOOL)textField:(UITextField *)textField shouldChangeCharactersInRange:(NSRange)range replacementString:(NSString *)string
{
     NSString *newString = [textField.text stringByReplacingCharactersInRange:range withString:string];
     return (newString.length<=4);
}

    Thank you august! (Post)

This is the code that I ended up with which works:

#define MAX_LENGTH 20

- (BOOL)textField:(UITextField *)textField shouldChangeCharactersInRange:(NSRange)range replacementString:(NSString *)string
{
    if (textField.text.length >= MAX_LENGTH && range.length == 0)
    {
        return NO; // return NO to not change text
    }
    else
    {return YES;}
}

    I simulate the actual string replacement that's about to happen to calculate that future string's length:

- (BOOL)textField:(UITextField *)textField shouldChangeCharactersInRange:(NSRange)range replacementString:(NSString *)string {

    NSString *newString = [textField.text stringByReplacingCharactersInRange:range withString:string];

    if([newString length] > maxLength)
       return NO;

    return YES;
}

    swift 3.0
This code is working fine when you are paste string more than your character limits.
func textView(_ textView: UITextView, shouldChangeTextIn range: NSRange, replacementText text: String) -> Bool {
        let str = (textView.text + text)
        if str.characters.count <= 10 {
            return true
        }
        textView.text = str.substring(to: str.index(str.startIndex, offsetBy: 10))
        return false
    }

Thanks for your votes. :)
    Swift 3 version
//***** This will NOT work with Swift 2.x! *****//

First create a new Swift file : TextFieldMaxLength.swift,
and then add the code below:

import UIKit

private var maxLengths = [UITextField: Int]()

extension UITextField {

   @IBInspectable var maxLength: Int {

      get {

          guard let length = maxLengths[self] 
             else {
                return Int.max
      }
      return length
   }
   set {
      maxLengths[self] = newValue
      addTarget(
         self,
         action: #selector(limitLength),
         for: UIControlEvents.editingChanged
      )
   }
}
func limitLength(textField: UITextField) {
    guard let prospectiveText = textField.text,
        prospectiveText.characters.count > maxLength
    else {
        return
    }

   let selection = selectedTextRange
   let maxCharIndex = prospectiveText.index(prospectiveText.startIndex, offsetBy: maxLength)
   text = prospectiveText.substring(to: maxCharIndex)
   selectedTextRange = selection
   }
}


and then you will see in Storyboard a new field (Max Length) when you select any TextField

if you still have more questions check out this link: http://www.globalnerdy.com/2016/05/18/ios-programming-trick-how-to-use-xcode-to-set-a-text-fields-maximum-length-visual-studio-style/
    The following code is similar to sickp's answer but handles correctly copy-paste operations. If you try to paste a text that is longer than the limit, the following code will truncate the text to fit the limit instead of refusing the paste operation completely.

- (BOOL)textField:(UITextField *)textField shouldChangeCharactersInRange:(NSRange)range replacementString:(NSString *)string {
    static const NSUInteger limit = 70; // we limit to 70 characters
    NSUInteger allowedLength = limit - [textField.text length] + range.length;
    if (string.length > allowedLength) {
        if (string.length > 1) {
            // get at least the part of the new string that fits
            NSString *limitedString = [string substringToIndex:allowedLength];
            NSMutableString *newString = [textField.text mutableCopy];
            [newString replaceCharactersInRange:range withString:limitedString];
            textField.text = newString;
        }
        return NO;
    } else {
        return YES;
    }
}

    I did this in Swift for an 8 character limit when using a number pad.

func textField(textField: UITextField, shouldChangeCharactersInRange range: NSRange, replacementString string: String) -> Bool {
    return !(textField.text?.characters.count == MAX_LENGTH && string != """")
}


I had to test for string != """" to allow the delete button to work on the number pad, otherwise it wouldn't allow deleting characters in the text field after it reached its max.
    The best way would be to set up a notification on the text changing. In your -awakeFromNib of your view controller method you'll want:

[[NSNotificationCenter defaultCenter] addObserver:self selector:@selector(limitTextField:) name:@""UITextFieldTextDidChangeNotification"" object:myTextField];


Then in the same class add:

- (void)limitTextField:(NSNotification *)note {
    int limit = 20;
    if ([[myTextField stringValue] length] > limit) {
        [myTextField setStringValue:[[myTextField stringValue] substringToIndex:limit]];
    }
}


Then link up the outlet myTextField to your UITextField and it will not let you add any more characters after you hit the limit. Be sure to add this to your dealloc method:

[[NSNotificationCenter defaultCenter] removeObserver:self name:@""UITextFieldTextDidChangeNotification"" object:myTextField];

    -(BOOL)textField:(UITextField *)textField shouldChangeCharactersInRange:(NSRange)range replacementString:(NSString *)string {
    if (textField.text.length >= 50) {
        return NO;
    }
    return YES;
}

    This is the correct way to handle max length on UITextField, it allows the return key to exit the resign the textfield as first responder and lets the user backspace when they reach the limit

- (BOOL)textField:(UITextField *)textField shouldChangeCharactersInRange:(NSRange)range replacementString:(NSString *)string {
int MAX_LENGHT = 5;
    if([string isEqualToString:@""\n""])
    {
        [textField resignFirstResponder];
        return FALSE;
    }
    else if(textField.text.length > MAX_LENGHT-1)
    {
        if([string isEqualToString:@""""] && range.length == 1)
        {
            return TRUE;
        }
        else
        {
            return FALSE;
        }
    }
    else
    {
        return TRUE;
    }
}

    Swift 4.2+

By implementing UITextFieldDelegate method


ViewController:

class MyViewController: UIViewController {

    let MAX_LENGTH = 256

    @IBOutlet weak var myTextField: UITextField!

    override viewDidLoad() {
        self.myTextField.delegate = self
    }
}

Delegate:

extension MyViewController: UITextFieldDelegate {

    func textField(_ textField: UITextField, shouldChangeCharactersIn range: NSRange, replacementString string: String) -> Bool {
        let userText =  textView.text ?? """"
        var newText = """"
        if range.length > 0 {
            let txt = NSString(string: userText)
            if txt.length > 0 {
                newText = txt.replacingCharacters(in: range, with: text)
            }
        } else {
            newText = userText + text
        }
        return newText.count <= MAX_LENGTH
    }

}


    While the UITextField class has no max length property, it's relatively simple to get this functionality by setting the text field's delegate and implementing the following delegate method:
Objective-C
- (BOOL)textField:(UITextField *)textField shouldChangeCharactersInRange:(NSRange)range replacementString:(NSString *)string {
    // Prevent crashing undo bug – see note below.
    if(range.length + range.location > textField.text.length)
    {
        return NO;
    }
        
    NSUInteger newLength = [textField.text length] + [string length] - range.length;
    return newLength <= 25;
}

Swift
func textField(_ textField: UITextField, shouldChangeCharactersIn range: NSRange, replacementString string: String) -> Bool {
    
    let currentCharacterCount = textField.text?.count ?? 0
    if range.length + range.location > currentCharacterCount {
        return false
    }
    let newLength = currentCharacterCount + string.count - range.length
    return newLength <= 25
}

Before the text field changes, the UITextField asks the delegate if the specified text should be changed. The text field has not changed at this point, so we grab it's current length and the string length we're inserting (either through pasting copied text or typing a single character using the keyboard), minus the range length. If this value is too long (more than 25 characters in this example), return NO to prohibit the change.
When typing in a single character at the end of a text field, the range.location will be the current field's length, and range.length will be 0 because we're not replacing/deleting anything. Inserting into the middle of a text field just means a different range.location, and pasting multiple characters just means string has more than one character in it.
Deleting single characters or cutting multiple characters is specified by a range with a non-zero length, and an empty string. Replacement is just a range deletion with a non-empty string.
A note on the crashing ""undo"" bug
As is mentioned in the comments, there is a bug with UITextField that can lead to a crash.
If you paste in to the field, but the paste is prevented by your validation implementation, the paste operation is still recorded in the application's undo buffer. If you then fire an undo (by shaking the device and confirming an Undo), the UITextField will attempt to replace the string it thinks it pasted in to itself with an empty string. This will crash because it never actually pasted the string in to itself. It will try to replace a part of the string that doesn't exist.
Fortunately you can protect the UITextField from killing itself like this. You just need to ensure that the range it proposes to replace does exist within its current string. This is what the initial sanity check above does.
swift 3.0 with copy and paste working fine.
func textView(_ textView: UITextView, shouldChangeTextIn range: NSRange, replacementText text: String) -> Bool {
        let str = (textView.text + text)
        if str.characters.count <= 10 {
            return true
        }
        textView.text = str.substring(to: str.index(str.startIndex, offsetBy: 10))
        return false
    }

Hope it's helpful to you.
    You can't do this directly - UITextField has no maxLength attribute, but you can set the UITextField's delegate, then use:

- (BOOL)textField:(UITextField *)textField shouldChangeCharactersInRange:(NSRange)range replacementString:(NSString *)string

    I created this UITextFieldLimit subclass:


Multiple textfields supported
Set the text length limit
Paste prevention
Displays a label of left characters inside the textfield, get hidden when you stop editing.
Shake animation when no characters left.


Grab the UITextFieldLimit.h and UITextFieldLimit.m from this GitHub repository:

https://github.com/JonathanGurebo/UITextFieldLimit

and begin to test!

Mark your storyboard-created UITextField and link it to my subclass using the Identity Inspector:



Then you can link it to an IBOutlet and set the limit(default is 10).



Your ViewController.h file should contain: (if you wan't to modify the setting, like the limit)

#import ""UITextFieldLimit.h""

/.../

@property (weak, nonatomic) IBOutlet UITextFieldLimit *textFieldLimit; // <--Your IBOutlet




Your ViewController.m file should @synthesize textFieldLimit.



Set the text length limit in your ViewController.m file:

- (void)viewDidLoad
{
    [super viewDidLoad];
// Do any additional setup after loading the view, typically from a nib.

    [textFieldLimit setLimit:25];// <-- and you won't be able to put more than 25 characters in the TextField.
}


Hope the class helps you. Good luck!
    Using Interface builder you can link and get the event for ""Editing changed"" in any of your function.
Now there you can put check for the length

- (IBAction)onValueChange:(id)sender 
{
    NSString *text = nil;
    int MAX_LENGTH = 20;
    switch ([sender tag] ) 
    {
        case 1: 
        {
            text = myEditField.text;
            if (MAX_LENGTH < [text length]) {
                myEditField.text = [text substringToIndex:MAX_LENGTH];
            }
        }
            break;
        default:
            break;
    }

}

    To make it work with cut & paste of strings of any length, I would suggest changing the function to something like: 

#define MAX_LENGTH 20

- (BOOL)textField:(UITextField *)textField shouldChangeCharactersInRange:(NSRange)range replacementString:(NSString *)string
    {
        NSInteger insertDelta = string.length - range.length;

        if (textField.text.length + insertDelta > MAX_LENGTH)
        {
           return NO; // the new string would be longer than MAX_LENGTH
        }
        else {
            return YES;
        }
    }

    Swift 2.0 +

First of all create a class for this process. Lets call it StringValidator.swift.

Then just paste the following code inside it.

import Foundation

extension String {

func containsCharactersIn(matchCharacters: String) -> Bool {
let characterSet = NSCharacterSet(charactersInString: matchCharacters)
return self.rangeOfCharacterFromSet(characterSet) != nil
}

func containsOnlyCharactersIn(matchCharacters: String) -> Bool {
let disallowedCharacterSet = NSCharacterSet(charactersInString: matchCharacters).invertedSet
return self.rangeOfCharacterFromSet(disallowedCharacterSet) == nil
}


func doesNotContainCharactersIn(matchCharacters: String) -> Bool {
let characterSet = NSCharacterSet(charactersInString: matchCharacters)
return self.rangeOfCharacterFromSet(characterSet) == nil
}

func isNumeric() -> Bool
{
let scanner = NSScanner(string: self)
scanner.locale = NSLocale.currentLocale()

return scanner.scanDecimal(nil) && scanner.atEnd
}

}


Now save the class.....

Usage..

Now goto your viewController.swift class and make your textfield's outlets as..

@IBOutlet weak var contactEntryTxtFld: UITextField! //First textfield
@IBOutlet weak var contactEntryTxtFld2: UITextField!   //Second textfield


Now goto the textfield's shouldChangeCharactersInRange method and use like the following.

func textField(textField: UITextField, shouldChangeCharactersInRange range: NSRange, replacementString string: String) -> Bool {
    if string.characters.count == 0 {
        return true
    }
    let latestText = textField.text ?? """"
    let checkAbleText = (latestText as NSString).stringByReplacingCharactersInRange(range, withString: string)


    switch textField {

    case contactEntryTxtFld:
        return checkAbleText.containsOnlyCharactersIn(""0123456789"") && prospectiveText.characters.count <= 5

    case contactEntryTxtFld2:
        return checkAbleText.containsOnlyCharactersIn(""0123456789"") && prospectiveText.characters.count <= 5

    default:
        return true
    }

}


Don't forget to set the delegate protocol/methods of textfields.

Let me explain about this... I am using the simple extension process of string which I wrote inside an another class. Now I am just calling those extension methods from another class where I need them by adding check and maximum value.

Features...


It will set maximum limit of a particular textfield.
It will set type of accepted keys for particular textfield.


Types...

containsOnlyCharactersIn //Accepts only Characters.

containsCharactersIn    //Accepts combination of characters

doesNotContainsCharactersIn  //Will not accept characters

Hope this helped....
Thanks..
    Other answers do not handle the case where user can paste a long string from clipboard. If I paste a long string it should just be truncated but shown.
Use this in your delegate:

static const NSUInteger maxNoOfCharacters = 5;

-(IBAction)textdidChange:(UITextField * )textField
{
NSString * text = textField.text;

if(text.length > maxNoOfCharacters)
{
    text = [text substringWithRange:NSMakeRange(0, maxNoOfCharacters)];
    textField.text = text;
}

// use 'text'

}

    Got it down to 1 line of code :)

Set your text view's delegate to ""self"" then add the <UITextViewDelegate> in your .h and the following code in your .m .... you can adjust the number ""7"" to be whatever you want your MAXIMUM number of characters to be. 

-(BOOL)textView:(UITextView *)a shouldChangeTextInRange:(NSRange)b replacementText:(NSString *)c {
    return ((a.text.length+c.length<=7)+(c.length<1)+(b.length>=c.length)>0);
}


This code accounts for typing new characters, deleting characters, selecting characters then typing or deleting, selecting characters and cutting, pasting in general, and selecting characters and pasting.

Done!





Alternatively, another cool way to write this code with bit-operations would be

-(BOOL)textView:(UITextView *)a shouldChangeTextInRange:(NSRange)b replacementText:(NSString *)c {
    return 0^((a.text.length+c.length<=7)+(c.length<1)+(b.length>=c.length));
}

    ","[487, 73, 11, 7, 14, 2, 4, 22, 3, 1, 1, 1, 11, 55, 7, 3, 7, 6, 1, 11, -1, 2, -1, 1045, 17, 11, 6, 5, 3, 1, 1]",298674,198,2009-01-11T18:08:11,2021-08-26 08:37:47Z,
Comparing date part only without comparing time in JavaScript,"
                
What is wrong with the code below?

Maybe it would be simpler to just compare date and not time. I am not sure how to do this either, and I searched, but I couldn't find my exact problem.

BTW, when I display the two dates in an alert, they show as exactly the same.

My code:

window.addEvent('domready', function() {
    var now = new Date();
    var input = $('datum').getValue();
    var dateArray = input.split('/');
    var userMonth = parseInt(dateArray[1])-1;
    var userDate = new Date();
    userDate.setFullYear(dateArray[2], userMonth, dateArray[0], now.getHours(), now.getMinutes(), now.getSeconds(), now.getMilliseconds());

    if (userDate > now)
    {
        alert(now + '\n' + userDate);
    }
});


Is there a simpler way to compare dates and not including the time?
    I'm still learning JavaScript, and the only way that I've found which works for me to compare two dates without the time is to use the setHours method of the Date object and set the hours, minutes, seconds and milliseconds to zero. Then compare the two dates.

For example,

date1 = new Date()
date2 = new Date(2011,8,20)


date2 will be set with hours, minutes, seconds and milliseconds to zero, but date1 will have them set to the time that date1 was created. To get rid of the hours, minutes, seconds and milliseconds on date1 do the following:

date1.setHours(0,0,0,0)


Now you can compare the two dates as DATES only without worrying about time elements.
    BEWARE THE TIMEZONE
Using the date object to represent just-a-date straight away gets you into a huge excess precision problem. You need to manage time and timezone to keep them out, and they can sneak back in at any step. The accepted answer to this question falls into the trap.
A javascript date has no notion of timezone. It's a moment in time (ticks since the epoch) with handy (static) functions for translating to and from strings, using by default the ""local"" timezone of the device, or, if specified, UTC or another timezone. To represent just-a-date™ with a date object, you want your dates to represent UTC midnight at the start of the date in question. This is a common and necessary convention that lets you work with dates regardless of the season or timezone of their creation. So you need to be very vigilant to manage the notion of timezone, both when you create your midnight UTC Date object, and when you serialize it.
Lots of folks are confused by the default behaviour of the console. If you spray a date to the console, the output you see will include your timezone. This is just because the console calls toString() on your date, and toString() gives you a local represenation. The underlying date has no timezone! (So long as the time matches the timezone offset, you still have a midnight UTC date object)
Deserializing (or creating midnight UTC Date objects)
This is the rounding step, with the trick that there are two ""right"" answers. Most of the time, you will want your date to reflect the local timezone of the user. What's the date here where I am.. Users in NZ and US can click at the same time and usually get different dates. In that case, do this...
// create a date (utc midnight) reflecting the value of myDate and the environment's timezone offset.
new Date(Date.UTC(myDate.getFullYear(),myDate.getMonth(), myDate.getDate()));

Sometimes, international comparability trumps local accuracy. In that case, do this...
// the date in London of a moment in time. Device timezone is ignored.
new Date(Date.UTC(myDate.getUTCFullYear(), myDate.getUTCMonth(), myDate.getUTCDate()));

Deserialize a date
Often dates on the wire will be in the format YYYY-MM-DD. To deserialize them, do this...
var midnightUTCDate = new Date( dateString + 'T00:00:00Z');

Serializing
Having taken care to manage timezone when you create, you now need to be sure to keep timezone out when you convert back to a string representation. So you can safely use...

toISOString()
getUTCxxx()
getTime() //returns a number with no time or timezone.
.toLocaleDateString(""fr"",{timeZone:""UTC""}) // whatever locale you want, but ALWAYS UTC.

And totally avoid everything else, especially...

getYear(),getMonth(),getDate()

So to answer your question, 7 years too late...
<input type=""date"" onchange=""isInPast(event)"">
<script>
var isInPast = function(event){
  var userEntered = new Date(event.target.valueAsNumber); // valueAsNumber has no time or timezone!
  var now = new Date();
  var today = new Date(Date.UTC(now.getUTCFullYear(), now.getUTCMonth(), now.getUTCDate() ));
  if(userEntered.getTime() < today.getTime())
    alert(""date is past"");
  else if(userEntered.getTime() == today.getTime())
    alert(""date is today"");
  else
    alert(""date is future"");

}
</script>

See it running...
Update 2019... free stuff...
Given the popularity of this answer, I've put it all in code. The following function returns a wrapped date object, and only exposes those functions that are safe to use with just-a-date™.
Call it with a Date object and it will resolve to JustADate reflecting the timezone of the user. Call it with a string: if the string is an ISO 8601 with timezone specified, we'll just round off the time part. If timezone is not specified, we'll convert it to a date reflecting the local timezone, just as for date objects.
function JustADate(initDate){
  var utcMidnightDateObj = null
  // if no date supplied, use Now.
  if(!initDate)
    initDate = new Date();

  // if initDate specifies a timezone offset, or is already UTC, just keep the date part, reflecting the date _in that timezone_
  if(typeof initDate === ""string"" && initDate.match(/((\+|-)\d{2}:\d{2}|Z)$/gm)){  
     utcMidnightDateObj = new Date( initDate.substring(0,10) + 'T00:00:00Z');
  } else {
    // if init date is not already a date object, feed it to the date constructor.
    if(!(initDate instanceof Date))
      initDate = new Date(initDate);
      // Vital Step! Strip time part. Create UTC midnight dateObj according to local timezone.
      utcMidnightDateObj = new Date(Date.UTC(initDate.getFullYear(),initDate.getMonth(), initDate.getDate()));
  }

  return {
    toISOString:()=>utcMidnightDateObj.toISOString(),
    getUTCDate:()=>utcMidnightDateObj.getUTCDate(),
    getUTCDay:()=>utcMidnightDateObj.getUTCDay(),
    getUTCFullYear:()=>utcMidnightDateObj.getUTCFullYear(),
    getUTCMonth:()=>utcMidnightDateObj.getUTCMonth(),
    setUTCDate:(arg)=>utcMidnightDateObj.setUTCDate(arg),
    setUTCFullYear:(arg)=>utcMidnightDateObj.setUTCFullYear(arg),
    setUTCMonth:(arg)=>utcMidnightDateObj.setUTCMonth(arg),
    addDays:(days)=>{
      utcMidnightDateObj.setUTCDate(utcMidnightDateObj.getUTCDate + days)
    },
    toString:()=>utcMidnightDateObj.toString(),
    toLocaleDateString:(locale,options)=>{
      options = options || {};
      options.timeZone = ""UTC"";
      locale = locale || ""en-EN"";
      return utcMidnightDateObj.toLocaleDateString(locale,options)
    }
  }
}


// if initDate already has a timezone, we'll just use the date part directly
console.log(JustADate('1963-11-22T12:30:00-06:00').toLocaleDateString())

    An efficient and correct way to compare dates is:

Math.floor(date1.getTime() / 86400000) > Math.floor(date2.getTime() / 86400000);


It ignores the time part, it works for different timezones, and you can compare for equality == too. 86400000 is the number of milliseconds in a day (= 24*60*60*1000). 

Beware that the equality operator == should never be used for comparing Date objects because it fails when you would expect an equality test to work because it is comparing two Date objects (and does not compare the two dates) e.g.:

> date1;
outputs: Thu Mar 08 2018 00:00:00 GMT+1300

> date2;
outputs: Thu Mar 08 2018 00:00:00 GMT+1300

> date1 == date2;
outputs: false

> Math.floor(date1.getTime() / 86400000) == Math.floor(date2.getTime() / 86400000);
outputs: true


Notes: If you are comparing Date objects that have the time part set to zero, then you could use date1.getTime() == date2.getTime() but it is hardly worth the optimisation. You can use <, >, <=, or >= when comparing Date objects directly because these operators first convert the Date object by calling .valueOf() before the operator does the comparison.
    If you are truly comparing date only with no time component, another solution that may feel wrong but works and avoids all Date() time and timezone headaches is to compare the ISO string date directly using string comparison:

> ""2019-04-22"" <= ""2019-04-23""
true
> ""2019-04-22"" <= ""2019-04-22""
true
> ""2019-04-22"" <= ""2019-04-21""
false
> ""2019-04-22"" === ""2019-04-22""
true


You can get the current date (UTC date, not neccesarily the user's local date) using:

> new Date().toISOString().split(""T"")[0]
""2019-04-22""


My argument in favor of it is programmer simplicity -- you're much less likely to botch this than trying to handle datetimes and offsets correctly, probably at the cost of speed (I haven't compared performance)
    Just use toDateString() on both dates. toDateString doesn't include the time, so for 2 times on the same date, the values will be equal, as demonstrated below. 

var d1 = new Date(2019,01,01,1,20)
var d2 = new Date(2019,01,01,2,20)
console.log(d1==d2) // false
console.log(d1.toDateString() == d2.toDateString()) // true


Obviously some of the timezone concerns expressed elsewhere on this question are valid, but in many scenarios, those are not relevant. 
    Simply compare using .toDateString like below:

new Date().toDateString();


This will return you date part only and not time or timezone, like this:


  ""Fri Feb 03 2017""


Hence both date can be compared in this format likewise without time part of it.
    How about this? 

Date.prototype.withoutTime = function () {
    var d = new Date(this);
    d.setHours(0, 0, 0, 0);
    return d;
}


It allows you to compare the date part of the date like this without affecting the value of your variable:

var date1 = new Date(2014,1,1);
new Date().withoutTime() > date1.withoutTime(); // true

    Compare Date and Time:
var t1 = new Date(); // say, in ISO String =  '2022-01-21T12:30:15.422Z'
var t2 = new Date(); // say, in ISO String =  '2022-01-21T12:30:15.328Z'
var t3 = t1;

Compare 2 date objects by milliseconds level:
console.log(t1 === t2); // false - Bcos there is some milliseconds difference
console.log(t1 === t3); // true - Both dates have milliseconds level same values

Compare 2 date objects ONLY by date (Ignore any time difference):
console.log(t1.toISOString().split('T')[0] === t2.toISOString().split('T')[0]); 
                                        // true; '2022-01-21' === '2022-01-21'

Compare 2 date objects ONLY by time(ms) (Ignore any date difference):
console.log(t1.toISOString().split('T')[1] === t3.toISOString().split('T')[1]); 
                                      // true; '12:30:15.422Z' === '12:30:15.422Z'

Above 2 methods uses toISOString() method so you no need to worry about the time zone difference across the countries.
    You can use fp_incr(0). Which sets the timezone part to midnight and returns a date object.
    This JS will change the content after the set date 
here's the same thing but on w3schools

date1 = new Date()
date2 = new Date(2019,5,2) //the date you are comparing

date1.setHours(0,0,0,0)

var stockcnt = document.getElementById('demo').innerHTML;
if (date1 > date2){
document.getElementById('demo').innerHTML=""yes""; //change if date is > set date (date2)
}else{
document.getElementById('demo').innerHTML=""hello""; //change if date is < set date (date2)
}<p id=""demo"">hello</p> <!--What will be changed-->
<!--if you check back in tomorrow, it will say yes instead of hello... or you could change the date... or change > to <-->

    Using Moment.js

If you have the option of including a third-party library, it's definitely worth taking a look at Moment.js. It makes working with Date and DateTime much, much easier.

For example, seeing if one Date comes after another Date but excluding their times, you would do something like this:

var date1 = new Date(2016,9,20,12,0,0); // October 20, 2016 12:00:00
var date2 = new Date(2016,9,20,12,1,0); // October 20, 2016 12:01:00

// Comparison including time.
moment(date2).isAfter(date1); // => true

// Comparison excluding time.
moment(date2).isAfter(date1, 'day'); // => false


The second parameter you pass into isAfter is the precision to do the comparison and can be any of year, month, week, day, hour, minute or second.
    This works for me:

 export default (chosenDate) => {
  const now = new Date();
  const today = new Date(Date.UTC(now.getUTCFullYear(), now.getUTCMonth(), now.getUTCDate()));
  const splitChosenDate = chosenDate.split('/');

  today.setHours(0, 0, 0, 0);
  const fromDate = today.getTime();
  const toDate = new Date(splitChosenDate[2], splitChosenDate[1] - 1, splitChosenDate[0]).getTime();

  return toDate < fromDate;
};


In accepted answer, there is timezone issue and in the other time is not 00:00:00
    Comparing with setHours() will be a solution. Sample:

var d1 = new Date();
var d2 = new Date(""2019-2-23"");
if(d1.setHours(0,0,0,0) == d2.setHours(0,0,0,0)){
    console.log(true)
}else{
    console.log(false)
}

    This might be a little cleaner version, also note that you should always use a radix when using parseInt.

window.addEvent('domready', function() {
    // Create a Date object set to midnight on today's date
    var today = new Date((new Date()).setHours(0, 0, 0, 0)),
    input = $('datum').getValue(),
    dateArray = input.split('/'),
    // Always specify a radix with parseInt(), setting the radix to 10 ensures that
    // the number is interpreted as a decimal.  It is particularly important with
    // dates, if the user had entered '09' for the month and you don't use a
    // radix '09' is interpreted as an octal number and parseInt would return 0, not 9!
    userMonth = parseInt(dateArray[1], 10) - 1,
    // Create a Date object set to midnight on the day the user specified
    userDate = new Date(dateArray[2], userMonth, dateArray[0], 0, 0, 0, 0);

    // Convert date objects to milliseconds and compare
    if(userDate.getTime() > today.getTime())
    {
            alert(today+'\n'+userDate);
    }
});


Checkout the MDC parseInt page for more information about the radix.

JSLint is a great tool for catching things like a missing radix and many other things that can cause obscure and hard to debug errors.  It forces you to use better coding standards so you avoid future headaches. I use it on every JavaScript project I code.
    After reading this question quite same time after it is posted I have decided to post another solution, as I didn't find it that quite satisfactory, at least to my needs:

I have used something like this:

var currentDate= new Date().setHours(0,0,0,0);

var startDay = new Date(currentDate - 86400000 * 2);
var finalDay = new Date(currentDate + 86400000 * 2);


In that way I could have used the dates in the format I wanted for processing afterwards. But this was only for my need, but I have decided to post it anyway, maybe it will help someone
    You can use some arithmetic with the total of ms. 

var date = new Date(date1);
date.setHours(0, 0, 0, 0);

var diff = date2.getTime() - date.getTime();
return diff >= 0 && diff < 86400000;


I like this because no updates to the original dates are made and perfom faster than string split and compare.

Hope this help!
    This is the way I do it:

var myDate  = new Date($('input[name=frequency_start]').val()).setHours(0,0,0,0);
var today   = new Date().setHours(0,0,0,0);
if(today>myDate){
    jAlert('Please Enter a date in the future','Date Start Error', function(){
        $('input[name=frequency_start]').focus().select();
    });
}

    The date.js library is handy for these things. It makes all JS date-related scriping a lot easier.
    As I don't see here similar approach, and I'm not enjoying setting h/m/s/ms to 0, as it can cause problems with accurate transition to local time zone with changed date object (I presume so), let me introduce here this, written few moments ago, lil function:

+: Easy to use, makes a basic comparison operations done (comparing day, month and year without time.)
-: It seems that this is a complete opposite of ""out of the box"" thinking.

function datecompare(date1, sign, date2) {
    var day1 = date1.getDate();
    var mon1 = date1.getMonth();
    var year1 = date1.getFullYear();
    var day2 = date2.getDate();
    var mon2 = date2.getMonth();
    var year2 = date2.getFullYear();
    if (sign === '===') {
        if (day1 === day2 && mon1 === mon2 && year1 === year2) return true;
        else return false;
    }
    else if (sign === '>') {
        if (year1 > year2) return true;
        else if (year1 === year2 && mon1 > mon2) return true;
        else if (year1 === year2 && mon1 === mon2 && day1 > day2) return true;
        else return false;
    }    
}


Usage:

datecompare(date1, '===', date2) for equality check,
datecompare(date1, '>', date2) for greater check,
!datecompare(date1, '>', date2) for less or equal check   

Also, obviously, you can switch date1 and date2 in places to achieve any other simple comparison.
    Make sure you construct userDate with a 4 digit year as setFullYear(10, ...) !== setFullYear(2010, ...).
    I know this question have been already answered and this may not be the best way, but in my scenario its working perfectly, so I thought it may help someone like me.  

if you have date string as 

String dateString=""2018-01-01T18:19:12.543"";


and you just want to compare the date part with another Date object in JS,

var anotherDate=new Date(); //some date


then you have to convert the string to Date object by using new Date(""2018-01-01T18:19:12.543"");

and here is the trick :-

var valueDate =new Date(new Date(dateString).toDateString());

            return valueDate.valueOf() == anotherDate.valueOf(); //here is the final result


I have used toDateString() of Date object of JS, which returns the Date string only. 

Note: Don't forget to use the .valueOf() function while comparing the dates.

more info about .valeOf() is here reference 

Happy codding.
    This will help. I managed to get it like this.    

var currentDate = new Date(new Date().getFullYear(), new Date().getMonth() , new Date().getDate())

    var fromdate = new Date(MM/DD/YYYY);
var todate = new Date(MM/DD/YYYY);
if (fromdate > todate){
    console.log('False');
}else{
    console.log('True');
}


if your date formate is different then use moment.js library to convert the format of your date and then use above code for compare two date

Example :

If your Date is in ""DD/MM/YYYY"" and wants to convert it into ""MM/DD/YYYY"" then see the below code example

var newfromdate = new Date(moment(fromdate, ""DD/MM/YYYY"").format(""MM/DD/YYYY""));
console.log(newfromdate);
var newtodate = new Date(moment(todate, ""DD/MM/YYYY"").format(""MM/DD/YYYY""));
console.log(newtodate);


    ","[487, 895, 210, 6, 12, 14, 23, 97, 1, 0, 3, 28, 2, 1, 9, 2, 1, 2, 2, 3, 1, 0, 0, 0]",568162,83,2010-04-23T13:08:05,2022-01-21 12:52:47Z,javascript 
How to replace item in array?,"
                
Each item of this array is some number:
var items = Array(523,3452,334,31, ...5346);

How to replace some item with a new one?
For example, we want to replace 3452 with 1010, how would we do this?
    var index = items.indexOf(3452);

if (index !== -1) {
    items[index] = 1010;
}


Also it is recommend you not use the constructor method to initialize your arrays. Instead, use the literal syntax:

var items = [523, 3452, 334, 31, 5346];


You can also use the ~ operator if you are into terse JavaScript and want to shorten the -1 comparison:

var index = items.indexOf(3452);

if (~index) {
    items[index] = 1010;
}


Sometimes I even like to write a contains function to abstract this check and make it easier to understand what's going on. What's awesome is this works on arrays and strings both:

var contains = function (haystack, needle) {
    return !!~haystack.indexOf(needle);
};

// can be used like so now:
if (contains(items, 3452)) {
    // do something else...
}


Starting with ES6/ES2015 for strings, and proposed for ES2016 for arrays, you can more easily determine if a source contains another value:

if (haystack.includes(needle)) {
    // do your thing
}

    Answer from @gilly3 is great.
Replace object in an array, keeping the array order unchanged
I prefer the following way to update the new updated record into my array of records when I get data from the server. It keeps the order intact and quite straight forward one liner.
users = users.map(u => u.id !== editedUser.id ? u : editedUser);
var users = [
{id: 1, firstname: 'John', lastname: 'Ken'},
{id: 2, firstname: 'Robin', lastname: 'Hood'},
{id: 3, firstname: 'William', lastname: 'Cook'}
];

var editedUser = {id: 2, firstname: 'Michael', lastname: 'Angelo'};

users = users.map(u => u.id !== editedUser.id ? u : editedUser);

console.log('users -> ', users);

    My suggested solution would be:
items.splice(1, 1, 1010);

The splice operation will start at index 1, remove 1 item in the array (i.e. 3452), and will replace it with the new item 1010.
    The Array.indexOf() method will replace the first instance.  To get every instance use Array.map():

a = a.map(function(item) { return item == 3452 ? 1010 : item; });


Of course, that creates a new array.  If you want to do it in place, use Array.forEach():

a.forEach(function(item, i) { if (item == 3452) a[i] = 1010; });

    A functional approach to replacing an element of an array in javascript:
const replace = (array, index, ...items) => [...array.slice(0, index), ...items, ...array.slice(index + 1)];

    ES6 way:

const items = Array(523, 3452, 334, 31, ...5346);


We wanna replace 3452 with 1010, solution:

const newItems = items.map(item => item === 3452 ? 1010 : item);


Surely, the question is for many years ago and for now I just prefer to use immutable solution, definitely, it is awesome for ReactJS.

For frequent usage I offer below function:

const itemReplacer = (array, oldItem, newItem) =>
  array.map(item => item === oldItem ? newItem : item);

    Use indexOf to find an element.
var i = items.indexOf(3452);
items[i] = 1010;

    If using a complex object (or even a simple one) and you can use es6, Array.prototype.findIndex is a good one. For the OP's array, they could do, 

const index = items.findIndex(x => x === 3452)
items[index] = 1010


For more complex objects, this really shines. For example, 

const index = 
    items.findIndex(
       x => x.jerseyNumber === 9 && x.school === 'Ohio State'
    )

items[index].lastName = 'Utah'
items[index].firstName = 'Johnny'

    You can edit any number of the list using indexes

for example : 

items[0] = 5;
items[5] = 100;

    First method

Best way in just one line to replace or update item of array

array.splice(array.indexOf(valueToReplace), 1, newValue)


Eg: 

let items = ['JS', 'PHP', 'RUBY'];

let replacedItem = items.splice(items.indexOf('RUBY'), 1, 'PYTHON')

console.log(replacedItem) //['RUBY']
console.log(items) //['JS', 'PHP', 'PYTHON']


Second method

An other simple way to do the same operation is :

items[items.indexOf(oldValue)] = newValue

    Here is the basic answer made into a reusable function:

function arrayFindReplace(array, findValue, replaceValue){
    while(array.indexOf(findValue) !== -1){
        let index = array.indexOf(findValue);
        array[index] = replaceValue;
    }
}

    If you want a simple sugar sintax oneliner you can just:

(elements = elements.filter(element => element.id !== updatedElement.id)).push(updatedElement);


Like:

let elements = [ { id: 1, name: 'element one' }, { id: 2, name: 'element two'} ];
const updatedElement = { id: 1, name: 'updated element one' };


If you don't have id you could stringify the element like:

(elements = elements.filter(element => JSON.stringify(element) !== JSON.stringify(updatedElement))).push(updatedElement);

     items[items.indexOf(3452)] = 1010

great for simple swaps. try the snippet below
const items = Array(523, 3452, 334, 31, 5346);
console.log(items)

items[items.indexOf(3452)] = 1010
console.log(items)

    The immutable way to replace the element in the list using ES6 spread operators and .slice method.

const arr = ['fir', 'next', 'third'], item = 'next'

const nextArr = [
  ...arr.slice(0, arr.indexOf(item)), 
  'second',
  ...arr.slice(arr.indexOf(item) + 1)
]


Verify that works

console.log(arr)     // [ 'fir', 'next', 'third' ]
console.log(nextArr) // ['fir', 'second', 'third']

    Replacement can be done in one line:

var items = Array(523, 3452, 334, 31, 5346);

items[items.map((e, i) => [i, e]).filter(e => e[1] == 3452)[0][0]] = 1010

console.log(items);


Or create a function to reuse:

Array.prototype.replace = function(t, v) {
    if (this.indexOf(t)!= -1)
        this[this.map((e, i) => [i, e]).filter(e => e[1] == t)[0][0]] = v;
  };

//Check
var items = Array(523, 3452, 334, 31, 5346);
items.replace(3452, 1010);
console.log(items);

    Easily accomplished with a for loop.

for (var i = 0; i < items.length; i++)
    if (items[i] == 3452)
        items[i] = 1010;

    var items = Array(523,3452,334,31,5346);


If you know the value then use,

items[items.indexOf(334)] = 1010;


If you want to know that value is present or not, then use,

var point = items.indexOf(334);

if (point !== -1) {
    items[point] = 1010;
}


If you know the place (position) then directly use,

items[--position] = 1010;


If you want replace few elements, and you know only starting position only means,

items.splice(2, 1, 1010, 1220);


for more about .splice
    Well if anyone is interresting on how to replace an object from its index in an array, here's a solution.

Find the index of the object by its id:

const index = items.map(item => item.id).indexOf(objectId)


Replace the object using Object.assign() method:

Object.assign(items[index], newValue)

    Here's a one liner. It assumes the item will be in the array.

var items = [523, 3452, 334, 31, 5346]
var replace = (arr, oldVal, newVal) => (arr[arr.indexOf(oldVal)] = newVal, arr)
console.log(replace(items, 3452, 1010))

    var index = Array.indexOf(Array value);
        if (index > -1) {
          Array.splice(index, 1);
        }


from here you can delete a particular value from array and based on the same index 
 you can insert value in array .

 Array.splice(index, 0, Array value);

    The easiest way is this.

var items = Array(523,3452,334,31, 5346);
var replaceWhat = 3452, replaceWith = 1010;
if ( ( i = items.indexOf(replaceWhat) ) >=0 ) items.splice(i, 1, replaceWith);

console.log(items);
>>> (5) [523, 1010, 334, 31, 5346]

    The easiest way is to use some libraries like underscorejs and map method.

var items = Array(523,3452,334,31,...5346);

_.map(items, function(num) {
  return (num == 3452) ? 1010 : num; 
});
=> [523, 1010, 334, 31, ...5346]

    This will do the job
Array.prototype.replace = function(a, b) {
    return this.map(item => item == a ? b : item)
}

Usage:
let items = ['hi', 'hi', 'hello', 'hi', 'hello', 'hello', 'hi']
console.log(items.replace('hello', 'hi'))

Output:
['hi', 'hi', 'hi', 'hi', 'hi', 'hi', 'hi']

The nice thing is, that EVERY array will have .replace() property.
    First, rewrite your array like this: 

var items = [523,3452,334,31,...5346];


Next, access the element in the array through its index number. The formula to determine the index number is: n-1

To replace the first item (n=1) in the array, write:

items[0] = Enter Your New Number;


In your example, the number 3452 is in the second position (n=2). So the formula to determine the index number is 2-1 = 1. So write the following code to replace 3452 with 1010:

items[1] = 1010;

    I solved this problem using for loops and iterating through the original array and adding the positions of the matching arreas to another array and then looping through that array and changing it in the original array then return it, I used and arrow function but a regular function would work too.

var replace = (arr, replaceThis, WithThis) => {
    if (!Array.isArray(arr)) throw new RangeError(""Error"");
    var itemSpots = [];
    for (var i = 0; i < arr.length; i++) {
        if (arr[i] == replaceThis) itemSpots.push(i);
    }

    for (var i = 0; i < itemSpots.length; i++) {
        arr[itemSpots[i]] = WithThis;
    }

    return arr;
};

    presentPrompt(id,productqty) {
    let alert = this.forgotCtrl.create({
      title: 'Test',
      inputs: [
        {
          name: 'pickqty',
          placeholder: 'pick quantity'
        },
        {
          name: 'state',
          value: 'verified',
          disabled:true,
          placeholder: 'state',

        }
      ],
      buttons: [
        {
          text: 'Ok',
          role: 'cancel',
          handler: data => {

            console.log('dataaaaname',data.pickqty);
            console.log('dataaaapwd',data.state);


          for (var i = 0; i < this.cottonLists.length; i++){

            if (this.cottonLists[i].id == id){
                this.cottonLists[i].real_stock = data.pickqty;

            }
          }

          for (var i = 0; i < this.cottonLists.length; i++){

            if (this.cottonLists[i].id == id){
              this.cottonLists[i].state = 'verified';   

          }
        }
            //Log object to console again.
            console.log(""After update: "", this.cottonLists)
            console.log('Ok clicked');
          }
        },

      ]
    });
    alert.present();
  }

As per your requirement you can change fields and array names.
thats all. Enjoy your coding.

    When your array have many old item to replace new item, you can use this way:
function replaceArray(array, oldItem, newItem) {
    for (let i = 0; i < array.length; i++) {
        const index = array.indexOf(oldItem);
        if (~index) {
            array[index] = newItem;
        }
    }
    return array
}

console.log(replaceArray([1, 2, 3, 2, 2, 8, 1, 9], 2, 5));
console.log(replaceArray([1, 2, 3, 2, 2, 8, 1, 9], 2, ""Hi""));

    const items = Array(1, 2, 3, 4, 5);
console.log(items)

items[items.indexOf(2)] = 1010
console.log(items)

    ","[487, 645, 66, 72, 145, 12, 17, 42, 23, 19, 27, 1, 2, 1, 7, 7, 28, 3, 2, 1, 1, 0, 3, -1, 0, 0, 0, 0, 0]",1185143,71,2011-05-06T18:52:37,2022-04-20 09:57:45Z,javascript 
How to listen for a WebView finishing loading a URL?,"
                
I have a WebView that is loading a page from the Internet. I want to show a ProgressBar until the loading is complete. 

How do I listen for the completion of page loading of a WebView?
    Extend WebViewClient and call onPageFinished() as follows:

mWebView.setWebViewClient(new WebViewClient() {

   public void onPageFinished(WebView view, String url) {
        // do your stuff here
    }
});

    If you want show a progress bar you need to listen for a progress change event, not just for the completion of page:

mWebView.setWebChromeClient(new WebChromeClient(){

            @Override
            public void onProgressChanged(WebView view, int newProgress) {

                //change your progress bar
            }


        });


BTW if you want display just an Indeterminate ProgressBar overriding the method onPageFinished is enough
    I found one elegant solution as well, have not tested it rigorously though:
public void onPageFinished(WebView view, String url) {
            super.onPageFinished(view, url);
            if (webView.getProgress() == 100) {
                progressBar.setVisibility(View.GONE);
                webView.setVisibility(View.VISIBLE);
            }
        } 

    for Kotlin users:

webView.webViewClient = object : WebViewClient() {
            override fun onPageFinished(view: WebView?, url: String?) {
                // do your logic
            }
        }


there are a lot of methods that you can override though
    @ian this is not 100% accurate. If you have several iframes in a page you will have multiple onPageFinished (and onPageStarted). And if you have several redirects it may also fail. This approach solves (almost) all the problems:

boolean loadingFinished = true;
boolean redirect = false;

mWebView.setWebViewClient(new WebViewClient() {

    @Override
    public boolean shouldOverrideUrlLoading(WebView view, String urlNewString) {
        if (!loadingFinished) {
            redirect = true;
        }

        loadingFinished = false;
        webView.loadUrl(urlNewString);
        return true;
    }

    @Override
    public void onPageStarted(WebView view, String url) {
        loadingFinished = false;
        //SHOW LOADING IF IT ISNT ALREADY VISIBLE  
    }

    @Override
    public void onPageFinished(WebView view, String url) {
        if (!redirect) {
           loadingFinished = true;
            //HIDE LOADING IT HAS FINISHED
        } else {
            redirect = false; 
        }
    }
});


UPDATE:

According to the documentation:
onPageStarted will NOT be called when the contents of an embedded frame changes, i.e. clicking a link whose target is an iframe.

I found a specific case like that on Twitter where only a pageFinished was called and messed the logic a bit. To solve that I added a scheduled task to remove loading after X seconds. This is not needed in all the other cases.

UPDATE 2:

Now with current Android WebView implementation:

boolean loadingFinished = true;
boolean redirect = false;

    mWebView.setWebViewClient(new WebViewClient() {

        @Override
        public boolean shouldOverrideUrlLoading(
                WebView view, WebResourceRequest request) {
            if (!loadingFinished) {
               redirect = true;
            }

            loadingFinished = false;
            webView.loadUrl(request.getUrl().toString());
            return true;
        }

        @Override
        public void onPageStarted(
                WebView view, String url, Bitmap favicon) {
            super.onPageStarted(view, url, favicon);
            loadingFinished = false;
            //SHOW LOADING IF IT ISNT ALREADY VISIBLE  
        }

        @Override
        public void onPageFinished(WebView view, String url) {
            if (!redirect) {
               loadingFinished = true;
                //HIDE LOADING IT HAS FINISHED
            } else {
                redirect = false; 
            }
        }
    });

    The renderer will not finish rendering when the OnPageFinshed method is called or the progress reaches 100% so both methods don't guarantee you that the view was completely rendered.

But you can figure out from OnLoadResource method what has been already rendered and what is still rendering. And this method gets called several times.

        @Override
        public void onLoadResource(WebView view, String url) {
            super.onLoadResource(view, url);
           // Log and see all the urls and know exactly what is being rendered and visible. If you wanna know when the entire page is completely rendered, find the last url from log and check it with if clause and implement your logic there.
            if (url.contains(""assets/loginpage/img/ui/forms/"")) {
                // loginpage is rendered and visible now.
               // your logic here.

            }
        }

    I am pretty partial to @NeTeInStEiN (and @polen) solution but would have implemented it with a counter instead of multiple booleans or state watchers (just another flavor but I thought might share).   It does have a JS nuance about it but I feel the logic is a little easier to understand.

private void setupWebViewClient() {
    webView.setWebViewClient(new WebViewClient() {
        private int running = 0; // Could be public if you want a timer to check.

        @Override
        public boolean shouldOverrideUrlLoading(WebView webView, String urlNewString) {
            running++;
            webView.loadUrl(urlNewString);
            return true;
        }

        @Override
        public void onPageStarted(WebView view, String url, Bitmap favicon) {
            running = Math.max(running, 1); // First request move it to 1.
        }

        @Override
        public void onPageFinished(WebView view, String url) {
            if(--running == 0) { // just ""running--;"" if you add a timer.
                // TODO: finished... if you want to fire a method.
            }
        }
    });
}

    Here's a novel method for detected when a URL has loaded by utilising Android's capability for JavaScript hooks. Using this pattern, we exploit JavaScript's knowledge of the document's state to generate a native method call within the Android runtime. These JavaScript-accessible calls can be made using the @JavaScriptInterface annotation.

This implementation requires that we call setJavaScriptEnabled(true) on the WebView's settings, so it might not be suitable depending on your application's requirements, e.g. security concerns. 

src/io/github/cawfree/webviewcallback/MainActivity.java (Jelly Bean, API Level 16)

package io.github.cawfree.webviewcallback;

/**
 *  Created by Alex Thomas (@Cawfree), 30/03/2017.
 **/

import android.net.http.SslError;
import android.support.v7.app.AppCompatActivity;
import android.os.Bundle;
import android.webkit.JavascriptInterface;
import android.webkit.SslErrorHandler;
import android.webkit.WebView;
import android.webkit.WebViewClient;
import android.widget.Toast;

/** An Activity demonstrating how to introduce a callback mechanism into Android's WebView. */
public class MainActivity extends AppCompatActivity {

    /* Static Declarations. */
    private static final String HOOK_JS             = ""Android"";
    private static final String URL_TEST            = ""http://www.zonal.co.uk/"";
    private static final String URL_PREPARE_WEBVIEW = """";

    /* Member Variables. */
    private WebView mWebView = null;

    /** Create the Activity. */
    @Override protected final void onCreate(final Bundle pSavedInstanceState) {
        // Initialize the parent definition.
        super.onCreate(pSavedInstanceState);
        // Set the Content View.
        this.setContentView(R.layout.activity_main);
        // Fetch the WebView.
        this.mWebView = (WebView)this.findViewById(R.id.webView);
        // Enable JavaScript.
        this.getWebView().getSettings().setJavaScriptEnabled(true);
        // Define the custom WebClient. (Here I'm just suppressing security errors, since older Android devices struggle with TLS.)
        this.getWebView().setWebViewClient(new WebViewClient() { @Override     public final void onReceivedSslError(final WebView pWebView, final SslErrorHandler pSslErrorHandler, final SslError pSslError) { pSslErrorHandler.proceed(); } });
        // Define the WebView JavaScript hook.
        this.getWebView().addJavascriptInterface(this, MainActivity.HOOK_JS);
        // Make this initial call to prepare JavaScript execution.
        this.getWebView().loadUrl(MainActivity.URL_PREPARE_WEBVIEW);
    }

    /** When the Activity is Resumed. */
    @Override protected final void onPostResume() {
        // Handle as usual.
        super.onPostResume();
        // Load the URL as usual.
        this.getWebView().loadUrl(MainActivity.URL_TEST);
        // Use JavaScript to embed a hook to Android's MainActivity. (The onExportPageLoaded() function implements the callback, whilst we add some tests for the state of the WebPage so as to infer when to export the event.)
        this.getWebView().loadUrl(""javascript:"" + ""function onExportPageLoaded() { "" + MainActivity.HOOK_JS + "".onPageLoaded(); }"" + ""if(document.readyState === 'complete') { onExportPageLoaded(); } else { window.addEventListener('onload', function () { onExportPageLoaded(); }, false); }"");
    }

    /** Javascript-accessible callback for declaring when a page has loaded. */
    @JavascriptInterface @SuppressWarnings(""unused"") public final void onPageLoaded() {
        // Display the Message.
        Toast.makeText(this, ""Page has loaded!"", Toast.LENGTH_SHORT).show();
    }

    /* Getters. */
    public final WebView getWebView() {
        return this.mWebView;
    }

}


res/layout/activity_main.xml

<?xml version=""1.0"" encoding=""utf-8""?>
<WebView
    xmlns:android=""http://schemas.android.com/apk/res/android""
    android:id=""@+id/webView""
    android:layout_width=""wrap_content""
    android:layout_height=""wrap_content""
/>


Essentially, we're appending an additional JavaScript function that is used to test the state of the document. If it's loaded, we launch a custom onPageLoaded() event in Android's MainActivity; otherwise, we register an event listener that updates Android once the page is ready, using window.addEventListener('onload', ...);.

Since we're appending this script after the call to this.getWebView().loadURL("""") has been made, it's probable that we don't need to 'listen' for the events at all, since we only get a chance to append the JavaScript hook by making a successive call to loadURL, once the page has already been loaded. 
    Just to show progress bar, ""onPageStarted"" and ""onPageFinished"" methods are enough; but if you want to have an ""is_loading"" flag (along with page redirects, ...), this methods may executed with non-sequencing, like ""onPageStarted > onPageStarted > onPageFinished > onPageFinished"" queue.

But with my short test (test it yourself.), ""onProgressChanged"" method values queue is ""0-100 > 0-100 > 0-100 > ...""

private boolean is_loading = false;

webView.setWebChromeClient(new MyWebChromeClient(context));

private final class MyWebChromeClient extends WebChromeClient{
    @Override
    public void onProgressChanged(WebView view, int newProgress) {
        if (newProgress == 0){
            is_loading = true;
        } else if (newProgress == 100){
            is_loading = false;
        }
        super.onProgressChanged(view, newProgress);
    }
}


Also set ""is_loading = false"" on activity close, if it is a static variable because activity can be finished before page finish.
    I have simplified NeTeInStEiN's code to be like this:

mWebView.setWebViewClient(new WebViewClient() {
        private int       webViewPreviousState;
        private final int PAGE_STARTED    = 0x1;
        private final int PAGE_REDIRECTED = 0x2;

        @Override
        public boolean shouldOverrideUrlLoading(WebView view, String urlNewString) {
            webViewPreviousState = PAGE_REDIRECTED;
            mWebView.loadUrl(urlNewString);
            return true;
        }

        @Override
        public void onPageStarted(WebView view, String url, Bitmap favicon) {
            super.onPageStarted(view, url, favicon);
            webViewPreviousState = PAGE_STARTED;
            if (dialog == null || !dialog.isShowing())
                dialog = ProgressDialog.show(WebViewActivity.this, """", getString(R.string.loadingMessege), true, true,
                        new OnCancelListener() {

                            @Override
                            public void onCancel(DialogInterface dialog) {
                                // do something
                            }
                        });
        }

        @Override
        public void onPageFinished(WebView view, String url) {

            if (webViewPreviousState == PAGE_STARTED) {
                dialog.dismiss();
                dialog = null;
            }

        }
 });


It is easy to understand, OnPageFinished if the previous callback is on onPageStarted, so the page is completely loaded.
    You can trace the Progress Staus by the getProgress method in webview class.

Initialize the progress status

private int mProgressStatus = 0;


then the AsyncTask for loading like this:

private class Task_News_ArticleView extends AsyncTask<Void, Void, Void> {
    private final ProgressDialog dialog = new ProgressDialog(
            your_class.this);

    // can use UI thread here
    protected void onPreExecute() {
        this.dialog.setMessage(""Loading..."");
        this.dialog.setCancelable(false);
        this.dialog.show();
    }

    @Override
    protected Void doInBackground(Void... params) {
        try {
            while (mProgressStatus < 100) {
                mProgressStatus = webview.getProgress();

            }
        } catch (Exception e) {

        }
        return null;

    }

    protected void onPostExecute(Void result) {
        if (this.dialog.isShowing()) {
            this.dialog.dismiss();
        }
    }
}

    thanks for the answers. It helped me, but I had to improve it a bit for my needs. I had several pagestarts and finishes so I added a timer which checks if atfer the pagefinish is started a new pagestart. Okay, bad explanation. See the code :)

myWebView.setWebViewClient(new WebViewClient() {
        boolean loadingFinished = true;
        boolean redirect = false;

        long last_page_start;
        long now;

        // Load the url
        public boolean shouldOverrideUrlLoading(WebView view, String url) {
            if (!loadingFinished) {
                redirect = true;
            }

            loadingFinished = false;
            view.loadUrl(url);
            return false;
        }

        @Override
        public void onPageStarted(WebView view, String url, Bitmap favicon) {
            Log.i(""p"",""pagestart"");
            loadingFinished = false;
            last_page_start = System.nanoTime();
            show_splash();
        }

        // When finish loading page
        public void onPageFinished(WebView view, String url) {
            Log.i(""p"",""pagefinish"");
            if(!redirect){
                loadingFinished = true;
            }
            //call remove_splash in 500 miSec
            if(loadingFinished && !redirect){
                now = System.nanoTime();
                new android.os.Handler().postDelayed(
                        new Runnable() {
                            public void run() {
                                remove_splash();
                            }
                        },
                        500);
            } else{
                redirect = false;
            }
        }
        private void show_splash() {
            if(myWebView.getVisibility() == View.VISIBLE) {
                myWebView.setVisibility(View.GONE);
                myWebView_splash.setVisibility(View.VISIBLE);
            }
        }
        //if a new ""page start"" was fired dont remove splash screen
        private void remove_splash() {
            if (last_page_start < now) {
                myWebView.setVisibility(View.VISIBLE);
                myWebView_splash.setVisibility(View.GONE);
            }
        }

});

    Use setWebViewClient() and override onPageFinished()
    Kotlin solution
First Solution is create webviewclient as private class and it is more efficient.
In the other hand second soltion is sorter :)
First Solution
class MainActivity : AppCompatActivity() {
  override fun onCreate(savedInstanceState: Bundle?) {
    super.onCreate(savedInstanceState)
    setContentView(R.layout.activity_main)
    val webView : WebView = findViewById(R.id.webView)
    webView.webViewClient = MyWebViewClient()
 }

private class MyWebViewClient : WebViewClient() {
    override fun onPageStarted(view: WebView?, url: String?, favicon: Bitmap?) {
        println(""Load Started"")
    }
    override fun onPageFinished(view: WebView, url: String) {
        println(""Load Finished"")
    }
  }
}

Second Solution
class MainActivity : AppCompatActivity() {
  override fun onCreate(savedInstanceState: Bundle?) {
    super.onCreate(savedInstanceState)
    setContentView(R.layout.activity_main)
    val webView : WebView = findViewById(R.id.webView)
    webView.webViewClient = object : WebViewClient() {
        override fun onPageStarted(view: WebView?, url: String?, favicon: Bitmap?) {
            println(""Load Started"")
        }
        override fun onPageFinished(view: WebView, url: String) {
            println(""Load Finished"")
        }
     }
 }

Both solution actually same. So onPageStarted function run when page started to load in the other hang onPageFinished function works when page loaded entirely. You may want to write your as an example loadFinishedRun() function inside onPageFinished funtion.

Better late than never

    Loading url with SwipeRefreshLayout and ProgressBar:
UrlPageActivity.java:

    WebView webView;
    SwipeRefreshLayout _swipe_procesbar;
    @Override
    protected void onCreate(Bundle savedInstanceState) {
        super.onCreate(savedInstanceState);
        setContentView(R.layout.activity_url_page);


        String url = ""http://stackoverflow.com/"";

        _swipe_procesbar = (SwipeRefreshLayout)findViewById(R.id.url_path_swipe_procesbar);

        _swipe_procesbar.post(new Runnable() {
                                  @Override
                                  public void run() {
                                      _swipe_procesbar.setRefreshing(true);
                                  }
                              }
        );

        webView = (WebView) findViewById(R.id.url_page_web_view);
        webView.getSettings().setJavaScriptEnabled(true);

        webView.setWebViewClient(new WebViewClient() {
            public void onPageFinished(WebView view, String url) {
                _swipe_procesbar.setRefreshing(false);
                _swipe_procesbar.setEnabled(false);
            }
        });
        webView.loadUrl(url);
    }


activity_url_page.xml:

<android.support.v4.widget.SwipeRefreshLayout xmlns:android=""http://schemas.android.com/apk/res/android""
    android:id=""@+id/url_path_swipe_procesbar""
    android:layout_width=""match_parent""
    android:layout_height=""wrap_content"">
        <RelativeLayout xmlns:android=""http://schemas.android.com/apk/res/android""
            xmlns:tools=""http://schemas.android.com/tools"" android:layout_width=""match_parent""
            android:layout_height=""match_parent""
            tools:context=""com.test.test1.UrlPageActivity"">


            <WebView
                android:layout_width=""fill_parent""
                android:layout_height=""fill_parent""
                android:id=""@+id/url_page_web_view"" />
        </RelativeLayout>

</android.support.v4.widget.SwipeRefreshLayout>

    Here's a method which allows you to register a Runnable to be executed once a particular web address has finished loading. We associate each Runnable with a corresponding URL String in a Map, and we use the WebView's getOriginalUrl() method to choose the appropriate callback.

package io.github.cawfree.webviewcallback;

/**
 *  Created by Alex Thomas (@Cawfree), 30/03/2017.
 **/

import android.net.http.SslError;
import android.os.Bundle;
import android.support.v7.app.AppCompatActivity;
import android.webkit.SslErrorHandler;
import android.webkit.WebView;
import android.webkit.WebViewClient;

import java.util.HashMap;
import java.util.Map;

/** An Activity demonstrating how to introduce a callback mechanism into Android's WebView. */
public class MainActivity extends AppCompatActivity {

    /* Member Variables. */
    private WebView               mWebView;
    private Map<String, Runnable> mCallbackMap;

    /** Create the Activity. */
    @Override protected final void onCreate(final Bundle pSavedInstanceState) {
        // Initialize the parent definition.
        super.onCreate(pSavedInstanceState);
        // Set the Content View.
        this.setContentView(R.layout.activity_main);
        // Fetch the WebView.
        this.mWebView     = (WebView)this.findViewById(R.id.webView);
        this.mCallbackMap = new HashMap<>();
        // Define the custom WebClient. (Here I'm just suppressing security errors, since older Android devices struggle with TLS.)
        this.getWebView().setWebViewClient(new WebViewClient() {
            /** Handle when a request has been launched. */
            @Override public final void onPageFinished(final WebView pWebView, final String pUrl) {
                // Determine whether we're allowed to process the Runnable; if the page hadn't been redirected, or if we've finished redirection.
                if(pUrl.equals(pWebView.getOriginalUrl())) {
                    // Fetch the Runnable for the OriginalUrl.
                    final Runnable lRunnable = getCallbackMap().get(pWebView.getOriginalUrl());
                    // Is it valid?
                    if(lRunnable != null) { lRunnable.run(); }
                }
                // Handle as usual.
                super.onPageFinished(pWebView, pUrl);
            }
            /** Ensure we handle SSL state properly. */
            @Override public final void onReceivedSslError(final WebView pWebView, final SslErrorHandler pSslErrorHandler, final SslError pSslError) { pSslErrorHandler.proceed(); }
        });
        // Assert that we wish to visit Zonal's website.
        this.getWebView().loadUrl(""http://www.zonal.co.uk/"");
        // Align a Callback for Zonal; this will be serviced once the page has loaded.
        this.getCallbackMap().put(""http://www.zonal.co.uk/"", new Runnable() {     @Override public void run() { /* Do something. */ } });
    }

    /* Getters. */
    public final WebView getWebView() {
        return this.mWebView;
    }

    private final Map<String, Runnable> getCallbackMap() {
        return this.mCallbackMap;
    }

}

    Use this it should help.`var currentUrl = ""google.com""
var partOfUrl = currentUrl.substring(0, currentUrl.length-2)

webView.setWebViewClient(object: WebViewClient() {

override fun onLoadResource(WebView view, String url) {
     //call loadUrl() method  here 
     // also check if url contains partOfUrl, if not load it differently.
     if(url.contains(partOfUrl, true)) {
         //it should work if you reach inside this if scope.
     } else if(!(currentUrl.startWith(""w"", true))) {
         webView.loadurl(""www.$currentUrl"")

     } else if(!(currentUrl.startWith(""h"", true))) {
         webView.loadurl(""https://$currentUrl"")

     } else { ...}


 }

override fun onReceivedSslError(view: WebView?, handler: SslErrorHandler?, error: SslError?) {
   // you can call again loadUrl from here too if there is any error.
}


//You should also override other override method for error such as onReceiveError to see how all these methods are called one after another and how they behave while debugging with break point.
}
`
    this will been called before he start loading the page
(and get the same parameters as onFinished())
@Override
public void onPageCommitVisible(WebView view, String url) {
   super.onPageCommitVisible(view, url);
}

    ","[487, 769, 24, 34, 4, 161, 1, 41, 3, 2, 23, 5, 5, 6, 0, 0, 0, 0, 0]",387520,121,2010-06-30T12:28:26,2022-03-28 06:27:28Z,
How do I add comments to package.json for npm install?,"
                
I've got a simple package.json file and I want to add a comment. Is there a way to do this, or are there any hacks to make this work?
{
  ""name"": ""My Project"",
  ""version"": ""0.0.1"",
  ""private"": true,
  ""dependencies"": {
    ""express"": ""3.x"",
    ""mongoose"": ""3.x""
  },
  ""devDependencies"" :  {
    ""should"": ""*""
    /* ""mocha"": ""*"" not needed as should be globally installed */
  }
}

The example comment above doesn't work as npm breaks. I've also tried // style comments.
    After wasting an hour on complex and hacky solutions, I've found both simple and valid solution for commenting my bulky dependencies section in package.json. Just like this:
{
  ""name"": ""package name"",
  ""version"": ""1.0"",
  ""description"": ""package description"",
  ""scripts"": {
    ""start"": ""npm install && node server.js""
  },
  ""scriptsComments"": {
    ""start"": ""Runs development build on a local server configured by server.js""
  },
  ""dependencies"": {
    ""ajv"": ""^5.2.2""
  },
  ""dependenciesComments"": {
    ""ajv"": ""JSON-Schema Validator for validation of API data""
  }
}

When sorted the same way, it's now very easy for me to track these pairs of dependencies/comments either in Git commit diffs or in an editor while working with file package.json.
And no extra tools are involved, just plain and valid JSON.
    This has recently been discussed on the Node.js mailing list.
According to Isaac Schlueter who created npm:

... the ""//"" key will never be used by npm for any purpose, and is reserved for comments ... If you want to use a multiple line comment, you can use either an array, or multiple ""//"" keys.

When using your usual tools (npm, yarn, etc.), multiple ""//"" keys will be removed. This survives:
{ ""//"": [
  ""first line"",
  ""second line"" ] }

This will not survive:
{ ""//"": ""this is the first line of a comment"",
  ""//"": ""this is the second line of the comment"" }

    I've been doing this:
{
  ...
  ""scripts"": {
    ""about"": ""echo 'Say something about this project'"",
    ""about:clean"": ""echo 'Say something about the clean script'"",
    ""clean"": ""do something"",
    ""about:build"": ""echo 'Say something about building it'"",
    ""build"": ""do something"",
    ""about:watch"": ""echo 'Say something about how watch works'"",
    ""watch"": ""do something"",
  }
  ...
}

This way, I can both read the ""pseudo-comments"" in the script itself, and also run something like the following, to see some kind of help in the terminal:
npm run about
npm run about:watch

Even better if you are using yarn.
yarn about:clean

Also, as pointed out by @Dakota Jang in comments, you can use keys like //something to make it even more clear that this is a comment.
Like so:
{
  ...
  ""scripts"": {
    ""//clean"": ""echo 'Say something about the clean script'"",
    ""clean"": ""do something"",
    ""//build"": ""echo 'Say something about building it'"",
    ""build"": ""do something"",
    ""//watch"": ""echo 'Say something about how watch works'"",
    ""watch"": ""do something"",
  }
  ...
}

And then run:
npm run //build
# or
yarn //build

And you will have a helper output in your terminal, and a ""comment"" in your package.json as well.
    As this answer explains, the // key was reserved, so it can be used conventionally for comments. The problem with // comment is that it's not practical, because it can't be used multiple times. Duplicate keys are deleted on package.json automatic updates:
""//"": ""this comment about dependencies stays"",
""dependencies"": {}
""//"": ""this comment disappears"",
""devDependencies"": {}

Another problem is that // comment can't be used inside dependencies and devDependencies because it's treated as a regular dependency:
""dependencies"": {
  ""//"": ""comment""
}


npm ERR! code EINVALIDPACKAGENAME
npm ERR! Invalid package name ""//"": name can only contain URL-friendly
characters

A workaround that works in NPM, but not Yarn, is to use a non-string value:
""dependencies"": {
  ""foo"": [""unused package""],
}

A workaround that works in NPM and Yarn is a comment added as a part of semantic versioning:
""dependencies"": {
  ""bar"": ""^2"",
  ""foo"": ""^2 || should be removed in 1.x release""
}

Notice that if the first part before OR doesn't match, versions from a comment can be parsed, e.g. 1.x.
Packages that need to be commented, but not installed, should be moved to another key, e.g. dependencies //:
""dependencies //"": {
  ""baz"": ""unused package"",
}

    Inspired by this thread, here's what we are using:

{
  ""//dependencies"": {
    ""crypto-exchange"": ""Unified exchange API""
  },
  ""dependencies"": {
    ""crypto-exchange"": ""^2.3.3""
  },
  ""//devDependencies"": {
    ""chai"": ""Assertions"",
    ""mocha"": ""Unit testing framwork"",
    ""sinon"": ""Spies, Stubs, Mocks"",
    ""supertest"": ""Test requests""
  },
  ""devDependencies"": {
    ""chai"": ""^4.1.2"",
    ""mocha"": ""^4.0.1"",
    ""sinon"": ""^4.1.3"",
    ""supertest"": ""^3.0.0""
  }
}

    Since most developers are familiar with tag/annotation-based documentation, the convention I have started using is similar. Here is a taste:
{
  ""@comment dependencies"": [
    ""These are the comments for the `dependencies` section."",
    ""The name of the section being commented is included in the key after the `@comment` 'annotation'/'tag' to ensure the keys are unique."",
    ""That is, using just \""@comment\"" would not be sufficient to keep keys unique if you need to add another comment at the same level."",
    ""Because JSON doesn't allow a multi-line string or understand a line continuation operator/character, just use an array for each line of the comment."",
    ""Since this is embedded in JSON, the keys should be unique."",
    ""Otherwise JSON validators, such as ones built into IDEs, will complain."",
    ""Or some tools, such as running `npm install something --save`, will rewrite the `package.json` file but with duplicate keys removed."",
    """",
    ""@package react - Using an `@package` 'annotation` could be how you add comments specific to particular packages.""
  ],
  ""dependencies"": {
    ...
  },
  ""@comment scripts"": {
    ""build"": ""This comment is about the build script."",
    ""start"": [
      ""This comment is about the `start` script."",
      ""It is wrapped in an array to allow line formatting."",
      ""When using npm, as opposed to yarn, to run the script, be sure to add ` -- ` before adding the options."",
      """",
      ""@option {number} --port - The port the server should listen on.""
    ],
    ""test"": ""This comment is about the test script."",
  },
  ""scripts"": {
    ""build"": ""..."",
    ""start"": ""..."",
    ""test"": ""...""
  }
}

Note: For the dependencies, devDependencies, etc. sections, the comment annotations can't be added directly above the individual package dependencies inside the configuration object since npm is expecting the key to be the name of an npm package. Hence the reason for the @comment dependencies.
I like the annotation/tag style way of adding comments to JSON because the @ symbol stands out from the normal declarations.
Older Recommendation
The following was my previous recommendation. It in-lined comments for the scripts, but I've come to realize that those comments show up as ""commands"" in some tools (in VS Code > Explorer > NPM Scripts section). The latest recommendation does not suffer from this issue but the script comments are no longer co-located.
{
  ""@comment dependencies"": [
    ...
  ],
  ""dependencies"": {
    ...
  },
  ""scripts"": {
    ""@comment build"": ""This comment is about the build script."",
    ""build"": ""..."",

    ""@comment start"": [
      ""This comment is about the `start` script."",
      ""It is wrapped in an array to allow line formatting."",
      ""When using npm, as opposed to yarn, to run the script, be sure to add ` -- ` before adding the options."",
      """",
      ""@option {number} --port - The port the server should listen on.""
    ],
    ""start"": ""..."",

    ""@comment test"": ""This comment is about the test script."",
    ""test"": ""...""
  }
}

Note: In certain contexts, such as in the ""scripts"" object, some editors/IDEs may complain about the array. In the scripts context, VS Code expects a string for the value — not an array.
    You can always abuse the fact that duplicated keys are overwritten. This is what I just wrote:

""dependencies"": {
  ""grunt"": ""..."",
  ""grunt-cli"": ""..."",

  ""api-easy"": ""# Here is the pull request: https://github.com/..."",
  ""api-easy"": ""git://...""

  ""grunt-vows"": ""..."",
  ""vows"": ""...""
}


However, it is not clear whether JSON allows duplicated keys (see
Does JSON syntax allow duplicate keys in an object?. It seems to work with npm, so I take the risk.

The recommened hack is to use ""//"" keys (from the nodejs mailing list). When I tested it, it did not work with ""dependencies"" sections, though. Also, the example in the post uses multiple ""//"" keys, which implies that npm does not reject JSON files with duplicated keys. In other words, the hack above should always be fine.

Update: One annoying disadvantage of the duplicated key hack is that npm install --save silently eliminates all duplicates. Unfortunately, it is very easy to overlook it and your well-intentioned comments are gone.

The ""//"" hack is still the safest as it seems. However, multi-line comments will be removed by npm install --save, too.
    NPS (Node Package Scripts) solved this problem for me. It lets you put your NPM scripts into a separate JavaScript file, where you can add comments galore and any other JavaScript logic you need to.
https://www.npmjs.com/package/nps
Sample of the package-scripts.js from one of my projects
module.exports = {
  scripts: {
    // makes sure e2e webdrivers are up to date
    postinstall: 'nps webdriver-update',

    // run the webpack dev server and open it in browser on port 7000
    server: 'webpack-dev-server --inline --progress --port 7000 --open',

    // start webpack dev server with full reload on each change
    default: 'nps server',

    // start webpack dev server with hot module replacement
    hmr: 'nps server -- --hot',

    // generates icon font via a gulp task
    iconFont: 'gulp default --gulpfile src/deps/build-scripts/gulp-icon-font.js',

    // No longer used
    // copyFonts: 'copyfiles -f src/app/glb/font/webfonts/**/* dist/1-0-0/font'
  }
}

I just did a local install npm install nps -save-dev and put this in my package.json scripts.
""scripts"": {
    ""start"": ""nps"",
    ""test"": ""nps test""
}

    I ended up with a scripts like that:

  ""scripts"": {
    ""//-1a"": ""---------------------------------------------------------------"",
    ""//-1b"": ""---------------------- from node_modules ----------------------"",
    ""//-1c"": ""---------------------------------------------------------------"",
    ""ng"": ""ng"",
    ""prettier"": ""prettier"",
    ""tslint"": ""tslint"",
    ""//-2a"": ""---------------------------------------------------------------"",
    ""//-2b"": ""--------------------------- backend ---------------------------"",
    ""//-2c"": ""---------------------------------------------------------------"",
    ""back:start"": ""node backend/index.js"",
    ""back:start:watch"": ""nodemon"",
    ""back:build:prod"": ""tsc -p backend/tsconfig.json"",
    ""back:serve:prod"": ""NODE_ENV=production node backend/dist/main.js"",
    ""back:lint:check"": ""tslint -c ./backend/tslint.json './backend/src/**/*.ts'"",
    ""back:lint:fix"": ""yarn run back:lint:check --fix"",
    ""back:check"": ""yarn run back:lint:check && yarn run back:prettier:check"",
    ""back:check:fix"": ""yarn run back:lint:fix; yarn run back:prettier:fix"",
    ""back:prettier:base-files"": ""yarn run prettier './backend/**/*.ts'"",
    ""back:prettier:fix"": ""yarn run back:prettier:base-files --write"",
    ""back:prettier:check"": ""yarn run back:prettier:base-files -l"",
    ""back:test"": ""ts-node --project backend/tsconfig.json node_modules/jasmine/bin/jasmine ./backend/**/*spec.ts"",
    ""back:test:watch"": ""watch 'yarn run back:test' backend"",
    ""back:test:coverage"": ""echo TODO"",
    ""//-3a"": ""---------------------------------------------------------------"",
    ""//-3b"": ""-------------------------- frontend ---------------------------"",
    ""//-3c"": ""---------------------------------------------------------------"",
    ""front:start"": ""yarn run ng serve"",
    ""front:test"": ""yarn run ng test"",
    ""front:test:ci"": ""yarn run front:test --single-run --progress=false"",
    ""front:e2e"": ""yarn run ng e2e"",
    ""front:e2e:ci"": ""yarn run ng e2e --prod --progress=false"",
    ""front:build:prod"": ""yarn run ng build --prod --e=prod --no-sourcemap --build-optimizer"",
    ""front:lint:check"": ""yarn run ng lint --type-check"",
    ""front:lint:fix"": ""yarn run front:lint:check --fix"",
    ""front:check"": ""yarn run front:lint:check && yarn run front:prettier:check"",
    ""front:check:fix"": ""yarn run front:lint:fix; yarn run front:prettier:fix"",
    ""front:prettier:base-files"": ""yarn run prettier \""./frontend/{e2e,src}/**/*.{scss,ts}\"""",
    ""front:prettier:fix"": ""yarn run front:prettier:base-files --write"",
    ""front:prettier:check"": ""yarn run front:prettier:base-files -l"",
    ""front:postbuild"": ""gulp compress"",
    ""//-4a"": ""---------------------------------------------------------------"",
    ""//-4b"": ""--------------------------- cypress ---------------------------"",
    ""//-4c"": ""---------------------------------------------------------------"",
    ""cy:open"": ""cypress open"",
    ""cy:headless"": ""cypress run"",
    ""cy:prettier:base-files"": ""yarn run prettier \""./cypress/**/*.{js,ts}\"""",
    ""cy:prettier:fix"": ""yarn run front:prettier:base-files --write"",
    ""cy:prettier:check"": ""yarn run front:prettier:base-files -l"",
    ""//-5a"": ""---------------------------------------------------------------"",
    ""//-5b"": ""--------------------------- common ----------------------------"",
    ""//-5c"": ""---------------------------------------------------------------"",
    ""all:check"": ""yarn run back:check && yarn run front:check && yarn run cy:prettier:check"",
    ""all:check:fix"": ""yarn run back:check:fix && yarn run front:check:fix && yarn run cy:prettier:fix"",
    ""//-6a"": ""---------------------------------------------------------------"",
    ""//-6b"": ""--------------------------- hooks -----------------------------"",
    ""//-6c"": ""---------------------------------------------------------------"",
    ""precommit"": ""lint-staged"",
    ""prepush"": ""yarn run back:lint:check && yarn run front:lint:check""
  },


My intent here is not to clarify one line, just to have some sort of delimiters between my scripts for backend, frontend, all, etc.

I'm not a huge fan of 1a, 1b, 1c, 2a, ... but the keys are different and I do not have any problem at all like that.
    DISCLAIMER: you probably should not use this hack. See comments below.

Here is another hack for adding comments in JSON.  Since:

{""a"": 1, ""a"": 2}

Is equivalent to
{""a"": 2}

You can do something like:
{
  ""devDependencies"": ""'mocha' not needed as should be globally installed"",
  ""devDependencies"" :  {
    ""should"": ""*""
  }
}

    As duplicate comment keys are removed running package.json tools (npm, yarn, etc.), I came to using a hashed version which allows for better reading as multiple lines and keys like:
""//"": {
  ""alpaca"": ""we use the bootstrap version"",
  ""eonasdan-bootstrap-datetimepicker"": ""instead of bootstrap-datetimepicker"",
  ""moment-with-locales"": ""is part of moment""
},

which is 'valid' according to my IDE as a root key, but within dependencies it complains expecting a string value.
    To summarise all of these answers:

Add a single top-level field called // that contains a comment string. This works, but it sucks because you can't put comments near the thing they are commenting on.

Add multiple top-level fields starting with //, e.g. //dependencies that contains a comment string. This is better, but it still only allows you to make top-level comments. You can't comment individual dependencies.

Add echo commands to your scripts. This works, but it sucks because you can only use it in scripts.


These solutions are also all not very readable. They add a ton of visual noise and IDEs will not syntax highlight them as comments.
I think the only reasonable solution is to generate the package.json from another file. The simplest way is to write your JSON as JavaScript and use Node.js to write it to package.json. Save this file as package.json.mjs, chmod +x it, and then you can just run it to generate your package.json.
#!/usr/bin/env node

import { writeFileSync } from ""fs"";

const config = {
  // TODO: Think of better name.
  name: ""foo"",
  dependencies: {
    // Bar 2.0 does not work due to bug 12345.
    bar: ""^1.2.0"",
  },
  // Look at these beautify comments. Perfectly syntax highlighted, you
  // can put them anywhere and there no risk of some tool removing them.
};

writeFileSync(""package.json"", JSON.stringify({
    ""//"": ""This file is \x40generated from package.json.mjs; do not edit."",
    ...config
  }, null, 2));

It uses the // key to warn people from editing it. \x40generated is deliberate. It turns into @generated in package.json and means some code review systems will collapse that file by default.
It's an extra step in your build system, but it beats all of the other hacks here.
    So far, most ""hacks"" here suggest to abuse JSON. But instead, why not abuse the underlying scripting language?
Edit The initial response was putting the description on the right using # add comments here to wrap it; however, this does not work on Windows, because flags (e.g., npm run myframework -- --myframework-flags) would be ignored. I changed my response to make it work on all platforms, and added some indents for readability purposes.
{
 ""scripts"": {
    ""help"": ""       echo 'Display help information (this screen)';          npm run"",
    ""myframework"": ""echo 'Run myframework binary';                          myframework"",
    ""develop"": ""    echo 'Run in development mode (with terminal output)';  npm run myframework""
    ""start"": ""      echo 'Start myFramework as a daemon';                   myframework start"",
    ""stop"":  ""      echo 'Stop the myFramework daemon';                     myframework stop""
    ""test"": ""echo \""Error: no test specified\"" && exit 1""
  }
}

This will:

Not break JSON compliance (or at least it's not a hack, and your IDE will not give you warnings for doing strange, dangerous stuff)
Works cross platform (tested on macOS and Windows, assuming it would work just fine on Linux)
Does not get in the way of running npm run myframework -- --help
Will output meaningful info when running npm run (which is the actual command to run to get information about available scripts)
Presents a more explicit help command (in case some developers are not aware that npm run presents such output)
Will show both the commands and its description when running the command itself
Is somewhat readable when just opening package.json (using less or your favorite IDE)

    I have a funny hack idea.
Create an npm package name suitably as a comment divider for dependencies and devDependencies block in file package.json, for example x----x----x
{
    ""name"": ""app-name"",
    ""dependencies"": {
        ""x----x----x"": ""this is the first line of a comment"",
        ""babel-cli"": ""6.x.x"",
        ""babel-core"": ""6.x.x"",
        ""x----x----x"": ""this is the second line of a comment"",
        ""knex"": ""^0.11.1"",
        ""mocha"": ""1.20.1"",
        ""x----x----x"": ""*""
    }
}

NOTE: You must add the last comment divider line with a valid version, like * in the block.
    For npm's package.json, I have found two ways (after reading this conversation):
  ""devDependencies"": {
    ""del-comment"": [
      ""some-text""
    ],
    ""del"": ""^5.1.0 ! inner comment"",
    ""envify-comment"": [
      ""some-text""
    ],
    ""envify"": ""4.1.0 ! inner comment""
  }

But with the update or reinstall of package with ""--save"" or ""--save-dev, a comment like ""^4.1.0 ! comment"" in the corresponding place will be deleted. And all this will break npm audit.
    Here's my take on comments within package.json / bower.json:
I have file package.json.js that contains a script that exports the actual package.json. Running the script overwrites the old package.json and tells me what changes it made, perfect to help you keep track of automatic changes npm made. That way I can even programmatically define what packages I want to use.
The latest Grunt task is here:
https://gist.github.com/MarZab/72fa6b85bc9e71de5991
    I do something that's some of you might like:
This // inside of the name means it's a comment for me:
  ""//"":""Main and typings are used till ES5"",
  ""//main"": ""build/index"",
  ""//typings"": ""build/index"",

    My take on the frustration of no comments in JSON.  I create new nodes, named for the nodes they refer to, but prefixed with underscores.  This is imperfect, but functional.

{
  ""name"": ""myapp"",
  ""version"": ""0.1.0"",
  ""private"": true,
  ""dependencies"": {
    ""react"": ""^16.3.2"",
    ""react-dom"": ""^16.3.2"",
    ""react-scripts"": ""1.1.4""
  },
  ""scripts"": {
    ""__start"": [
        ""a note about how the start script works""
    ],
    ""start"": ""react-scripts start"",
    ""build"": ""react-scripts build"",
    ""test"": ""react-scripts test --env=jsdom"",
    ""eject"": ""react-scripts eject""
  },
  ""__proxy"": [
    ""A note about how proxy works"",
    ""multilines are easy enough to add""
  ],
  ""proxy"": ""http://server.whatever.com:8000""
}

    Another hack
I created a script to read file package.json as the context for a handlebars template.
The code is below, in case someone finds this approach useful:
const templateData = require('../package.json');
const Handlebars = require('handlebars');
const fs = require('fs-extra');
const outputPath = __dirname + '/../package-json-comments.md';
const srcTemplatePath = __dirname + '/package-json-comments/package-json-comments.hbs';

Handlebars.registerHelper('objlist', function() {
  // The first argument is an object, and the list is a set of keys for that obj
  const obj = arguments[0];
  const list = Array.prototype.slice.call(arguments, 1).slice(0,-1);

  const mdList = list.map(function(k) {
    return '* ' + k + ': ' + obj[k];
  });

  return new Handlebars.SafeString(mdList.join(""\n""));
});

fs.readFile(srcTemplatePath, 'utf8', function(err, srcTemplate){
  if (err) throw err;
  const template = Handlebars.compile(srcTemplate);
  const content = template(templateData);

  fs.writeFile(outputPath, content, function(err) {
    if (err) throw err;
  });
});

handlebars template file package-json-comments.hbs
### Dependency Comments
For package: {{ name }}: {{version}}

#### Current Core Packages
should be safe to update
{{{objlist dependencies
           ""@material-ui/core""
           ""@material-ui/icons""
           ""@material-ui/styles""
}}}

#### Lagging Core Packages
breaks current code if updated
{{{objlist dependencies
           ""amazon-cognito-identity-js""
}}}

#### Major version change
Not tested yet
{{{objlist dependencies
           ""react-dev-utils""
           ""react-redux""
           ""react-router""
           ""redux-localstorage-simple""

}}}

    I like this:
  ""scripts"": {
    ""⏬⏬⏬ Jenkins Build - in this order ⏬⏬⏬                                                                                                  "": """",
    ""purge"": ""lerna run something"",
    ""clean:test"": ""lerna exec --ignore nanana""
}

There are extra spaces in the command name, so in Visual Studio Code's NPM Scripts plugin you have a better look.
    ","[487, 195, 528, 49, 6, 23, 11, 15, 23, 3, 125, 1, 6, 10, 10, 1, 7, 1, -1, 0, 0]",170978,70,2013-01-08T18:23:59,2022-01-24 03:33:53Z,
SVG fill color transparency / alpha?,"
                
Is it possible to set a transparency or alpha level on SVG fill colours?

I've tried adding two values to the fill tag (changing it from fill=""#044B94"" to fill=""#044B9466""), but this doesn't work.
    You use an addtional attribute; fill-opacity: This attribute takes a decimal number between 0.0 and 1.0, inclusive; where 0.0 is completely transparent.

For example:

<rect ... fill=""#044B94"" fill-opacity=""0.4""/>


Additionally you have the following:


stroke-opacity attribute for the stroke
opacity for the entire object

    As a not yet fully standardized solution (though in alignment with the color syntax in CSS3) you can use e.g fill=""rgba(124,240,10,0.5)"". Works fine in Firefox, Opera, Chrome.

Here's an example.
    fill=""#044B9466""

This is an RGBA color in hex notation inside the SVG, defined with hex values. This is valid, but not all programs can display it properly...
You can find the browser support for this syntax here: https://caniuse.com/#feat=css-rrggbbaa
As of August 2017: RGBA fill colors will display properly on Mozilla Firefox (54), Apple Safari (10.1) and Mac OS X Finder's ""Quick View"". However Google Chrome did not support this syntax until version 62 (was previously supported from version 54 with the Experimental Platform Features flag enabled).
As of April 2021, Inkscape version 1.0.2 cannot read this format in SVG files, and instead converts any RGBA color to opaque black. The bug report is here: https://gitlab.com/inkscape/inbox/-/issues/1195
    To change transparency on an svg code the simplest way is to open it on any text editor and look for the style attributes. It depends on the svg creator the way the styles are displayed. As i am an Inkscape user the usual way it set the style values is through a style tag just as if it were html but using svg native attributes like fill, stroke, stroke-width, opacity and so on. opacity affects the whole svg object, or path or group in which its stated and fill-opacity, stroke-opacity will affect just the fill and the stroke transparency. That said, I have also used and tasted to just use fill and instead of using#fff use instead the rgba standard like this rgba(255, 255, 255, 1) just as in css. This works fine for must modern browsers.
Keep in mind that if you intend to further reedit your svg the best practice, in my experience, is to always keep an untouched version at hand. Inkscape is more flexible with hand changed svgs but Illustrator and CorelDraw may have issues importing and edited svg.
Example
<path style=""fill:#ff0000;fill-opacity:1;stroke:#1a1a1a;stroke-width:2px;stroke-opacity:1"" d=""m 144.44226,461.14425 q 16.3125,-15.05769 37.64423,-15.05769 21.33173,0 36.38942,15.05769 15.0577,15.05769 15.0577,36.38942 0,21.33173 -15.0577,36.38943 -15.05769,16.3125 -36.38942,16.3125 -21.33173,0 -37.64423,-16.3125 -15.05769,-15.0577 -15.05769,-36.38943 0,-21.33173 15.05769,-36.38942 z M 28.99995,35.764435 l 85.32692,0 23.84135,52.701923 386.48078,0 q 10.03846,0 17.5673,7.528847 8.78366,7.528845 8.78366,17.567305 0,7.52885 -2.50962,12.54808 l -94.11058,161.87019 q -13.80288,27.60577 -45.17307,27.60577 l -194.4952,0 -26.35096,40.15385 q -2.50962,6.27404 -2.50962,7.52885 0,6.27404 6.27404,6.27404 l 298.64424,0 0,50.1923 -304.91828,0 q -25.09615,0 -41.40865,-13.80288 -15.05769,-13.80289 -15.05769,-38.89904 0,-15.05769 6.27404,-25.09615 l 38.89903,-63.9952 -92.855766,-189.475962 -52.701924,0 0,-52.701923 z M 401.67784,461.14425 q 15.05769,-15.05769 36.38942,-15.05769 21.33174,0 36.38943,15.05769 16.3125,15.05769 16.3125,36.38942 0,21.33173 -16.3125,36.38943 -15.05769,16.3125 -36.38943,16.3125 -21.33173,0 -36.38942,-16.3125 -15.05769,-15.0577 -15.05769,-36.38943 0,-21.33173 15.05769,-36.38942 z""/>

Example 2
<path style=""fill:#ff0000;fill-opacity:.5;stroke:#1a1a1a;stroke-width:2px;stroke-opacity:1"" d=""m 144.44226,461.14425 q 16.3125,-15.05769 37.64423,-15.05769 21.33173,0 36.38942,15.05769 15.0577,15.05769 15.0577,36.38942 0,21.33173 -15.0577,36.38943 -15.05769,16.3125 -36.38942,16.3125 -21.33173,0 -37.64423,-16.3125 -15.05769,-15.0577 -15.05769,-36.38943 0,-21.33173 15.05769,-36.38942 z M 28.99995,35.764435 l 85.32692,0 23.84135,52.701923 386.48078,0 q 10.03846,0 17.5673,7.528847 8.78366,7.528845 8.78366,17.567305 0,7.52885 -2.50962,12.54808 l -94.11058,161.87019 q -13.80288,27.60577 -45.17307,27.60577 l -194.4952,0 -26.35096,40.15385 q -2.50962,6.27404 -2.50962,7.52885 0,6.27404 6.27404,6.27404 l 298.64424,0 0,50.1923 -304.91828,0 q -25.09615,0 -41.40865,-13.80288 -15.05769,-13.80289 -15.05769,-38.89904 0,-15.05769 6.27404,-25.09615 l 38.89903,-63.9952 -92.855766,-189.475962 -52.701924,0 0,-52.701923 z M 401.67784,461.14425 q 15.05769,-15.05769 36.38942,-15.05769 21.33174,0 36.38943,15.05769 16.3125,15.05769 16.3125,36.38942 0,21.33173 -16.3125,36.38943 -15.05769,16.3125 -36.38943,16.3125 -21.33173,0 -36.38942,-16.3125 -15.05769,-15.0577 -15.05769,-36.38943 0,-21.33173 15.05769,-36.38942 z""/>

Example 3
<path style=""fill:rgba(255, 0, 0, .5);stroke:rgba(242, 242, 242, .5);stroke-width:2px"" d=""m 144.44226,461.14425 q 16.3125,-15.05769 37.64423,-15.05769 21.33173,0 36.38942,15.05769 15.0577,15.05769 15.0577,36.38942 0,21.33173 -15.0577,36.38943 -15.05769,16.3125 -36.38942,16.3125 -21.33173,0 -37.64423,-16.3125 -15.05769,-15.0577 -15.05769,-36.38943 0,-21.33173 15.05769,-36.38942 z M 28.99995,35.764435 l 85.32692,0 23.84135,52.701923 386.48078,0 q 10.03846,0 17.5673,7.528847 8.78366,7.528845 8.78366,17.567305 0,7.52885 -2.50962,12.54808 l -94.11058,161.87019 q -13.80288,27.60577 -45.17307,27.60577 l -194.4952,0 -26.35096,40.15385 q -2.50962,6.27404 -2.50962,7.52885 0,6.27404 6.27404,6.27404 l 298.64424,0 0,50.1923 -304.91828,0 q -25.09615,0 -41.40865,-13.80288 -15.05769,-13.80289 -15.05769,-38.89904 0,-15.05769 6.27404,-25.09615 l 38.89903,-63.9952 -92.855766,-189.475962 -52.701924,0 0,-52.701923 z M 401.67784,461.14425 q 15.05769,-15.05769 36.38942,-15.05769 21.33174,0 36.38943,15.05769 16.3125,15.05769 16.3125,36.38942 0,21.33173 -16.3125,36.38943 -15.05769,16.3125 -36.38943,16.3125 -21.33173,0 -36.38942,-16.3125 -15.05769,-15.0577 -15.05769,-36.38943 0,-21.33173 15.05769,-36.38942 z""/>

Notice that in the last example the fill-opacity and stroke-opacity have been removed as rgba standard covers both color and alpha channel in both cases.
    I am sharing a related tip that you might come across when you want the SVG to inherit the container's styles like normal state, hover state and visited state :
use fill='currentColor' on the path. This is how the SVG's produced by font awesome icons could take any fore color applied to fonts!
    Use attribute fill-opacity in your element of SVG.

Default value is 1, minimum is 0, in step use decimal values EX: 0.5 = 50% of alpha. Note: It is necessary to define fill color to apply fill-opacity.

See my example.

References.
    To make a fill completely transparent, fill=""transparent"" seems to work in modern browsers. But it didn't work in Microsoft Word (for Mac), I had to use fill-opacity=""0"".
    ","[487, 759, 83, 10, 2, 0, 2, 2]",417203,50,2011-05-18T09:29:53,2021-09-25 00:41:39Z,
Using async/await for multiple tasks,"
                
I'm using an API client that is completely asynchrounous, that is, each operation either returns Task or Task<T>, e.g:

static async Task DoSomething(int siteId, int postId, IBlogClient client)
{
    await client.DeletePost(siteId, postId); // call API client
    Console.WriteLine(""Deleted post {0}."", siteId);
}


Using the C# 5 async/await operators, what is the correct/most efficient way to start multiple tasks and wait for them all to complete:

int[] ids = new[] { 1, 2, 3, 4, 5 };
Parallel.ForEach(ids, i => DoSomething(1, i, blogClient).Wait());


or:

int[] ids = new[] { 1, 2, 3, 4, 5 };
Task.WaitAll(ids.Select(i => DoSomething(1, i, blogClient)).ToArray());


Since the API client is using HttpClient internally, I would expect this to issue 5 HTTP requests immediately, writing to the console as each one completes.
    int[] ids = new[] { 1, 2, 3, 4, 5 };
Parallel.ForEach(ids, i => DoSomething(1, i, blogClient).Wait());


Although you run the operations in parallel with the above code, this code blocks each thread that each operation runs on. For example, if the network call takes 2 seconds, each thread hangs for 2 seconds w/o doing anything but waiting.

int[] ids = new[] { 1, 2, 3, 4, 5 };
Task.WaitAll(ids.Select(i => DoSomething(1, i, blogClient)).ToArray());


On the other hand, the above code with WaitAll also blocks the threads and your threads won't be free to process any other work till the operation ends. 

Recommended Approach

I would prefer WhenAll which will perform your operations asynchronously in Parallel.

public async Task DoWork() {

    int[] ids = new[] { 1, 2, 3, 4, 5 };
    await Task.WhenAll(ids.Select(i => DoSomething(1, i, blogClient)));
}



  In fact, in the above case, you don't even need to await, you can just directly return from the method as you don't have any continuations:

public Task DoWork() 
{
    int[] ids = new[] { 1, 2, 3, 4, 5 };
    return Task.WhenAll(ids.Select(i => DoSomething(1, i, blogClient)));
}



To back this up, here is a detailed blog post going through all the
alternatives and their advantages/disadvantages: How and Where Concurrent Asynchronous I/O with ASP.NET Web API
    I was curious to see the results of the methods provided in the question as well as the accepted answer, so I put it to the test.

Here's the code:

using System;
using System.Collections.Generic;
using System.Linq;
using System.Threading;
using System.Threading.Tasks;

namespace AsyncTest
{
    class Program
    {
        class Worker
        {
            public int Id;
            public int SleepTimeout;

            public async Task DoWork(DateTime testStart)
            {
                var workerStart = DateTime.Now;
                Console.WriteLine(""Worker {0} started on thread {1}, beginning {2} seconds after test start."",
                    Id, Thread.CurrentThread.ManagedThreadId, (workerStart-testStart).TotalSeconds.ToString(""F2""));
                await Task.Run(() => Thread.Sleep(SleepTimeout));
                var workerEnd = DateTime.Now;
                Console.WriteLine(""Worker {0} stopped; the worker took {1} seconds, and it finished {2} seconds after the test start."",
                   Id, (workerEnd-workerStart).TotalSeconds.ToString(""F2""), (workerEnd-testStart).TotalSeconds.ToString(""F2""));
            }
        }

        static void Main(string[] args)
        {
            var workers = new List<Worker>
            {
                new Worker { Id = 1, SleepTimeout = 1000 },
                new Worker { Id = 2, SleepTimeout = 2000 },
                new Worker { Id = 3, SleepTimeout = 3000 },
                new Worker { Id = 4, SleepTimeout = 4000 },
                new Worker { Id = 5, SleepTimeout = 5000 },
            };

            var startTime = DateTime.Now;
            Console.WriteLine(""Starting test: Parallel.ForEach..."");
            PerformTest_ParallelForEach(workers, startTime);
            var endTime = DateTime.Now;
            Console.WriteLine(""Test finished after {0} seconds.\n"",
                (endTime - startTime).TotalSeconds.ToString(""F2""));

            startTime = DateTime.Now;
            Console.WriteLine(""Starting test: Task.WaitAll..."");
            PerformTest_TaskWaitAll(workers, startTime);
            endTime = DateTime.Now;
            Console.WriteLine(""Test finished after {0} seconds.\n"",
                (endTime - startTime).TotalSeconds.ToString(""F2""));

            startTime = DateTime.Now;
            Console.WriteLine(""Starting test: Task.WhenAll..."");
            var task = PerformTest_TaskWhenAll(workers, startTime);
            task.Wait();
            endTime = DateTime.Now;
            Console.WriteLine(""Test finished after {0} seconds.\n"",
                (endTime - startTime).TotalSeconds.ToString(""F2""));

            Console.ReadKey();
        }

        static void PerformTest_ParallelForEach(List<Worker> workers, DateTime testStart)
        {
            Parallel.ForEach(workers, worker => worker.DoWork(testStart).Wait());
        }

        static void PerformTest_TaskWaitAll(List<Worker> workers, DateTime testStart)
        {
            Task.WaitAll(workers.Select(worker => worker.DoWork(testStart)).ToArray());
        }

        static Task PerformTest_TaskWhenAll(List<Worker> workers, DateTime testStart)
        {
            return Task.WhenAll(workers.Select(worker => worker.DoWork(testStart)));
        }
    }
}


And the resulting output:

Starting test: Parallel.ForEach...
Worker 1 started on thread 1, beginning 0.21 seconds after test start.
Worker 4 started on thread 5, beginning 0.21 seconds after test start.
Worker 2 started on thread 3, beginning 0.21 seconds after test start.
Worker 5 started on thread 6, beginning 0.21 seconds after test start.
Worker 3 started on thread 4, beginning 0.21 seconds after test start.
Worker 1 stopped; the worker took 1.90 seconds, and it finished 2.11 seconds after the test start.
Worker 2 stopped; the worker took 3.89 seconds, and it finished 4.10 seconds after the test start.
Worker 3 stopped; the worker took 5.89 seconds, and it finished 6.10 seconds after the test start.
Worker 4 stopped; the worker took 5.90 seconds, and it finished 6.11 seconds after the test start.
Worker 5 stopped; the worker took 8.89 seconds, and it finished 9.10 seconds after the test start.
Test finished after 9.10 seconds.

Starting test: Task.WaitAll...
Worker 1 started on thread 1, beginning 0.01 seconds after test start.
Worker 2 started on thread 1, beginning 0.01 seconds after test start.
Worker 3 started on thread 1, beginning 0.01 seconds after test start.
Worker 4 started on thread 1, beginning 0.01 seconds after test start.
Worker 5 started on thread 1, beginning 0.01 seconds after test start.
Worker 1 stopped; the worker took 1.00 seconds, and it finished 1.01 seconds after the test start.
Worker 2 stopped; the worker took 2.00 seconds, and it finished 2.01 seconds after the test start.
Worker 3 stopped; the worker took 3.00 seconds, and it finished 3.01 seconds after the test start.
Worker 4 stopped; the worker took 4.00 seconds, and it finished 4.01 seconds after the test start.
Worker 5 stopped; the worker took 5.00 seconds, and it finished 5.01 seconds after the test start.
Test finished after 5.01 seconds.

Starting test: Task.WhenAll...
Worker 1 started on thread 1, beginning 0.00 seconds after test start.
Worker 2 started on thread 1, beginning 0.00 seconds after test start.
Worker 3 started on thread 1, beginning 0.00 seconds after test start.
Worker 4 started on thread 1, beginning 0.00 seconds after test start.
Worker 5 started on thread 1, beginning 0.00 seconds after test start.
Worker 1 stopped; the worker took 1.00 seconds, and it finished 1.00 seconds after the test start.
Worker 2 stopped; the worker took 2.00 seconds, and it finished 2.00 seconds after the test start.
Worker 3 stopped; the worker took 3.00 seconds, and it finished 3.00 seconds after the test start.
Worker 4 stopped; the worker took 4.00 seconds, and it finished 4.00 seconds after the test start.
Worker 5 stopped; the worker took 5.00 seconds, and it finished 5.00 seconds after the test start.
Test finished after 5.00 seconds.

    All the answers seem to be complicated.
Following code works for me, just put your  regular Task.Run() inside an array and call with Task.WhenAll():

await Task.WhenAll(new Task[] { 
                Task.Run(() => Func1(args)),
                Task.Run(() => Func2(args))
            });

    You can use Task.WhenAll function that you can pass n tasks; Task.WhenAll will return a task which runs to completion when all the tasks that you passed to Task.WhenAll complete. You have to wait asynchronously on Task.WhenAll so that you'll not block your UI thread:
   public async Task DoSomeThing() {
       
       Task[] tasks = new Task[numTasks];
       for(int i = 0; i < numTask; i++)
       {
          tasks[i] = CallSomeAsync();
       }
       await Task.WhenAll(tasks);
       // code that'll execute on UI thread
   }

    Parallel.ForEach requires a list of user-defined workers and a non-async Action to perform with each worker.

Task.WaitAll and Task.WhenAll require a List<Task>, which are by definition asynchronous.

I found RiaanDP's response very useful to understand the difference, but it needs a correction for Parallel.ForEach. Not enough reputation to respond to his comment, thus my own response.

using System;
using System.Collections.Generic;
using System.Linq;
using System.Threading;
using System.Threading.Tasks;

namespace AsyncTest
{
    class Program
    {
        class Worker
        {
            public int Id;
            public int SleepTimeout;

            public void DoWork(DateTime testStart)
            {
                var workerStart = DateTime.Now;
                Console.WriteLine(""Worker {0} started on thread {1}, beginning {2} seconds after test start."",
                    Id, Thread.CurrentThread.ManagedThreadId, (workerStart - testStart).TotalSeconds.ToString(""F2""));
                Thread.Sleep(SleepTimeout);
                var workerEnd = DateTime.Now;
                Console.WriteLine(""Worker {0} stopped; the worker took {1} seconds, and it finished {2} seconds after the test start."",
                   Id, (workerEnd - workerStart).TotalSeconds.ToString(""F2""), (workerEnd - testStart).TotalSeconds.ToString(""F2""));
            }

            public async Task DoWorkAsync(DateTime testStart)
            {
                var workerStart = DateTime.Now;
                Console.WriteLine(""Worker {0} started on thread {1}, beginning {2} seconds after test start."",
                    Id, Thread.CurrentThread.ManagedThreadId, (workerStart - testStart).TotalSeconds.ToString(""F2""));
                await Task.Run(() => Thread.Sleep(SleepTimeout));
                var workerEnd = DateTime.Now;
                Console.WriteLine(""Worker {0} stopped; the worker took {1} seconds, and it finished {2} seconds after the test start."",
                   Id, (workerEnd - workerStart).TotalSeconds.ToString(""F2""), (workerEnd - testStart).TotalSeconds.ToString(""F2""));
            }
        }

        static void Main(string[] args)
        {
            var workers = new List<Worker>
            {
                new Worker { Id = 1, SleepTimeout = 1000 },
                new Worker { Id = 2, SleepTimeout = 2000 },
                new Worker { Id = 3, SleepTimeout = 3000 },
                new Worker { Id = 4, SleepTimeout = 4000 },
                new Worker { Id = 5, SleepTimeout = 5000 },
            };

            var startTime = DateTime.Now;
            Console.WriteLine(""Starting test: Parallel.ForEach..."");
            PerformTest_ParallelForEach(workers, startTime);
            var endTime = DateTime.Now;
            Console.WriteLine(""Test finished after {0} seconds.\n"",
                (endTime - startTime).TotalSeconds.ToString(""F2""));

            startTime = DateTime.Now;
            Console.WriteLine(""Starting test: Task.WaitAll..."");
            PerformTest_TaskWaitAll(workers, startTime);
            endTime = DateTime.Now;
            Console.WriteLine(""Test finished after {0} seconds.\n"",
                (endTime - startTime).TotalSeconds.ToString(""F2""));

            startTime = DateTime.Now;
            Console.WriteLine(""Starting test: Task.WhenAll..."");
            var task = PerformTest_TaskWhenAll(workers, startTime);
            task.Wait();
            endTime = DateTime.Now;
            Console.WriteLine(""Test finished after {0} seconds.\n"",
                (endTime - startTime).TotalSeconds.ToString(""F2""));

            Console.ReadKey();
        }

        static void PerformTest_ParallelForEach(List<Worker> workers, DateTime testStart)
        {
            Parallel.ForEach(workers, worker => worker.DoWork(testStart));
        }

        static void PerformTest_TaskWaitAll(List<Worker> workers, DateTime testStart)
        {
            Task.WaitAll(workers.Select(worker => worker.DoWorkAsync(testStart)).ToArray());
        }

        static Task PerformTest_TaskWhenAll(List<Worker> workers, DateTime testStart)
        {
            return Task.WhenAll(workers.Select(worker => worker.DoWorkAsync(testStart)));
        }
    }
}


The resulting output is below. Execution times are comparable. I ran this test while my computer was doing the weekly anti virus scan. Changing the order of the tests did change the execution times on them.

Starting test: Parallel.ForEach...
Worker 1 started on thread 9, beginning 0.02 seconds after test start.
Worker 2 started on thread 10, beginning 0.02 seconds after test start.
Worker 3 started on thread 11, beginning 0.02 seconds after test start.
Worker 4 started on thread 13, beginning 0.03 seconds after test start.
Worker 5 started on thread 14, beginning 0.03 seconds after test start.
Worker 1 stopped; the worker took 1.00 seconds, and it finished 1.02 seconds after the test start.
Worker 2 stopped; the worker took 2.00 seconds, and it finished 2.02 seconds after the test start.
Worker 3 stopped; the worker took 3.00 seconds, and it finished 3.03 seconds after the test start.
Worker 4 stopped; the worker took 4.00 seconds, and it finished 4.03 seconds after the test start.
Worker 5 stopped; the worker took 5.00 seconds, and it finished 5.03 seconds after the test start.
Test finished after 5.03 seconds.

Starting test: Task.WaitAll...
Worker 1 started on thread 9, beginning 0.00 seconds after test start.
Worker 2 started on thread 9, beginning 0.00 seconds after test start.
Worker 3 started on thread 9, beginning 0.00 seconds after test start.
Worker 4 started on thread 9, beginning 0.00 seconds after test start.
Worker 5 started on thread 9, beginning 0.01 seconds after test start.
Worker 1 stopped; the worker took 1.00 seconds, and it finished 1.01 seconds after the test start.
Worker 2 stopped; the worker took 2.00 seconds, and it finished 2.01 seconds after the test start.
Worker 3 stopped; the worker took 3.00 seconds, and it finished 3.01 seconds after the test start.
Worker 4 stopped; the worker took 4.00 seconds, and it finished 4.01 seconds after the test start.
Worker 5 stopped; the worker took 5.00 seconds, and it finished 5.01 seconds after the test start.
Test finished after 5.01 seconds.

Starting test: Task.WhenAll...
Worker 1 started on thread 9, beginning 0.00 seconds after test start.
Worker 2 started on thread 9, beginning 0.00 seconds after test start.
Worker 3 started on thread 9, beginning 0.00 seconds after test start.
Worker 4 started on thread 9, beginning 0.00 seconds after test start.
Worker 5 started on thread 9, beginning 0.00 seconds after test start.
Worker 1 stopped; the worker took 1.00 seconds, and it finished 1.00 seconds after the test start.
Worker 2 stopped; the worker took 2.00 seconds, and it finished 2.00 seconds after the test start.
Worker 3 stopped; the worker took 3.00 seconds, and it finished 3.00 seconds after the test start.
Worker 4 stopped; the worker took 4.00 seconds, and it finished 4.00 seconds after the test start.
Worker 5 stopped; the worker took 5.00 seconds, and it finished 5.01 seconds after the test start.
Test finished after 5.01 seconds.

    Since the API you're calling is async, the Parallel.ForEach version doesn't make much sense. You shouldnt use .Wait in the WaitAll version since that would lose the parallelism  Another alternative if the caller is async is using Task.WhenAll after doing Select and ToArray to generate the array of tasks. A second alternative is using Rx 2.0
    I just want to add to all great answers above,
that if you write a library it's a good practice to use ConfigureAwait(false)
and get better performance, as said here.
So this snippet seems to be better:
 public static async Task DoWork() 
 {
     int[] ids = new[] { 1, 2, 3, 4, 5 };
     await Task.WhenAll(ids.Select(i => DoSomething(1, i))).ConfigureAwait(false);
 }

A full fiddle link here.
    ","[487, 675, 63, 2, 22, 11, 26, 1]",345799,117,2012-09-09T08:40:04,2022-01-19 22:57:39Z,c 
How do I create variable variables?,"
                
How do I accomplish variable variables in Python?
Here is an elaborative manual entry, for instance: Variable variables
I hear this is a bad idea in general though, and it is a security hole in PHP. Is that true?
    You can use dictionaries to accomplish this. Dictionaries are stores of keys and values. 

>>> dct = {'x': 1, 'y': 2, 'z': 3}
>>> dct
{'y': 2, 'x': 1, 'z': 3}
>>> dct[""y""]
2


You can use variable key names to achieve the effect of variable variables without the security risk.

>>> x = ""spam""
>>> z = {x: ""eggs""}
>>> z[""spam""]
'eggs'


For cases where you're thinking of doing something like

var1 = 'foo'
var2 = 'bar'
var3 = 'baz'
...


a list may be more appropriate than a dict. A list represents an ordered sequence of objects, with integer indices:

lst = ['foo', 'bar', 'baz']
print(lst[1])           # prints bar, because indices start at 0
lst.append('potatoes')  # lst is now ['foo', 'bar', 'baz', 'potatoes']


For ordered sequences, lists are more convenient than dicts with integer keys, because lists support iteration in index order, slicing, append, and other operations that would require awkward key management with a dict.
    New coders sometimes write code like this:

my_calculator.button_0 = tkinter.Button(root, text=0)
my_calculator.button_1 = tkinter.Button(root, text=1)
my_calculator.button_2 = tkinter.Button(root, text=2)
...


The coder is then left with a pile of named variables, with a coding effort of O(m * n), where m is the number of named variables and n is the number of times that group of variables needs to be accessed (including creation). The more astute beginner observes that the only difference in each of those lines is a number that changes based on a rule, and decides to use a loop. However, they get stuck on how to dynamically create those variable names, and may try something like this:

for i in range(10):
    my_calculator.('button_%d' % i) = tkinter.Button(root, text=i)


They soon find that this does not work.

If the program requires arbitrary variable ""names,"" a dictionary is the best choice, as explained in other answers. However, if you're simply trying to create many variables and you don't mind referring to them with a sequence of integers, you're probably looking for a list. This is particularly true if your data are homogeneous, such as daily temperature readings, weekly quiz scores, or a grid of graphical widgets.

This can be assembled as follows:

my_calculator.buttons = []
for i in range(10):
    my_calculator.buttons.append(tkinter.Button(root, text=i))


This list can also be created in one line with a comprehension:

my_calculator.buttons = [tkinter.Button(root, text=i) for i in range(10)]


The result in either case is a populated list, with the first element accessed with my_calculator.buttons[0], the next with my_calculator.buttons[1], and so on. The ""base"" variable name becomes the name of the list and the varying identifier is used to access it.

Finally, don't forget other data structures, such as the set - this is similar to a dictionary, except that each ""name"" doesn't have a value attached to it. If you simply need a ""bag"" of objects, this can be a great choice. Instead of something like this:

keyword_1 = 'apple'
keyword_2 = 'banana'

if query == keyword_1 or query == keyword_2:
    print('Match.')


You will have this:

keywords = {'apple', 'banana'}
if query in keywords:
    print('Match.')


Use a list for a sequence of similar objects, a set for an arbitrarily-ordered bag of objects, or a dict for a bag of names with associated values.
    It's not a good idea. If you are accessing a global variable you can use globals().

>>> a = 10
>>> globals()['a']
10


If you want to access a variable in the local scope you can use locals(), but you cannot assign values to the returned dict.

A better solution is to use getattr or store your variables in a dictionary and then access them by name.
    # Python 3.8.2 (default, Feb 26 2020, 02:56:10)

Variable variables in Python
""""""
<?php
$a = 'hello';
$e = 'wow'
?>
<?php
$$a = 'world';
?>
<?php
echo ""$a ${$a}\n"";
echo ""$a ${$a[1]}\n"";
?>
<?php
echo ""$a $hello"";
?>
""""""

a = 'hello'  #<?php $a = 'hello'; ?>
e = 'wow'   #<?php $e = 'wow'; ?>
vars()[a] = 'world' #<?php $$a = 'world'; ?>
print(a, vars()[a]) #<?php echo ""$a ${$a}\n""; ?>
print(a, vars()[vars()['a'][1]]) #<?php echo ""$a ${$a[1]}\n""; ?>
print(a, hello) #<?php echo ""$a $hello""; ?>

Output:
hello world
hello wow
hello world


Using globals(), locals(), or vars() will produce the same results
# Python 3.8.2 (default, Feb 26 2020, 02:56:10)

#<?php $a = 'hello'; ?>
#<?php $e = 'wow'; ?>
#<?php $$a = 'world'; ?>
#<?php echo ""$a ${$a}\n""; ?>
#<?php echo ""$a ${$a[1]}\n""; ?>
#<?php echo ""$a $hello""; ?>

print('locals():\n')
a = 'hello'
e = 'wow'
locals()[a] = 'world'
print(a, locals()[a])
print(a, locals()[locals()['a'][1]])
print(a, hello)

print('\n\nglobals():\n')
a = 'hello'
e = 'wow'
globals()[a] = 'world'
print(a, globals()[a])
print(a, globals()[globals()['a'][1]])
print(a, hello)

Output:
locals():

hello world
hello wow
hello world


globals():

hello world
hello wow
hello world


Bonus (creating variables from strings)
# Python 2.7.16 (default, Jul 13 2019, 16:01:51)
# [GCC 8.3.0] on linux2

Creating variables and unpacking tuple:
g = globals()
listB = []
for i in range(10):
    g[""num%s"" % i] = i ** 10
    listB.append(""num{0}"".format(i))

def printNum():
    print ""Printing num0 to num9:""
    for i in range(10):
        print ""num%s = "" % i, 
        print g[""num%s"" % i]

printNum()

listA = []
for i in range(10):
    listA.append(i)

listA = tuple(listA)
print listA, '""Tuple to unpack""'

listB = str(str(listB).strip(""[]"").replace(""'"", """") + "" = listA"")

print listB

exec listB

printNum()

Output:
Printing num0 to num9:
num0 =  0
num1 =  1
num2 =  1024
num3 =  59049
num4 =  1048576
num5 =  9765625
num6 =  60466176
num7 =  282475249
num8 =  1073741824
num9 =  3486784401
(0, 1, 2, 3, 4, 5, 6, 7, 8, 9) ""Tuple to unpack""
num0, num1, num2, num3, num4, num5, num6, num7, num8, num9 = listA
Printing num0 to num9:
num0 =  0
num1 =  1
num2 =  2
num3 =  3
num4 =  4
num5 =  5
num6 =  6
num7 =  7
num8 =  8
num9 =  9

    Use the built-in getattr function to get an attribute on an object by name.  Modify the name as needed.

obj.spam = 'eggs'
name = 'spam'
getattr(obj, name)  # returns 'eggs'

    You have to use globals() built in method  to achieve that behaviour:
def var_of_var(k, v):
    globals()[k] = v

print variable_name # NameError: name 'variable_name' is not defined
some_name = 'variable_name'
globals()[some_name] = 123
print(variable_name) # 123

some_name = 'variable_name2'
var_of_var(some_name, 456)
print(variable_name2) # 456

    Use globals()

You can actually assign variables to global scope dynamically, for instance, if you want 10 variables that can be accessed on a global scope i_1, i_2 ... i_10:

for i in range(10):
    globals()['i_{}'.format(i)] = 'a'


This will assign 'a' to all of these 10 variables, of course you can change the value dynamically as well. All of these variables can be accessed now like other globally declared variable:

>>> i_5
'a'

    The SimpleNamespace class could be used to create new attributes with setattr, or subclass SimpleNamespace and create your own function to add new attribute names (variables). 

from types import SimpleNamespace

variables = {""b"":""B"",""c"":""C""}
a = SimpleNamespace(**variables)
setattr(a,""g"",""G"")
a.g = ""G+""
something = a.a

    I have tried both in python 3.7.3, you can use either globals() or vars()

>>> food #Error
>>> milkshake #Error
>>> food=""bread""
>>> drink=""milkshake""
>>> globals()[food] = ""strawberry flavor""
>>> vars()[drink] = ""chocolate flavor""
>>> bread
'strawberry flavor'
>>> milkshake
'chocolate flavor'
>>> globals()[drink]
'chocolate flavor'
>>> vars()[food]
'strawberry flavor'




Reference:
https://www.daniweb.com/programming/software-development/threads/111526/setting-a-string-as-a-variable-name#post548936
    Instead of a dictionary you can also use namedtuple from the collections module, which makes access easier.

For example:

# using dictionary
variables = {}
variables[""first""] = 34
variables[""second""] = 45
print(variables[""first""], variables[""second""])

# using namedtuple
Variables = namedtuple('Variables', ['first', 'second'])
vars = Variables(34, 45)
print(vars.first, vars.second)

    Whenever you want to use variable variables, it's probably better to use a dictionary. So instead of writing

$foo = ""bar""
$$foo = ""baz""


you write 

mydict = {}
foo = ""bar""
mydict[foo] = ""baz""


This way you won't accidentally overwrite previously existing variables (which is the security aspect) and you can have different ""namespaces"".
    Any set of variables can also be wrapped up in a class. 
""Variable"" variables may be added to the class instance during runtime by directly accessing the built-in dictionary through __dict__ attribute. 

The following code defines Variables class, which adds variables (in this case attributes) to its instance during the construction. Variable names are taken from a specified list (which, for example, could have been generated by program code):

# some list of variable names
L = ['a', 'b', 'c']

class Variables:
    def __init__(self, L):
        for item in L:
            self.__dict__[item] = 100

v = Variables(L)
print(v.a, v.b, v.c)
#will produce 100 100 100

    If you don't want to use any object, you can still use setattr() inside your current module:

import sys
current_module = module = sys.modules[__name__]  # i.e the ""file"" where your code is written
setattr(current_module, 'variable_name', 15)  # 15 is the value you assign to the var
print(variable_name)  # >>> 15, created from a string

    The consensus is to use a dictionary for this - see the other answers. This is a good idea for most cases, however, there are many aspects arising from this:


you'll yourself be responsible for this dictionary, including garbage collection (of in-dict variables) etc.
there's either no locality or globality for variable variables, it depends on the globality of the dictionary
if you want to rename a variable name, you'll have to do it manually
however, you are much more flexible, e.g. 


you can decide to overwrite existing variables or  ...
... choose to implement const variables
to raise an exception on overwriting for different types
etc.



That said, I've implemented a variable variables manager-class which provides some of the above ideas. It works for python 2 and 3.

You'd use the class like this:

from variableVariablesManager import VariableVariablesManager

myVars = VariableVariablesManager()
myVars['test'] = 25
print(myVars['test'])

# define a const variable
myVars.defineConstVariable('myconst', 13)
try:
    myVars['myconst'] = 14 # <- this raises an error, since 'myconst' must not be changed
    print(""not allowed"")
except AttributeError as e:
    pass

# rename a variable
myVars.renameVariable('myconst', 'myconstOther')

# preserve locality
def testLocalVar():
    myVars = VariableVariablesManager()
    myVars['test'] = 13
    print(""inside function myVars['test']:"", myVars['test'])
testLocalVar()
print(""outside function myVars['test']:"", myVars['test'])

# define a global variable
myVars.defineGlobalVariable('globalVar', 12)
def testGlobalVar():
    myVars = VariableVariablesManager()
    print(""inside function myVars['globalVar']:"", myVars['globalVar'])
    myVars['globalVar'] = 13
    print(""inside function myVars['globalVar'] (having been changed):"", myVars['globalVar'])
testGlobalVar()
print(""outside function myVars['globalVar']:"", myVars['globalVar'])


If you wish to allow overwriting of variables with the same type only:

myVars = VariableVariablesManager(enforceSameTypeOnOverride = True)
myVars['test'] = 25
myVars['test'] = ""Cat"" # <- raises Exception (different type on overwriting)

    The setattr() method sets the value of the specified attribute of the specified object.
Syntax goes like this –
setattr(object, name, value)
Example –

setattr(self,id,123)

which is equivalent to self.id = 123
As you might have observed, setattr() expects an object to be passed along with the value to generate/modify a new attribute.
We can use setattr() with a workaround to be able to use within modules. Here’ how –
import sys
x = ""pikachu""
value = 46
thismodule = sys.modules[__name__]
setattr(thismodule, x, value)
print(pikachu)

    It should be extremely risky...
but you can use exec():
a = 'b=5'
exec(a)
c = b*2
print (c)

Result:
10
    I'm am answering the question: How to get the value of a variable given its name in a string?
which is closed as a duplicate with a link to this question. 

If the variables in question are part of an object (part of a class for example) then some useful functions to achieve exactly that are hasattr, getattr, and setattr. 

So for example you can have:

class Variables(object):
    def __init__(self):
        self.foo = ""initial_variable""
    def create_new_var(self,name,value):
        setattr(self,name,value)
    def get_var(self,name):
        if hasattr(self,name):
            return getattr(self,name)
        else:
            raise(""Class does not have a variable named: ""+name)


Then you can do:

v = Variables()
v.get_var(""foo"")



  ""initial_variable""


v.create_new_var(v.foo,""is actually not initial"")
v.initial_variable



  ""is actually not initial""

    ","[487, 394, 63, 85, 7, 109, 9, 20, 13, 6, 15, 42, 1, 10, 3, 0, 0, 7]",209805,133,2009-09-03T12:37:48,2022-04-02 08:12:48Z,python 
Difference between EXISTS and IN in SQL?,"
                
What is the difference between the EXISTS and IN clause in SQL?

When should we use EXISTS, and when should we use IN?
    IN supports only equality relations (or inequality when preceded by NOT).
It is a synonym to =any / =some, e.g
select    * 
from      t1 
where     x in (select x from t2)
;

EXISTS supports variant types of relations, that cannot be expressed using IN, e.g. -
select    * 
from      t1 
where     exists (select    null 
                  from      t2 
                  where     t2.x=t1.x 
                        and t2.y>t1.y 
                        and t2.z like '℅' || t1.z || '℅'
                  )
;


And on a different note -
The allegedly performance and technical differences between EXISTS and IN may result from specific vendor's implementations/limitations/bugs, but many times they are nothing but myths created due to lack of understanding of the databases internals.
The tables' definition, statistics' accuracy, database configuration and optimizer's version have all impact on the execution plan and therefore on the performance metrics.
    The exists keyword can be used in that way, but really it's intended as a way to avoid counting:



--this statement needs to check the entire table
select count(*) from [table] where ...

--this statement is true as soon as one match is found
exists ( select * from [table] where ... )


This is most useful where you have if conditional statements, as exists can be a lot quicker than count.

The in is best used where you have a static list to pass:

 select * from [table]
 where [field] in (1, 2, 3)


When you have a table in an in statement it makes more sense to use a join, but mostly it shouldn't matter. The query optimiser should return the same plan either way. In some implementations (mostly older, such as Microsoft SQL Server 2000) in queries will always get a nested join plan, while join queries will use nested, merge or hash as appropriate. More modern implementations are smarter and can adjust the plan even when in is used.
    
EXISTS is much faster than IN when the subquery results is very large.
IN is faster than EXISTS when the subquery results is very small.

CREATE TABLE t1 (id INT, title VARCHAR(20), someIntCol INT)
GO
CREATE TABLE t2 (id INT, t1Id INT, someData VARCHAR(20))
GO

INSERT INTO t1
SELECT 1, 'title 1', 5 UNION ALL
SELECT 2, 'title 2', 5 UNION ALL
SELECT 3, 'title 3', 5 UNION ALL
SELECT 4, 'title 4', 5 UNION ALL
SELECT null, 'title 5', 5 UNION ALL
SELECT null, 'title 6', 5

INSERT INTO t2
SELECT 1, 1, 'data 1' UNION ALL
SELECT 2, 1, 'data 2' UNION ALL
SELECT 3, 2, 'data 3' UNION ALL
SELECT 4, 3, 'data 4' UNION ALL
SELECT 5, 3, 'data 5' UNION ALL
SELECT 6, 3, 'data 6' UNION ALL
SELECT 7, 4, 'data 7' UNION ALL
SELECT 8, null, 'data 8' UNION ALL
SELECT 9, 6, 'data 9' UNION ALL
SELECT 10, 6, 'data 10' UNION ALL
SELECT 11, 8, 'data 11'

Query 1

SELECT
FROM    t1 
WHERE   not  EXISTS (SELECT * FROM t2 WHERE t1.id = t2.t1id)


Query 2

SELECT t1.* 
FROM   t1 
WHERE  t1.id not in (SELECT  t2.t1id FROM t2 )


If in t1 your id has null value then Query 1 will find them, but Query 2 cant find null parameters.

I mean IN can't compare anything with null, so it has no result for null, but EXISTS can compare everything with null.

    EXISTS will tell you whether a query returned any results. e.g.:

SELECT * 
FROM Orders o 
WHERE EXISTS (
    SELECT * 
    FROM Products p 
    WHERE p.ProductNumber = o.ProductNumber)


IN is used to compare one value to several, and can use literal values, like this:

SELECT * 
FROM Orders 
WHERE ProductNumber IN (1, 10, 100)


You can also use query results with the IN clause, like this:

SELECT * 
FROM Orders 
WHERE ProductNumber IN (
    SELECT ProductNumber 
    FROM Products 
    WHERE ProductInventoryQuantity > 0)

    Based on rule optimizer: 


EXISTS is much faster than IN, when the sub-query results is very large.
IN is  faster than EXISTS, when the sub-query results is very small.


Based on cost optimizer:  


There is no difference. 

    I'm assuming you know what they do, and thus are used differently, so I'm going to understand your question as: When would it be a good idea to rewrite the SQL to use IN instead of EXISTS, or vice versa.

Is that a fair assumption?



Edit: The reason I'm asking is that in many cases you can rewrite an SQL based on IN to use an EXISTS instead, and vice versa, and for some database engines, the query optimizer will treat the two differently.

For instance:

SELECT *
FROM Customers
WHERE EXISTS (
    SELECT *
    FROM Orders
    WHERE Orders.CustomerID = Customers.ID
)


can be rewritten to:

SELECT *
FROM Customers
WHERE ID IN (
    SELECT CustomerID
    FROM Orders
)


or with a join:

SELECT Customers.*
FROM Customers
    INNER JOIN Orders ON Customers.ID = Orders.CustomerID


So my question still stands, is the original poster wondering about what IN and EXISTS does, and thus how to use it, or does he ask wether rewriting an SQL using IN to use EXISTS instead, or vice versa, will be a good idea?
    In certain circumstances, it is better to use IN rather than EXISTS. In general, if the selective predicate is in the subquery, then use IN. If the selective predicate is in the parent query, then use EXISTS.

https://docs.oracle.com/cd/B19306_01/server.102/b14211/sql_1016.htm#i28403
    If you are using the IN operator, the SQL engine will scan all records fetched from the inner query. On the other hand if we are using EXISTS, the SQL engine will stop the scanning process as soon as it found a match.
    The Exists keyword evaluates true or false, but IN keyword compare all value in the corresponding sub query column. 
Another one Select 1 can be use with Exists command. Example:

SELECT * FROM Temp1 where exists(select 1 from Temp2 where conditions...)


But IN is less efficient so Exists faster.
    The reason is that the EXISTS operator works based on the “at least found” principle. It returns true and stops scanning table once at least one matching row found.

On the other hands, when the IN operator is combined with a subquery, MySQL must process the subquery first, and then uses the result of the subquery to process the whole query.


  The general rule of thumb is that if the subquery contains a large
  volume of data, the EXISTS operator provides a better performance.
  
  However, the query that uses the IN operator will perform faster if
  the result set returned from the subquery is very small.

    EXISTS Is Faster in Performance than IN.
If Most of the filter criteria is in subquery then better to use IN and If most of the filter criteria is in main query then better to use EXISTS.
    If you are using the IN operator, the SQL engine will scan all records fetched from the inner query. On the other hand if we are using EXISTS, the SQL engine will stop the scanning process as soon as it found a match. 
    Difference lies here:

select * 
from abcTable
where exists (select null)


Above query will return all the records while below one would return empty.

select *
from abcTable
where abcTable_ID in (select null)


Give it a try and observe the output.
    I think, 


EXISTS is when you need to match the results of query with another subquery.
Query#1 results need to be retrieved where SubQuery results match. Kind of a Join..
E.g. select customers table#1 who have placed orders table#2 too
IN is to retrieve if the value of a specific column lies IN a list (1,2,3,4,5)
E.g. Select customers who lie in the following zipcodes i.e. zip_code values lies in (....) list.


When to use one over the other... when you feel it reads appropriately (Communicates intent better). 
    As per my knowledge when a subquery returns a NULL value then the whole statement becomes NULL. In that cases we are using the EXITS keyword. If we want to compare particular values in subqueries then we are using the IN keyword.
    Which one is faster depends on the number of queries fetched by the inner query:


When your inner query fetching thousand of rows then EXIST would be better choice
When your inner query fetching few rows, then IN will be faster


EXIST evaluate on true or false but IN compare multiple value. When you don't know the record is exist or not, your should choose EXIST
    My understand is both should be the same as long as we are not dealing with NULL values. 

The same reason why the query does not return the value for = NULL vs is NULL. 
http://sqlinthewild.co.za/index.php/2010/02/18/not-exists-vs-not-in/ 

As for as boolean vs comparator argument goes, to generate a boolean both values needs to be compared and that is how any if condition works.So i fail to understand how IN and EXISTS behave differently
.  
    If a subquery returns more than one value, you might need to execute the outer query- if the values within the column specified in the condition match any value in the result set of the subquery. To perform this task, you need to use the in keyword.

You can use a subquery to check if a set of records exists. For this, you need to use the exists clause with a subquery. The exists keyword always return true or false value.
    I believe this has a straightforward answer. Why don't you check it from the people who developed that function in their systems?

If you are a MS SQL developer, here is the answer directly from Microsoft.

IN:


  Determines whether a specified value matches any value in a subquery or a list.


EXISTS:


  Specifies a subquery to test for the existence of rows.

    I found that using EXISTS keyword is often really slow (that is very true in Microsoft Access).
I instead use the join operator in this manner :
should-i-use-the-keyword-exists-in-sql
    If you can use where in instead of where exists, then where in is probably faster.
Using where in or where exists
will go through all results of your parent result. The difference here is that the where exists will cause a lot of dependet sub-queries. If you can prevent dependet sub-queries, then where in will be the better choice.
Example
Assume we have 10,000 companies, each has 10 users (thus our users table has 100,000 entries). Now assume you want to find a user by his name or his company name.
The following query using were exists has an execution of 141ms:
select * from `users` 
where `first_name` ='gates' 
or exists 
(
  select * from `companies` 
  where `users`.`company_id` = `companies`.`id`
  and `name` = 'gates'
)

This happens, because for each user a dependent sub query is executed:

However, if we avoid the exists query and write it using:
select * from `users` 
where `first_name` ='gates' 
or users.company_id in  
(
    select id from `companies` 
    where  `name` = 'gates'
)

Then depended sub queries are avoided and the query would run in 0,012 ms

    ","[487, 15, 241, 32, 146, 89, 45, 2, 18, 10, 3, -1, -2, 3, 5, 3, 3, 1, 0, 0, 0, 0]",602850,162,2008-08-24T08:42:23,2022-02-05 15:58:10Z,sql 
"""Invalid signature file"" when attempting to run a .jar","
                
My java program is packaged in a jar file and makes use of an external jar library, bouncy castle. My code compiles fine, but running the jar leads to the following error:

Exception in thread ""main"" java.lang.SecurityException: Invalid signature file digest for Manifest main attributes

I've googled for over an hour searching for an explanation and found very little of value. If anyone has seen this error before and could offer some help, I would be obliged.
    For those who got this error when trying to create a shaded uber-jar with maven-shade-plugin, the solution is to exclude manifest signature files by adding the following lines to the plugin configuration:
<configuration>
    <filters>
        <filter>
            <artifact>*:*</artifact>
            <excludes>
                <exclude>META-INF/*.SF</exclude>
                <exclude>META-INF/*.DSA</exclude>
                <exclude>META-INF/*.RSA</exclude>
            </excludes>
        </filter>
    </filters>
    <!-- Additional configuration. -->
</configuration>

    Security is already a tough topic, but I'm disappointed to see the most popular solution is to delete the security signatures. JCE requires these signatures. Maven shade explodes the BouncyCastle jar file which puts the signatures into META-INF, but the BouncyCastle signatures aren't valid for a new, uber-jar (only for the BC jar), and that's what causes the Invalid signature error in this thread.

Yes, excluding or deleting the signatures as suggested by @ruhsuzbaykus does indeed make the original error go away, but it can also lead to new, cryptic errors:

java.security.NoSuchAlgorithmException: PBEWithSHA256And256BitAES-CBC-BC SecretKeyFactory not available


By explicitly specifying where to find the algorithm like this:

SecretKeyFactory.getInstance(""PBEWithSHA256And256BitAES-CBC-BC"",""BC"");


I was able to get a different error:

java.security.NoSuchProviderException: JCE cannot authenticate the provider BC


JCE can't authenticate the provider because we've deleted the cryptographic signatures by following the suggestion elsewhere in this same thread.

The solution I found was the executable packer plugin that uses a jar-in-jar approach to preserve the BouncyCastle signature in a single, executable jar.

UPDATE:

Another way to do this (the correct way?) is to use Maven Jar signer. This allows you to keep using Maven shade without getting security errors. HOWEVER, you must have a code signing certificate (Oracle suggests searching for ""Java Code Signing Certificate""). The POM config looks like this:

<plugin>
    <groupId>org.apache.maven.plugins</groupId>
    <artifactId>maven-shade-plugin</artifactId>
    <version>3.1.0</version>
    <executions>
        <execution>
            <phase>package</phase>
            <goals>
                <goal>shade</goal>
            </goals>
            <configuration>
                <filters>
                    <filter>
                        <artifact>org.bouncycastle:*</artifact>
                        <excludes>
                            <exclude>META-INF/*.SF</exclude>
                            <exclude>META-INF/*.DSA</exclude>
                            <exclude>META-INF/*.RSA</exclude>
                        </excludes>
                    </filter>
                </filters>
                <transformers>
                    <transformer implementation=""org.apache.maven.plugins.shade.resource.ManifestResourceTransformer"">
                        <mainClass>your.class.here</mainClass>
                    </transformer>
                </transformers>
                <shadedArtifactAttached>true</shadedArtifactAttached>
            </configuration>
        </execution>
    </executions>
</plugin>
<plugin>
    <groupId>org.apache.maven.plugins</groupId>
    <artifactId>maven-jarsigner-plugin</artifactId>
    <version>1.4</version>
    <executions>
        <execution>
            <id>sign</id>
            <goals>
                <goal>sign</goal>
            </goals>
        </execution>
        <execution>
            <id>verify</id>
            <goals>
                <goal>verify</goal>
            </goals>
        </execution>
    </executions>
    <configuration>
        <keystore>/path/to/myKeystore</keystore>
        <alias>myfirstkey</alias>
        <storepass>111111</storepass>
        <keypass>111111</keypass>
    </configuration>
</plugin>


No, there's no way to get JCE to recognize a self-signed cert, so if you need to preserve the BouncyCastle certs, you have to either use the jar-in-jar plugin or get a JCE cert. 
    I had the same issue in gradle when creating a fat Jar; updating the build.gradle file with an exclude line corrected the problem.
jar {
    from {
        configurations.compile.collect {
            it.isDirectory() ? it : zipTree(it)
        }
    }
    exclude 'META-INF/*.RSA', 'META-INF/*.SF','META-INF/*.DSA'
    manifest {
        attributes 'Main-Class': 'com.test.Main'
    }
}

    Please use the following command
zip -d yourjar.jar 'META-INF/*.SF' 'META-INF/*.RSA' 'META-INF/*.DSA'

    I faced the same issue, after reference somewhere, it worked as below changing:

<plugin>
    <groupId>org.apache.maven.plugins</groupId>
    <artifactId>maven-shade-plugin</artifactId>
    <version>3.2.1</version>
    <configuration>
        <createDependencyReducedPom>false</createDependencyReducedPom>
    </configuration>
    <executions>
        <execution>
            <phase>package</phase>
            <goals>
                <goal>shade</goal>
            </goals>
            <configuration>
                <filters>
                    <filter>
                        <artifact>*:*</artifact>
                        <excludes>
                            <exclude>META-INF/*.SF</exclude>
                            <exclude>META-INF/*.DSA</exclude>
                            <exclude>META-INF/*.RSA</exclude>
                        </excludes>
                    </filter>
                </filters>
            </configuration>
        </execution>
    </executions>
</plugin>

    I've recently started using IntelliJ on my projects. However, some of my colleagues still use Eclipse on the same projects. Today, I've got the very same error after executing the jar-file created by my IntelliJ.  While all the solutions in here talking about almost the same thing, none of them worked for me easily (possibly because I don't use ANT, maven build gave me other errors which referred me to http://cwiki.apache.org/confluence/display/MAVEN/MojoExecutionException, and also I couldn't figure out what are the signed jars by myself!)

Finally, this helped me 

zip -d demoSampler.jar 'META-INF/*.SF' 'META-INF/*.RSA' 'META-INF/*SF'


Guess what's been removed from my jar file?!

deleting: META-INF/ECLIPSE_.SF 
deleting: META-INF/ECLIPSE_.RSA


It seems that the issue was relevant to some eclipse-relevant files.
    For those using gradle and trying to create and use a fat jar, the following syntax might help.

jar {
    doFirst {
        from { configurations.compile.collect { it.isDirectory() ? it : zipTree(it) } } 
    }
    exclude 'META-INF/*.RSA', 'META-INF/*.SF','META-INF/*.DSA' 
}

    Some of your dependencies are likely signed jarfiles. When you combine them all into one big jarfile, the corresponding signature files are still present, and no longer match the ""big combined"" jarfile, so the runtime halts thinking the jar file has been tampered with (which it...has so to speak).
Assuming you're using ant, you can solve the problem by eliminating the signature files from your jarfile dependencies. Unfortunately, it's not possible to do this in one step in ant.
However, I was able to get this working with Ant in two steps, without specifically naming each jarfile dependency, by using:
<target name=""jar"" depends=""compile"" description=""Create one big jarfile."">
    <jar jarfile=""${output.dir}/deps.jar"">
        <zipgroupfileset dir=""jars"">
            <include name=""**/*.jar"" />
        </zipgroupfileset>
    </jar>
    <sleep seconds=""1"" />
    <jar jarfile=""${output.dir}/myjar.jar"" basedir=""${classes.dir}"">
        <zipfileset src=""${output.dir}/deps.jar"" excludes=""META-INF/*.SF"" />
        <manifest>
            <attribute name=""Main-Class"" value=""com.mycompany.MyMain"" />
        </manifest>
    </jar>
</target>

The sleep element is supposed to prevent errors about files with modification dates in the future.
Other variations I found in the linked threads didn't work for me.
    The solution listed here might provide a pointer.


  Invalid signature file digest for Manifest main attributes


Bottom line : 


  It's probably best to keep the official jar as
  is and just add it as a dependency in the manifest file for your
  application jar file.

    I had this problem when using IntelliJ IDEA 14.01. 

I was able to fix it by:

File->Project Structure->Add New (Artifacts)->jar->From Modules With Dependencies on the Create Jar From Module Window:

Select you main class

JAR File from Libraries
Select copy to the output directory and link via manifest
    A strategy would consist in using ANT to simplify the removal of the signature from each Jar file. It would proceed with the following steps:


Copying the MANIFEST.MF in a temporary file 
Removing the Name and SHA entries from the temporary file
Creating a temporary Jar file with the temporary manifest
Removing the temporary manifest
Swapping the original Jar file with the temporary one


Here is an ANT macrodef doing the work:

<macrodef name=""unsignjar"" description=""To unsign a specific Jar file"">
    <attribute name=""jarfile"" 
        description=""The jar file to unsign"" />
    <sequential>
<!-- Copying to the temporary manifest file -->
        <copy toFile=""@{jarFile}_MANIFEST.tmp"">
            <resources>
                <zipentry zipfile=""@{jarFile}"" name=""META-INF/MANIFEST.MF""/>
            </resources>
        </copy>
<!-- Removing the Name and SHA entries from the temporary file -->
        <replaceregexp file=""@{jarFile}_MANIFEST.tmp"" match=""\nName:(.+?)\nSH"" replace=""SH"" flags=""gis"" byline=""false""/>
        <replaceregexp file=""@{jarFile}_MANIFEST.tmp"" match=""SHA(.*)"" replace="""" flags=""gis"" byline=""false""/>
<!-- Creating a temporary Jar file with the temporary manifest -->
        <jar jarfile=""@{jarFile}.tmp""
            manifest=""@{jarFile}_MANIFEST.tmp"">
            <zipfileset src=""@{jarFile}"">
                <include name=""**""/>
                <exclude name=""META-INF/*.SF""/>
                <exclude name=""META-INF/*.DSA""/>
                <exclude name=""META-INF/*.RSA""/>
            </zipfileset>
        </jar>
<!-- Removing the temporary manifest -->
        <delete file=""@{jarFile}_MANIFEST.tmp"" />
<!-- Swapping the original Jar file with the temporary one -->
        <move file=""@{jarFile}.tmp""
              tofile=""@{jarFile}""
              overwrite=""true"" />
</sequential>


`

The definition can then be called this way in an ANT task:

<target name=""unsignJar"">
    <unsignjar jarFile=""org.test.myjartounsign.jar"" />
</target>

    In case you're using gradle, here is a full farJar task:

version = '1.0'
//create a single Jar with all dependencies
task fatJar(type: Jar) {
    manifest {
        attributes 'Implementation-Title': 'Gradle Jar File Example',  
            'Implementation-Version': version,
            'Main-Class': 'com.example.main'
    }
    baseName = project.name + '-all'
    from { configurations.compile.collect { it.isDirectory() ? it : zipTree(it) } }
    exclude 'META-INF/*.RSA', 'META-INF/*.SF','META-INF/*.DSA' 
    with jar
}

    If you are looking for a Fat JAR solution without unpacking or tampering with the original libraries but with a special JAR classloader, take a look at my project here.

Disclaimer: I did not write the code, just package it and publish it on Maven Central and describe in my read-me how to use it.

I personally use it for creating runnable uber JARs containing BouncyCastle dependencies. Maybe it is useful for you, too.
    
  Error: A JNI error has occurred, please check your installation and try again
  Exception in thread ""main"" java.lang.SecurityException: Invalid signature file digest for Manifest main attributes
      at sun.security.util.SignatureFileVerifier.processImpl(SignatureFileVerifier.java:314)
      at sun.security.util.SignatureFileVerifier.process(SignatureFileVerifier.java:268)
      at java.util.jar.JarVerifier.processEntry(JarVerifier.java:316)
      at java.util.jar.JarVerifier.update(JarVerifier.java:228)
      at java.util.jar.JarFile.initializeVerifier(JarFile.java:383)
      at java.util.jar.JarFile.getInputStream(JarFile.java:450)
      at sun.misc.URLClassPath$JarLoader$2.getInputStream(URLClassPath.java:977)
      at sun.misc.Resource.cachedInputStream(Resource.java:77)
      at sun.misc.Resource.getByteBuffer(Resource.java:160)
      at java.net.URLClassLoader.defineClass(URLClassLoader.java:454)
      at java.net.URLClassLoader.access$100(URLClassLoader.java:73)
      at java.net.URLClassLoader$1.run(URLClassLoader.java:368)
      at java.net.URLClassLoader$1.run(URLClassLoader.java:362)
      at java.security.AccessController.doPrivileged(Native Method)
      at java.net.URLClassLoader.findClass(URLClassLoader.java:361)
      at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
      at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)
      at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
      at sun.launcher.LauncherHelper.checkAndLoadMain(LauncherHelper.java:495)


What helped me (IntelliJ IDEA 2016.3): 
File -> Project Structure -> Artifacts -> Add JAR -> Select Main Class -> Choose ""copy to the output directory and link via manifest"" -> OK -> Apply -> Build -> Build Artifacts... -> Build
    I had a similar problem. The reason was that I was compiling using a JDK with a different JRE than the default one in my Windows box. 

Using the correct java.exe solved my problem. 
    If you're getting this when trying to bind JAR files for a Xamarin.Android bindings project like so:


  JARTOXML : warning J2XA006: missing class error was raised while reflecting com.your.class : Invalid signature file digest for Manifest main attributes


Just open the JAR files using Winzip and delete the meta-inf directories. Rebuild - job done
    Assuming you build your jar file with ant, you can just instruct ant to leave out the META-INF dir. This is a simplified version of my ant target:

<jar destfile=""app.jar"" basedir=""${classes.dir}"">
    <zipfileset excludes=""META-INF/**/*"" src=""${lib.dir}/bcprov-jdk16-145.jar""></zipfileset>
    <manifest>
        <attribute name=""Main-Class"" value=""app.Main""/>
    </manifest>
</jar>

    Compare the folder META-INF in new jar with old jar (before you added new libraries). It is possibility that there will be new files. If yes, you can remove them. It should helps.
Regards,
999michal
    It's possible that two different signers mess up java mind.

Try removing META-INF folder from jar, adding manifest and signing JAR again, it helped me: http://jehy.ru/articles/2013/12/13/invalid-signature-file-digest-for-manifest-main-attributes/
    For those who have trouble with the accepted solution, there is another way to exclude resource from shaded jar with DontIncludeResourceTransformer:

https://maven.apache.org/plugins/maven-shade-plugin/examples/resource-transformers.html#DontIncludeResourceTransformer

          <transformers>
            <transformer implementation=""org.apache.maven.plugins.shade.resource.DontIncludeResourceTransformer"">
                <resource>BC1024KE.DSA</resource>
            </transformer>
          </transformers>


From Shade 3.0, this transformer accepts a list of resources. Before that you just need to use multiple transformer each with one resource.
    This happened to me in Intellij when I clicked ""Add as a Maven Project"" on bottom line when Intellij said ""non-managed pom files found."". Meanwhile out folder was already generated. So it did not get recent changes.

Deleting out folder and running the program solved the issue for me. out folder was then recreated.

See the answer of Little Fox as well. The error I received was very similar to his.
    You can use Shadow to generate a jar.

Shadow is a Gradle plugin for combining a project's dependency classes and resources into a single output Jar. The combined Jar is often referred to a fat-jar or uber-jar.


Modify build.gradle
plugins {
    ...
    // ① Add the shadow plugin
    id ""com.github.johnrengelman.shadow"" version ""5.2.0""
}

...
// ② Config the shadow jar, its name is baseName-1.0-classifier.jar
shadowJar {
    archiveBaseName.set('baseName')
    archiveClassifier.set('classifier')
    archiveVersion.set('1.0')
    manifest {
        attributes 'Main-Class': 'Main'
    }
}

// ③ Disable the default jar task
jar.enabled = false
// ④ Execute the shadowJar task when compiling
build.dependsOn(shadowJar)


Execute the command gradle build, the jar file will be generated:

<Project Directory>/build/libs/baseName-1.0-classifier.jar



    ","[486, 1169, 27, 5, 68, 19, 6, 148, 62, 48, 26, 2, 3, 1, 2, -1, -3, 8, 2, 1, 0, 0, 0]",273719,126,2009-06-16T03:49:51,2022-04-07 01:16:12Z,java 
Suppress InsecureRequestWarning: Unverified HTTPS request is being made in Python2.6,"
                
I am writing scripts in Python2.6 with use of pyVmomi and while using one of the connection methods:

service_instance = connect.SmartConnect(host=args.ip,
                                        user=args.user,
                                        pwd=args.password)


I get the following warning:

/usr/lib/python2.6/site-packages/requests/packages/urllib3/connectionpool.py:734: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.org/en/latest/security.html
  InsecureRequestWarning)


What's interesting is that I do not have urllib3 installed with pip (but it's there in /usr/lib/python2.6/site-packages/requests/packages/urllib3/).

I have tried as suggested here

import urllib3
...
urllib3.disable_warnings()


but that didn't change anything.
    You can disable any Python warnings via the PYTHONWARNINGS environment variable. In this case, you want:

export PYTHONWARNINGS=""ignore:Unverified HTTPS request""


To disable using Python code (requests >= 2.16.0):

import urllib3
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)


For requests < 2.16.0, see original answer below.

Original answer

The reason doing urllib3.disable_warnings() didn't work for you is because it looks like you're using a separate instance of urllib3 vendored inside of requests.

I gather this based on the path here: /usr/lib/python2.6/site-packages/requests/packages/urllib3/connectionpool.py

To disable warnings in requests' vendored urllib3, you'll need to import that specific instance of the module:

import requests
from requests.packages.urllib3.exceptions import InsecureRequestWarning

requests.packages.urllib3.disable_warnings(InsecureRequestWarning)

    This is the answer in 2017. urllib3 not a part of requests anymore

import urllib3
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

    If you want to disable the warnings, but do not want to silence warnings from other packages, or other parts of your application, here is how to disable them per call.
Step 1, create a context manager.
from contextlib import contextmanager

@contextmanager
def disable_ssl_warnings():
    import warnings
    import urllib3

    with warnings.catch_warnings():
        urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
        yield None

Step 2, wrap your calls:
with disable_ssl_warnings():
    requests.get('https://example.com')

The warning will only be silenced for that call.
(As per @shazow's answer, this works with requests >= 2.16.0)
    For Python 3.7.9 and requests 2.11.1, this is the only way it worked to suppress the specific Exception in the OP:
import requests
requests.packages.urllib3.disable_warnings(
    requests.packages.urllib3.exceptions.InsecureRequestWarning)

Not sure why the above worked and this one did not:
import urllib3
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

Here is a simplification of the working version:
from requests.packages import urllib3
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

... it would appear that the import of urllib3 directly does not contain the same namespace as the one loaded by requests and thus the disable_warnings does not mutate the data structure touched by requests.
    The accepted answer doesn't work if some package vendors it's own copy of urllib3, in which case this will still work:

import warnings

warnings.filterwarnings('ignore', message='Unverified HTTPS request')

    Per this github comment, one can disable urllib3 request warnings via requests in a 1-liner:

requests.packages.urllib3.disable_warnings()

This will suppress all warnings though, not just InsecureRequest (ie it will also suppress InsecurePlatform etc).  In cases where we just want stuff to work, I find the conciseness handy.  
    That's probably useful for someone, who uses unittest, if imported modules use request library.
To suppress warnings in requests' vendored urllib3, add
warnings.filterwarnings('ignore', message='Unverified HTTPS request')

to setUp method in your testclass, i.e:
import unittest, warnings

class MyTests(unittest.TestCase):
    
    def setUp(self):
        warnings.filterwarnings('ignore', message='Unverified HTTPS request')
    
    (all test methods here)

    The HTTPS certificate verification security measure isn't something to be discarded light-heartedly. The Man-in-the-middle attack that it prevents safeguards you from a third party e.g. sipping a virus in or tampering with or stealing your data.
Even if you only intend to do that in a test environment, you can easily forget to undo it when moving elsewhere.
Instead, read the relevant section on the provided link and do as it says. The way specific for requests (which bundles with its own copy of urllib3), as per CA Certificates — Advanced Usage — Requests 2.8.1 documentation:

requests ships with its own certificate bundle (but it can only be updated together with the module)
it will use (since requests v2.4.0) the certifi package instead if it's installed
In a test environment, you can easily slip a test certificate into certifi as per how do I update root certificates of certifi? . E.g. if you replace its bundle with just your test certificate, you will immediately see it if you forget to undo that when moving to production.

Finally, with today's government-backed global hacking operations like Tailored Access Operations and the Great Firewall of China that target network infrastructure, falling under a MITM attack is more probable than you think.
    For impatient, a quick way to disable python unverified HTTPS warning:

export PYTHONWARNINGS=""ignore:Unverified HTTPS request""

    Warning message

~/venv/lib/python3.4/site-packages/urllib3/connectionpool.py:857: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings
InsecureRequestWarning)

In Debian 8 this steps works

In python3 code

import urllib3
urllib3.disable_warnings()


Install two packages on Debian


libssl1.0.0_1.0.2l-1_bpo8+1_amd64.deb


libssl-dev_1.0.2l-1_bpo8+1_amd64.deb

debian mirror
To build dependencies with new library

Create new venv for python project

python3 -m venv .venv
source .venv/bin/activate

Clean Install modules under python project inside virtual environment by
python3 -m pip install -e .

    I had a similar issue with PyVmomi Client. With Python Version 2.7.9, I have solved this issue with the following line of code:

default_sslContext = ssl._create_unverified_context()
self.client = \
                Client(<vcenterip>, username=<username>, password=<passwd>,
                       sslContext=default_sslContext )


Note that, for this to work, you need Python 2.7.9 atleast.
    For Python 2.7

Add the environment variable PYTHONWARNINGS as key and the corresponding value to be ignored like:

os.environ['PYTHONWARNINGS']=""ignore:Unverified HTTPS request""
    Why not using pyvmomi original function SmartConnectNoSSL.
They added this function on June 14, 2016 and named it ConnectNoSSL, one day after they changed the name to SmartConnectNoSSL, use that instead of by passing the warning with unnecessary lines of code in your project?


  Provides a standard method for connecting to a specified server without SSL
     verification. Useful when connecting to servers with self-signed certificates
     or when you wish to ignore SSL altogether


service_instance = connect.SmartConnectNoSSL(host=args.ip,
                                             user=args.user,
                                             pwd=args.password)

    Suppress logs using standard python library 'logging'

Place this code on the top of your existing code
import logging
urllib3_logger = logging.getLogger('urllib3')
urllib3_logger.setLevel(logging.CRITICAL)

    ","[486, 1065, 149, 4, 9, 32, 55, 4, 44, 14, 2, 2, 0, 0, 0]",618032,96,2015-01-16T10:07:19,2021-11-18 18:21:20Z,python 
"How can I stage and commit all files, including newly added files, using a single command?","
                
How can I stage and commit all files, including newly added files, using a single command?
    Does
git add -A && git commit -m ""Your Message""

count as a ""single command""?
Edit based on @thefinnomenon's answer below
To have it as a git alias, use:
git config --global alias.coa ""!git add -A && git commit -m""

and commit all files, including new files, with a message with:
git coa ""A bunch of horrible changes""

Explanation
From git add documentation:

-A, --all, --no-ignore-removal
Update the index not only where the working tree has a file matching  but also where the index already has an
entry. This adds, modifies, and removes index entries to match the
working tree.
If no <pathspec> is given when -A option is used, all files in the
entire working tree are updated (old versions of Git used to limit the
update to the current directory and its subdirectories).


    This command will add and commit all the modified files, but not newly created files:
git commit -am  ""<commit message>""

From man git-commit:
-a, --all
    Tell the command to automatically stage files that have been modified
    and deleted, but new files you have not told Git about are not
    affected.

    Not sure why these answers all dance around what I believe to be the right solution but for what it's worth here is what I use:
1. Create an alias:
git config --global alias.coa '!git add -A && git commit -m'

2. Add all files & commit with a message:
git coa ""A bunch of horrible changes""

NOTE: coa is short for commit all and can be replaced with anything your heart desires
    One-liner to stage ALL files (modified, deleted, and new) and commit with comment:

git add --all && git commit -m ""comment""


http://git-scm.com/docs/git-add
http://git-scm.com/docs/git-commit
    I think this is the most elegant way to stage and commit all changes:
git commit -am  ""message""

    Run the given command

git add . && git commit -m ""Changes Committed""


However, even if it seems a single command, It's two separate command runs one by one. Here we just used && to combine them. It's not much different than running 
git add . and git commit -m ""Changes Committed"" separately. You can run multiple commands together but sequence matters here. How if you want to push the changes to remote server along with staging and commit you can do it as given,

git add . && git commit -m ""Changes Committed"" && git push origin master


Instead, if you change the sequence and put the push to first, It will be executed first and does not give desired push after staging and commit just because it already ran first.

&& runs the second command on the line when the first command comes back successfully, or with an error level of 0. The opposite of && is ||, which runs the second command when the first command is unsuccessful, or with an error level of 1.

Alternatively, you can create alise as git config --global alias.addcommit '!git add -a && git commit -m' and use it as git addcommit -m ""Added and commited new files""
    try using: 

git add . && git commit -m ""your message here""

    I use this function:

gcaa() { git add --all && git commit -m ""$*"" }


In my zsh config file, so i can just do:

> gcaa This is the commit message


To automatically stage and commit all files.
    Committing in git can be a multiple step process or one step depending on the situation. 


This situation is where you have multiple file updated and wants to
commit:

You have to add all the modified files before you commit anything.

git add -A


or

git add --all

After that you can use commit all the added files 

git commit


with this you have to add the message for this commit.

    If you just want a ""quick and dirty"" way to stash changes on the current branch, you can use the following alias:

git config --global alias.temp '!git add -A && git commit -m ""Temp""'  


After running that command, you can just type git temp to have git automatically commit all your changes to the current branch as a commit named ""Temp"". Then, you can use git reset HEAD~ later to ""uncommit"" the changes so you can continue working on them, or git commit --amend to add more changes to the commit and/or give it a proper name.
    I have in my config two aliases:

alias.foo=commit -a -m 'none'
alias.coa=commit -a -m


if I am too lazy I just commit all changes with

git foo


and just to do a quick commit

git coa ""my changes are...""


coa stands for ""commit all""
    You can write a small script (look at Ian Clelland's answer) called git-commitall which uses several git commands to perform what you want to do.
Place this script in your anywhere in your $PATH. You can call it by git commitall ... very handy!

Found here (question and all answers unfortunately deleted, only visible with high reputation)
    Great answers, but if you look for a singe line do all, you can concatenate, alias and enjoy the convenience: 

git add * && git commit -am  ""<commit message>""

It is a single line but two commands, and as mentioned you can alias these commands: 

alias git-aac=""git add * && git commit -am "" (the space at the end is important) because you are going to parameterize the new short hand command.

From this moment on, you will be using this alias: 

git-acc ""<commit message>"" 

You basically say: 

git, add for me all untracked files and commit them with this given commit message.

Hope you use Linux, hope this helps.
    Here is a shell script which does a somewhat close thing. Currently it doesn't commit newly added files (it should be easy to add this feature), but it does commit everything else. Also, it visits Git submodules recursively. The intended usage scenario is as simple as
$ git powercommit

    ","[486, 644, 457, 41, 27, 2, 5, 1, 28, 9, 6, 4, 0, 2, 0]",544617,132,2010-03-10T17:53:04,2021-07-26 12:31:03Z,
"Understanding offsetWidth, clientWidth, scrollWidth and -Height, respectively","
                
There are several questions on StackOverflow regarding offsetWidth / clientWidth / scrollWidth (and -Height, respectively), but none give comprehensive explanation of what those values are.
Also, there are several sources on the web giving confusing or incorrect information.
Can you give a complete explanation including some visual hints?
Also, how can those values be used to calculate scroll bar widths?
    The CSS box model is rather complicated, particularly when it comes to scrolling content. While the browser uses the values from your CSS to draw boxes, determining all the dimensions using JS is not straight-forward if you only have the CSS.

That's why each element has six DOM properties for your convenience: offsetWidth, offsetHeight, clientWidth, clientHeight, scrollWidth and scrollHeight. These are read-only attributes representing the current visual layout, and all of them are integers (thus possibly subject to rounding errors).

Let's go through them in detail:


offsetWidth, offsetHeight: The size of the visual box incuding all borders. Can be calculated by adding width/height and paddings and borders, if the element has display: block
clientWidth, clientHeight: The visual portion of the box content, not including borders or scroll bars , but includes padding . Can not be calculated directly from CSS, depends on the system's scroll bar size.
scrollWidth, scrollHeight: The size of all of the box's content, including the parts that are currently hidden outside the scrolling area. Can not be calculated directly from CSS, depends on the content.




Try it out: jsFiddle



Since offsetWidth takes the scroll bar width into account, we can use it to calculate the scroll bar width via the formula

scrollbarWidth = offsetWidth - clientWidth - getComputedStyle().borderLeftWidth - getComputedStyle().borderRightWidth


Unfortunately, we may get rounding errors, since offsetWidth and clientWidth are always integers, while the actual sizes may be fractional with zoom levels other than 1.

Note that this

scrollbarWidth = getComputedStyle().width + getComputedStyle().paddingLeft + getComputedStyle().paddingRight - clientWidth


does not work reliably in Chrome, since Chrome returns width with scrollbar already substracted. (Also, Chrome renders paddingBottom to the bottom of the scroll content, while other browsers don't)
    I created a more comprehensive and cleaner version that some people might find useful for remembering which name corresponds to which value. I used Chrome Dev Tool's color code and labels are organized symmetrically to pick up analogies faster:




Note 1: clientLeft also includes the width of the vertical scroll
bar if the direction of the text is set to right-to-left (since the
bar is displayed to the left in that case)
Note 2: the outermost line represents the closest positioned parent
(an element whose position property is set to a value different than
static or initial). Thus, if the direct container isn’t a positioned
element, then the line doesn’t represent the first container in
the hierarchy but another element higher in the hierarchy. If no
positioned parent is found, the browser will take the html or body
element as reference




Hope somebody finds it useful, just my 2 cents ;)
    My personal cheatsheet, covering:


.offsetWidth/.offsetHeight
.clientWidth/.clientHeight
.scrollWidth/.scrollHeight
.scrollLeft/.scrollTop
.getBoundingClientRect()

with small/simple/not-all-in-one diagrams :)

👁 see full-size: https://docs.google.com/drawings/d/1bOOJnkN5G_lBs3Oz9NfQQH1I0aCrX5EZYPY3mu3_ROI/edit?usp=sharing
    client width/height and offset width/height calculation - a quick summary using a sample css style:

Ref: https://javascript.info/size-and-scroll
    If you want to use scrollWidth to get the ""REAL"" CONTENT WIDTH/HEIGHT (as content can be BIGGER than the css-defined width/height-Box) the scrollWidth/Height is very UNRELIABLE as some browser seem to ""MOVE"" the paddingRIGHT & paddingBOTTOM if the content is to big. They then place the paddings at the RIGHT/BOTTOM of the ""too broad/high content"" (see picture below). 

==> Therefore to get the REAL CONTENT WIDTH in some browsers you have to substract BOTH paddings from the scrollwidth and in some browsers you only have to substract the LEFT Padding.

I found a solution for this and wanted to add this as a comment, but was not allowed. So I took the picture and made it a bit clearer in the regard of the ""moved paddings"" and the ""unreliable scrollWidth"". In the BLUE AREA you find my solution on how to get the ""REAL"" CONTENT WIDTH!

Hope this helps to make things even clearer!


    There is a good article on MDN that explains the theory behind those concepts:
https://developer.mozilla.org/en-US/docs/Web/API/CSS_Object_Model/Determining_the_dimensions_of_elements

It also explains the important conceptual differences between boundingClientRect's width/height vs offsetWidth/offsetHeight.

Then, to prove the theory right or wrong, you need some tests.
That's what I did here: https://github.com/lingtalfi/dimensions-cheatsheet

It's testing for chrome53, ff49, safari9, edge13 and ie11.

The results of the tests prove that the theory is generally right.
For the tests, I created 3 divs containing 10 lorem ipsum paragraphs each.
Some css was applied to them:

.div1{
    width: 500px;
    height: 300px;
    padding: 10px;
    border: 5px solid black;
    overflow: auto;
}
.div2{
    width: 500px;
    height: 300px;
    padding: 10px;
    border: 5px solid black;
    box-sizing: border-box;
    overflow: auto;
}

.div3{
    width: 500px;
    height: 300px;
    padding: 10px;
    border: 5px solid black;
    overflow: auto;
    transform: scale(0.5);
}


And here are the results:


div1


offsetWidth: 530 (chrome53, ff49, safari9, edge13, ie11)
offsetHeight: 330 (chrome53, ff49, safari9, edge13, ie11)
bcr.width: 530 (chrome53, ff49, safari9, edge13, ie11)
bcr.height: 330 (chrome53, ff49, safari9, edge13, ie11)
clientWidth: 505 (chrome53, ff49, safari9)
clientWidth: 508 (edge13)
clientWidth: 503 (ie11)
clientHeight: 320 (chrome53, ff49, safari9, edge13, ie11)
scrollWidth: 505 (chrome53, safari9, ff49)
scrollWidth: 508 (edge13)
scrollWidth: 503 (ie11)
scrollHeight: 916 (chrome53, safari9)
scrollHeight: 954 (ff49)
scrollHeight: 922 (edge13, ie11)

div2


offsetWidth: 500 (chrome53, ff49, safari9, edge13, ie11)
offsetHeight: 300 (chrome53, ff49, safari9, edge13, ie11)
bcr.width: 500 (chrome53, ff49, safari9, edge13, ie11)
bcr.height: 300 (chrome53, ff49, safari9)
bcr.height: 299.9999694824219 (edge13, ie11)
clientWidth: 475 (chrome53, ff49, safari9)
clientWidth: 478 (edge13)
clientWidth: 473 (ie11)
clientHeight: 290 (chrome53, ff49, safari9, edge13, ie11)
scrollWidth: 475 (chrome53, safari9, ff49)
scrollWidth: 478 (edge13)
scrollWidth: 473 (ie11)
scrollHeight: 916 (chrome53, safari9)
scrollHeight: 954 (ff49)
scrollHeight: 922 (edge13, ie11)

div3


offsetWidth: 530 (chrome53, ff49, safari9, edge13, ie11)
offsetHeight: 330 (chrome53, ff49, safari9, edge13, ie11)
bcr.width: 265 (chrome53, ff49, safari9, edge13, ie11)
bcr.height: 165 (chrome53, ff49, safari9, edge13, ie11)
clientWidth: 505 (chrome53, ff49, safari9)
clientWidth: 508 (edge13)
clientWidth: 503 (ie11)
clientHeight: 320 (chrome53, ff49, safari9, edge13, ie11)
scrollWidth: 505 (chrome53, safari9, ff49)
scrollWidth: 508 (edge13)
scrollWidth: 503 (ie11)
scrollHeight: 916 (chrome53, safari9)
scrollHeight: 954 (ff49)
scrollHeight: 922 (edge13, ie11)



So, apart from the boundingClientRect's height value (299.9999694824219 instead of expected 300) in edge13 and ie11, the results confirm that the theory behind this works.

From there, here is my definition of those concepts:


offsetWidth/offsetHeight: dimensions of the layout border box
boundingClientRect: dimensions of the rendering border box
clientWidth/clientHeight: dimensions of the visible part of the layout padding box (excluding scroll bars)
scrollWidth/scrollHeight: dimensions of the layout padding box if it wasn't constrained by scroll bars


Note: the default vertical scroll bar's width is 12px in edge13, 15px in chrome53, ff49 and safari9, and 17px in ie11 (done by measurements in photoshop from screenshots, and proven right by the results of the tests).

However, in some cases, maybe your app is not using the default vertical scroll bar's width.

So, given the definitions of those concepts, the vertical scroll bar's width should be equal to (in pseudo code):


layout dimension: offsetWidth - clientWidth - (borderLeftWidth + borderRightWidth)
rendering dimension: boundingClientRect.width - clientWidth - (borderLeftWidth + borderRightWidth)


Note, if you don't understand layout vs rendering please read the mdn article.

Also, if you have another browser (or if you want to see the results of the tests for yourself), you can see my test page here: http://codepen.io/lingtalfi/pen/BLdBdL
    ","[486, 1066, 86, 11, 1, 35, 17]",199973,360,2014-01-11T15:26:57,2021-10-26 06:05:19Z,html css 
Run function from the command line,"
                
I have this code:

def hello():
    return 'Hi :)'


How would I run this directly from the command line?
    With the -c (command) argument (assuming your file is named foo.py):

$ python -c 'import foo; print foo.hello()'


Alternatively, if you don't care about namespace pollution:

$ python -c 'from foo import *; print hello()'


And the middle ground:

$ python -c 'from foo import hello; print hello()'

    add this snippet to the bottom of your script
def myfunction():
    ...


if __name__ == '__main__':
    globals()[sys.argv[1]]()

You can now call your function by running
python myscript.py myfunction

This works because you are passing the command line argument (a string of the function's name) into locals, a dictionary with a current local symbol table. The parantheses at the end will make the function be called.
update: if you would like the function to accept a parameter from the command line, you can pass in sys.argv[2] like this:
def myfunction(mystring):
    print(mystring)


if __name__ == '__main__':
    globals()[sys.argv[1]](sys.argv[2])

This way, running python myscript.py myfunction ""hello"" will output hello.
    We can write something like this. I have used with python-3.7.x
import sys

def print_fn():
    print(""Hi"")

def sum_fn(a, b):
    print(a + b)

if __name__ == ""__main__"":
    args = sys.argv
    # args[0] = current file
    # args[1] = function name
    # args[2:] = function args : (*unpacked)
    globals()[args[1]](*args[2:])


python demo.py print_fn
python demo.py sum_fn 5 8

    Just put hello() somewhere below the function and it will execute when you do python your_file.py

For a neater solution you can use this:

if __name__ == '__main__':
    hello()


That way the function will only be executed if you run the file, not when you import the file.
    Below is the Odd_Even_function.py file that has the definition of the function.

def OE(n):
    for a in range(n):
        if a % 2 == 0:
            print(a)
        else:
            print(a, ""ODD"")


Now to call the same from Command prompt below are the options worked for me.

Options 1
Full path of the exe\python.exe -c 
""import Odd_Even_function; Odd_Even_function.OE(100)""

Option 2
Full path of the exe\python.exe -c 
""from Odd_Even_function import OE; OE(100)""

Thanks.
    Let's make this a little easier on ourselves and just use a module...

Try: pip install compago

Then write:

import compago
app = compago.Application()

@app.command
def hello():
    print ""hi there!""

@app.command
def goodbye():
    print ""see ya later.""

if __name__ == ""__main__"":
    app.run()


Then use like so:

$ python test.py hello
hi there!

$ python test.py goodbye
see ya later.


Note: There's a bug in Python 3 at the moment, but works great with Python 2.

Edit: An even better option, in my opinion is the module fire by Google which makes it easy to also pass function arguments. It is installed with pip install fire. From their GitHub:

Here's a simple example.

import fire

class Calculator(object):
  """"""A simple calculator class.""""""

  def double(self, number):
    return 2 * number

if __name__ == '__main__':
  fire.Fire(Calculator)


Then, from the command line, you can run:

python calculator.py double 10  # 20
python calculator.py double --number=15  # 30

    I had a requirement of using various python utilities (range, string, etc.) on the command line and had written the tool pyfunc specifically for that. You can use it to enrich you command line usage experience:

 $ pyfunc -m range -a 1 7 2
 1
 3
 5

 $ pyfunc -m string.upper -a test
 TEST

 $ pyfunc -m string.replace -a 'analyze what' 'what' 'this'
 analyze this

    python -c 'from myfile import hello; hello()' where myfile must be replaced with the basename of your Python script. (E.g., myfile.py becomes myfile).

However, if hello() is your ""permanent"" main entry point in your Python script, then the usual way to do this is as follows:

def hello():
    print ""Hi :)""

if __name__ == ""__main__"":
    hello()


This allows you to execute the script simply by running python myfile.py or python -m myfile.

Some explanation here: __name__ is a special Python variable that holds the name of the module currently being executed, except when the module is started from the command line, in which case it becomes ""__main__"".
    I wrote a quick little Python script that is callable from a bash command line. It takes the name of the module, class and method you want to call and the parameters you want to pass. I call it PyRun and left off the .py extension and made it executable with chmod +x PyRun so that I can just call it quickly as follow:

./PyRun PyTest.ClassName.Method1 Param1


Save this in a file called PyRun

#!/usr/bin/env python
#make executable in bash chmod +x PyRun

import sys
import inspect
import importlib
import os

if __name__ == ""__main__"":
    cmd_folder = os.path.realpath(os.path.abspath(os.path.split(inspect.getfile( inspect.currentframe() ))[0]))
    if cmd_folder not in sys.path:
        sys.path.insert(0, cmd_folder)

    # get the second argument from the command line      
    methodname = sys.argv[1]

    # split this into module, class and function name
    modulename, classname, funcname = methodname.split(""."")

    # get pointers to the objects based on the string names
    themodule = importlib.import_module(modulename)
    theclass = getattr(themodule, classname)
    thefunc = getattr(theclass, funcname)

    # pass all the parameters from the third until the end of 
    # what the function needs & ignore the rest
    args = inspect.getargspec(thefunc)
    z = len(args[0]) + 2
    params=sys.argv[2:z]
    thefunc(*params)


Here is a sample module to show how it works. This is saved in a file called PyTest.py:

class SomeClass:
 @staticmethod
 def First():
     print ""First""

 @staticmethod
 def Second(x):
    print(x)
    # for x1 in x:
    #     print x1

 @staticmethod
 def Third(x, y):
     print x
     print y

class OtherClass:
    @staticmethod
    def Uno():
        print(""Uno"")


Try running these examples:

./PyRun PyTest.SomeClass.First
./PyRun PyTest.SomeClass.Second Hello
./PyRun PyTest.SomeClass.Third Hello World
./PyRun PyTest.OtherClass.Uno
./PyRun PyTest.SomeClass.Second ""Hello""
./PyRun PyTest.SomeClass.Second \(Hello, World\)


Note the last example of escaping the parentheses to pass in a tuple as the only parameter to the Second method.

If you pass too few parameters for what the method needs you get an error. If you pass too many, it ignores the extras. The module must be in the current working folder, put PyRun can be anywhere in your path.
    Something like this:
call_from_terminal.py

# call_from_terminal.py
# Ex to run from terminal
# ip='""hi""'
# python -c ""import call_from_terminal as cft; cft.test_term_fun(${ip})""
# or
# fun_name='call_from_terminal'
# python -c ""import ${fun_name} as cft; cft.test_term_fun(${ip})""
def test_term_fun(ip):
    print ip


This works in bash.

$ ip='""hi""' ; fun_name='call_from_terminal' 
$ python -c ""import ${fun_name} as cft; cft.test_term_fun(${ip})""
hi

    Use the python-c tool (pip install python-c) and then simply write:

$ python-c foo 'hello()'


or in case you have no function name clashes in your python files:

$ python-c 'hello()'

    First you have to call the function as they told you or the founction will display nothing in the output, after that save the file and copy the path of the file by right click to the folder of the file and click on""copy file"" then go to terminal and write:
- cd ""the path of the file""
- python ""name of the file for example (main.py)""
after that it will display the output of your code.
    Interestingly enough, if the goal was to print to the command line console or perform some other minute python operation, you can pipe input into the python interpreter like so:

echo print(""hi:)"") | python


as well as pipe files..

python < foo.py


*Note that the extension does not have to be .py for the second to work. 
**Also note that for bash you may need to escape the characters

echo print\(\""hi:\)\""\) | python

    It is always an option to enter python on the command line with the command python

then import your file so import example_file

then run the command with example_file.hello()

This avoids the weird .pyc copy function that crops up every time you run python -c etc.

Maybe not as convenient as a single-command, but a good quick fix to text a file from the command line, and allows you to use python to call and execute your file.
    If you install the runp package with pip install runp its a matter of running:

runp myfile.py hello

You can find the repository at: https://github.com/vascop/runp
    Make your life easier, install Spyder. Open your file then run it (click the green arrow). Afterwards your hello() method is defined and known to the IPython Console, so you can call it from the console. 
    This function cannot be run from the command line as it returns a value which will go unhanded. You can remove the return and use print instead
    ","[486, 735, 69, 14, 150, 2, 14, 5, 76, 31, 2, -1, -2, 6, 1, 5, -6, 0]",757602,152,2010-10-21T11:44:25,2021-04-16 17:51:14Z,python 
Resolving instances with ASP.NET Core DI from within ConfigureServices,"
                
How do I manually resolve a type using the ASP.NET Core MVC built-in dependency injection framework?

Setting up the container is easy enough:

public void ConfigureServices(IServiceCollection services)
{
    // ...

    services.AddTransient<ISomeService, SomeConcreteService>();
}


But how can I resolve ISomeService without performing injection?  For example, I want to do this:

ISomeService service = services.Resolve<ISomeService>();


There are no such methods in IServiceCollection.
    The IServiceCollection interface is used for building a dependency injection container. After it's fully built, it gets composed to an IServiceProvider instance which you can use to resolve services. You can inject an IServiceProvider into any class. The IApplicationBuilder and HttpContext classes can provide the service provider as well, via their ApplicationServices or RequestServices properties respectively.
IServiceProvider defines a GetService(Type type) method to resolve a service:
var service = (IFooService)serviceProvider.GetService(typeof(IFooService));

There are also several convenience extension methods available, such as serviceProvider.GetService<IFooService>() (add a using for Microsoft.Extensions.DependencyInjection).
Resolving services inside the startup class
Injecting dependencies
The runtime's hosting service provider can inject certain services into the constructor of the Startup class, such as IConfiguration,
IWebHostEnvironment (IHostingEnvironment in pre-3.0 versions), ILoggerFactory and IServiceProvider. Note that the latter is an instance built by the hosting layer and contains only the essential services for starting up an application.
The ConfigureServices() method does not allow injecting services, it only accepts an IServiceCollection argument. This makes sense because ConfigureServices() is where you register the services required by your application. However you can use services injected in the startup's constructor here, for example:
public Startup(IConfiguration configuration)
{
    Configuration = configuration;
}

public IConfiguration Configuration { get; }

public void ConfigureServices(IServiceCollection services)
{
    // Use Configuration here
}

Any services registered in ConfigureServices() can then be injected into the Configure() method; you can add an arbitrary number of services after the IApplicationBuilder parameter:
public void ConfigureServices(IServiceCollection services)
{
    services.AddScoped<IFooService>();
}

public void Configure(IApplicationBuilder app, IFooService fooService)
{
    fooService.Bar();
}

Manually resolving dependencies
If you need to manually resolve services, you should preferably use the ApplicationServices provided by IApplicationBuilder in the Configure() method:
public void Configure(IApplicationBuilder app)
{
    var serviceProvider = app.ApplicationServices;
    var hostingEnv = serviceProvider.GetService<IHostingEnvironment>();
}

It is possible to pass and directly use an IServiceProvider in the constructor of your Startup class, but as above this will contain a limited subset of services, and thus has limited utility:
public Startup(IServiceProvider serviceProvider)
{
    var hostingEnv = serviceProvider.GetService<IWebHostEnvironment>();
}

If you must resolve services in the ConfigureServices() method, a different approach is required. You can build an intermediate IServiceProvider from the IServiceCollection instance which contains the services which have been registered up to that point:
public void ConfigureServices(IServiceCollection services)
{
    services.AddSingleton<IFooService, FooService>();

    // Build the intermediate service provider
    var sp = services.BuildServiceProvider();

    // This will succeed.
    var fooService = sp.GetService<IFooService>();
    // This will fail (return null), as IBarService hasn't been registered yet.
    var barService = sp.GetService<IBarService>();
}

Please note:
Generally you should avoid resolving services inside the ConfigureServices() method, as this is actually the place where you're configuring the application services. Sometimes you just need access to an IOptions<MyOptions> instance. You can accomplish this by binding the values from the IConfiguration instance to an instance of MyOptions (which is essentially what the options framework does):
public void ConfigureServices(IServiceCollection services)
{
    var myOptions = new MyOptions();
    Configuration.GetSection(""SomeSection"").Bind(myOptions);
}

Or use an overload for AddSingleton/AddScoped/AddTransient:
// Works for AddScoped and AddTransient as well
services.AddSingleton<IBarService>(sp =>
{
    var fooService = sp.GetRequiredService<IFooService>();
    return new BarService(fooService);
}

Manually resolving services (aka Service Locator) is generally considered an anti-pattern. While it has its use-cases (for frameworks and/or infrastructure layers), you should avoid it as much as possible.
    Manually resolving instances involves using the IServiceProvider interface:
Resolving Dependency in Startup.ConfigureServices
public void ConfigureServices(IServiceCollection services)
{
    services.AddTransient<IMyService, MyService>();

    var serviceProvider = services.BuildServiceProvider();
    var service = serviceProvider.GetService<IMyService>();
}

Resolving Dependencies in Startup.Configure
public void Configure(
    IApplicationBuilder application,
    IServiceProvider serviceProvider)
{
    // By type.
    var service1 = (MyService)serviceProvider.GetService(typeof(MyService));

    // Using extension method.
    var service2 = serviceProvider.GetService<MyService>();

    // ...
}

Resolving Dependencies in Startup.Configure in ASP.NET Core 3
public void Configure(
    IApplicationBuilder application,
    IWebHostEnvironment webHostEnvironment)
{
    application.ApplicationServices.GetService<MyService>();
}

Using Runtime Injected Services
Some types can be injected as method parameters:
public class Startup
{
    public Startup(
        IHostingEnvironment hostingEnvironment,
        ILoggerFactory loggerFactory)
    {
    }

    public void ConfigureServices(
        IServiceCollection services)
    {
    }

    public void Configure(
        IApplicationBuilder application,
        IHostingEnvironment hostingEnvironment,
        IServiceProvider serviceProvider,
        ILoggerFactory loggerfactory,
        IApplicationLifetime applicationLifetime)
    {
    }
}

Resolving Dependencies in Controller Actions
[HttpGet(""/some-action"")]
public string SomeAction([FromServices] IMyService myService) => ""Hello"";

    If you just need to resolve one dependency for the purpose of passing it to the constructor of another dependency you are registering, you can do this.

Let's say you had a service that took in a string and an ISomeService.

public class AnotherService : IAnotherService
{
    public AnotherService(ISomeService someService, string serviceUrl)
    {
        ...
    }
}


When you go to register this inside Startup.cs, you'll need to do this:

services.AddScoped<IAnotherService>(ctx => 
      new AnotherService(ctx.GetService<ISomeService>(), ""https://someservice.com/"")
);

    You can inject dependencies in attributes like AuthorizeAttribute in this way

var someservice = (ISomeService)context.HttpContext.RequestServices.GetService(typeof(ISomeService));

    You can inject dependencies using IApplicationBuilder instance in this way
public void Configure(IApplicationBuilder app)
    {
        //---------- Your code
        
        using (var serviceScope = app.ApplicationServices.GetRequiredService<IServiceScopeFactory>().CreateScope())
        {
            var resultLogic = serviceScope.ServiceProvider.GetService<IResultLogic>();
            resultLogic.YourMethod();
        }           

        //---------- Your code
    }

    If you generate an application with a template you are going to have something like this on the Startup class:

public void ConfigureServices(IServiceCollection services)
{
    // Add framework services.
    services.AddApplicationInsightsTelemetry(Configuration);

    services.AddMvc();
}


You can then add dependencies there, for example:

services.AddTransient<ITestService, TestService>();


If you want to access ITestService on your controller you can add IServiceProvider on the constructor and it will be injected:

public HomeController(IServiceProvider serviceProvider)


Then you can resolve the service you added:

var service = serviceProvider.GetService<ITestService>();


Note that to use the generic version you have to include the namespace with the extensions:

using Microsoft.Extensions.DependencyInjection;




ITestService.cs

public interface ITestService
{
    int GenerateRandom();
}


TestService.cs

public class TestService : ITestService
{
    public int GenerateRandom()
    {
        return 4;
    }
}


Startup.cs (ConfigureServices)

public void ConfigureServices(IServiceCollection services)
{
    services.AddApplicationInsightsTelemetry(Configuration);
    services.AddMvc();

    services.AddTransient<ITestService, TestService>();
}


HomeController.cs

using Microsoft.Extensions.DependencyInjection;

namespace Core.Controllers
{
    public class HomeController : Controller
    {
        public HomeController(IServiceProvider serviceProvider)
        {
            var service = serviceProvider.GetService<ITestService>();
            int rnd = service.GenerateRandom();
        }

    I know this is an old question but I'm astonished that a rather obvious and disgusting hack isn't here.

You can exploit the ability to define your own ctor function to grab necessary values out of your services as you define them... obviously this would be ran every time the service was requested unless you explicitly remove/clear and re-add the definition of this service within the first construction of the exploiting ctor.

This method has the advantage of not requiring you to build the service tree, or use it, during the configuration of the service. You are still defining how services will be configured. 

public void ConfigureServices(IServiceCollection services)
{
    //Prey this doesn't get GC'd or promote to a static class var
    string? somevalue = null;

    services.AddSingleton<IServiceINeedToUse, ServiceINeedToUse>(scope => {
         //create service you need
         var service = new ServiceINeedToUse(scope.GetService<IDependantService>())
         //get the values you need
         somevalue = somevalue ?? service.MyDirtyHack();
         //return the instance
         return service;
    });
    services.AddTransient<IOtherService, OtherService>(scope => {
         //Explicitly ensuring the ctor function above is called, and also showcasing why this is an anti-pattern.
         scope.GetService<IServiceINeedToUse>();
         //TODO: Clean up both the IServiceINeedToUse and IOtherService configuration here, then somehow rebuild the service tree.
         //Wow!
         return new OtherService(somevalue);
    });
}


The way to fix this pattern would be to give OtherService an explicit dependency on IServiceINeedToUse, rather than either implicitly depending on it or its method's return value... or resolving that dependency explicitly in some other fashion. 
    public void ConfigureServices(IServiceCollection services)
{
    services.AddMvc();

    services.AddDbContext<ConfigurationRepository>(options =>
        options.UseSqlServer(Configuration.GetConnectionString(""SqlConnectionString"")));

    services.AddScoped<IConfigurationBL, ConfigurationBL>();
    services.AddScoped<IConfigurationRepository, ConfigurationRepository>();
}

    public void ConfigureServices(IServiceCollection services)
{
        services.AddSingleton<ISelfServiceConfigLoad, SelfServiceConfigLoader>();
        var sp = services.BuildServiceProvider();
        var configservice = sp.GetServices<ISelfServiceConfigLoad>();
        services.AddSingleton<IExtractor, ConfigExtractor>( sp =>
        {
            var con = sp.GetRequiredService<ISelfServiceConfigLoad>();
             var config = con.Load();
            return new ConfigExtractor(config.Result);
        });
        services.AddSingleton<IProcessor<EventMessage>, SelfServiceProcessor>();          
        services.AddTransient<ISolrPush, SolrDataPush>();
        services.AddSingleton<IAPICaller<string, string>, ApiRestCaller<string, string>>();
        services.AddSingleton<IDataRetriever<SelfServiceApiRequest, IDictionary<string, object>>, SelfServiceDataRetriever>();
       


    }

    ","[486, 775, 181, 19, 14, 3, 25, 6, -7, -1]",394766,149,2015-09-08T13:53:47,2021-11-19 08:25:30Z,c 
Format a Go string without printing?,"
                
Is there a simple way to format a string in Go without printing the string?

I can do:

bar := ""bar""
fmt.Printf(""foo: %s"", bar)


But I want the formatted string returned rather than printed so I can manipulate it further.

I could also do something like:

s := ""foo: "" + bar


But this becomes difficult to read when the format string is complex, and cumbersome when one or many of the parts aren't strings and have to be converted first, like

i := 25
s := ""foo: "" + strconv.Itoa(i)


Is there a simpler way to do this?
    
                
Sprintf is what you are looking for.

Example

fmt.Sprintf(""foo: %s"", bar)


You can also see it in use in the Errors example as part of ""A Tour of Go.""

return fmt.Sprintf(""at %v, %s"", e.When, e.What)

    1. Simple strings

For ""simple"" strings (typically what fits into a line) the simplest solution is using fmt.Sprintf() and friends (fmt.Sprint(), fmt.Sprintln()). These are analogous to the functions without the starter S letter, but these Sxxx() variants return the result as a string instead of printing them to the standard output.

For example:

s := fmt.Sprintf(""Hi, my name is %s and I'm %d years old."", ""Bob"", 23)


The variable s will be initialized with the value:

Hi, my name is Bob and I'm 23 years old.


Tip: If you just want to concatenate values of different types, you may not automatically need to use Sprintf() (which requires a format string) as Sprint() does exactly this. See this example:

i := 23
s := fmt.Sprint(""[age:"", i, ""]"") // s will be ""[age:23]""


For concatenating only strings, you may also use strings.Join() where you can specify a custom separator string (to be placed between the strings to join).

Try these on the Go Playground.

2. Complex strings (documents)

If the string you're trying to create is more complex (e.g. a multi-line email message), fmt.Sprintf() becomes less readable and less efficient (especially if you have to do this many times).

For this the standard library provides the packages text/template and html/template. These packages implement data-driven templates for generating textual output. html/template is for generating HTML output safe against code injection. It provides the same interface as package text/template and should be used instead of text/template whenever the output is HTML.

Using the template packages basically requires you to provide a static template in the form of a string value (which may be originating from a file in which case you only provide the file name) which may contain static text, and actions which are processed and executed when the engine processes the template and generates the output.

You may provide parameters which are included/substituted in the static template and which may control the output generation process. Typical form of such parameters are structs and map values which may be nested.

Example:

For example let's say you want to generate email messages that look like this:

Hi [name]!

Your account is ready, your user name is: [user-name]

You have the following roles assigned:
[role#1], [role#2], ... [role#n]


To generate email message bodies like this, you could use the following static template:

const emailTmpl = `Hi {{.Name}}!

Your account is ready, your user name is: {{.UserName}}

You have the following roles assigned:
{{range $i, $r := .Roles}}{{if $i}}, {{end}}{{.}}{{end}}
`


And provide data like this for executing it:

data := map[string]interface{}{
    ""Name"":     ""Bob"",
    ""UserName"": ""bob92"",
    ""Roles"":    []string{""dbteam"", ""uiteam"", ""tester""},
}


Normally output of templates are written to an io.Writer, so if you want the result as a string, create and write to a bytes.Buffer (which implements io.Writer). Executing the template and getting the result as string:

t := template.Must(template.New(""email"").Parse(emailTmpl))
buf := &bytes.Buffer{}
if err := t.Execute(buf, data); err != nil {
    panic(err)
}
s := buf.String()


This will result in the expected output:

Hi Bob!

Your account is ready, your user name is: bob92

You have the following roles assigned:
dbteam, uiteam, tester


Try it on the Go Playground.

Also note that since Go 1.10, a newer, faster, more specialized alternative is available to bytes.Buffer which is: strings.Builder. Usage is very similar:

builder := &strings.Builder{}
if err := t.Execute(builder, data); err != nil {
    panic(err)
}
s := builder.String()


Try this one on the Go Playground.

Note: you may also display the result of a template execution if you provide os.Stdout as the target (which also implements io.Writer):

t := template.Must(template.New(""email"").Parse(emailTmpl))
if err := t.Execute(os.Stdout, data); err != nil {
    panic(err)
}


This will write the result directly to os.Stdout. Try this on the Go Playground.
    try using Sprintf(); it will not print the output but save it for future purpose.
check this out.
package main

import ""fmt""

func main() {
    
    address := ""NYC""

    fmt.Sprintf(""I live in %v"", address)

}

when you run this code, it will not output anything. But once you assigned the Sprintf() to a separate variable, it can be used for future purposes.
package main

import ""fmt""

func main() {
    
    address := ""NYC""

    fmt.Sprintf(""I live in %v"", address)

    var city = fmt.Sprintf(""lives in %v"", address)
    fmt.Println(""Michael"",city)

}

    I've created go project for string formatting from template (it allow to format strings in C# or Python style, just first version for very simple cases), you could find it here https://github.com/Wissance/stringFormatter
it works in following manner:

func TestStrFormat(t *testing.T) {
    strFormatResult, err := Format(""Hello i am {0}, my age is {1} and i am waiting for {2}, because i am {0}!"",
                              ""Michael Ushakov (Evillord666)"", ""34"", ""\""Great Success\"""")
    assert.Nil(t, err)
    assert.Equal(t, ""Hello i am Michael Ushakov (Evillord666), my age is 34 and i am waiting for \""Great Success\"", because i am Michael Ushakov (Evillord666)!"", strFormatResult)

    strFormatResult, err = Format(""We are wondering if these values would be replaced : {5}, {4}, {0}"", ""one"", ""two"", ""three"")
    assert.Nil(t, err)
    assert.Equal(t, ""We are wondering if these values would be replaced : {5}, {4}, one"", strFormatResult)

    strFormatResult, err = Format(""No args ... : {0}, {1}, {2}"")
    assert.Nil(t, err)
    assert.Equal(t, ""No args ... : {0}, {1}, {2}"", strFormatResult)
}

func TestStrFormatComplex(t *testing.T) {
    strFormatResult, err := FormatComplex(""Hello {user} what are you doing here {app} ?"", map[string]string{""user"":""vpupkin"", ""app"":""mn_console""})
    assert.Nil(t, err)
    assert.Equal(t, ""Hello vpupkin what are you doing here mn_console ?"", strFormatResult)
}


    We can custom A new String type via define new Type with Format support.
package main

import (
    ""fmt""
    ""text/template""
    ""strings""
)

type String string
func (s String) Format(data map[string]interface{}) (out string, err error) {
    t := template.Must(template.New("""").Parse(string(s)))
    builder := &strings.Builder{}
    if err = t.Execute(builder, data); err != nil {
        return
    }
    out = builder.String()
    return
}


func main() {
    const tmpl = `Hi {{.Name}}!  {{range $i, $r := .Roles}}{{if $i}}, {{end}}{{.}}{{end}}`
    data := map[string]interface{}{
        ""Name"":     ""Bob"",
        ""Roles"":    []string{""dbteam"", ""uiteam"", ""tester""},
    }

    s ,_:= String(tmpl).Format(data)
    fmt.Println(s)
}

Note: {{.}} represent {{$r}} in {{range $i, $r := .Roles}} {{.}} {{end}}
    fmt.SprintF function returns a string and you can format the string the very same way you would have with fmt.PrintF
    In your case, you need to use Sprintf() for format string.

func Sprintf(format string, a ...interface{}) string

Sprintf formats according to a format specifier and returns the resulting string.

s := fmt.Sprintf(""Good Morning, This is %s and I'm living here from last %d years "", ""John"", 20)

Your output will be :


  Good Morning, This is John and I'm living here from last 20 years.

    I came to this page specifically looking for a way to format an error string. So if someone needs help with the same, you want to use the fmt.Errorf() function.
The method signature is func Errorf(format string, a ...interface{}) error.
It returns the formatted string as a value that satisfies the error interface.
You can look up more details in the documentation - https://golang.org/pkg/fmt/#Errorf.
    Instead of using template.New, you can just use the new builtin with
template.Template:
package main

import (
   ""strings""
   ""text/template""
)

func format(s string, v interface{}) string {
   t, b := new(template.Template), new(strings.Builder)
   template.Must(t.Parse(s)).Execute(b, v)
   return b.String()
}

func main() {
   bar := ""bar""
   println(format(""foo: {{.}}"", bar))
   i := 25
   println(format(""foo: {{.}}"", i))
}

    ","[486, 613, 236, 5, 2, 2, 0, 3, 1, 0]",301735,63,2012-06-20T16:21:34,2021-11-02 06:23:08Z,go 
Convert Iterable to Stream using Java 8 JDK,"
                
I have an interface which returns java.lang.Iterable<T>.

I would like to manipulate that result using the Java 8 Stream API.

However Iterable can't ""stream"".

Any idea how to use the Iterable as a Stream without converting it to List?
    There's a much better answer than using spliteratorUnknownSize directly, which is both easier and gets a better result.  Iterable has a spliterator() method, so you should just use that to get your spliterator.  In the worst case, it's the same code (the default implementation uses spliteratorUnknownSize), but in the more common case, where your Iterable is already a collection, you'll get a better spliterator, and therefore better stream performance (maybe even good parallelism).  It's also less code:

StreamSupport.stream(iterable.spliterator(), false)
             .filter(...)
             .moreStreamOps(...);


As you can see, getting a stream from an Iterable (see also this question) is not very painful.
    If you can use Guava library, since version 21, you can use

Streams.stream(iterable)

    I've created this class:

public class Streams {
    /**
     * Converts Iterable to stream
     */
    public static <T> Stream<T>  streamOf(final Iterable<T> iterable) {
        return toStream(iterable, false);
    }

    /**
     * Converts Iterable to parallel stream
     */
    public static <T> Stream<T> parallelStreamOf(final Iterable<T> iterable) {
        return toStream(iterable, true);
    }

    private static <T> Stream<T> toStream(final Iterable<T> iterable, final boolean isParallel) {
        return StreamSupport.stream(iterable.spliterator(), isParallel);
    }
}


I think it's perfectly readable because you don't have to think about spliterators and booleans (isParallel).
    So as another answer mentioned Guava has support for this by using:

Streams.stream(iterable);


I want to highlight that the implementation does something slightly different than other answers suggested. If the Iterable is of type Collection they cast it.

public static <T> Stream<T> stream(Iterable<T> iterable) {
  return (iterable instanceof Collection)
    ? ((Collection<T>) iterable).stream()
    : StreamSupport.stream(iterable.spliterator(), false);
}

public static <T> Stream<T> stream(Iterator<T> iterator) {
  return StreamSupport.stream(
    Spliterators.spliteratorUnknownSize(iterator, 0),
    false
  );
}

    You can easily create a Stream out of an Iterable or Iterator:

public static <T> Stream<T> stream(Iterable<T> iterable) {
    return StreamSupport.stream(
        Spliterators.spliteratorUnknownSize(
            iterable.iterator(),
            Spliterator.ORDERED
        ),
        false
    );
}

    A very simple work-around for this issue is to create a Streamable<T> interface extending Iterable<T> that holds a default <T> stream() method.

interface Streamable<T> extends Iterable<T> {
    default Stream<T> stream() {
        return StreamSupport.stream(spliterator(), false);
    }
}


Now any of your Iterable<T>s can be trivially made streamable just by declaring them implements Streamable<T> instead of Iterable<T>.
    I would like to suggest using JOOL library, it hides spliterator magic behind the Seq.seq(iterable) call and also provides a whole bunch of additional useful functionality.
    If you happen to use Vavr(formerly known as Javaslang), this can be as easy as:

Iterable i = //...
Stream.ofAll(i);

    ","[486, 659, 91, 6, 8, 24, 4, 8, 0]",141780,65,2014-05-29T11:16:28,2021-02-04 01:55:08Z,java 
Deep copy of a dict in python,"
                
I would like to make a deep copy of a dict in python. Unfortunately the .deepcopy() method doesn't exist for the dict. How do I do that?

>>> my_dict = {'a': [1, 2, 3], 'b': [4, 5, 6]}
>>> my_copy = my_dict.deepcopy()
Traceback (most recent calll last):
  File ""<stdin>"", line 1, in <module>
AttributeError: 'dict' object has no attribute 'deepcopy'
>>> my_copy = my_dict.copy()
>>> my_dict['a'][2] = 7
>>> my_copy['a'][2]
7


The last line should be 3.

I would like that modifications in my_dict don't impact the snapshot my_copy.

How do I do that? The solution should be compatible with Python 3.x.
    How about:

import copy
d = { ... }
d2 = copy.deepcopy(d)


Python 2 or 3:

Python 3.2 (r32:88445, Feb 20 2011, 21:30:00) [MSC v.1500 64 bit (AMD64)] on win32
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import copy
>>> my_dict = {'a': [1, 2, 3], 'b': [4, 5, 6]}
>>> my_copy = copy.deepcopy(my_dict)
>>> my_dict['a'][2] = 7
>>> my_copy['a'][2]
3
>>>

    Python 3.x
from copy import deepcopy

my_dict = {'one': 1, 'two': 2}
new_dict_deepcopy = deepcopy(my_dict)

Without deepcopy, I am unable to remove the hostname dictionary from within my domain dictionary.
Without deepcopy I get the following error:
""RuntimeError: dictionary changed size during iteration""

...when I try to remove the desired element from my dictionary inside of another dictionary.
import socket
import xml.etree.ElementTree as ET
from copy import deepcopy

domain is a dictionary object
def remove_hostname(domain, hostname):
    domain_copy = deepcopy(domain)
    for domains, hosts in domain_copy.items():
        for host, port in hosts.items():
           if host == hostname:
                del domain[domains][host]
    return domain

Example output:
[orginal]domains = {'localdomain': {'localhost': {'all': '4000'}}}
[new]domains = {'localdomain': {} }}
So what's going on here is I am iterating over a copy of a dictionary rather than iterating over the dictionary itself. With this method, you are able to remove elements as needed.
    dict.copy() is a shallow copy function for dictionary 

id is built-in function that gives you the address of variable

First you need to understand ""why is this particular problem is happening?""

In [1]: my_dict = {'a': [1, 2, 3], 'b': [4, 5, 6]}

In [2]: my_copy = my_dict.copy()

In [3]: id(my_dict)
Out[3]: 140190444167808

In [4]: id(my_copy)
Out[4]: 140190444170328

In [5]: id(my_copy['a'])
Out[5]: 140190444024104

In [6]: id(my_dict['a'])
Out[6]: 140190444024104


The address of the list present in both the dicts for key 'a' is pointing to same location. 
Therefore when you change value of the list in my_dict, the list in my_copy changes as well.



Solution for data structure mentioned in the question:

In [7]: my_copy = {key: value[:] for key, value in my_dict.items()}

In [8]: id(my_copy['a'])
Out[8]: 140190444024176


Or you can use deepcopy as mentioned above.
    ","[486, 691, 34, 57]",361631,57,2011-02-24T13:52:22,2022-01-30 18:55:18Z,python 
Git conflict markers [duplicate],"
                    
            
        
            
                
                    
                        This question already has answers here:
                        
                    
                
            
                    
                        Git merge left HEAD marks in my files
                            
                                (5 answers)
                            
                    
                Closed 9 years ago.
        

    

After I pulled from remote branch, I got conflict, when I open the file it looks something like below:

<<<<<<< HEAD:file.txt
Hello world
=======
Goodbye
>>>>>>> 77976da35a11db4580b80ae27e8d65caf5208086:file.txt


I need some explanations of the markers, which portion of code is pulled from remote and which is from local?

What does the code 77976da35a11db4580b80ae27e8d65caf5208086 stand for?
    The line (or lines) between the lines beginning <<<<<<< and ====== here:

<<<<<<< HEAD:file.txt
Hello world
=======


... is what you already had locally - you can tell because HEAD points to your current branch or commit.  The line (or lines) between the lines beginning ======= and >>>>>>>:

=======
Goodbye
>>>>>>> 77976da35a11db4580b80ae27e8d65caf5208086:file.txt


... is what was introduced by the other (pulled) commit, in this case 77976da35a11.  That is the object name (or ""hash"", ""SHA1sum"", etc.) of the commit that was merged into HEAD.  All objects in git, whether they're commits (version), blobs (files), trees (directories) or tags have such an object name, which identifies them uniquely based on their content.
    ","[486, 763]",222671,144,2011-10-26T11:16:57,2019-02-20 07:11:38Z,
How to pass an array within a query string?,"
                
Is there a standard way of passing an array through a query string?
To be clear, I have a query string with multiple values, one of which would be an array value.  I want that query string value to be treated as an array- I don't want the array to be exploded so that it is indistinguishable from the other query string variables.
Also, according to this post answer, the author suggests that query string support for arrays is not defined.  Is this accurate?
EDIT:
Based on @Alex's answer, there is no standard way of doing this, so my follow-up is then what is an easy way to recognize that the parameter I'm reading is an array in both PHP and Javascript?
Would it be acceptable to name multiple params the same name, and that way I would know that they belong to an array? Example:
?myarray=value1&myarray=value2&myarray=value3...

Or would this be a bad practice?
    Here's what I figured out:

Submitting multi-value form fields, i.e. submitting arrays through GET/POST vars, can be done several different ways, as a standard is not necessarily spelled out.

Three possible ways to send multi-value fields or arrays would be:


?cars[]=Saab&cars[]=Audi (Best way- PHP reads this into an array)
?cars=Saab&cars=Audi (Bad way- PHP will only register last value)
?cars=Saab,Audi (Haven't tried this)


Form Examples

On a form, multi-valued fields could take the form of a select box set to multiple:

<form> 
    <select multiple=""multiple"" name=""cars[]""> 
        <option>Volvo</option> 
        <option>Saab</option> 
        <option>Mercedes</option> 
    </select>
</form>


(NOTE: In this case, it would be important to name the select control some_name[], so that the resulting request vars would be registered as an array by PHP)  

... or as multiple hidden fields with the same name:

<input type=""hidden"" name=""cars[]"" value=""Volvo"">
<input type=""hidden"" name=""cars[]"" value=""Saab"">
<input type=""hidden"" name=""cars[]"" value=""Mercedes"">




NOTE: Using field[] for multiple values is really poorly documented. I don't see any mention of it in the section on multi-valued keys in Query string - Wikipedia, or in the W3C docs dealing with multi-select inputs.



UPDATE

As commenters have pointed out, this is very much framework-specific. Some examples:

Query string:

?list_a=1&list_a=2&list_a=3&list_b[]=1&list_b[]=2&list_b[]=3&list_c=1,2,3


Rails:

""list_a"": ""3"", 
""list_b"":[
    ""1"",
    ""2"",
    ""3""
  ], 
""list_c"": ""1,2,3""


Angular:

 ""list_a"": [
    ""1"",
    ""2"",
    ""3""
  ],
  ""list_b[]"": [
    ""1"",
    ""2"",
    ""3""
  ],
  ""list_c"": ""1,2,3""


(Angular discussion)

See comments for examples in node.js, Wordpress, ASP.net



Maintaining order:
One more thing to consider is that if you need to maintain the order of your items (i.e. array as an ordered list), you really only have one option, which is passing a delimited list of values, and explicitly converting it to an array yourself.
    Note that the query-string module lists the different types of array encoding it supports (https://www.npmjs.com/package/query-string):
For instance {foo: ['1', '2', '3']} can be encoded as:
'foo[]=1&foo[]=2&foo[]=3'
'foo[0]=1&foo[1]=2&foo[3]=3'
'foo=1,2,3'
'foo=1&foo=2&foo=3'
// Any custom separator can be used:
'foo=1|2|3'
// ... and more custom formats

This shows that there are many solutions adopted out there...
    This works for me:
In link, to attribute has value:
to=""/filter/arr?fruits=apple&fruits=banana""

Route can handle this:
path=""/filter/:arr""

For Multiple arrays:
to=""filter/arr?fruits=apple&fruits=banana&vegetables=potato&vegetables=onion""

Route stays same.
SCREENSHOT

UPDATE:
In order to achieve this string structure, query-string is the best package.
For example:
import { stringify, parse } from 'query-string';

const queryParams={
   fruits:['apple','banana'],
   vegetables:['potato','onion']
}
//arrayFormat can be bracket or comma 
stringify(queryParams, { arrayFormat: 'bracket' });

    A query string carries textual data so there is no option but to explode the array, encode it correctly and pass it in a representational format of your choice:

p1=value1&pN=valueN...
data=[value1,...,valueN]
data={p1:value1,...,pN:valueN}

and then decode it in your server side code.
    Although there isn't a standard on the URL part, there is one standard for JavaScript. If you pass objects containing arrays to URLSearchParams, and call toString() on it, it will transform it into a comma separated list of items:
let data = {
  str: 'abc',
  arr: ['abc', 123]
}

new URLSearchParams(data).toString();
// ?str=abc&arr=abc,123 (with escaped comma characters)

    I don't think there's a standard.
Each web environment provides its own 'standard' for such things. Besides, the url is usually too short for anything (256 bytes limit on some browsers). Of course longer arrays/data can be send with POST requests.

However, there are some methods:


There's a PHP way, which uses square brackets ([,]) in URL queries. For example a query such as ?array_name[]=item&array_name[]=item_2 has been said to work, despite being poorly documented, with PHP automatically converting it into an array. Source: https://stackoverflow.com/a/9547490/3787376
Object data-interchange formats (e.g. JSON - official website, PHP documentation) can also be used if they have methods of converting variables to and from strings as JSON does.
Also an url-encoder (available for most programming languages) is required for HTTP get requests to encode the string data correctly.


Although the ""square brackets method"" is simple and works, it is limited to PHP and arrays.
If other types of variable such as classes or passing variables within query strings in a language other than PHP is required, the JSON method is recommended.

Example in PHP of JSON method (method 2):


$myarray = array(2, 46, 34, ""dfg"");
$serialized = json_encode($myarray)
$data = 'myarray=' . rawurlencode($serialized);
// Send to page via cURL, header() or other service.


Code for receiving page (PHP):


$myarray = json_decode($_GET[""myarray""]); // Or $_POST[""myarray""] if a post request.

    I use React and Rails. I did:

js

  let params = {
    filter_array: ['A', 'B', 'C']
  }

  ...

  //transform params in URI

  Object.keys(params).map(key => {
    if (Array.isArray(params[key])) {
      return params[key].map((value) => `${key}[]=${value}`).join('&')
    }
  }
  //filter_array[]=A&filter_array[]=B&filter_array[]=C

    I feel it would be helpful for someone who is looking for passing the array in a query string to a servlet. I tested below query string and was able to get the array values using req.getgetParameterValues(); method. Below is the query string I passed through browser.

  http://localhost:8080/ServletsTutorials/*.html? 
  myname=abc&initial=xyz&checkbox=a&checkbox=b


checkbox is my parameter array here.
    You mention PHP and Javascript in your question, but not in the tags. I reached this question with the intention of passing an array to an MVC.Net action.

I found the answer to my question here: the expected format is the one you proposed in your question, with multiple parameters having the same name.
    You can use http_build_query to generate a URL-encoded querystring from an array in PHP. Whilst the resulting querystring will be expanded, you can decide on a unique separator you want as a parameter to the http_build_query method, so when it comes to decoding, you can check what separator was used. If it was the unique one you chose, then that would be the array querystring otherwise it would be the normal querystrings.
    Check the parse_string function http://php.net/manual/en/function.parse-str.php

It will return all the variables from a query string, including arrays.

Example from php.net:

<?php
$str = ""first=value&arr[]=foo+bar&arr[]=baz"";
parse_str($str);
echo $first;  // value
echo $arr[0]; // foo bar
echo $arr[1]; // baz

parse_str($str, $output);
echo $output['first'];  // value
echo $output['arr'][0]; // foo bar
echo $output['arr'][1]; // baz

?>

    ","[486, 554, 6, 14, 45, 15, 25, 4, 7, 2, 1, 0]",800501,128,2011-06-05T13:03:27,2021-07-13 23:46:08Z,php 
What is the difference between Nullable<T>.HasValue or Nullable<T> != null?,"
                
I always used Nullable<>.HasValue because I liked the semantics. However, recently I was working on someone else's existing codebase where they used Nullable<> != null exclusively instead.

Is there a reason to use one over the other, or is it purely preference?


int? a;
if (a.HasValue)
    // ...



vs.


int? b;
if (b != null)
    // ...


    The compiler replaces null comparisons with a call to HasValue, so there is no real difference. Just do whichever is more readable/makes more sense to you and your colleagues.
    I did some research on this by using different methods to assign values to a nullable int. Here is what happened when I did various things. Should clarify what's going on.
Keep in mind: Nullable<something> or the shorthand something? is a struct for which the compiler seems to be doing a lot of work to let us use with null as if it were a class.
As you'll see below, SomeNullable == null and SomeNullable.HasValue will always return an expected true or false. Although not demonstrated below, SomeNullable == 3 is valid too (assuming SomeNullable is an int?).
While SomeNullable.Value gets us a runtime error if we assigned null to SomeNullable. This is in fact the only case where nullables could cause us a problem, thanks to a combination of overloaded operators, overloaded object.Equals(obj) method, and compiler optimization and monkey business.

Here is a description of some code I ran, and what output it produced in labels:

int? val = null;
lbl_Val.Text = val.ToString(); //Produced an empty string.
lbl_ValVal.Text = val.Value.ToString(); //Produced a runtime error. (""Nullable object must have a value."")
lbl_ValEqNull.Text = (val == null).ToString(); //Produced ""True"" (without the quotes)
lbl_ValNEqNull.Text = (val != null).ToString(); //Produced ""False""
lbl_ValHasVal.Text = val.HasValue.ToString(); //Produced ""False""
lbl_NValHasVal.Text = (!(val.HasValue)).ToString(); //Produced ""True""
lbl_ValValEqNull.Text = (val.Value == null).ToString(); //Produced a runtime error. (""Nullable object must have a value."")
lbl_ValValNEqNull.Text = (val.Value != null).ToString(); //Produced a runtime error. (""Nullable object must have a value."")


Ok, lets try the next initialization method:

int? val = new int?();
lbl_Val.Text = val.ToString(); //Produced an empty string.
lbl_ValVal.Text = val.Value.ToString(); //Produced a runtime error. (""Nullable object must have a value."")
lbl_ValEqNull.Text = (val == null).ToString(); //Produced ""True"" (without the quotes)
lbl_ValNEqNull.Text = (val != null).ToString(); //Produced ""False""
lbl_ValHasVal.Text = val.HasValue.ToString(); //Produced ""False""
lbl_NValHasVal.Text = (!(val.HasValue)).ToString(); //Produced ""True""
lbl_ValValEqNull.Text = (val.Value == null).ToString(); //Produced a runtime error. (""Nullable object must have a value."")
lbl_ValValNEqNull.Text = (val.Value != null).ToString(); //Produced a runtime error. (""Nullable object must have a value."")


All the same as before. Keep in mind that initializing with int? val = new int?(null);, with null passed to the constructor, would have produced a COMPILE time error, since the nullable object's VALUE is NOT nullable. It is only the wrapper object itself that can equal null.

Likewise, we would get a compile time error from:

int? val = new int?();
val.Value = null;


not to mention that val.Value is a read-only property anyway, meaning we can't even use something like:

val.Value = 3;


but again, polymorphous overloaded implicit conversion operators let us do:

val = 3;


No need to worry about polysomthing whatchamacallits though, so long as it works right? :)
    I prefer (a != null) so that the syntax matches reference types.
    In VB.Net, do NOT use IsNot Nothing when you can use .HasValue.  I just solved an ""Operation could destabilize the runtime"" Medium trust error by replacing IsNot Nothing with .HasValue in one spot.  I don't really understand why, but something is happening differently in the compiler.  I would assume that != null in C# may have the same issue.
    If you use linq and want to keep your code short, I recommand to always use !=null 

And this is why:

Let imagine we have some class Foo with a nullable double variable SomeDouble

public class Foo
{
    public double? SomeDouble;
    //some other properties
}   


If somewhere in our code we want to get all Foo with a non null SomeDouble values from a collection of Foo (assuming some foos in the collection can be null too), we end up with at least three way to write our function (if we use C# 6) :

public IEnumerable<Foo> GetNonNullFoosWithSomeDoubleValues(IEnumerable<Foo> foos)
{
     return foos.Where(foo => foo?.SomeDouble != null);
     return foos.Where(foo=>foo?.SomeDouble.HasValue); // compile time error
     return foos.Where(foo=>foo?.SomeDouble.HasValue == true); 
     return foos.Where(foo=>foo != null && foo.SomeDouble.HasValue); //if we don't use C#6
}


And in this kind of situation I recommand to always go for the shorter one
    There second method will be many times more effective (mostly because of compilers inlining and boxing but still numbers are very expressive):
public static bool CheckObjectImpl(object o)
{
    return o != null;
}

public static bool CheckNullableImpl<T>(T? o) where T: struct
{
    return o.HasValue;
}

Benchmark test:
BenchmarkDotNet=v0.10.5, OS=Windows 10.0.14393
Processor=Intel Core i5-2500K CPU 3.30GHz (Sandy Bridge), ProcessorCount=4
Frequency=3233539 Hz, Resolution=309.2587 ns, Timer=TSC
  [Host] : Clr 4.0.30319.42000, 64bit RyuJIT-v4.6.1648.0
  Clr    : Clr 4.0.30319.42000, 64bit RyuJIT-v4.6.1648.0
  Core   : .NET Core 4.6.25009.03, 64bit RyuJIT


        Method |  Job | Runtime |       Mean |     Error |    StdDev |        Min |        Max |     Median | Rank |  Gen 0 | Allocated |
-------------- |----- |-------- |-----------:|----------:|----------:|-----------:|-----------:|-----------:|-----:|-------:|----------:|
   CheckObject |  Clr |     Clr | 80.6416 ns | 1.1983 ns | 1.0622 ns | 79.5528 ns | 83.0417 ns | 80.1797 ns |    3 | 0.0060 |      24 B |
 CheckNullable |  Clr |     Clr |  0.0029 ns | 0.0088 ns | 0.0082 ns |  0.0000 ns |  0.0315 ns |  0.0000 ns |    1 |      - |       0 B |
   CheckObject | Core |    Core | 77.2614 ns | 0.5703 ns | 0.4763 ns | 76.4205 ns | 77.9400 ns | 77.3586 ns |    2 | 0.0060 |      24 B |
 CheckNullable | Core |    Core |  0.0007 ns | 0.0021 ns | 0.0016 ns |  0.0000 ns |  0.0054 ns |  0.0000 ns |    1 |      - |       0 B |

Benchmark code:
public class BenchmarkNullableCheck
{
    static int? x = (new Random()).Next();

    public static bool CheckObjectImpl(object o)
    {
        return o != null;
    }

    public static bool CheckNullableImpl<T>(T? o) where T: struct
    {
        return o.HasValue;
    }

    [Benchmark]
    public bool CheckObject()
    {
        return CheckObjectImpl(x);
    }

    [Benchmark]
    public bool CheckNullable()
    {
        return CheckNullableImpl(x);
    }
}

https://github.com/dotnet/BenchmarkDotNet was used
So if you have an option (e.g. writing custom serializers) to process Nullable in different pipeline than  object - and use their specific properties - do it and use Nullable specific properties.
So from consistent thinking point of view HasValue should be preferred. Consistent thinking can help you to write better code do not spending too much time in details.
PS. People say that advice ""prefer HasValue because of consistent thinking"" is not related and useless. Can you predict the performance of this?
public static bool CheckNullableGenericImpl<T>(T? t) where T: struct
{
    return t != null; // or t.HasValue?
}

PPS People continue minus, seems nobody tries to predict  performance of CheckNullableGenericImpl. I will tell you: there compiler will not help you replacing !=null with HasValue. HasValue should be used directly if you are interested in performance.
    ","[486, 528, 22, 55, 13, 0, -9]",115395,45,2009-03-24T03:30:01,2022-05-02 20:11:44Z,c 
How to manually include external aar package using Gradle for Android,"
                
I've been experimenting with the new android build system and I've run into a small issue.  I've compiled my own aar package of ActionBarSherlock which I've called 'actionbarsherlock.aar'.  What I'm trying to do is actually use this aar to build my final APK.  If I include the whole ActionBarSherlock library as an android-library module to my main project using compile project (':actionbarsherlock') I'm able to build successfully without any problems.

But my problem is that I want to provide that dependency as a aar file package MANUALLY just if I would a JAR then I can't seem to figure out how to properly include it into my project.  I've attempted to use the compile configuration but this doesn't seem to work.  I keep on getting cannot find symbol during compile which tells me that the classes.jar from aar package isn't getting included in the classpath.

Does anyone know of the syntax to manually include an aar package as a file?

build.gradle 

buildscript {

 repositories {
     mavenCentral()
  }
  dependencies {
    classpath 'com.android.tools.build:gradle:0.4'
  }
}
apply plugin: 'android'

repositories {
   mavenCentral()
}
dependencies {
    compile files('libs/actionbarsherlock.aar')
}

android {
    compileSdkVersion 15
    buildToolsVersion ""17.0""
}


EDIT: So the answer is that it's not currently supported, here's the issue if you want to track it.

EDIT: Currently as this is still not supported directly the best alternative seems to be the proposed solution from @RanWakshlak

EDIT: Also simpler by using the syntax proposed by @VipulShah 
    Add below line in app level build.gradle
  implementation fileTree(dir: ""libs"", include: [""*.aar""])

Change Project structure from Android to Project.
Navigaate to app->libs as below

Then paste ""aar"" in libs folder.
Click on File at top left of android studio and click ""Sync Project with Gradle Files"" as below.

That's it.
    With Android Studio 3.4 and Gradle 5 you can simply do it like this

dependencies {
    implementation files('libs/actionbarsherlock.aar')
}

    To manually import AAR files with Android Studio Arctic Fox
Step 1. Open Project Structure

Step 2. Open Project Structure

Step 3. Enter file path

DONE!
    If you use Gradle Kotlin DSL, you need to add a file in your module directory.
For example: libs/someAndroidArchive.aar
After just write this in your module build.gradle.kts in the dependency block:
implementation(files(""libs/someAndroidArchive.aar""))

    Please follow below steps to get it working ( I have tested it up to Android Studio 2.2)
Lets say you have kept aar file in libs folder. ( assume file name is cards.aar )
then in app build.gradle specify following and click sync project with Gradle files.
Open Project level build.gradle and add flatDir{dirs 'libs'} like did below
allprojects {
   repositories {
      jcenter()
      flatDir {
        dirs 'libs'
      }
   }
}

and now open app level build.grdle file and add .aar file
    dependencies {
       implementation(name:'cards', ext:'aar')
}

If everything goes well you will see library entry is made in build -> exploded-aar
Also note that if you are importing a .aar file from another project that has dependencies you'll need to include these in your build.gradle, too.
    
Right click on your project and select ""Open Module Settings"".



Click the ""+"" button in the top left corner of window to add a new module.



Select ""Import .JAR or .AAR Package"" and click the ""Next"" button.



Find the AAR file using the ellipsis button ""..."" beside the ""File name"" field.



Keep the app's module selected and click on the Dependencies pane to add the new module as a dependency.



Use the ""+"" button of the dependencies screen and select ""Module dependency"".



Select the module and click ""OK"".


EDIT: Module dependency in screenshot 6 has been removed in Android Studio 4.1. As an alternative add the module dependency to the build.gradle.
dependencies {
    implementation project(':your_module')
}

EDIT: The user interface and the work flow have been changed a lot in Android Studio 4.2. The process to add a dependency is very well explained in an official documentation now: Adding dependencies with the Project Structure Dialog
    The below approach works with Android studio v0.8.x:

Save the aar file under app module's libs folder (eg: <project>/<app>/libs/myaar.aar)

Add the below to build.gradle of your ""app"" module folder (not your project root build.gradle). Note the name in compile line, it is myaar@aar not myaar.aar.
 dependencies {
     compile 'package.name.of.your.aar:myaar@aar'
 }

 repositories{
     flatDir{
         dirs 'libs'
     }
 }


Click Tools -> Android -> Sync Project with Gradle Files


    before(default)

implementation fileTree(include: ['*.jar'], dir: 'libs')


just add '*.aar' in include array.

implementation fileTree(include: ['*.jar', '*.aar'], dir: 'libs')


it works well on Android Studio 3.x.

if you want ignore some library? do like this.

implementation fileTree(include: ['*.jar', '*.aar'], exclude: 'test_aar*', dir: 'libs')
debugImplementation files('libs/test_aar-debug.aar')
releaseImplementation files('libs/test_aar-release.aar')

    You can reference an aar file from a repository.
A maven is an option, but there is a simpler solution: put the aar file in your libs directory and add a directory repository.

    repositories {
      mavenCentral()
      flatDir {
        dirs 'libs'
      }
    }


Then reference the library in the dependency section:

  dependencies {
        implementation 'com.actionbarsherlock:actionbarsherlock:4.4.0@aar'
}



You can check out  Min'an blog post for more info.
    I've just succeeded!


Copy the mylib-0.1.aar file into the libs/ folder
Add these lines to the bottom of build.gradle (should be app, not project):

repositories {
   flatDir {
       dirs 'libs'
   }
}
dependencies {
    compile 'com.example.lib:mylib:0.1@aar'
}

So far so good. Here comes the most important point: 


Gradle needs to access the network for dependencies unless offline mode is enabled. 

Make sure that you have enabled Offline work via the checkbox in Project Structures/Gradle 

-- OR -- 

Configure the proxy settings in order to access the network.

To configure the proxy settings you have to modify the project's gradle.properties file, configuring http and https separately as below:

systemProp.http.proxyHost=proxy.example.com
systemProp.http.proxyPort=8080
systemProp.http.proxyUser=user
systemProp.http.proxyPassword=pass
systemProp.http.nonProxyHosts=localhost
systemProp.http.auth.ntlm.domain=example <for NT auth>

systemProp.https.proxyHost=proxy.example.com
systemProp.https.proxyPort=8080
systemProp.https.proxyUser=user
systemProp.https.proxyPassword=pass
systemProp.https.nonProxyHosts=localhost
systemProp.https.auth.ntlm.domain=example <for NT auth>


Hope this works.
    There are 2 ways:

The first way


Open your Android Studio and navigate to the Create New Module window by File -> New -> New Module


 


Select the Import .JAR/.AAR Package item and click the Next button
Add a dependency in the build.gradle file that belongs to your app module.


    dependencies {
        ...
        implementation project(path: ':your aar lib name')
    }


That's all.

The second way


Create a folder in libs directory, such as aars.
Put your aar lib into the aars folder.
Add the code snippet 


repositories {
    flatDir {
        dirs 'libs/aars'
    }
}


into your build.gradle file belongs to the app module.


Add a dependency in the build.gradle file that belongs to your app module.


dependencies {
    ...
    implementation (name:'your aar lib name', ext:'aar')
}


That's all.

If you can read Chinese, you can check the blog 什么是AAR文件以及如何在Android开发中使用
    UPDATE ANDROID STUDIO 3.4


Go to File -> Project Structure





Modules and click on +





Select Import .aar Package





Find the .aar route





Finish and Apply, then verify if package is added





Now in the app module, click on + and Module Dependency





Check the library package and Ok





Verify the added dependency





And the project structure like this



    The standard way to import AAR file in an application is given in https://developer.android.com/studio/projects/android-library.html#AddDependency

Click File > New > New Module.
Click Import .JAR/.AAR Package then click Next.
Enter the location of the compiled AAR or JAR file then click Finish.

Please refer the link above for next steps.
    There is 1 more way to do this.
Usually the .aar file is not supposed to be directly used like we use a .jar and hence the solutions mentioned above to mention it in libs folder and declaring in gradle can be avoided.
Step 1: Unpack the .aar file (You can do this by renaming its extension from "".aar"" to "".zip"")
Step 2: You will most probably find the .jar file in the folder after extraction. Copy this .jar file and paste it in your module/libs folder
Step 3: That's it, now sync your project and you should be able to access all classes/methods/ properties from that .jar . You don't need to mention about it's path/name/existence in any gradle file, this is because the gradle build system always looks out for files existing in libs folder while building the project
    I've also had this problem. This issue report: https://code.google.com/p/android/issues/detail?id=55863 seems to suggest that directly referencing the .AAR file is not supported.

Perhaps the alternative for now is to define the actionbarsherlock library as a Gradle library under the parent directory of your project and reference accordingly.

The syntax is defined here http://tools.android.com/tech-docs/new-build-system/user-guide#TOC-Referencing-a-Library
    In my case I have some depencies in my library and when I create an aar from it I failed, because of missed depencies, so my solution is to add all depencies from my lib with an arr file. 

So my project level build.gradle looks so:

buildscript {
    repositories {
        mavenCentral()
    }
    dependencies {
        classpath 'com.android.tools.build:gradle:2.1.2'
    }
}

allprojects {
    repositories {
        mavenCentral()
        //add it to be able to add depency to aar-files from libs folder in build.gradle(yoursAppModule)
        flatDir {
            dirs 'libs'
        }
    }
}

task clean(type: Delete) {
    delete rootProject.buildDir
}


build.gradle(modile app) so:

apply plugin: 'com.android.application'

android {
    compileSdkVersion 23
    buildToolsVersion ""23.0.3""

    defaultConfig {
        applicationId ""com.example.sampleapp""
        minSdkVersion 15
        targetSdkVersion 23
        versionCode 1
        versionName ""1.0""
    }
    buildTypes {
        release {
            minifyEnabled false
            proguardFiles getDefaultProguardFile('proguard-android.txt'), 'proguard-rules.pro'
        }
    }
}

dependencies {
    //your project depencies
    ...
    //add lib via aar-depency
    compile(name: 'aarLibFileNameHere', ext: 'aar')
    //add all its internal depencies, as arr don't have it
    ...
}


and library build.gradle:

apply plugin: 'com.android.library'

android {
    compileSdkVersion 23
    buildToolsVersion ""23.0.3""

    defaultConfig {
        minSdkVersion 15
        targetSdkVersion 23
        versionCode 1
        versionName ""1.0""
    }
    buildTypes {
        release {
            minifyEnabled false
            proguardFiles getDefaultProguardFile('proguard-android.txt'), 'proguard-rules.pro'
        }
    }
}

dependencies {
    compile fileTree(include: ['*.jar'], dir: 'libs')
    //here goes library projects dependencies, which you must include
    //in yours build.gradle(modile app) too
    ...
}

    You can add multiple aar dependencies with just few lines of code.

Add local flatDir repository:

repositories {
    flatDir {
        dirs 'libs'
    }
} 


Add every aar in libs directory to compile dependency configuration:

fileTree(dir: 'libs', include: '**/*.aar')
        .each { File file ->
    dependencies.add(""compile"", [name: file.name.lastIndexOf('.').with { it != -1 ? file.name[0..<it] : file.name }, ext: 'aar'])
}

    I found this workaround in the Android issue tracker:
https://code.google.com/p/android/issues/detail?id=55863#c21

The trick (not a fix) is to isolating your .aar files into a subproject and adding your libs as artifacts:

configurations.create(""default"")
artifacts.add(""default"", file('somelib.jar'))
artifacts.add(""default"", file('someaar.aar'))


More info:
Handling-transitive-dependencies-for-local-artifacts-jars-and-aar
    Unfortunately none of the solutions here worked for me (I get unresolved dependencies). What finally worked and is the easiest way IMHO is: Highlight the project name from Android Studio then File -> New Module -> Import JAR or AAR Package. Credit goes to the solution in this post
    I tried all solution here but none is working, then I realise I made a mistake, I put the .aar in wrong folder, as you can see below, I thought I should put in root folder, so I created a libs folder there (1 in picture), but inside the app folder, there is already a libs, you should put in second libs, hope this help those who has same issue as mine:


    Just to simplify the answer

If .aar file is locally present then include
compile project(':project_directory') in dependencies of build.gradle of your project.

If .aar file present at remote then include
compile 'com.*********.sdk:project_directory:0.0.1@aar' in dependencies of build.gradle of your project.
    Currently referencing a local .aar file is not supported (as confirmed by Xavier Ducrochet)

What you can do instead is set up a local Maven repository (much more simple than it sounds) and reference the .aar from there.

I've written a blogpost detailing how to get it working here:

http://www.flexlabs.org/2013/06/using-local-aar-android-library-packages-in-gradle-builds
    In my case just work when i add ""project"" to compile:

repositories {
    mavenCentral()
    flatDir {
        dirs 'libs'
    }
}


dependencies {
   compile project('com.x.x:x:1.0.0')
}

    you can do something like this:


Put your local libraries (with extension: .jar, .aar, ...) into 'libs' Folder (or another if you want).
In build.gradle (app level), add this line into dependences

implementation fileTree(include: ['*.jar', '*.aar'], dir: 'libs')

    For me, this was an issue with how Android Studio environment was configured.
When I updated the File -> Project Structure -> JDK Location to a later Java version (jdk1.8.0_192.jdk - for me), everything started working.
    ","[485, 27, 30, 9, 15, 752, 269, 55, 72, 130, 21, 21, 12, 4, 2, 7, 4, 19, 3, 15, 3, 2, 20, -1, 0, 0]",429864,187,2013-05-22T03:09:25,2022-01-25 16:12:24Z,
wget/curl large file from google drive,"
                
I'm trying to download a file from google drive in a script, and I'm having a little trouble doing so. The files I'm trying to download are here.

I've looked online extensively and I finally managed to get one of them to download. I got the UIDs of the files and the smaller one (1.6MB) downloads fine, however the larger file (3.7GB) always redirects to a page which asks me whether I want to proceed with the download without a virus scan. Could someone help me get past that screen?

Here's how I got the first file working - 

curl -L ""https://docs.google.com/uc?export=download&id=0Bz-w5tutuZIYeDU0VDRFWG9IVUE"" > phlat-1.0.tar.gz


When I run the same on the other file, 

curl -L ""https://docs.google.com/uc?export=download&id=0Bz-w5tutuZIYY3h5YlMzTjhnbGM"" > index4phlat.tar.gz


I get the the following output -


I notice on the third-to-last line in the link, there a &confirm=JwkK which is a random 4 character string but suggests there's a way to add a confirmation to my URL. One of the links I visited suggested &confirm=no_antivirus but that's not working.

I hope someone here can help with this!
    November 2021
You can use gdown. Consider also visiting that page for full instructions; this is just a summary and the source repo may have more up-to-date instructions.

Instructions
Install it with the following command:
pip install gdown

After that, you can download any file from Google Drive by running one of these commands:
gdown https://drive.google.com/uc?id=<file_id>  # for files
gdown <file_id>                                 # alternative format
gdown --folder https://drive.google.com/drive/folders/<file_id>  # for folders
gdown --folder --id <file_id>                                   # this format works for folders too

Example: to download the readme file from this directory
gdown https://drive.google.com/uc?id=0B7EVK8r0v71pOXBhSUdJWU1MYUk

The file_id should look something like 0Bz8a_Dbh9QhbNU3SGlFaDg. You can find this ID by right-clicking on the file of interest, and selecting Get link. As of November 2021, this link will be of the form:
# Files
https://drive.google.com/file/d/<file_id>/view?usp=sharing
# Folders
https://drive.google.com/drive/folders/<file_id>

Caveats

Only works on open access files. (""Anyone who has a link can View"")
Cannot download more than 50 files into a single folder.

If you have access to the source file, you can consider using tar/zip to make it a single file to work around this limitation.



    April 2022

First, extract the ID of your desire file from google drive:

In your browser, navigate to drive.google.com.

Right-click on the file, and click ""Get a shareable link""


Then extract the ID of the file from URL:




Next, install gdown PyPI module using pip:
pip install gdown

Finally, download the file using gdown and the intended ID:
gdown --id <put-the-ID>



[NOTE]:

In google-colab you have to use ! before bash commands.
(i.e. !gdown --id 1-1wAx7b-USG0eQwIBVwVDUl3K1_1ReCt)
You should change the permission of the intended file from ""Restricted"" to ""Anyone with the link"".

    Here's a quick way to do this.
Make sure the link is shared, and it will look something like this:
https://drive.google.com/open?id=FILEID&authuser=0
Then, copy that FILEID and use it like this
wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=FILEID' -O FILENAME

If the file is large and triggers the virus check page, you can use do this (but it will download two files, one html file and the actual file):
wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=FILEID' -r -A 'uc*' -e robots=off -nd

    The easy way:
(if you just need it for a one-off download)

Go to the Google Drive webpage that has the download link
Open your browser console and go to the ""network"" tab
Click the download link
Wait for it the file to start downloading, and find the corresponding request (should be the last one in the list), then you can cancel the download
Right click on the request and click ""Copy as cURL"" (or similar)

You should end up with something like:
curl 'https://doc-0s-80-docs.googleusercontent.com/docs/securesc/aa51s66fhf9273i....................blah blah blah...............gEIqZ3KAQ==' --compressed

Past it in your console, add   > my-file-name.extension to the end (otherwise it will write the file into your console), then press enter :)
The link does have some kind of expiration in it, so it won't work to start a download after a few minutes of generating that first request.
    I wrote a Python snippet that downloads a file from Google Drive, given a shareable link. It works, as of August 2017.
The snipped does not use gdrive, nor the Google Drive API. It uses the requests module.
When downloading large files from Google Drive, a single GET request is not sufficient. A second one is needed, and this one has an extra URL parameter called confirm, whose value should equal the value of a certain cookie.
import requests

def download_file_from_google_drive(id, destination):
    def get_confirm_token(response):
        for key, value in response.cookies.items():
            if key.startswith('download_warning'):
                return value

        return None

    def save_response_content(response, destination):
        CHUNK_SIZE = 32768

        with open(destination, ""wb"") as f:
            for chunk in response.iter_content(CHUNK_SIZE):
                if chunk: # filter out keep-alive new chunks
                    f.write(chunk)

    URL = ""https://docs.google.com/uc?export=download""

    session = requests.Session()

    response = session.get(URL, params = { 'id' : id }, stream = True)
    token = get_confirm_token(response)

    if token:
        params = { 'id' : id, 'confirm' : token }
        response = session.get(URL, params = params, stream = True)

    save_response_content(response, destination)    


if __name__ == ""__main__"":
    import sys
    if len(sys.argv) is not 3:
        print(""Usage: python google_drive.py drive_file_id destination_file_path"")
    else:
        # TAKE ID FROM SHAREABLE LINK
        file_id = sys.argv[1]
        # DESTINATION FILE ON YOUR DISK
        destination = sys.argv[2]
        download_file_from_google_drive(file_id, destination)

    You can use the open source Linux / Unix command line tool gdrive.

To install it:


Download the binary. Choose the one that fits your architecture, for example gdrive-linux-x64.
Copy it to your path.

sudo cp gdrive-linux-x64 /usr/local/bin/gdrive;
sudo chmod a+x /usr/local/bin/gdrive;



To use it:


Determine the Google Drive file ID. For that, right-click the desired file in the Google Drive website and choose ""Get Link …"". It will return something like https://drive.google.com/open?id=0B7_OwkDsUIgFWXA1B2FPQfV5S8H. Obtain the string behind the ?id= and copy it to your clipboard. That's the file's ID.
Download the file. Of course, use your file's ID instead in the following command.

gdrive download 0B7_OwkDsUIgFWXA1B2FPQfV5S8H



At first usage, the tool will need to obtain access permissions to the Google Drive API. For that, it will show you a link which you have to visit in a browser, and then you will get a verification code to copy&paste back to the tool. The download then starts automatically. There is no progress indicator, but you can observe the progress in a file manager or second terminal.

Source: A comment by Tobi on another answer here.

 

Additional trick: rate limiting. To download with gdrive at a limited maximum rate (to not swamp the network …), you can use a command like this (pv is PipeViewer):

gdrive download --stdout 0B7_OwkDsUIgFWXA1B2FPQfV5S8H | \
  pv -br -L 90k | \
  cat > file.ext


This will show the amount of data downloaded (-b) and the rate of download (-r) and limit that rate to 90 kiB/s (-L 90k).
    Nov 2020
If you prefer using bash script, this worked for me:
(5Gb file, publicly available)
#!/bin/bash
if [ $# != 2 ]; then
echo ""Usage: googledown.sh ID save_name""
exit 0
fi
confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id='$1 -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\1\n/p')
echo $confirm
wget --load-cookies /tmp/cookies.txt ""https://docs.google.com/uc?export=download&confirm=$confirm&id=$1"" -O $2 && rm -rf /tmp/cookies.txt

    Update as of March 2018.

I tried various techniques given in other answers to download my file (6 GB) directly from Google drive to my AWS ec2 instance but none of them work (might be because they are old).

So, for the information of others, here is how I did it successfully:


Right-click on the file you want to download, click share, under link sharing section, select ""anyone with this link can edit"".
Copy the link. It should be in this format: https://drive.google.com/file/d/FILEIDENTIFIER/view?usp=sharing
Copy the FILEIDENTIFIER portion from the link.
Copy the below script to a file. It uses curl and processes the cookie to automate the downloading of the file.

#!/bin/bash
fileid=""FILEIDENTIFIER""
filename=""FILENAME""
curl -c ./cookie -s -L ""https://drive.google.com/uc?export=download&id=${fileid}"" > /dev/null
curl -Lb ./cookie ""https://drive.google.com/uc?export=download&confirm=`awk '/download/ {print $NF}' ./cookie`&id=${fileid}"" -o ${filename}

As shown above, paste the FILEIDENTIFIER in the script. Remember to keep the double quotes!
Provide a name for the file in place of FILENAME. Remember to keep the double quotes and also include the extension in FILENAME (for example, myfile.zip).
Now, save the file and make the file executable by running this command in terminal sudo chmod +x download-gdrive.sh.
Run the script using `./download-gdrive.sh"". 


PS: Here is the Github gist for the above given script: https://gist.github.com/amit-chahar/db49ce64f46367325293e4cce13d2424
    I have been using the curl snippet of @Amit Chahar who posted a good answer in this thread. I found it useful
to put it in a bash function rather than a separate .sh file
function curl_gdrive {

    GDRIVE_FILE_ID=$1
    DEST_PATH=$2

    curl -c ./cookie -s -L ""https://drive.google.com/uc?export=download&id=${GDRIVE_FILE_ID}"" > /dev/null
    curl -Lb ./cookie ""https://drive.google.com/uc?export=download&confirm=`awk '/download/ {print $NF}' ./cookie`&id=${GDRIVE_FILE_ID}"" -o ${DEST_PATH}
    rm -f cookie
}

that can be included in e.g a ~/.bashrc (after sourcing it ofcourse if not sourced automatically) and used in the following way
   $ curl_gdrive 153bpzybhfqDspyO_gdbcG5CMlI19ASba imagenet.tar

UPDATE 2022-03-01 - wget version that works also when virus scan is triggered
function wget_gdrive {

    GDRIVE_FILE_ID=$1
    DEST_PATH=$2

    wget --save-cookies cookies.txt 'https://docs.google.com/uc?export=download&id='$GDRIVE_FILE_ID -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\1/p' > confirm.txt
    wget --load-cookies cookies.txt -O $DEST_PATH 'https://docs.google.com/uc?export=download&id='$GDRIVE_FILE_ID'&confirm='$(<confirm.txt)
    rm -fr cookies.txt confirm.txt
}

sample usage:
    $ wget_gdrive 1gzp8zIDo888AwMXRTZ4uzKCMiwKynHYP foo.out

    --UPDATED--

To download the file first get youtube-dl for python from here:

youtube-dl: https://rg3.github.io/youtube-dl/download.html

or install it with pip:

sudo python2.7 -m pip install --upgrade youtube_dl 
# or 
# sudo python3.6 -m pip install --upgrade youtube_dl




UPDATE:

I just found out this:


Right click on the file you want to download from drive.google.com
Click Get Sharable link
Toggle On Link sharing on
Click on Sharing settings
Click on the top dropdown for options
Click on More
Select [x] On - Anyone with a link
Copy Link


https://drive.google.com/file/d/3PIY9dCoWRs-930HHvY-3-FOOPrIVoBAR/view?usp=sharing       
(This is not a real file address)


Copy the id after https://drive.google.com/file/d/:

3PIY9dCoWRs-930HHvY-3-FOOPrIVoBAR


Paste this into command line:

youtube-dl https://drive.google.com/open?id=


Paste the id behind open?id=

youtube-dl https://drive.google.com/open?id=3PIY9dCoWRs-930HHvY-3-FOOPrIVoBAR


[GoogleDrive] 3PIY9dCoWRs-930HHvY-3-FOOPrIVoBAR: Downloading webpage
[GoogleDrive] 3PIY9dCoWRs-930HHvY-3-FOOPrIVoBAR: Requesting source file
[download] Destination: your_requested_filename_here-3PIY9dCoWRs-930HHvY-3-FOOPrIVoBAR
[download] 240.37MiB at  2321.53MiB/s (00:01)


Hope it helps
    the easy way to down file from google drive you can also download file on colab   

pip install gdown

import gdown


Then

url = 'https://drive.google.com/uc?id=0B9P1L--7Wd2vU3VUVlFnbTgtS2c'
output = 'spam.txt'
gdown.download(url, output, quiet=False)


or

fileid='0B9P1L7Wd2vU3VUVlFnbTgtS2c'

gdown https://drive.google.com/uc?id=+fileid


Document https://pypi.org/project/gdown/
    I found a working solution to this... Simply use the following 

wget --load-cookies /tmp/cookies.txt ""https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1HlzTR1-YVoBPlXo0gMFJ_xY4ogMnfzDi' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\1\n/p')&id=1HlzTR1-YVoBPlXo0gMFJ_xY4ogMnfzDi"" -O besteyewear.zip && rm -rf /tmp/cookies.txt

    Based on the answer from Roshan Sethia

May 2018

Using WGET:


Create a shell script called wgetgdrive.sh as below:

#!/bin/bash

# Get files from Google Drive

# $1 = file ID
# $2 = file name

URL=""https://docs.google.com/uc?export=download&id=$1""

wget --load-cookies /tmp/cookies.txt ""https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate $URL -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\1\n/p')&id=$1"" -O $2 && rm -rf /tmp/cookies.txt

Give the right permissions to execute the script
In terminal, run:

./wgetgdrive.sh <file ID> <filename>


for example:

./wgetgdrive.sh 1lsDPURlTNzS62xEOAIG98gsaW6x2PYd2 images.zip


    ggID='put_googleID_here'  
ggURL='https://drive.google.com/uc?export=download'  
filename=""$(curl -sc /tmp/gcokie ""${ggURL}&id=${ggID}"" | grep -o '=""uc-name.*</span>' | sed 's/.*"">//;s/<.a> .*//')""  
getcode=""$(awk '/_warning_/ {print $NF}' /tmp/gcokie)""  
curl -Lb /tmp/gcokie ""${ggURL}&confirm=${getcode}&id=${ggID}"" -o ""${filename}""  


How does it work?
Get cookie file and html code with curl.
Pipe html to grep and sed and search for file name.
Get confirm code from cookie file with awk.
Finally download file with cookie enabled,  confirm code and filename.  

curl -Lb /tmp/gcokie ""https://drive.google.com/uc?export=download&confirm=Uq6r&id=0B5IRsLTwEO6CVXFURmpQZ1Jxc0U"" -o ""SomeBigFile.zip""




If you dont need filename variable curl can guess it
-L Follow redirects
-O Remote-name
-J Remote-header-name   

curl -sc /tmp/gcokie ""${ggURL}&id=${ggID}"" >/dev/null  
getcode=""$(awk '/_warning_/ {print $NF}' /tmp/gcokie)""  
curl -LOJb /tmp/gcokie ""${ggURL}&confirm=${getcode}&id=${ggID}"" 




To extract google file ID from URL you can use:  

echo ""gURL"" | egrep -o '(\w|-){26,}'  
# match more than 26 word characters  


OR  

echo ""gURL"" | sed 's/[^A-Za-z0-9_-]/\n/g' | sed -rn '/.{26}/p'  
# replace non-word characters with new line,   
# print only line with more than 26 word characters 

    All of the above responses seem to obscure the simplicity of the answer or have some nuances that are not explained.  

If the file is shared publicly, you can generate a direct download link by just knowing the file ID. The URL must be in the form "" https://drive.google.com/uc?id=[FILEID]&export=download"" This works as of 11-22-2019. This does not require the receiver to log in to google but does require the file to be shared publicly.  


In your browser, navigate to drive.google.com.
Right click on the file, and click ""Get a shareable link""





Open a new tab, select the address bar, and paste in the contents of your clipboard which will be the shareable link. You'll see the file displayed by Google's viewer. The ID is the number right before the ""View"" component of the URL: 





Edit the URL so it is in the following format, replacing ""[FILEID]"" with the ID of your shared file: 

https://drive.google.com/uc?id=[FILEID]&export=download
That's your direct download link. If you click on it in your browser the file will now be ""pushed"" to your browser, opening the download dialog, allowing you to save or open the file.  You can also use this link in your download scripts. 
So the equivalent curl command would be: 


curl -L ""https://drive.google.com/uc?id=AgOATNfjpovfFrft9QYa-P1IeF9e7GWcH&export=download"" > phlat-1.0.tar.gz

    The easiest way is:


Create download link and copy fileID 
Download with WGET: wget --load-cookies /tmp/cookies.txt ""https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=FILEID' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\1\n/p')&id=FILEID"" -O FILENAME && rm -rf /tmp/cookies.txt

    This works as of Nov 2017
https://gist.github.com/ppetraki/258ea8240041e19ab258a736781f06db

#!/bin/bash

SOURCE=""$1""
if [ ""${SOURCE}"" == """" ]; then
    echo ""Must specify a source url""
    exit 1
fi

DEST=""$2""
if [ ""${DEST}"" == """" ]; then
    echo ""Must specify a destination filename""
    exit 1
fi

FILEID=$(echo $SOURCE | rev | cut -d= -f1 | rev)
COOKIES=$(mktemp)

CODE=$(wget --save-cookies $COOKIES --keep-session-cookies --no-check-certificate ""https://docs.google.com/uc?export=download&id=${FILEID}"" -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/Code: \1\n/p')

# cleanup the code, format is 'Code: XXXX'
CODE=$(echo $CODE | rev | cut -d: -f1 | rev | xargs)

wget --load-cookies $COOKIES ""https://docs.google.com/uc?export=download&confirm=${CODE}&id=${FILEID}"" -O $DEST

rm -f $COOKIES

    There's an easier way.

Install cliget/CURLWGET from firefox/chrome extension. 

Download the file from browser. This creates a curl/wget link that remembers the cookies and headers used while downloading the file. Use this command from any shell to download
    Alternative Method, 2020
Works well for headless servers. I was trying to download a ~200GB private file but couldn't get any of the other methods, mentioned in this thread, to work.
Solution

(Skip this step if the file is already in your own google drive) Make a copy of the file you want to download from a Public/Shared Folder into your Google Drive account. Select File -> Right Click -> Make a copy



Install and setup Rclone, an open-source command line tool, to sync files between your local storage and Google Drive. Here's a quick tutorial to install and setup rclone for Google Drive.

Copy your file from Google Drive to your machine using Rclone


rclone copy mygoogledrive:path/to/file /path/to/file/on/local/machine -P

-P argument helps to track progress of the download and lets you know when its finished.
    The above answers are outdated for April 2020, since google drive now uses a redirect to the actual location of the file.

Working as of April 2020 on macOS 10.15.4 for public documents:

# this is used for drive directly downloads
function download-google(){
  echo ""https://drive.google.com/uc?export=download&id=$1""
  mkdir -p .tmp
  curl -c .tmp/$1cookies ""https://drive.google.com/uc?export=download&id=$1"" > .tmp/$1intermezzo.html;
  curl -L -b .tmp/$1cookies ""$(egrep -o ""https.+download"" .tmp/$1intermezzo.html)"" > $2;
}

# some files are shared using an indirect download
function download-google-2(){
  echo ""https://drive.google.com/uc?export=download&id=$1""
  mkdir -p .tmp
  curl -c .tmp/$1cookies ""https://drive.google.com/uc?export=download&id=$1"" > .tmp/$1intermezzo.html;
  code=$(egrep -o ""confirm=(.+)&amp;id="" .tmp/$1intermezzo.html | cut -d""="" -f2 | cut -d""&"" -f1)
  curl -L -b .tmp/$1cookies ""https://drive.google.com/uc?export=download&confirm=$code&id=$1"" > $2;
}

# used like this
download-google <id> <name of item.extension>

    I had the same problem with Google Drive.

Here's how I solved the problem using Links 2.


Open a browser on your PC, navigate to your file in Google Drive. Give your file a public link.
Copy the public link to your clipboard (eg right click, Copy link address)
Open a Terminal. If you're downloading to another PC/server/machine you should SSH to it as this point
Install Links 2 (debian/ubuntu method, use your distro or OS equivalent)

sudo apt-get install links2
Paste the link in to your terminal and open it with Links like so:

links2 ""paste url here""
Navigate to the download link within Links using your Arrow Keys and press Enter
Choose a filename and it'll download your file

    I was unable to get Nanoix's perl script to work, or other curl examples I had seen, so I started looking into the api myself in python.  This worked fine for small files, but large files choked past available ram so I found some other nice chunking code that uses the api's ability to partial download.  Gist here: 
https://gist.github.com/csik/c4c90987224150e4a0b2

Note the bit about downloading client_secret json file from the API interface to your local directory.

Source

$ cat gdrive_dl.py
from pydrive.auth import GoogleAuth  
from pydrive.drive import GoogleDrive    

""""""API calls to download a very large google drive file.  The drive API only allows downloading to ram 
   (unlike, say, the Requests library's streaming option) so the files has to be partially downloaded
   and chunked.  Authentication requires a google api key, and a local download of client_secrets.json
   Thanks to Radek for the key functions: http://stackoverflow.com/questions/27617258/memoryerror-how-to-download-large-file-via-google-drive-sdk-using-python
""""""

def partial(total_byte_len, part_size_limit):
    s = []
    for p in range(0, total_byte_len, part_size_limit):
        last = min(total_byte_len - 1, p + part_size_limit - 1)
        s.append([p, last])
    return s

def GD_download_file(service, file_id):
  drive_file = service.files().get(fileId=file_id).execute()
  download_url = drive_file.get('downloadUrl')
  total_size = int(drive_file.get('fileSize'))
  s = partial(total_size, 100000000) # I'm downloading BIG files, so 100M chunk size is fine for me
  title = drive_file.get('title')
  originalFilename = drive_file.get('originalFilename')
  filename = './' + originalFilename
  if download_url:
      with open(filename, 'wb') as file:
        print ""Bytes downloaded: ""
        for bytes in s:
          headers = {""Range"" : 'bytes=%s-%s' % (bytes[0], bytes[1])}
          resp, content = service._http.request(download_url, headers=headers)
          if resp.status == 206 :
                file.write(content)
                file.flush()
          else:
            print 'An error occurred: %s' % resp
            return None
          print str(bytes[1])+""...""
      return title, filename
  else:
    return None          


gauth = GoogleAuth()
gauth.CommandLineAuth() #requires cut and paste from a browser 

FILE_ID = 'SOMEID' #FileID is the simple file hash, like 0B1NzlxZ5RpdKS0NOS0x0Ym9kR0U

drive = GoogleDrive(gauth)
service = gauth.service
#file = drive.CreateFile({'id':FILE_ID})    # Use this to get file metadata
GD_download_file(service, FILE_ID) 

    JULY 2020 - Windows users batch file solution
I would like to add a simple batch file solution for windows users, as I found only linux solutions and it took me several days to learn all this stuff for creating a solution for windows. So to save this work from others that may need it, here it is.
Tools you need

wget for windows (small 5KB exe program, no need installation)
Download it from here.
https://eternallybored.org/misc/wget/

jrepl for windows (small 117KB batch file program, no need installation)
This tool is similar to linux sed tool.
Download it from here:
https://www.dostips.com/forum/viewtopic.php?t=6044


Assuming
%filename% - the file name you want the the download will be saved to.
%fileid%   = google file id (as already was explained here before)
Batch code for downloading small file from google drive
wget -O ""%filename%"" ""https://docs.google.com/uc?export=download&id=%fileid%""        

Batch code for downloading large file from google drive
set cookieFile=""cookie.txt""
set confirmFile=""confirm.txt""
   
REM downlaod cooky and message with request for confirmation
wget --quiet --save-cookies ""%cookieFile%"" --keep-session-cookies --no-check-certificate ""https://docs.google.com/uc?export=download&id=%fileid%"" -O ""%confirmFile%""
   
REM extract confirmation key from message saved in confirm file and keep in variable resVar
jrepl "".*confirm=([0-9A-Za-z_]+).*"" ""$1"" /F ""%confirmFile%"" /A /rtn resVar
   
REM when jrepl writes to variable, it adds carriage return (CR) (0x0D) and a line feed (LF) (0x0A), so remove these two last characters
set confirmKey=%resVar:~0,-2%
   
REM download the file using cookie and confirmation key
wget --load-cookies ""%cookieFile%"" -O ""%filename%"" ""https://docs.google.com/uc?export=download&id=%fileid%&confirm=%confirmKey%""
   
REM clear temporary files 
del %cookieFile%
del %confirmFile%

    After messing around with this garbage. I've found a way to download my sweet file by using chrome - developer tools.


At your google docs tab, Ctr+Shift+J (Setting --> Developer tools)
Switch to Network tabs
At your docs file, click ""Download"" --> Download as CSV, xlsx,....
It will show you the request in the ""Network"" console

Right click -> Copy -> Copy as Curl
Your Curl command will be like this, and add -o to create a exported file.

curl 'https://docs.google.com/spreadsheets/d/1Cjsryejgn29BDiInOrGZWvg/export?format=xlsx&id=1Cjsryejgn29BDiInOrGZWvg' -H 'authority: docs.google.com' -H 'upgrade-insecure-requests: 1' -H 'user-agent: Mozilla/5.0 (X..... -o server.xlsx



Solved!
    No answer proposes what works for me as of december 2016 (source):

curl -L https://drive.google.com/uc?id={FileID}


provided the Google Drive file has been shared with those having the link and {FileID} is the string behind ?id= in the shared URL.

Although I did not check with huge files, I believe it might be useful to know.
    Use youtube-dl!

youtube-dl https://drive.google.com/open?id=ABCDEFG1234567890


You can also pass --get-url to get a direct download URL.
    May 2018 WORKING

Hi based on this comments ... i create a bash to export a list of URL from file URLS.txt to a URLS_DECODED.txt
an used in some accelerator like flashget ( i use cygwin to combine windows & linux )

Command spider was introduced to avoid download and get the final link ( directly )

Command GREP HEAD and CUT, process and get the final link, Is based in spanish language, maybe you could be port to ENGLISH LANGUAGE

echo -e ""$URL_TO_DOWNLOAD\r"" probably the \r is only cywin and must be replace by a \n (break line)

**********user*********** is the user folder

*******Localización*********** is in spanish language, clear the asterics and let the word in english Location and adapt THE HEAD and the CUT numbers to appropiate approach.

rm -rf /home/**********user***********/URLS_DECODED.txt
COUNTER=0
while read p; do 
    string=$p
    hash=""${string#*id=}""
    hash=""${hash%&*}""
    hash=""${hash#*file/d/}""
    hash=""${hash%/*}""
    let COUNTER=COUNTER+1
    echo ""Enlace ""$COUNTER"" id=""$hash
    URL_TO_DOWNLOAD=$(wget --spider --load-cookies /tmp/cookies.txt ""https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id='$hash -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\1\n/p')&id=""$hash 2>&1 | grep *******Localización***********: | head -c-13 | cut -c16-)
    rm -rf /tmp/cookies.txt
    echo -e ""$URL_TO_DOWNLOAD\r"" >> /home/**********user***********/URLS_DECODED.txt
    echo ""Enlace ""$COUNTER"" URL=""$URL_TO_DOWNLOAD
done < /home/**********user***********/URLS.txt

    Here's a little bash script I wrote that does the job today. It works on large files and can resume partially fetched files too. It takes two arguments, the first is the file_id and the second is the name of the output file. The main improvements over previous answers here are that it works on large files and only needs commonly available tools: bash, curl, tr, grep, du, cut and mv.

#!/usr/bin/env bash
fileid=""$1""
destination=""$2""

# try to download the file
curl -c /tmp/cookie -L -o /tmp/probe.bin ""https://drive.google.com/uc?export=download&id=${fileid}""
probeSize=`du -b /tmp/probe.bin | cut -f1`

# did we get a virus message?
# this will be the first line we get when trying to retrive a large file
bigFileSig='<!DOCTYPE html><html><head><title>Google Drive - Virus scan warning</title><meta http-equiv=""content-type"" content=""text/html; charset=utf-8""/>'
sigSize=${#bigFileSig}

if (( probeSize <= sigSize )); then
  virusMessage=false
else
  firstBytes=$(head -c $sigSize /tmp/probe.bin)
  if [ ""$firstBytes"" = ""$bigFileSig"" ]; then
    virusMessage=true
  else
    virusMessage=false
  fi
fi

if [ ""$virusMessage"" = true ] ; then
  confirm=$(tr ';' '\n' </tmp/probe.bin | grep confirm)
  confirm=${confirm:8:4}
  curl -C - -b /tmp/cookie -L -o ""$destination"" ""https://drive.google.com/uc?export=download&id=${fileid}&confirm=${confirm}""
else
  mv /tmp/probe.bin ""$destination""
fi

    The default behavior of google drive is to scan files for viruses if the file is to big it will prompte the user and notifies him that the file could not be scanned. 

At the moment the only workaround I found is to share the file with the web and create a web resource. 

Quote from the google drive help page:

With Drive, you can make web resources — like HTML, CSS, and Javascript files — viewable as a website.

To host a webpage with Drive:


  
  Open Drive at drive.google.com and select a file.  
  Click the Share button at the top of the page.  
  Click Advanced in the bottom right corner of the sharing box.  
  Click Change....  
  Choose On - Public on the web and click Save.  
  Before closing the sharing box, copy the document ID from the URL in the field below ""Link to share"". The document ID is a string of uppercase and lowercase letters and numbers between slashes in the URL.  
  Share the URL that looks like ""www.googledrive.com/host/[doc id] where [doc id] is replaced by the document ID you copied in step 6.
  Anyone can now view your webpage.  
  


Found here: https://support.google.com/drive/answer/2881970?hl=en

So for example when you share a file on google drive publicly the sharelink looks like this:

https://drive.google.com/file/d/0B5IRsLTwEO6CVXFURmpQZ1Jxc0U/view?usp=sharing


Then you copy the file id and create a googledrive.com linke that look like this:

https://www.googledrive.com/host/0B5IRsLTwEO6CVXFURmpQZ1Jxc0U

    Here is workaround which I came up download files from Google Drive to my Google Cloud Linux shell.


Share the file to PUBLIC and with Edit permissions using advanced sharing.
You will get a sharing link which would have an ID. See the link:-
drive.google.com/file/d/[ID]/view?usp=sharing
Copy that ID and Paste it in the following link:-


googledrive.com/host/[ID]


The above link would be our download link.
Use wget to download the file:-


wget https://googledrive.com/host/[ID]


This command will download the file with name as [ID] with no extension and but with same file size on the same location where you ran the wget command.
Actually, I downloaded a zipped folder in my practice. so I renamed that awkward file using:-


mv [ID] 1.zip


then using 


unzip 1.zip

we will get the files.
    ","[485, 548, 72, 67, 50, 216, 76, 1, 58, 9, 11, 4, 4, 14, 57, 7, 9, 4, 3, 3, 8, 6, 4, 1, 3, 7, 5, 1, 3, 23, 2]",584963,190,2014-07-29T07:39:37,2022-04-18 10:42:15Z,
Easy way to write contents of a Java InputStream to an OutputStream,"
                
I was surprised to find today that I couldn't track down any simple way to write the contents of an InputStream to an OutputStream in Java. Obviously, the byte buffer code isn't difficult to write, but I suspect I'm just missing something which would make my life easier (and the code clearer).

So, given an InputStream in and an OutputStream out, is there a simpler way to write the following?

byte[] buffer = new byte[1024];
int len = in.read(buffer);
while (len != -1) {
    out.write(buffer, 0, len);
    len = in.read(buffer);
}

    Java 9

Since Java 9, InputStream provides a method called transferTo with the following signature:

public long transferTo(OutputStream out) throws IOException


As the documentation states, transferTo will:


  Reads all bytes from this input stream and writes the bytes to the
  given output stream in the order that they are read. On return, this
  input stream will be at end of stream. This method does not close
  either stream. 
  
  This method may block indefinitely reading from the
  input stream, or writing to the output stream. The behavior for the
  case where the input and/or output stream is asynchronously closed, or
  the thread interrupted during the transfer, is highly input and output
  stream specific, and therefore not specified


So in order to write contents of a Java InputStream to an OutputStream, you can write:

input.transferTo(output);

    If you are using Java 7, Files (in the standard library) is the best approach:

/* You can get Path from file also: file.toPath() */
Files.copy(InputStream in, Path target)
Files.copy(Path source, OutputStream out)


Edit: Of course it's just useful when you create one of InputStream or OutputStream from file. Use file.toPath() to get path from file.

To write into an existing file (e.g. one created with File.createTempFile()), you'll need to pass the REPLACE_EXISTING copy option (otherwise FileAlreadyExistsException is thrown):

Files.copy(in, target, StandardCopyOption.REPLACE_EXISTING)

    Simple Function

If you only need this for writing an InputStream to a File then you can use this simple function:

private void copyInputStreamToFile( InputStream in, File file ) {
    try {
        OutputStream out = new FileOutputStream(file);
        byte[] buf = new byte[1024];
        int len;
        while((len=in.read(buf))>0){
            out.write(buf,0,len);
        }
        out.close();
        in.close();
    } catch (Exception e) {
        e.printStackTrace();
    }
}

    I think this will work, but make sure to test it... minor ""improvement"", but it might be a bit of a cost at readability.

byte[] buffer = new byte[1024];
int len;
while ((len = in.read(buffer)) != -1) {
    out.write(buffer, 0, len);
}

    As WMR mentioned, org.apache.commons.io.IOUtils from Apache has a method called copy(InputStream,OutputStream) which does exactly what you're looking for.

So, you have:

InputStream in;
OutputStream out;
IOUtils.copy(in,out);
in.close();
out.close();


...in your code.

Is there a reason you're avoiding IOUtils? 
    For those who use Spring framework there is a useful StreamUtils class:

StreamUtils.copy(in, out);


The above does not close the streams. If you want the streams closed after the copy, use FileCopyUtils class instead:

FileCopyUtils.copy(in, out);

    I use BufferedInputStream and BufferedOutputStream to remove the buffering semantics from the code

try (OutputStream out = new BufferedOutputStream(...);
     InputStream in   = new BufferedInputStream(...))) {
  int ch;
  while ((ch = in.read()) != -1) {
    out.write(ch);
  }
}

    Here comes how I'm doing with a simplest for loop.
private void copy(final InputStream in, final OutputStream out)
    throws IOException {
    final byte[] b = new byte[8192];
    for (int r; (r = in.read(b)) != -1;) {
        out.write(b, 0, r);
    }
}

    Not very readable, but effective, has no dependencies and runs with any java version
byte[] buffer=new byte[1024];
for(int n; (n=inputStream.read(buffer))!=-1; outputStream.write(buffer,0,n));

    The JDK uses the same code so it seems like there is no ""easier"" way without clunky third party libraries (which probably don't do anything different anyway). The following is directly copied from java.nio.file.Files.java:

// buffer size used for reading and writing
private static final int BUFFER_SIZE = 8192;

/**
  * Reads all bytes from an input stream and writes them to an output stream.
  */
private static long copy(InputStream source, OutputStream sink) throws IOException {
    long nread = 0L;
    byte[] buf = new byte[BUFFER_SIZE];
    int n;
    while ((n = source.read(buf)) > 0) {
        sink.write(buf, 0, n);
        nread += n;
    }
    return nread;
}

    Using Java7 and try-with-resources, comes with a simplified and readable version.

try(InputStream inputStream = new FileInputStream(""C:\\mov.mp4"");
    OutputStream outputStream = new FileOutputStream(""D:\\mov.mp4"")) {

    byte[] buffer = new byte[10*1024];

    for (int length; (length = inputStream.read(buffer)) != -1; ) {
        outputStream.write(buffer, 0, length);
    }
} catch (FileNotFoundException exception) {
    exception.printStackTrace();
} catch (IOException ioException) {
    ioException.printStackTrace();
}

    Using Guava's ByteStreams.copy():

ByteStreams.copy(inputStream, outputStream);

    PipedInputStream and PipedOutputStream should only be used when you have multiple threads, as noted by the Javadoc.

Also, note that input streams and output streams do not wrap any thread interruptions with IOExceptions... So, you should consider incorporating an interruption policy to your code:

byte[] buffer = new byte[1024];
int len = in.read(buffer);
while (len != -1) {
    out.write(buffer, 0, len);
    len = in.read(buffer);
    if (Thread.interrupted()) {
        throw new InterruptedException();
    }
}


This would be an useful addition if you expect to use this API for copying large volumes of data, or data from streams that get stuck for an intolerably long time.
    This is my best shot!!

And do not use inputStream.transferTo(...) because is too generic.
Your code performance will be better if you control your buffer memory.

public static void transfer(InputStream in, OutputStream out, int buffer) throws IOException {
    byte[] read = new byte[buffer]; // Your buffer size.
    while (0 < (buffer = in.read(read)))
        out.write(read, 0, buffer);
}


I use it with this (improvable) method when I know in advance the size of the stream.

public static void transfer(int size, InputStream in, OutputStream out) throws IOException {
    transfer(in, out,
            size > 0xFFFF ? 0xFFFF // 16bits 65,536
                    : size > 0xFFF ? 0xFFF// 12bits 4096
                            : size < 0xFF ? 0xFF // 8bits 256
                                    : size
    );
}

    public static boolean copyFile(InputStream inputStream, OutputStream out) {
    byte buf[] = new byte[1024];
    int len;
    long startTime=System.currentTimeMillis();

    try {
        while ((len = inputStream.read(buf)) != -1) {
            out.write(buf, 0, len);
        }

        long endTime=System.currentTimeMillis()-startTime;
        Log.v("""",""Time taken to transfer all bytes is : ""+endTime);
        out.close();
        inputStream.close();

    } catch (IOException e) {

        return false;
    }
    return true;
}

    Try Cactoos:

new LengthOf(new TeeInput(input, output)).value();


More details here: http://www.yegor256.com/2017/06/22/object-oriented-input-output-in-cactoos.html
    A IMHO more minimal snippet (that also more narrowly scopes the length variable):

byte[] buffer = new byte[2048];
for (int n = in.read(buffer); n >= 0; n = in.read(buffer))
    out.write(buffer, 0, n);


As a side note, I don't understand why more people don't use a for loop, instead opting for a while with an assign-and-test expression that is regarded by some as ""poor"" style.
    Use Commons Net's Util class:

import org.apache.commons.net.io.Util;
...
Util.copyStream(in, out);

    you can use this method

public static void copyStream(InputStream is, OutputStream os)
 {
     final int buffer_size=1024;
     try
     {
         byte[] bytes=new byte[buffer_size];
         for(;;)
         {
           int count=is.read(bytes, 0, buffer_size);
           if(count==-1)
               break;
           os.write(bytes, 0, count);
         }
     }
     catch(Exception ex){}
 }

    There's no way to do this a lot easier with JDK methods, but as Apocalisp has already noted, you're not the only one with this idea: You could use IOUtils from Jakarta Commons IO, it also has a lot of other useful things, that IMO should actually be part of the JDK...
    I think it's better to use a large buffer, because most of the files are greater than 1024 bytes. Also it's a good practice to check the number of read bytes to be positive.

byte[] buffer = new byte[4096];
int n;
while ((n = in.read(buffer)) > 0) {
    out.write(buffer, 0, n);
}
out.close();

    PipedInputStream and PipedOutputStream may be of some use, as you can connect one to the other.
    Another possible candidate are the Guava I/O utilities:

http://code.google.com/p/guava-libraries/wiki/IOExplained

I thought I'd use these since Guava is already immensely useful in my project, rather than adding yet another library for one function.
    I used ByteStreamKt.copyTo(src, dst, buffer.length) method
Here is my code
public static void replaceCurrentDb(Context context, Uri newDbUri) {
    try {
        File currentDb = context.getDatabasePath(DATABASE_NAME);
        if (currentDb.exists()) {
            InputStream src = context.getContentResolver().openInputStream(newDbUri);
            FileOutputStream dst = new FileOutputStream(currentDb);
            final byte[] buffer = new byte[8 * 1024];
            ByteStreamsKt.copyTo(src, dst, buffer.length);
            src.close();
            dst.close();
            Toast.makeText(context, ""SUCCESS! Your selected file is set as current menu."", Toast.LENGTH_LONG).show();
        }
        else
            Log.e(""DOWNLOAD:::: Database"", "" fail, database not found"");
    }
    catch (IOException e) {
        Toast.makeText(context, ""Data Download FAIL."", Toast.LENGTH_LONG).show();
        Log.e(""DOWNLOAD FAIL!!!"", ""fail, reason:"", e);
    }
}

    ","[485, 225, 337, 31, 109, 408, 20, 4, 6, 2, 21, 7, 57, 18, 2, -1, -1, 3, 4, -6, 8, 2, 0, 0, 0]",471738,95,2008-09-04T03:46:16,2021-10-31 06:09:33Z,java 
Asynchronously wait for Task<T> to complete with timeout,"
                
I want to wait for a Task<T> to complete with some special rules:
If it hasn't completed after X milliseconds, I want to display a message to the user.
And if it hasn't completed after Y milliseconds, I want to automatically request cancellation.

I can use Task.ContinueWith to asynchronously wait for the task to complete (i.e. schedule an action to be executed when the task is complete), but that doesn't allow to specify a timeout.
I can use Task.Wait to synchronously wait for the task to complete with a timeout, but that blocks my thread.
How can I asynchronously wait for the task to complete with a timeout?
    How about this:

int timeout = 1000;
var task = SomeOperationAsync();
if (await Task.WhenAny(task, Task.Delay(timeout)) == task) {
    // task completed within timeout
} else { 
    // timeout logic
}


And here's a great blog post ""Crafting a Task.TimeoutAfter Method""  (from MS Parallel Library team) with more info on this sort of thing.

Addition: at the request of a comment on my answer, here is an expanded solution that includes cancellation handling. Note that passing cancellation to the task and the timer means that there are multiple ways cancellation can be experienced in your code, and you should be sure to test for and be confident you properly handle all of them. Don't leave to chance various combinations and hope your computer does the right thing at runtime.

int timeout = 1000;
var task = SomeOperationAsync(cancellationToken);
if (await Task.WhenAny(task, Task.Delay(timeout, cancellationToken)) == task)
{
    // Task completed within timeout.
    // Consider that the task may have faulted or been canceled.
    // We re-await the task so that any exceptions/cancellation is rethrown.
    await task;

}
else
{
    // timeout/cancellation logic
}

    Here's a extension method version that incorporates cancellation of the timeout when the original task completes as suggested by Andrew Arnott in a comment to his answer. 

public static async Task<TResult> TimeoutAfter<TResult>(this Task<TResult> task, TimeSpan timeout) {

    using (var timeoutCancellationTokenSource = new CancellationTokenSource()) {

        var completedTask = await Task.WhenAny(task, Task.Delay(timeout, timeoutCancellationTokenSource.Token));
        if (completedTask == task) {
            timeoutCancellationTokenSource.Cancel();
            return await task;  // Very important in order to propagate exceptions
        } else {
            throw new TimeoutException(""The operation has timed out."");
        }
    }
}

    From .Net 6 (Preview 7) or later, there is a new build-in method Task.WaitAsync to achieve this.
// Using TimeSpan
await myTask.WaitAsync(TimeSpan.FromSeconds(10));

// Using CancellationToken
await myTask.WaitAsync(cancellationToken);

// Using both TimeSpan and CancellationToken
await myTask.WaitAsync(TimeSpan.FromSeconds(10), cancellationToken);

    Using Stephen Cleary's excellent AsyncEx library, you can do:

TimeSpan timeout = TimeSpan.FromSeconds(10);

using (var cts = new CancellationTokenSource(timeout))
{
    await myTask.WaitAsync(cts.Token);
}


TaskCanceledException will be thrown in the event of a timeout.
    You can use Task.WaitAny to wait the first of multiple tasks.

You could create two additional tasks (that complete after the specified timeouts) and then use WaitAny to wait for whichever completes first. If the task that completed first is your ""work"" task, then you're done. If the task that completed first is a timeout task, then you can react to the timeout (e.g. request cancellation).
    With .Net 6 (preview 7 as the date of this answer), it is possible to use the new WaitAsync(TimeSpan, CancellationToken) which answers to this particular need.
If you can use .Net6, this version is moreover described to be optimized if we compare to the majority of good solutions proposed in this posts.
(Thanks for all participants because I used your solution for years)
    This is a slightly enhanced version of previous answers.


In addition to Lawrence's answer, it cancels the original task when timeout occurs.
In addtion to sjb's answer variants 2 and 3, you can provide CancellationToken for the original task, and when timeout occurs, you get TimeoutException instead of OperationCanceledException.


async Task<TResult> CancelAfterAsync<TResult>(
    Func<CancellationToken, Task<TResult>> startTask,
    TimeSpan timeout, CancellationToken cancellationToken)
{
    using (var timeoutCancellation = new CancellationTokenSource())
    using (var combinedCancellation = CancellationTokenSource
        .CreateLinkedTokenSource(cancellationToken, timeoutCancellation.Token))
    {
        var originalTask = startTask(combinedCancellation.Token);
        var delayTask = Task.Delay(timeout, timeoutCancellation.Token);
        var completedTask = await Task.WhenAny(originalTask, delayTask);
        // Cancel timeout to stop either task:
        // - Either the original task completed, so we need to cancel the delay task.
        // - Or the timeout expired, so we need to cancel the original task.
        // Canceling will not affect a task, that is already completed.
        timeoutCancellation.Cancel();
        if (completedTask == originalTask)
        {
            // original task completed
            return await originalTask;
        }
        else
        {
            // timeout
            throw new TimeoutException();
        }
    }
}




Usage

InnerCallAsync may take a long time to complete. CallAsync wraps it with a timeout.

async Task<int> CallAsync(CancellationToken cancellationToken)
{
    var timeout = TimeSpan.FromMinutes(1);
    int result = await CancelAfterAsync(ct => InnerCallAsync(ct), timeout,
        cancellationToken);
    return result;
}

async Task<int> InnerCallAsync(CancellationToken cancellationToken)
{
    return 42;
}

    Here is a fully worked example based on the top voted answer, which is:

int timeout = 1000;
var task = SomeOperationAsync();
if (await Task.WhenAny(task, Task.Delay(timeout)) == task) {
    // task completed within timeout
} else { 
    // timeout logic
}


The main advantage of the implementation in this answer is that generics have been added, so the function (or task) can return a value. This means that any existing function can be wrapped in a timeout function, e.g.:

Before: 

int x = MyFunc();


After:

// Throws a TimeoutException if MyFunc takes more than 1 second
int x = TimeoutAfter(MyFunc, TimeSpan.FromSeconds(1));


This code requires .NET 4.5.

using System;
using System.Threading;
using System.Threading.Tasks;

namespace TaskTimeout
{
    public static class Program
    {
        /// <summary>
        ///     Demo of how to wrap any function in a timeout.
        /// </summary>
        private static void Main(string[] args)
        {

            // Version without timeout.
            int a = MyFunc();
            Console.Write(""Result: {0}\n"", a);
            // Version with timeout.
            int b = TimeoutAfter(() => { return MyFunc(); },TimeSpan.FromSeconds(1));
            Console.Write(""Result: {0}\n"", b);
            // Version with timeout (short version that uses method groups). 
            int c = TimeoutAfter(MyFunc, TimeSpan.FromSeconds(1));
            Console.Write(""Result: {0}\n"", c);

            // Version that lets you see what happens when a timeout occurs.
            try
            {               
                int d = TimeoutAfter(
                    () =>
                    {
                        Thread.Sleep(TimeSpan.FromSeconds(123));
                        return 42;
                    },
                    TimeSpan.FromSeconds(1));
                Console.Write(""Result: {0}\n"", d);
            }
            catch (TimeoutException e)
            {
                Console.Write(""Exception: {0}\n"", e.Message);
            }

            // Version that works on tasks.
            var task = Task.Run(() =>
            {
                Thread.Sleep(TimeSpan.FromSeconds(1));
                return 42;
            });

            // To use async/await, add ""await"" and remove ""GetAwaiter().GetResult()"".
            var result = task.TimeoutAfterAsync(TimeSpan.FromSeconds(2)).
                           GetAwaiter().GetResult();

            Console.Write(""Result: {0}\n"", result);

            Console.Write(""[any key to exit]"");
            Console.ReadKey();
        }

        public static int MyFunc()
        {
            return 42;
        }

        public static TResult TimeoutAfter<TResult>(
            this Func<TResult> func, TimeSpan timeout)
        {
            var task = Task.Run(func);
            return TimeoutAfterAsync(task, timeout).GetAwaiter().GetResult();
        }

        private static async Task<TResult> TimeoutAfterAsync<TResult>(
            this Task<TResult> task, TimeSpan timeout)
        {
            var result = await Task.WhenAny(task, Task.Delay(timeout));
            if (result == task)
            {
                // Task completed within timeout.
                return task.GetAwaiter().GetResult();
            }
            else
            {
                // Task timed out.
                throw new TimeoutException();
            }
        }
    }
}


Caveats

Having given this answer, its generally not a good practice to have exceptions thrown in your code during normal operation, unless you absolutely have to: 


Each time an exception is thrown, its an extremely heavyweight operation, 
Exceptions can slow your code down by a factor of 100 or more if the exceptions are in a tight loop.


Only use this code if you absolutely cannot alter the function you are calling so it times out after a specific TimeSpan.

This answer is really only applicable when dealing with 3rd party library libraries that you simply cannot refactor to include a timeout parameter.

How to write robust code

If you want to write robust code, the general rule is this:


  Every single operation that could potentially block indefinitely, must have a timeout.


If you do not observe this rule, your code will eventually hit an operation that fails for some reason, then it will block indefinitely, and your app has just permanently hung. 

If there was a reasonable timeout after some time, then your app would hang for some extreme amount of time (e.g. 30 seconds) then it would either display an error and continue on its merry way, or retry.
    For the fun of it I made a 'OnTimeout' extension to Task. On timeout Task executes the desired inline lambda Action() and returns true, otherwise false.
public static async Task<bool> OnTimeout<T>(this T t, Action<T> action, int waitms) where T : Task
{
    if (!(await Task.WhenAny(t, Task.Delay(waitms)) == t))
    {
        action(t);
        return true;
    } else {
        return false;
    }
}

The OnTimeout extension returns a bool result that can be assigned to a variable like in this example calling an UDP socket Async:
var t = UdpSocket.ReceiveAsync();

var timeout = await t.OnTimeout(task => {
    Console.WriteLine(""No Response"");
}, 5000);

The 'task' variable is accessible in the timeout lambda for more processing.
The use of Action receiving an object may inspire to various other extension designs.
    Use a Timer to handle the message and automatic cancellation.  When the Task completes, call Dispose on the timers so that they will never fire.  Here is an example; change taskDelay to 500, 1500, or 2500 to see the different cases: 

using System;
using System.Threading;
using System.Threading.Tasks;

namespace ConsoleApplication1
{
    class Program
    {
        private static Task CreateTaskWithTimeout(
            int xDelay, int yDelay, int taskDelay)
        {
            var cts = new CancellationTokenSource();
            var token = cts.Token;
            var task = Task.Factory.StartNew(() =>
            {
                // Do some work, but fail if cancellation was requested
                token.WaitHandle.WaitOne(taskDelay);
                token.ThrowIfCancellationRequested();
                Console.WriteLine(""Task complete"");
            });
            var messageTimer = new Timer(state =>
            {
                // Display message at first timeout
                Console.WriteLine(""X milliseconds elapsed"");
            }, null, xDelay, -1);
            var cancelTimer = new Timer(state =>
            {
                // Display message and cancel task at second timeout
                Console.WriteLine(""Y milliseconds elapsed"");
                cts.Cancel();
            }
                , null, yDelay, -1);
            task.ContinueWith(t =>
            {
                // Dispose the timers when the task completes
                // This will prevent the message from being displayed
                // if the task completes before the timeout
                messageTimer.Dispose();
                cancelTimer.Dispose();
            });
            return task;
        }

        static void Main(string[] args)
        {
            var task = CreateTaskWithTimeout(1000, 2000, 2500);
            // The task has been started and will display a message after
            // one timeout and then cancel itself after the second
            // You can add continuations to the task
            // or wait for the result as needed
            try
            {
                task.Wait();
                Console.WriteLine(""Done waiting for task"");
            }
            catch (AggregateException ex)
            {
                Console.WriteLine(""Error waiting for task:"");
                foreach (var e in ex.InnerExceptions)
                {
                    Console.WriteLine(e);
                }
            }
        }
    }
}




Also, the Async CTP provides a TaskEx.Delay method that will wrap the timers in tasks for you.  This can give you more control to do things like set the TaskScheduler for the continuation when the Timer fires.  

private static Task CreateTaskWithTimeout(
    int xDelay, int yDelay, int taskDelay)
{
    var cts = new CancellationTokenSource();
    var token = cts.Token;
    var task = Task.Factory.StartNew(() =>
    {
        // Do some work, but fail if cancellation was requested
        token.WaitHandle.WaitOne(taskDelay);
        token.ThrowIfCancellationRequested();
        Console.WriteLine(""Task complete"");
    });

    var timerCts = new CancellationTokenSource();

    var messageTask = TaskEx.Delay(xDelay, timerCts.Token);
    messageTask.ContinueWith(t =>
    {
        // Display message at first timeout
        Console.WriteLine(""X milliseconds elapsed"");
    }, TaskContinuationOptions.OnlyOnRanToCompletion);

    var cancelTask = TaskEx.Delay(yDelay, timerCts.Token);
    cancelTask.ContinueWith(t =>
    {
        // Display message and cancel task at second timeout
        Console.WriteLine(""Y milliseconds elapsed"");
        cts.Cancel();
    }, TaskContinuationOptions.OnlyOnRanToCompletion);

    task.ContinueWith(t =>
    {
        timerCts.Cancel();
    });

    return task;
}

    Create a extension to wait for the task or a delay to complete, whichever comes first. Throw an exception if the delay wins.
public static async Task<TResult> WithTimeout<TResult>(this Task<TResult> task, TimeSpan timeout)
{
    if (await Task.WhenAny(task, Task.Delay(timeout)) != task)
        throw new TimeoutException();
    return await task;
}

    I felt the Task.Delay() task and CancellationTokenSource in the other answers a bit much for my use case in a tight-ish networking loop.

And although Joe Hoag's Crafting a Task.TimeoutAfter Method on MSDN blogs was inspiring, I was a little weary of using TimeoutException for flow control for the same reason as above, because timeouts are expected more frequently than not.

So I went with this, which also handles the optimizations mentioned in the blog:

public static async Task<bool> BeforeTimeout(this Task task, int millisecondsTimeout)
{
    if (task.IsCompleted) return true;
    if (millisecondsTimeout == 0) return false;

    if (millisecondsTimeout == Timeout.Infinite)
    {
        await Task.WhenAll(task);
        return true;
    }

    var tcs = new TaskCompletionSource<object>();

    using (var timer = new Timer(state => ((TaskCompletionSource<object>)state).TrySetCanceled(), tcs,
        millisecondsTimeout, Timeout.Infinite))
    {
        return await Task.WhenAny(task, tcs.Task) == task;
    }
}


An example use case is as such:

var receivingTask = conn.ReceiveAsync(ct);

while (!await receivingTask.BeforeTimeout(keepAliveMilliseconds))
{
    // Send keep-alive
}

// Read and do something with data
var data = await receivingTask;

    A generic version of @Kevan's answer above, using Reactive Extensions.

public static Task<T> TimeoutAfter<T>(this Task<T> task, TimeSpan timeout, IScheduler scheduler)
{
    return task.ToObservable().Timeout(timeout, scheduler).ToTask();
}


With optional Scheduler:

public static Task<T> TimeoutAfter<T>(this Task<T> task, TimeSpan timeout, Scheduler scheduler = null)
{
    return scheduler is null 
       ? task.ToObservable().Timeout(timeout).ToTask() 
       : task.ToObservable().Timeout(timeout, scheduler).ToTask();
}


BTW: When a Timeout happens, a timeout exception will be thrown
    A few variants of Andrew Arnott's answer: 


If you want to wait for an existing task and find out whether it completed or timed out, but don't want to cancel it if the timeout occurs:

public static async Task<bool> TimedOutAsync(this Task task, int timeoutMilliseconds)
{
    if (timeoutMilliseconds < 0 || (timeoutMilliseconds > 0 && timeoutMilliseconds < 100)) { throw new ArgumentOutOfRangeException(); }

    if (timeoutMilliseconds == 0) {
        return !task.IsCompleted; // timed out if not completed
    }
    var cts = new CancellationTokenSource();
    if (await Task.WhenAny( task, Task.Delay(timeoutMilliseconds, cts.Token)) == task) {
        cts.Cancel(); // task completed, get rid of timer
        await task; // test for exceptions or task cancellation
        return false; // did not timeout
    } else {
        return true; // did timeout
    }
}

If you want to start a work task and cancel the work if the timeout occurs: 

public static async Task<T> CancelAfterAsync<T>( this Func<CancellationToken,Task<T>> actionAsync, int timeoutMilliseconds)
{
    if (timeoutMilliseconds < 0 || (timeoutMilliseconds > 0 && timeoutMilliseconds < 100)) { throw new ArgumentOutOfRangeException(); }

    var taskCts = new CancellationTokenSource();
    var timerCts = new CancellationTokenSource();
    Task<T> task = actionAsync(taskCts.Token);
    if (await Task.WhenAny(task, Task.Delay(timeoutMilliseconds, timerCts.Token)) == task) {
        timerCts.Cancel(); // task completed, get rid of timer
    } else {
        taskCts.Cancel(); // timer completed, get rid of task
    }
    return await task; // test for exceptions or task cancellation
}

If you have a task already created that you want to cancel if a timeout occurs: 

public static async Task<T> CancelAfterAsync<T>(this Task<T> task, int timeoutMilliseconds, CancellationTokenSource taskCts)
{
    if (timeoutMilliseconds < 0 || (timeoutMilliseconds > 0 && timeoutMilliseconds < 100)) { throw new ArgumentOutOfRangeException(); }

    var timerCts = new CancellationTokenSource();
    if (await Task.WhenAny(task, Task.Delay(timeoutMilliseconds, timerCts.Token)) == task) {
        timerCts.Cancel(); // task completed, get rid of timer
    } else {
        taskCts.Cancel(); // timer completed, get rid of task
    }
    return await task; // test for exceptions or task cancellation
}



Another comment, these versions will cancel the timer if the timeout does not occur, so multiple calls will not cause timers to pile up. 

sjb
    I'm recombinging the ideas of some other answers here and this answer on another thread into a Try-style extension method. This has a benefit if you want an extension method, yet avoiding an exception upon timeout.

public static async Task<bool> TryWithTimeoutAfter<TResult>(this Task<TResult> task,
    TimeSpan timeout, Action<TResult> successor)
{

    using var timeoutCancellationTokenSource = new CancellationTokenSource();
    var completedTask = await Task.WhenAny(task, Task.Delay(timeout, timeoutCancellationTokenSource.Token))
                                  .ConfigureAwait(continueOnCapturedContext: false);

    if (completedTask == task)
    {
        timeoutCancellationTokenSource.Cancel();

        // propagate exception rather than AggregateException, if calling task.Result.
        var result = await task.ConfigureAwait(continueOnCapturedContext: false);
        successor(result);
        return true;
    }
    else return false;        
}     

async Task Example(Task<string> task)
{
    string result = null;
    if (await task.TryWithTimeoutAfter(TimeSpan.FromSeconds(1), r => result = r))
    {
        Console.WriteLine(result);
    }
}    

    Another way of solving this problem is using Reactive Extensions:

public static Task TimeoutAfter(this Task task, TimeSpan timeout, IScheduler scheduler)
{
        return task.ToObservable().Timeout(timeout, scheduler).ToTask();
}


Test up above using below code in your unit test, it works for me

TestScheduler scheduler = new TestScheduler();
Task task = Task.Run(() =>
                {
                    int i = 0;
                    while (i < 5)
                    {
                        Console.WriteLine(i);
                        i++;
                        Thread.Sleep(1000);
                    }
                })
                .TimeoutAfter(TimeSpan.FromSeconds(5), scheduler)
                .ContinueWith(t => { }, TaskContinuationOptions.OnlyOnFaulted);

scheduler.AdvanceBy(TimeSpan.FromSeconds(6).Ticks);


You may need the following namespace:

using System.Threading.Tasks;
using System.Reactive.Subjects;
using System.Reactive.Linq;
using System.Reactive.Threading.Tasks;
using Microsoft.Reactive.Testing;
using System.Threading;
using System.Reactive.Concurrency;

    If you use a BlockingCollection to schedule the task, the producer can run the potentially long running task and the consumer can use the TryTake method which has timeout and cancellation token built in.
    So this is ancient, but there's a much better modern solution. Not sure what version of c#/.NET is required, but this is how I do it:

... Other method code not relevant to the question.

// a token source that will timeout at the specified interval, or if cancelled outside of this scope
using var timeoutTokenSource = new CancellationTokenSource(TimeSpan.FromSeconds(5));
using var linkedTokenSource = CancellationTokenSource.CreateLinkedTokenSource(token, timeoutTokenSource.Token);

async Task<MessageResource> FetchAsync()
{
    try
    {
        return await MessageResource.FetchAsync(m.Sid);
    } catch (TaskCanceledException e)
    {
        if (timeoutTokenSource.IsCancellationRequested)
            throw new TimeoutException(""Timeout"", e);
        throw;
    }
}

return await Task.Run(FetchAsync, linkedTokenSource.Token);

the CancellationTokenSource constructor takes a TimeSpan parameter which will cause that token to cancel after that interval has elapsed. You can then wrap your async (or syncronous, for that matter) code in another call to Task.Run, passing the timeout token.
This assumes you're passing in a cancellation token (the token variable). If you don't have a need to cancel the task separately from the timeout, you can just use timeoutTokenSource directly. Otherwise, you create linkedTokenSource, which will cancel if the timeout ocurrs, or if it's otherwise cancelled.
We then just catch OperationCancelledException and check which token threw the exception, and throw a TimeoutException if a timeout caused this to raise. Otherwise, we rethrow.
Also, I'm using local functions here, which were introduced in C# 7, but you could easily use lambda or actual functions to the same affect. Similarly, c# 8 introduced a simpler syntax for using statements, but those are easy enough to rewrite.
    What about something like this?

    const int x = 3000;
    const int y = 1000;

    static void Main(string[] args)
    {
        // Your scheduler
        TaskScheduler scheduler = TaskScheduler.Default;

        Task nonblockingTask = new Task(() =>
            {
                CancellationTokenSource source = new CancellationTokenSource();

                Task t1 = new Task(() =>
                    {
                        while (true)
                        {
                            // Do something
                            if (source.IsCancellationRequested)
                                break;
                        }
                    }, source.Token);

                t1.Start(scheduler);

                // Wait for task 1
                bool firstTimeout = t1.Wait(x);

                if (!firstTimeout)
                {
                    // If it hasn't finished at first timeout display message
                    Console.WriteLine(""Message to user: the operation hasn't completed yet."");

                    bool secondTimeout = t1.Wait(y);

                    if (!secondTimeout)
                    {
                        source.Cancel();
                        Console.WriteLine(""Operation stopped!"");
                    }
                }
            });

        nonblockingTask.Start();
        Console.WriteLine(""Do whatever you want..."");
        Console.ReadLine();
    }


You can use the Task.Wait option without blocking main thread using another Task.
    Here is a low level implementation of a WaitAsync method that accepts both a timeout and a CancellationToken, and in case of an exception propagates all the errors of the Task<T>, instead of just the first error:
public static Task<TResult> WaitAsync<TResult>(this Task<TResult> task,
    TimeSpan timeout, CancellationToken cancellationToken = default)
{
    if (task == null) throw new ArgumentNullException(nameof(task));
    if (timeout < TimeSpan.Zero && timeout != Timeout.InfiniteTimeSpan)
        throw new ArgumentOutOfRangeException(nameof(timeout));

    var cts = CancellationTokenSource.CreateLinkedTokenSource(cancellationToken);
    cts.CancelAfter(timeout);

    return task
        .ContinueWith(_ => { }, cts.Token,
            TaskContinuationOptions.ExecuteSynchronously, TaskScheduler.Default)
        .ContinueWith(continuation =>
        {
            cts.Dispose();
            if (task.IsCompleted) return task;
            cancellationToken.ThrowIfCancellationRequested();
            if (continuation.IsCanceled) throw new TimeoutException();
            return task;
        }, TaskScheduler.Default).Unwrap();
}

A TimeoutException is thrown if the timeout elapses before the completion of the task.
Honestly propagating all the errors is not really a value-adding feature in this case. The reason is that if you use the WaitAsync like this: await someTask.WaitAsync(timeout), any extra errors will be swallowed by the await operator anyway, which by design propagates only the first exception of the awaited task. And there is not much point in storing the WaitAsync task in a variable and examining it inside the catch block, because you already have the someTask available, and you could examine this instead.
    ","[485, 686, 294, 15, 21, 51, 5, 25, 16, 1, 9, 1, 1, 5, 1, 0, 6, 0, 1, 17, 0]",303195,150,2010-11-21T14:29:16,2021-10-21 10:11:39Z,c 
NSOperation vs Grand Central Dispatch,"
                
I'm learning about concurrent programming for iOS. So far I've read about NSOperation/NSOperationQueue and GCD. What are the reasons for using NSOperationQueue over GCD and vice versa?

Sounds like both GCD and NSOperationQueue abstract away the explicit creation of NSThreads from the user. However the relationship between the two approaches isn't clear to me so any feedback to appreciated!
    GCD is a low-level C-based API.
NSOperation and NSOperationQueue are Objective-C classes.
NSOperationQueue is objective C wrapper over GCD.
If you are using NSOperation, then you are implicitly using Grand Central Dispatch.

GCD advantage over NSOperation:
i. implementation
For GCD implementation is very light-weight
NSOperationQueue is complex and heavy-weight

NSOperation advantages over GCD:

i. Control On Operation
you can Pause, Cancel, Resume an NSOperation

ii. Dependencies
you can set up a dependency between two NSOperations
operation will not started until all of its dependencies return true for finished.

iii. State of Operation
can monitor the state of an operation or operation queue.
ready ,executing or finished

iv. Max Number of Operation
you can specify the maximum number of queued operations that can run simultaneously

When to Go for GCD or NSOperation
when you want more control over queue (all above mentioned) use NSOperation 
and for simple cases where you want less overhead 
(you just want to do some work ""into the background"" with very little additional work) use GCD

ref:
https://cocoacasts.com/choosing-between-nsoperation-and-grand-central-dispatch/
http://iosinfopot.blogspot.in/2015/08/nsthread-vs-gcd-vs-nsoperationqueue.html
http://nshipster.com/nsoperation/
    GCD is a low-level C-based API that enables very simple use of a task-based concurrency model. NSOperation and NSOperationQueue are Objective-C classes that do a similar thing. NSOperation was introduced first, but as of 10.5 and iOS 2, NSOperationQueue and friends are internally implemented using GCD.

In general, you should use the highest level of abstraction that suits your needs. This means that you should usually use NSOperationQueue instead of GCD, unless you need to do something that NSOperationQueue doesn't support.

Note that NSOperationQueue isn't a ""dumbed-down"" version of GCD; in fact, there are many things that you can do very simply with NSOperationQueue that take a lot of work with pure GCD. (Examples: bandwidth-constrained queues that only run N operations at a time;  establishing dependencies between operations. Both very simple with NSOperation, very difficult with GCD.) Apple's done the hard work of leveraging GCD to create a very nice object-friendly API with NSOperation. Take advantage of their work unless you have a reason not to.

Caveat:
On the other hand, if you really just need to send off a block, and don't need any of the additional functionality that NSOperationQueue provides, there's nothing wrong with using GCD. Just be sure it's the right tool for the job.
    In line with my answer to a related question, I'm going to disagree with BJ and suggest you first look at GCD over NSOperation / NSOperationQueue, unless the latter provides something you need that GCD doesn't.

Before GCD, I used a lot of NSOperations / NSOperationQueues within my applications for managing concurrency. However, since I started using GCD on a regular basis, I've almost entirely replaced NSOperations and NSOperationQueues with blocks and dispatch queues. This has come from how I've used both technologies in practice, and from the profiling I've performed on them.

First, there is a nontrivial amount of overhead when using NSOperations and NSOperationQueues. These are Cocoa objects, and they need to be allocated and deallocated. In an iOS application that I wrote which renders a 3-D scene at 60 FPS, I was using NSOperations to encapsulate each rendered frame. When I profiled this, the creation and teardown of these NSOperations was accounting for a significant portion of the CPU cycles in the running application, and was slowing things down. I replaced these with simple blocks and a GCD serial queue, and that overhead disappeared, leading to noticeably better rendering performance. This wasn't the only place where I noticed overhead from using NSOperations, and I've seen this on both Mac and iOS.

Second, there's an elegance to block-based dispatch code that is hard to match when using NSOperations. It's so incredibly convenient to wrap a few lines of code in a block and dispatch it to be performed on a serial or concurrent queue, where creating a custom NSOperation or NSInvocationOperation to do this requires a lot more supporting code. I know that you can use an NSBlockOperation, but you might as well be dispatching something to GCD then. Wrapping this code in blocks inline with related processing in your application leads in my opinion to better code organization than having separate methods or custom NSOperations which encapsulate these tasks.

NSOperations and NSOperationQueues still have very good uses. GCD has no real concept of dependencies, where NSOperationQueues can set up pretty complex dependency graphs. I use NSOperationQueues for this in a handful of cases.

Overall, while I usually advocate for using the highest level of abstraction that accomplishes the task, this is one case where I argue for the lower-level API of GCD. Among the iOS and Mac developers I've talked with about this, the vast majority choose to use GCD over NSOperations unless they are targeting OS versions without support for it (those before iOS 4.0 and Snow Leopard).
    GCD is very easy to use - if you want to do something in the background, all you need to do is write the code and dispatch it on a background queue. Doing the same thing with NSOperation is a lot of additional work. 

The advantage of NSOperation is that (a) you have a real object that you can send messages to, and (b) that you can cancel an NSOperation. That's not trivial. You need to subclass NSOperation, you have to write your code correctly so that cancellation and correctly finishing a task both work correctly. So for simple things you use GCD, and for more complicated things you create a subclass of NSOperation. (There are subclasses NSInvocationOperation and NSBlockOperation, but everything they do is easier done with GCD, so there is no good reason to use them). 
    Both NSQueueOperations and GCD allow executing heavy computation task in the background on separate threads by freeing the UI Application Main Tread.

Well, based previous post we see NSOperations has addDependency so that you can queue your operation one after another sequentially. 

But I also read about GCD serial Queues you can create run your operations in the queue using dispatch_queue_create. This will allow running a set of operations one after another in a sequential manner.

NSQueueOperation Advantages over GCD:


It allows to add dependency and allows you to remove dependency so for one transaction you can run sequential using dependency and for other transaction run concurrently while GCD 
doesn't allow to run this way.
It is easy to cancel an operation if it is in the queue it can be stopped if it is running.
You can define the maximum number of concurrent operations.
You can suspend operation which they are in Queue
You can find how many pending operations are there in queue.

    Another reason to prefer NSOperation over GCD is the cancelation mechanism of NSOperation. For example, an App like 500px that shows dozens of photos, use NSOperation we can cancel requests of invisible image cells when we scroll table view or collection view, this can greatly improve App performance and reduce memory footprint. GCD can't easily support this.

Also with NSOperation, KVO can be possible.

Here is an article from Eschaton which is worth reading. 
    Well, NSOperations are simply an API built on top of Grand Central Dispatch. So when you’re using NSOperations, you’re really still using Grand Central Dispatch.
It’s just that NSOperations give you some fancy features that you might like. You can make some operations dependent on other operations, reorder queues after you sumbit items, and other things like that.
In fact, ImageGrabber is already using NSOperations and operation queues! ASIHTTPRequest uses them under the hood, and you can configure the operation queue it uses for different behavior if you’d like.
So which should you use? Whichever makes sense for your app. For this app it’s pretty simple so we just used Grand Central Dispatch directly, no need for the fancy features of NSOperation. But if you need them for your app, feel free to use it!
    GCD is indeed lower-level than NSOperationQueue, its major advantage is that its implementation is very light-weight and focused on lock-free algorithms and performance.

NSOperationQueue does provide facilities that are not available in GCD, but they come at non-trivial cost, the implementation of NSOperationQueue is complex and heavy-weight, involves a lot of locking, and uses GCD internally only in a very minimal fashion.

If you need the facilities provided by NSOperationQueue by all means use it, but if GCD is sufficient for your needs, I would recommend using it directly for better performance, significantly lower CPU and power cost and more flexibility.
    I agree with @Sangram and other answers but want to add few points. Correct me if I am wrong.
I think now a days first two points of @Sangram's answer are not valid (i. Control On Operation  ii. Dependencies). We can achieve these two by using GCD also. Trying to explain by code(do not focus on quality of code, this is for reference purpose only)
func methodsOfGCD() {
    
    let concurrentQueue = DispatchQueue.init(label: ""MyQueue"", qos: .background, attributes: .concurrent)
    
    
    //We can suspend and resume Like this
    concurrentQueue.suspend()
    concurrentQueue.resume()
    
    //We can cancel using DispatchWorkItem
    let workItem = DispatchWorkItem {
        print(""Do something"")
    }
    concurrentQueue.async(execute: workItem)
    workItem.cancel()
    
    //Cam add dependency like this.
    //Operation 1
    concurrentQueue.async(flags: .barrier) {
        print(""Operation1"")
    }

    //Operation 2
    concurrentQueue.async(flags: .barrier) {
        print(""Operation2"")
    }

    //Operation 3.
    //Operation 3 have dependency on Operation1 and Operation2. Once 1 and 2 will finish will execute Operation 3. Here operation queue work as a serial queue.
    concurrentQueue.async(flags: .barrier) {
        print(""Operation3"")

    }

}

    ","[485, 124, 540, 380, 6, 24, 34, 3, 33, 0]",127061,229,2012-04-29T15:24:46,2021-10-03 13:30:50Z,
Inserting code in this LaTeX document with indentation,"
                
How do I insert code into a LaTeX document? Is there something like:

\begin{code}## Heading ##
...
\end{code}


The only thing that I really need is indentation and a fixed width font. Syntax highlighting could be nice although it is definitely not required.
    Use listings package.

Simple configuration for LaTeX header (before \begin{document}):

\usepackage{listings}
\usepackage{color}

\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

\lstset{frame=tb,
  language=Java,
  aboveskip=3mm,
  belowskip=3mm,
  showstringspaces=false,
  columns=flexible,
  basicstyle={\small\ttfamily},
  numbers=none,
  numberstyle=\tiny\color{gray},
  keywordstyle=\color{blue},
  commentstyle=\color{dkgreen},
  stringstyle=\color{mauve},
  breaklines=true,
  breakatwhitespace=true,
  tabsize=3
}


You can change default language in the middle of document with \lstset{language=Java}.

Example of usage in the document:

\begin{lstlisting}
// Hello.java
import javax.swing.JApplet;
import java.awt.Graphics;

public class Hello extends JApplet {
    public void paintComponent(Graphics g) {
        g.drawString(""Hello, world!"", 65, 95);
    }    
}
\end{lstlisting}


Here's the result:


    You could also use the verbatim environment

\begin{verbatim}
your
code
example
\end{verbatim}

    A very simple way if your code is in Python, where I didn't have to install a Python package, is the following:
\documentclass[11pt]{article}  
\usepackage{pythonhighlight}

\begin{document}

The following is some Python code

\begin{python}
# A comment
x = [5, 7, 10]
y = 0

for num in x:
    y += num
    
print(y)
\end{python}

\end{document}

which looks like:

Unfortunately, this only works for Python.
    Minted, whether from GitHub or CTAN, the Comprehensive TeX Archive Network, works in Overleaf, TeX Live and MiKTeX.
It requires the installation of the Python package Pygments; this is explained in the documentation in either source above. Although Pygments brands itself as a Python syntax highlighter, Minted guarantees the coverage of hundreds of other languages.
Example:
\documentclass{article}
\usepackage{minted}
\begin{document}

\begin{minted}[mathescape, linenos]{python}

# Note: $\pi=\lim_{n\to\infty}\frac{P_n}{d}$
title = ""Hello World""

sum = 0
for i in range(10):
 sum += i

\end{minted}

\end{document}

Output:

    Specialized packages such as minted, which relies on Pygments to do the formatting, offer various advantages over the listings package. To quote from the minted manual,


  Pygments provides far superior syntax highlighting compared to conventional packages. For example, listings basically only highlights strings, comments and keywords. Pygments, on the other hand, can be completely customized to highlight any token kind the source language might support. This might include special formatting sequences inside strings, numbers, different kinds of identifiers and exotic constructs such as HTML tags.

    Here is how to add inline code:

You can add inline code with {\tt code } or \texttt{ code }. If you want to format the inline code, then it would be best to make your own command

\newcommand{\code}[1]{\texttt{#1}}


Also, note that code blocks can be loaded from other files with

\lstinputlisting[breaklines]{source.c}


breaklines isn't required, but I find it useful. Be aware that you'll have to specify \usepackage{ listings } for this one.

Update: The listings package also includes the \lstinline command, which has the same syntax highlighting features as the \lstlisting and \lstinputlisting commands (see Cloudanger's answer for configuration details). As mentioned in a few other answers, there's also the minted package, which provides the \mintinline command. Like \lstinline, \mintinline provides the same syntax highlighting as a regular minted code block:


\documentclass{article}

\usepackage{minted}

\begin{document}
  This is a sentence with \mintinline{python}{def inlineCode(a=""ipsum)}
\end{document}

    Use Minted.

It's a package that facilitates expressive syntax highlighting in LaTeX using the powerful Pygments library. The package also provides options to customize the highlighted source code output using fancyvrb.

It's much more evolved and customizable than any other package!
    Since it wasn't yet mentioned here, it may be worth to add one more option, package spverbatim (no syntax highlighting):

\documentclass{article}
\usepackage{spverbatim}

\begin{document}

\begin{spverbatim}
  Your code here
\end{spverbatim}

\end{document}


Also, if syntax highlighting is not required, package alltt:

\documentclass{article}
\usepackage{alltt}

\begin{document}

\begin{alltt}
  Your code here
\end{alltt}

\end{document}

    Use Pygments !
    ","[485, 722, 202, 8, 20, 35, 123, 13, 7, 6]",681191,217,2010-07-04T15:13:20,2020-07-29 18:41:32Z,
What's the difference between commit() and apply() in SharedPreferences,"
                
I am using SharedPreferences in my android app. I am using both commit() and apply() method from shared preference. When I use AVD 2.3 it shows no error, but when I run the code in AVD 2.1, apply() method shows error. 

So what's the difference between these two? And by using only commit() can I store the preference value without any problem?
    tl;dr:


commit() writes the data synchronously (blocking the thread its called from). It then informs you about the success of the operation.
apply() schedules the data to be written asynchronously. It does not inform you about the success of the operation.
If you save with apply() and immediately read via any getX-method, the new value will be returned!
If you called apply() at some point and it's still executing, any calls to commit() will block until all past apply-calls and the current commit-call are finished.


More in-depth information from the SharedPreferences.Editor Documentation:


  Unlike commit(), which writes its
  preferences out to persistent storage
  synchronously, apply() commits its
  changes to the in-memory
  SharedPreferences immediately but
  starts an asynchronous commit to disk
  and you won't be notified of any
  failures. If another editor on this
  SharedPreferences does a regular
  commit() while a apply() is still
  outstanding, the commit() will block
  until all async commits are completed
  as well as the commit itself.
  
  As SharedPreferences instances are
  singletons within a process, it's safe
  to replace any instance of commit()
  with apply() if you were already
  ignoring the return value.
  
  The SharedPreferences.Editor interface
  isn't expected to be implemented
  directly. However, if you previously
  did implement it and are now getting
  errors about missing apply(), you can
  simply call commit() from apply().

    apply() was added in 2.3, it commits without returning a boolean indicating success or failure.

commit() returns true if the save works, false otherwise. 

apply() was added as the Android dev team noticed that almost no one took notice of the return value, so apply is faster as it is asynchronous.

http://developer.android.com/reference/android/content/SharedPreferences.Editor.html#apply()
    
  The difference between commit() and apply()


We might be confused by those two terms, when we are using SharedPreference. Basically they are probably the same, so let’s clarify the differences of commit() and apply().


  1.Return value:


apply() commits without returning a boolean indicating success or failure.
commit() returns true if the save works, false otherwise.


  
  Speed:
  


apply() is faster.
commit() is slower.


  
  Asynchronous v.s. Synchronous:
  


apply(): Asynchronous
commit(): Synchronous


  
  Atomic:
  


apply(): atomic
commit(): atomic


  
  Error notification:
  


apply(): No
commit(): Yes
    
commit() is synchronously, apply() is asynchronous
apply() is void function. 
commit() returns true if the new values were successfully written to persistent storage. 
apply() guarantees  complete before switching states , you don't need to worry about Android component lifecycles


If you dont use  value returned from commit() and you're using commit() from main thread, use apply() instead of  commit()
    I'm experiencing some problems using apply() instead commit(). As stated before in other responses, the apply() is asynchronous. I'm getting the problem that the changes formed to a ""string set"" preference are never written to the persistent memory.

It happens if you ""force detention"" of the program or, in the ROM that I have installed on my device with Android 4.1, when the process is killed by the system due to memory necessities.

I recommend to use ""commit()"" instead ""apply()"" if you want your preferences alive.
    From javadoc:


  Unlike commit(), which writes its
  preferences out to persistent storage
  synchronously, apply() commits its
  changes to the in-memory
  SharedPreferences immediately but
  starts an asynchronous commit to disk
  and you won't be notified of any
  failures. If another editor on this SharedPreferences does a regular commit() while a > apply() is still outstanding, the commit() will block until all async commits are completed as well as the commit itself

    The docs give a pretty good explanation of the difference between apply() and commit():


  Unlike commit(), which writes its preferences out to persistent
  storage synchronously, apply() commits its changes to the in-memory
  SharedPreferences immediately but starts an asynchronous commit to
  disk and you won't be notified of any failures. If another editor on
  this SharedPreferences does a regular commit() while a apply() is
  still outstanding, the commit() will block until all async commits are
  completed as well as the commit itself. As SharedPreferences instances
  are singletons within a process, it's safe to replace any instance of
  commit() with apply() if you were already ignoring the return value.

    Use apply(). 

It writes the changes to the RAM immediately and waits and writes it to the internal storage(the actual preference file) after. Commit writes the changes synchronously and directly to the file. 
    apply() changes the in-memory SharedPreferences object immediately but writes the updates to disk asynchronously.
commit() to write the data to disk synchronously. But because commit() is synchronous, you should avoid calling it from your main thread because it could pause your UI rendering.
    ","[485, 256, 712, 7, 15, 24, 7, 13, 14, 0]",147056,93,2011-05-11T07:26:01,2021-08-26 20:45:05Z,
WCF - How to Increase Message Size Quota,"
                
I have a WCF Service which returns 1000 records from database to the client. I have an ASP.NET WCF client (I have added service reference in asp.net web application project to consume WCF). 

I get the following message when I run the client application:


  The maximum message size quota for incoming messages (65536) has been
  exceeded. To increase the quota, use
  the MaxReceivedMessageSize property on
  the appropriate binding element.


Any help? How to increase message size quota?
    If you're still getting this error message while using the WCF Test Client, it's because the client has a separate MaxBufferSize setting.   

To correct the issue:


Right-Click on the Config File node at the bottom of the tree
Select Edit with SvcConfigEditor  


A list of editable settings will appear, including MaxBufferSize.

Note: Auto-generated proxy clients also set MaxBufferSize to 65536 by default. 
    If you are creating your WCF bindings dynamically here's the code to use:

BasicHttpBinding httpBinding = new BasicHttpBinding();
httpBinding.MaxReceivedMessageSize = Int32.MaxValue;
httpBinding.MaxBufferSize = Int32.MaxValue;
// Commented next statement since it is not required
// httpBinding.MaxBufferPoolSize = Int32.MaxValue;

    You'll want something like this to increase the message size quotas, in the App.config or Web.config file:

<bindings>
    <basicHttpBinding>
        <binding name=""basicHttp"" allowCookies=""true""
                 maxReceivedMessageSize=""20000000"" 
                 maxBufferSize=""20000000""
                 maxBufferPoolSize=""20000000"">
            <readerQuotas maxDepth=""32"" 
                 maxArrayLength=""200000000""
                 maxStringContentLength=""200000000""/>
        </binding>
    </basicHttpBinding>
</bindings>


And use the binding name in your endpoint configuration e.g.

...
bindingConfiguration=""basicHttp""
...


The justification for the values is simple, they are sufficiently large to accommodate most messages. You can tune that number to fit your needs. The low default value is basically there to prevent DOS type attacks. Making it 20000000 would allow for a distributed DOS attack to be effective, the default size of 64k would require a very large number of clients to overpower most servers these days.
    Another important thing to consider from my experience..

I would strongly advice NOT to maximize maxBufferPoolSize, because buffers from the pool are never released until the app-domain (ie the Application Pool) recycles.

A period of high traffic could cause a lot of memory to be used and never released.

More details here:


https://stackoverflow.com/a/19953113/496676
http://andriybuday.com/2011/08/wcf-configuration-caused-memory-leaks.html

    For HTTP:

<bindings>
  <basicHttpBinding>
    <binding name=""basicHttp"" allowCookies=""true""
             maxReceivedMessageSize=""20000000"" 
             maxBufferSize=""20000000""
             maxBufferPoolSize=""20000000"">
        <readerQuotas maxDepth=""200"" 
             maxArrayLength=""200000000""
             maxBytesPerRead=""4096""
             maxStringContentLength=""200000000""
             maxNameTableCharCount=""16384""/>
    </binding>
  </basicHttpBinding>
</bindings>


For TCP:

<bindings>
  <netTcpBinding>
    <binding name=""tcpBinding""
             maxReceivedMessageSize=""20000000""
             maxBufferSize=""20000000""
             maxBufferPoolSize=""20000000"">
      <readerQuotas maxDepth=""200""
           maxArrayLength=""200000000""
           maxStringContentLength=""200000000""
           maxBytesPerRead=""4096""
           maxNameTableCharCount=""16384""/>
    </binding>
  </netTcpBinding>
</bindings>


IMPORTANT:

If you try to pass complex object that has many connected objects (e.g: a tree data structure, a list that has many objects...), the communication will fail no matter how you increased the Quotas.
In such cases, you must increase the containing objects count:

<behaviors>
  <serviceBehaviors>
    <behavior name=""NewBehavior"">
      ...
      <dataContractSerializer maxItemsInObjectGraph=""2147483646""/>
    </behavior>
  </serviceBehaviors>
</behaviors>

    I found the easy way 


  --- right click the webconfig or app config file and click EDIT WCF CONFIGURATION and got to bingdigs ans select yore service and right
  side show maxReciveMessageSize give a large number ---

    The WCF Test Client has it's own client config. 

Run the test client and scroll to the bottom. 
If you double click the Config File node you will see the XML representation. As you can see the maxReceivedMessageSize is 65536. 

To edit this, Right Click the Config File tree node and select Edit With SvcConfigEditor. 
When the editor opens expand Bindings and double click the binding that was automatically generated. 

You can edit all the properties here, including maxReceivedMessageSize. When you are done click File - Save. 

Lastly, when you are back at the WCF Test Client window, click Tools - Options.

NOTE: Uncheck the Always regenerate config when launching services.
    For me, all I had to do is add maxReceivedMessageSize=""2147483647"" to the client app.config. The server left untouched.
    I solved my issue on Bing Maps WPF on my project Using CalculateRoute ().
The solution in my case was setting the maxReceivedMessageSize and maxReceivedMessageSize on attribute ""httpTransport"" for ""customBinding"" section .

I set in the applications.config file (es. myApp.config) this configuration:

<system.serviceModel>
    <bindings>
        <basicHttpBinding>
            <binding name=""BasicHttpBinding_IGeocodeService"" />
            <binding name=""BasicHttpBinding_IRouteService"" />
        </basicHttpBinding>
        <customBinding>
            <binding name=""CustomBinding_IGeocodeService"">
                <binaryMessageEncoding />
              <httpTransport manualAddressing=""false"" maxBufferPoolSize=""524288""
                                maxReceivedMessageSize=""2147483647"" allowCookies=""false"" authenticationScheme=""Anonymous""
                                bypassProxyOnLocal=""false"" decompressionEnabled=""true"" hostNameComparisonMode=""StrongWildcard""
                                keepAliveEnabled=""true"" maxBufferSize=""2147483647"" proxyAuthenticationScheme=""Anonymous""
                                realm="""" transferMode=""Buffered"" unsafeConnectionNtlmAuthentication=""false""
                                useDefaultWebProxy=""true"" />
            </binding>
            <binding name=""CustomBinding_IRouteService"">
                <binaryMessageEncoding />
              <httpTransport manualAddressing=""false"" maxBufferPoolSize=""524288""
                                maxReceivedMessageSize=""2147483647"" allowCookies=""false"" authenticationScheme=""Anonymous""
                                bypassProxyOnLocal=""false"" decompressionEnabled=""true"" hostNameComparisonMode=""StrongWildcard""
                                keepAliveEnabled=""true"" maxBufferSize=""2147483647"" proxyAuthenticationScheme=""Anonymous""
                                realm="""" transferMode=""Buffered"" unsafeConnectionNtlmAuthentication=""false""
                                useDefaultWebProxy=""true"" />
            </binding>
        </customBinding>
    </bindings>
    <client>
        <endpoint address=""http://dev.virtualearth.net/webservices/v1/geocodeservice/GeocodeService.svc""
            binding=""basicHttpBinding"" bindingConfiguration=""BasicHttpBinding_IGeocodeService""
            contract=""BingServices.IGeocodeService"" name=""BasicHttpBinding_IGeocodeService"" />
        <endpoint address=""http://dev.virtualearth.net/webservices/v1/geocodeservice/GeocodeService.svc/binaryHttp""
            binding=""customBinding"" bindingConfiguration=""CustomBinding_IGeocodeService""
            contract=""BingServices.IGeocodeService"" name=""CustomBinding_IGeocodeService"" />
        <endpoint address=""http://dev.virtualearth.net/webservices/v1/routeservice/routeservice.svc""
            binding=""basicHttpBinding"" bindingConfiguration=""BasicHttpBinding_IRouteService""
            contract=""BingServices.IRouteService"" name=""BasicHttpBinding_IRouteService"" />
        <endpoint address=""http://dev.virtualearth.net/webservices/v1/routeservice/routeservice.svc/binaryHttp""
            binding=""customBinding"" bindingConfiguration=""CustomBinding_IRouteService""
            contract=""BingServices.IRouteService"" name=""CustomBinding_IRouteService"" />
    </client>
</system.serviceModel>

    Don't forget that the app.config of the execution entry point will be considered, not the one in class library project managing Web-Service calls if there is one.

For example if you get the error while running unit test, you need to set up appropriate config in the testing project.
    
  

<bindings>
  <wsHttpBinding>
    <binding name=""wsHttpBinding_Username"" maxReceivedMessageSize=""20000000""          maxBufferPoolSize=""20000000"">
      <security mode=""TransportWithMessageCredential"">
        <message clientCredentialType=""UserName"" establishSecurityContext=""false""/>
      </security>
    </binding>
  </wsHttpBinding>
</bindings>

<client>
  <endpoint
            binding=""wsHttpBinding""
            bindingConfiguration=""wsHttpBinding_Username""
            contract=""Exchange.Exweb.ExchangeServices.ExchangeServicesGenericProxy.ExchangeServicesType""
            name=""ServicesFacadeEndpoint"" />
</client>



    I solve the problem ...as follows 

    <bindings>
  <netTcpBinding>
    <binding name=""ECMSBindingConfig"" closeTimeout=""00:10:00"" openTimeout=""00:10:00""
      sendTimeout=""00:10:00"" maxBufferPoolSize=""2147483647"" maxBufferSize=""2147483647""
      maxReceivedMessageSize=""2147483647"" portSharingEnabled=""true"">
      <readerQuotas maxArrayLength=""2147483647"" maxNameTableCharCount=""2147483647""
          maxStringContentLength=""2147483647"" maxDepth=""2147483647""
          maxBytesPerRead=""2147483647"" />
      <security mode=""None"" />
    </binding>
  </netTcpBinding>
</bindings>
<behaviors>
  <serviceBehaviors>
    <behavior name=""ECMSServiceBehavior"">
      <dataContractSerializer ignoreExtensionDataObject=""true"" maxItemsInObjectGraph=""2147483647"" />
      <serviceDebug includeExceptionDetailInFaults=""true"" />
      <serviceTimeouts transactionTimeout=""00:10:00"" />
      <serviceThrottling maxConcurrentCalls=""200"" maxConcurrentSessions=""100""
        maxConcurrentInstances=""100"" />
    </behavior>
  </serviceBehaviors>
</behaviors>

    i got this error when using this settings on web.config

System.ServiceModel.ServiceActivationException


i set settings like this:

      <service name=""idst.Controllers.wcf.Service_Talks"">
    <endpoint address="""" behaviorConfiguration=""idst.Controllers.wcf.Service_TalksAspNetAjaxBehavior""
      binding=""webHttpBinding"" contract=""idst.Controllers.wcf.Service_Talks"" />
  </service>
  <service name=""idst.Controllers.wcf.Service_Project"">
    <endpoint address="""" behaviorConfiguration=""idst.Controllers.wcf.Service_ProjectAspNetAjaxBehavior""
      binding=""basicHttpBinding"" bindingConfiguration="""" bindingName=""largBasicHttp""
      contract=""idst.Controllers.wcf.Service_Project"" />
  </service>
</services>

<bindings>
<basicHttpBinding>
    <binding name=""largBasicHttp"" allowCookies=""true""
             maxReceivedMessageSize=""20000000""
             maxBufferSize=""20000000""
             maxBufferPoolSize=""20000000"">
        <readerQuotas maxDepth=""32""
             maxArrayLength=""200000000""
             maxStringContentLength=""200000000""/>
    </binding>
</basicHttpBinding>



    ","[485, 163, 114, 641, 8, 7, 25, 47, 6, 8, 3, 6, 8, 0]",453580,114,2009-05-19T18:04:02,2018-07-24 14:50:15Z,
Declaring a custom android UI element using XML,"
                
How do I declare an Android UI element using XML?
    The Android Developer Guide has a section called Building Custom Components. Unfortunately, the discussion of XML attributes only covers declaring the control inside the layout file and not actually handling the values inside the class initialisation. The steps are as follows:

1. Declare attributes in values\attrs.xml

<?xml version=""1.0"" encoding=""utf-8""?>
<resources>
    <declare-styleable name=""MyCustomView"">
        <attr name=""android:text""/>
        <attr name=""android:textColor""/>            
        <attr name=""extraInformation"" format=""string"" />
    </declare-styleable>
</resources>


Notice the use of an unqualified name in the declare-styleable tag. Non-standard android  attributes like extraInformation need to have their type declared. Tags declared in the  superclass will be available in subclasses without having to be redeclared.

2. Create constructors

Since there are two constructors that use an AttributeSet for initialisation, it is convenient to create a separate initialisation method for the constructors to call. 

private void init(AttributeSet attrs) { 
    TypedArray a=getContext().obtainStyledAttributes(
         attrs,
         R.styleable.MyCustomView);

    //Use a
    Log.i(""test"",a.getString(
         R.styleable.MyCustomView_android_text));
    Log.i(""test"",""""+a.getColor(
         R.styleable.MyCustomView_android_textColor, Color.BLACK));
    Log.i(""test"",a.getString(
         R.styleable.MyCustomView_extraInformation));

    //Don't forget this
    a.recycle();
}


R.styleable.MyCustomView is an autogenerated int[] resource where each element is the ID of an attribute. Attributes are generated for each property in the XML by appending the attribute name to the element name. For example, R.styleable.MyCustomView_android_text contains the android_text attribute for MyCustomView. Attributes can then be retrieved from the TypedArray using various get functions. If the attribute is not defined in the defined in the XML, then null is returned. Except, of course, if the return type is a primitive, in which case the second argument is returned.

If you don't want to retrieve all of the attributes, it is possible to create this array manually.The ID for standard android attributes are included in android.R.attr, while attributes for this project are in R.attr.

int attrsWanted[]=new int[]{android.R.attr.text, R.attr.textColor};


Please note that you should not use anything in android.R.styleable, as per this thread it may change in the future. It is still in the documentation as being to view all these constants in the one place is useful.

3. Use it in a layout files such as layout\main.xml

Include the namespace declaration xmlns:app=""http://schemas.android.com/apk/res-auto"" in the top level xml element. Namespaces provide a method to avoid the conflicts that sometimes occur when different schemas use the same element names (see this article for more info). The URL is simply a manner of uniquely identifying schemas - nothing actually needs to be hosted at that URL. If this doesn't appear to be doing anything, it is because you don't actually need to add the namespace prefix unless you need to resolve a conflict.

<com.mycompany.projectname.MyCustomView
    android:layout_width=""wrap_content""
    android:layout_height=""wrap_content""
    android:background=""@android:color/transparent""
    android:text=""Test text""
    android:textColor=""#FFFFFF""
    app:extraInformation=""My extra information""
/> 


Reference the custom view using the fully qualified name.

Android LabelView Sample

If you want a complete example, look at the android label view sample.

LabelView.java

 TypedArray a=context.obtainStyledAttributes(attrs, R.styleable.LabelView);
 CharSequences=a.getString(R.styleable.LabelView_text);


attrs.xml

<declare-styleable name=""LabelView"">
    <attr name=""text""format=""string""/>
    <attr name=""textColor""format=""color""/>
    <attr name=""textSize""format=""dimension""/>
</declare-styleable>


custom_view_1.xml

<com.example.android.apis.view.LabelView
    android:background=""@drawable/blue""
    android:layout_width=""fill_parent""
    android:layout_height=""wrap_content""
    app:text=""Blue"" app:textSize=""20dp""/>


This is contained in a LinearLayout with a namespace attribute: xmlns:app=""http://schemas.android.com/apk/res-auto""

Links


StackOverflow Thread: Retrieving an XML attribute for custom control
How do I use obtainStyledAttributes with internal themes of Android
Defining custom attributes + list of supported attribute formats

    It seems that Google has updated its developer page and added various trainings there. 

One of them deals with the creation of custom views and can be found here
    Great reference. Thanks!
An addition to it:

If you happen to have a library project included which has declared custom attributes for a custom view, you have to declare your project namespace, not the library one's. Eg:

Given that the library has the package ""com.example.library.customview"" and the working project has the package ""com.example.customview"", then:

Will not work (shows the error "" error: No resource identifier found for attribute 'newAttr' in package 
     'com.example.library.customview'"" ):

<com.library.CustomView
        xmlns:android=""http://schemas.android.com/apk/res/android""
        xmlns:app=""http://schemas.android.com/apk/res/com.example.library.customview""
        android:id=""@+id/myView""
        app:newAttr=""value"" />


Will work:

<com.library.CustomView
        xmlns:android=""http://schemas.android.com/apk/res/android""
        xmlns:app=""http://schemas.android.com/apk/res/com.example.customview""
        android:id=""@+id/myView""
        app:newAttr=""value"" />

    Addition to most voted answer.

obtainStyledAttributes()

I want to add some words about obtainStyledAttributes() usage, when we create custom view using android:xxx prdefined attributes. Especially when we use TextAppearance.
As was mentioned in ""2. Creating constructors"", custom view gets AttributeSet on its creation. Main usage we can see in TextView source code (API 16).

final Resources.Theme theme = context.getTheme();

// TextAppearance is inspected first, but let observe it later

TypedArray a = theme.obtainStyledAttributes(
            attrs, com.android.internal.R.styleable.TextView, defStyle, 0);

int n = a.getIndexCount();
for (int i = 0; i < n; i++) 
{
    int attr = a.getIndex(i);
    // huge switch with pattern value=a.getXXX(attr) <=> a.getXXX(a.getIndex(i))
}
a.recycle();


What we can see here?
obtainStyledAttributes(AttributeSet set, int[] attrs, int defStyleAttr, int defStyleRes)
Attribute set is processed by theme according to documentation. Attribute values are compiled step by step. First attributes are filled from theme, then values are replaced by values from style, and finally exact values from XML for special view instance replace others.
Array of requested attributes - com.android.internal.R.styleable.TextView
It is an ordinary array of constants. If we are requesting standard attributes, we can build this array manually.

What is not mentioned in documentation - order of result TypedArray elements.
When custom view is declared in attrs.xml, special constants for attribute indexes are generated. And we can extract values this way: a.getString(R.styleable.MyCustomView_android_text). But for manual int[] there are no constants. I suppose, that getXXXValue(arrayIndex) will work fine.

And other question is: ""How we can replace internal constants, and request standard attributes?"" We can use android.R.attr.* values.

So if we want to use standard TextAppearance attribute in custom view and read its values in constructor, we can modify code from TextView this way:

ColorStateList textColorApp = null;
int textSize = 15;
int typefaceIndex = -1;
int styleIndex = -1;

Resources.Theme theme = context.getTheme();

TypedArray a = theme.obtainStyledAttributes(attrs, R.styleable.CustomLabel, defStyle, 0);
TypedArray appearance = null;
int apResourceId = a.getResourceId(R.styleable.CustomLabel_android_textAppearance, -1);
a.recycle();
if (apResourceId != -1)
{
    appearance = 
        theme.obtainStyledAttributes(apResourceId, new int[] { android.R.attr.textColor, android.R.attr.textSize, 
            android.R.attr.typeface, android.R.attr.textStyle });
}
if (appearance != null)
{
    textColorApp = appearance.getColorStateList(0);
    textSize = appearance.getDimensionPixelSize(1, textSize);
    typefaceIndex = appearance.getInt(2, -1);
    styleIndex = appearance.getInt(3, -1);

    appearance.recycle();
}


Where CustomLabel is defined:

<declare-styleable name=""CustomLabel"">
    <!-- Label text. -->
    <attr name=""android:text"" />
    <!-- Label text color. -->
    <attr name=""android:textColor"" />
    <!-- Combined text appearance properties. -->
    <attr name=""android:textAppearance"" />
</declare-styleable>


Maybe, I'm mistaken some way, but Android documentation on obtainStyledAttributes() is very poor.

Extending standard UI component

At the same time we can just extend standard UI component, using all its declared attributes.
This approach is not so good, because TextView for instance declares a lot of properties. And it will be impossible
to implement full functionality in overriden onMeasure() and onDraw().

But we can sacrifice theoretical wide reusage of custom component. Say ""I know exactly what features I will use"", and
don't share code with anybody.

Then we can implement constructor CustomComponent(Context, AttributeSet, defStyle). 
After calling super(...) we will have all attributes parsed and available through getter methods.
    Thanks a lot for the first answer.

As for me, I had just one problem with it. When inflating my view, i had a bug :
java.lang.NoSuchMethodException : MyView(Context, Attributes)

I resolved it by creating a new constructor :

public MyView(Context context, AttributeSet attrs) {
     super(context, attrs);
     // some code
}


Hope this will help !
    You can include any layout file in other layout file as-

             <RelativeLayout
                android:layout_width=""wrap_content""
                android:layout_height=""wrap_content""
                android:layout_marginLeft=""10dp""
                android:layout_marginRight=""30dp"" >

                <include
                    android:id=""@+id/frnd_img_file""
                    android:layout_width=""wrap_content""
                    android:layout_height=""wrap_content""
                    layout=""@layout/include_imagefile""/>

                <include
                    android:id=""@+id/frnd_video_file""
                    android:layout_width=""wrap_content""
                    android:layout_height=""wrap_content""
                    layout=""@layout/include_video_lay"" />

                <ImageView
                    android:id=""@+id/downloadbtn""
                    android:layout_width=""30dp""
                    android:layout_height=""30dp""
                    android:layout_centerInParent=""true""
                    android:src=""@drawable/plus""/>
            </RelativeLayout>


here the layout files in include tag are other .xml layout files in the same res folder.
    ","[485, 846, 13, 91, 27, 5, 0]",201770,340,2010-04-23T01:36:27,2017-09-21 19:13:57Z,xml 
"Why does ""not(True) in [False, True]"" return False?","
                
If I do this:

>>> False in [False, True]
True


That returns True. Simply because False is in the list.

But if I do:

>>> not(True) in [False, True]
False


That returns False. Whereas not(True) is equal to False:

>>> not(True)
False


Why?
    Operator precedence 2.x, 3.x. The precedence of not is lower than that of in. So it is equivalent to:

>>> not ((True) in [False, True])
False


This is what you want:

>>> (not True) in [False, True]
True




As @Ben points out: It's recommended to never write not(True), prefer not True. The former makes it look like a function call, while not is an operator, not a function.
    not x in y is evaluated as x not in y

You can see exactly what's happening by disassembling the code.  The first case works as you expect:

>>> x = lambda: False in [False, True]
>>> dis.dis(x)
  1           0 LOAD_GLOBAL              0 (False)
              3 LOAD_GLOBAL              0 (False)
              6 LOAD_GLOBAL              1 (True)
              9 BUILD_LIST               2
             12 COMPARE_OP               6 (in)
             15 RETURN_VALUE


The second case, evaluates to True not in [False, True], which is False clearly:

>>> x = lambda: not(True) in [False, True]
>>> dis.dis(x)
  1           0 LOAD_GLOBAL              0 (True)
              3 LOAD_GLOBAL              1 (False)
              6 LOAD_GLOBAL              0 (True)
              9 BUILD_LIST               2
             12 COMPARE_OP               7 (not in)
             15 RETURN_VALUE        
>>> 


What you wanted to express instead was (not(True)) in [False, True], which as expected is True, and you can see why:

>>> x = lambda: (not(True)) in [False, True]
>>> dis.dis(x)
  1           0 LOAD_GLOBAL              0 (True)
              3 UNARY_NOT           
              4 LOAD_GLOBAL              1 (False)
              7 LOAD_GLOBAL              0 (True)
             10 BUILD_LIST               2
             13 COMPARE_OP               6 (in)
             16 RETURN_VALUE        

    Operator precedence. in binds more tightly than not, so your expression is equivalent to not((True) in [False, True]).
    It's all about operator precedence (in is stronger than not). But it can be easily corrected by adding parentheses at the right place:

(not(True)) in [False, True]  # prints true


writing:

not(True) in [False, True]


is the same like:

not((True) in [False, True])


which looks if True is in the list and returns the ""not"" of the result.
    It is evaluating as not True in [False, True], which returns False because True is in [False, True] 

If you try 

>>>(not(True)) in [False, True]
True


You get the expected result.
    Alongside the other answers that mentioned the precedence of not is lower than in, actually your statement is equivalent to :

not (True in [False, True])


But note that if you don't separate your condition from the other ones, python will use 2 roles (precedence or chaining) in order to separate that, and in this case python used precedence. Also, note that if you want to separate a condition you need to put all the condition in parenthesis not just the object or value :

(not True) in [False, True]




But as mentioned, there is another modification by python on operators that is chaining:

Based on python documentation :


  Note that comparisons, membership tests, and identity tests, all have the same precedence and have a left-to-right chaining feature as described in the Comparisons section.


For example the result of following statement is False:

>>> True == False in [False, True]
False


Because python will chain the statements like following :

(True == False) and (False in [False, True])


Which exactly is False and True that is False. 

You can assume that the central object will be shared between 2 operations and other objects (False in this case).

And note that its also true for all Comparisons, including membership tests and identity tests operations which are following operands :

in, not in, is, is not, <, <=, >, >=, !=, ==


Example :

>>> 1 in [1,2] == True
False


Another famous example is number range :

7<x<20


which is equal to :

7<x and x<20   

    Let's see it as a collection containment checking operation: [False, True] is a list containing some elements.

The expression True in [False, True] returns True, as True is an element contained in the list.

Therefore, not True in [False, True] gives the ""boolean opposite"", not result of the above expression (without any parentheses to preserve precedence, as in has greater precedence than not operator).
Therefore, not True will result False.

On the other hand, (not True) in [False, True], is equal to False in [False, True], which is True (False is contained in the list).
    To clarify on some of the other answers, adding parentheses after a unary operator does not change its precedence. not(True) does not make not bind more tightly to True. It's just a redundant set of parentheses around True. It's much the same as (True) in [True, False]. The parentheses don't do anything.  If you want the binding to be more tight, you have to put the parentheses around the whole expression, meaning both the operator and the operand, i.e., (not True) in [True, False].

To see this another way, consider 

>>> -2**2
-4


** binds more tightly than -, which is why you get the negative of two squared, not the square of negative two (which would be positive four). 

What if you did want the square of negative two? Obviously, you'd add parentheses:

>>> (-2)**2
4


However, it's not reasonable to expect the following to give 4

>>> -(2)**2
-4


because -(2) is the same as -2. The parentheses do absolutely nothing. not(True) is exactly the same. 
    ","[485, 737, 76, 36, 33, 14, 13, 6, 6]",31643,57,2015-07-15T04:12:58,2021-01-17 23:42:57Z,python 
How to pretty print XML from Java?,"
                
I have a Java String that contains XML, with no line feeds or indentations. I would like to turn it into a String with nicely formatted XML. How do I do this?

String unformattedXml = ""<tag><nested>hello</nested></tag>"";
String formattedXml = new [UnknownClass]().format(unformattedXml);


Note: My input is a String. My output is a String. 

(Basic) mock result:



<?xml version=""1.0"" encoding=""UTF-8""?>
<root>
  <tag>
    <nested>hello</nested>
  </tag>
</root>

    Transformer transformer = TransformerFactory.newInstance().newTransformer();
transformer.setOutputProperty(OutputKeys.INDENT, ""yes"");
transformer.setOutputProperty(""{http://xml.apache.org/xslt}indent-amount"", ""2"");
// initialize StreamResult with File object to save to file
StreamResult result = new StreamResult(new StringWriter());
DOMSource source = new DOMSource(doc);
transformer.transform(source, result);
String xmlString = result.getWriter().toString();
System.out.println(xmlString);

Note: Results may vary depending on the Java version. Search for workarounds specific to your platform.
    Here's an answer to my own question. I combined the answers from the various results to write a class that pretty prints XML.

No guarantees on how it responds with invalid XML or large documents.

package ecb.sdw.pretty;

import org.apache.xml.serialize.OutputFormat;
import org.apache.xml.serialize.XMLSerializer;
import org.w3c.dom.Document;
import org.xml.sax.InputSource;
import org.xml.sax.SAXException;

import javax.xml.parsers.DocumentBuilder;
import javax.xml.parsers.DocumentBuilderFactory;
import javax.xml.parsers.ParserConfigurationException;
import java.io.IOException;
import java.io.StringReader;
import java.io.StringWriter;
import java.io.Writer;

/**
 * Pretty-prints xml, supplied as a string.
 * <p/>
 * eg.
 * <code>
 * String formattedXml = new XmlFormatter().format(""<tag><nested>hello</nested></tag>"");
 * </code>
 */
public class XmlFormatter {

    public XmlFormatter() {
    }

    public String format(String unformattedXml) {
        try {
            final Document document = parseXmlFile(unformattedXml);

            OutputFormat format = new OutputFormat(document);
            format.setLineWidth(65);
            format.setIndenting(true);
            format.setIndent(2);
            Writer out = new StringWriter();
            XMLSerializer serializer = new XMLSerializer(out, format);
            serializer.serialize(document);

            return out.toString();
        } catch (IOException e) {
            throw new RuntimeException(e);
        }
    }

    private Document parseXmlFile(String in) {
        try {
            DocumentBuilderFactory dbf = DocumentBuilderFactory.newInstance();
            DocumentBuilder db = dbf.newDocumentBuilder();
            InputSource is = new InputSource(new StringReader(in));
            return db.parse(is);
        } catch (ParserConfigurationException e) {
            throw new RuntimeException(e);
        } catch (SAXException e) {
            throw new RuntimeException(e);
        } catch (IOException e) {
            throw new RuntimeException(e);
        }
    }

    public static void main(String[] args) {
        String unformattedXml =
                ""<?xml version=\""1.0\"" encoding=\""UTF-8\""?><QueryMessage\n"" +
                        ""        xmlns=\""http://www.SDMX.org/resources/SDMXML/schemas/v2_0/message\""\n"" +
                        ""        xmlns:query=\""http://www.SDMX.org/resources/SDMXML/schemas/v2_0/query\"">\n"" +
                        ""    <Query>\n"" +
                        ""        <query:CategorySchemeWhere>\n"" +
                        ""   \t\t\t\t\t         <query:AgencyID>ECB\n\n\n\n</query:AgencyID>\n"" +
                        ""        </query:CategorySchemeWhere>\n"" +
                        ""    </Query>\n\n\n\n\n"" +
                        ""</QueryMessage>"";

        System.out.println(new XmlFormatter().format(unformattedXml));
    }

}

    Using jdom2 : http://www.jdom.org/

import java.io.StringReader;
import org.jdom2.input.SAXBuilder;
import org.jdom2.output.Format;
import org.jdom2.output.XMLOutputter;

String prettyXml = new XMLOutputter(Format.getPrettyFormat()).
                         outputString(new SAXBuilder().build(new StringReader(uglyXml)));

    a simpler solution based on this answer:
public static String prettyFormat(String input, int indent) {
    try {
        Source xmlInput = new StreamSource(new StringReader(input));
        StringWriter stringWriter = new StringWriter();
        StreamResult xmlOutput = new StreamResult(stringWriter);
        TransformerFactory transformerFactory = TransformerFactory.newInstance();
        transformerFactory.setAttribute(""indent-number"", indent);
        transformerFactory.setAttribute(XMLConstants.ACCESS_EXTERNAL_DTD, """");
        transformerFactory.setAttribute(XMLConstants.ACCESS_EXTERNAL_STYLESHEET, """");
        Transformer transformer = transformerFactory.newTransformer(); 
        transformer.setOutputProperty(OutputKeys.INDENT, ""yes"");
        transformer.transform(xmlInput, xmlOutput);
        return xmlOutput.getWriter().toString();
    } catch (Exception e) {
        throw new RuntimeException(e); // simple exception handling, please review it
    }
}

public static String prettyFormat(String input) {
    return prettyFormat(input, 2);
}

testcase:
prettyFormat(""<root><child>aaa</child><child/></root>"");

returns:
<?xml version=""1.0"" encoding=""UTF-8""?>
<root>
  <child>aaa</child>
  <child/>
</root>

//Ignore: Original edit just needs missing s in the Class name in code. redundant six characters added to get over 6 characters validation on SO
    Now it's 2012 and Java can do more than it used to with XML, I'd like to add an alternative to my accepted answer. This has no dependencies outside of Java 6.

import org.w3c.dom.Node;
import org.w3c.dom.bootstrap.DOMImplementationRegistry;
import org.w3c.dom.ls.DOMImplementationLS;
import org.w3c.dom.ls.LSSerializer;
import org.xml.sax.InputSource;

import javax.xml.parsers.DocumentBuilderFactory;
import java.io.StringReader;

/**
 * Pretty-prints xml, supplied as a string.
 * <p/>
 * eg.
 * <code>
 * String formattedXml = new XmlFormatter().format(""<tag><nested>hello</nested></tag>"");
 * </code>
 */
public class XmlFormatter {

    public String format(String xml) {

        try {
            final InputSource src = new InputSource(new StringReader(xml));
            final Node document = DocumentBuilderFactory.newInstance().newDocumentBuilder().parse(src).getDocumentElement();
            final Boolean keepDeclaration = Boolean.valueOf(xml.startsWith(""<?xml""));

        //May need this: System.setProperty(DOMImplementationRegistry.PROPERTY,""com.sun.org.apache.xerces.internal.dom.DOMImplementationSourceImpl"");


            final DOMImplementationRegistry registry = DOMImplementationRegistry.newInstance();
            final DOMImplementationLS impl = (DOMImplementationLS) registry.getDOMImplementation(""LS"");
            final LSSerializer writer = impl.createLSSerializer();

            writer.getDomConfig().setParameter(""format-pretty-print"", Boolean.TRUE); // Set this to true if the output needs to be beautified.
            writer.getDomConfig().setParameter(""xml-declaration"", keepDeclaration); // Set this to true if the declaration is needed to be outputted.

            return writer.writeToString(document);
        } catch (Exception e) {
            throw new RuntimeException(e);
        }
    }

    public static void main(String[] args) {
        String unformattedXml =
                ""<?xml version=\""1.0\"" encoding=\""UTF-8\""?><QueryMessage\n"" +
                        ""        xmlns=\""http://www.SDMX.org/resources/SDMXML/schemas/v2_0/message\""\n"" +
                        ""        xmlns:query=\""http://www.SDMX.org/resources/SDMXML/schemas/v2_0/query\"">\n"" +
                        ""    <Query>\n"" +
                        ""        <query:CategorySchemeWhere>\n"" +
                        ""   \t\t\t\t\t         <query:AgencyID>ECB\n\n\n\n</query:AgencyID>\n"" +
                        ""        </query:CategorySchemeWhere>\n"" +
                        ""    </Query>\n\n\n\n\n"" +
                        ""</QueryMessage>"";

        System.out.println(new XmlFormatter().format(unformattedXml));
    }
}

    Kevin Hakanson said:
""However, if you know your XML string is valid, and you don't want to incur the memory overhead of parsing a string into a DOM, then running a transform over the DOM to get a string back - you could just do some old fashioned character by character parsing. Insert a newline and spaces after every  characters, keep and indent counter (to determine the number of spaces) that you increment for every <...> and decrement for every  you see.""

Agreed. Such an approach is much faster and has far fewer dependencies.

Example solution:

/**
 * XML utils, including formatting.
 */
public class XmlUtils
{
  private static XmlFormatter formatter = new XmlFormatter(2, 80);

  public static String formatXml(String s)
  {
    return formatter.format(s, 0);
  }

  public static String formatXml(String s, int initialIndent)
  {
    return formatter.format(s, initialIndent);
  }

  private static class XmlFormatter
  {
    private int indentNumChars;
    private int lineLength;
    private boolean singleLine;

    public XmlFormatter(int indentNumChars, int lineLength)
    {
      this.indentNumChars = indentNumChars;
      this.lineLength = lineLength;
    }

    public synchronized String format(String s, int initialIndent)
    {
      int indent = initialIndent;
      StringBuilder sb = new StringBuilder();
      for (int i = 0; i < s.length(); i++)
      {
        char currentChar = s.charAt(i);
        if (currentChar == '<')
        {
          char nextChar = s.charAt(i + 1);
          if (nextChar == '/')
            indent -= indentNumChars;
          if (!singleLine)   // Don't indent before closing element if we're creating opening and closing elements on a single line.
            sb.append(buildWhitespace(indent));
          if (nextChar != '?' && nextChar != '!' && nextChar != '/')
            indent += indentNumChars;
          singleLine = false;  // Reset flag.
        }
        sb.append(currentChar);
        if (currentChar == '>')
        {
          if (s.charAt(i - 1) == '/')
          {
            indent -= indentNumChars;
            sb.append(""\n"");
          }
          else
          {
            int nextStartElementPos = s.indexOf('<', i);
            if (nextStartElementPos > i + 1)
            {
              String textBetweenElements = s.substring(i + 1, nextStartElementPos);

              // If the space between elements is solely newlines, let them through to preserve additional newlines in source document.
              if (textBetweenElements.replaceAll(""\n"", """").length() == 0)
              {
                sb.append(textBetweenElements + ""\n"");
              }
              // Put tags and text on a single line if the text is short.
              else if (textBetweenElements.length() <= lineLength * 0.5)
              {
                sb.append(textBetweenElements);
                singleLine = true;
              }
              // For larger amounts of text, wrap lines to a maximum line length.
              else
              {
                sb.append(""\n"" + lineWrap(textBetweenElements, lineLength, indent, null) + ""\n"");
              }
              i = nextStartElementPos - 1;
            }
            else
            {
              sb.append(""\n"");
            }
          }
        }
      }
      return sb.toString();
    }
  }

  private static String buildWhitespace(int numChars)
  {
    StringBuilder sb = new StringBuilder();
    for (int i = 0; i < numChars; i++)
      sb.append("" "");
    return sb.toString();
  }

  /**
   * Wraps the supplied text to the specified line length.
   * @lineLength the maximum length of each line in the returned string (not including indent if specified).
   * @indent optional number of whitespace characters to prepend to each line before the text.
   * @linePrefix optional string to append to the indent (before the text).
   * @returns the supplied text wrapped so that no line exceeds the specified line length + indent, optionally with
   * indent and prefix applied to each line.
   */
  private static String lineWrap(String s, int lineLength, Integer indent, String linePrefix)
  {
    if (s == null)
      return null;

    StringBuilder sb = new StringBuilder();
    int lineStartPos = 0;
    int lineEndPos;
    boolean firstLine = true;
    while(lineStartPos < s.length())
    {
      if (!firstLine)
        sb.append(""\n"");
      else
        firstLine = false;

      if (lineStartPos + lineLength > s.length())
        lineEndPos = s.length() - 1;
      else
      {
        lineEndPos = lineStartPos + lineLength - 1;
        while (lineEndPos > lineStartPos && (s.charAt(lineEndPos) != ' ' && s.charAt(lineEndPos) != '\t'))
          lineEndPos--;
      }
      sb.append(buildWhitespace(indent));
      if (linePrefix != null)
        sb.append(linePrefix);

      sb.append(s.substring(lineStartPos, lineEndPos + 1));
      lineStartPos = lineEndPos + 1;
    }
    return sb.toString();
  }

  // other utils removed for brevity
}

    For those searching for a quick and dirty solution - which doesn't need the XML to be 100% valid. e.g. in case of REST / SOAP logging (you never know what the others send ;-))

I found and advanced a code snipped I found online which I think is still missing here as a valid possible approach: 

public static String prettyPrintXMLAsString(String xmlString) {
    /* Remove new lines */
    final String LINE_BREAK = ""\n"";
    xmlString = xmlString.replaceAll(LINE_BREAK, """");
    StringBuffer prettyPrintXml = new StringBuffer();
    /* Group the xml tags */
    Pattern pattern = Pattern.compile(""(<[^/][^>]+>)?([^<]*)(</[^>]+>)?(<[^/][^>]+/>)?"");
    Matcher matcher = pattern.matcher(xmlString);
    int tabCount = 0;
    while (matcher.find()) {
        String str1 = (null == matcher.group(1) || ""null"".equals(matcher.group())) ? """" : matcher.group(1);
        String str2 = (null == matcher.group(2) || ""null"".equals(matcher.group())) ? """" : matcher.group(2);
        String str3 = (null == matcher.group(3) || ""null"".equals(matcher.group())) ? """" : matcher.group(3);
        String str4 = (null == matcher.group(4) || ""null"".equals(matcher.group())) ? """" : matcher.group(4);

        if (matcher.group() != null && !matcher.group().trim().equals("""")) {
            printTabs(tabCount, prettyPrintXml);
            if (!str1.equals("""") && str3.equals("""")) {
                ++tabCount;
            }
            if (str1.equals("""") && !str3.equals("""")) {
                --tabCount;
                prettyPrintXml.deleteCharAt(prettyPrintXml.length() - 1);
            }

            prettyPrintXml.append(str1);
            prettyPrintXml.append(str2);
            prettyPrintXml.append(str3);
            if (!str4.equals("""")) {
                prettyPrintXml.append(LINE_BREAK);
                printTabs(tabCount, prettyPrintXml);
                prettyPrintXml.append(str4);
            }
            prettyPrintXml.append(LINE_BREAK);
        }
    }
    return prettyPrintXml.toString();
}

private static void printTabs(int count, StringBuffer stringBuffer) {
    for (int i = 0; i < count; i++) {
        stringBuffer.append(""\t"");
    }
}

public static void main(String[] args) {
    String x = new String(
            ""<soap:Envelope xmlns:soap=\""http://schemas.xmlsoap.org/soap/envelope/\""><soap:Body><soap:Fault><faultcode>soap:Client</faultcode><faultstring>INVALID_MESSAGE</faultstring><detail><ns3:XcbSoapFault xmlns=\""\"" xmlns:ns3=\""http://www.someapp.eu/xcb/types/xcb/v1\""><CauseCode>20007</CauseCode><CauseText>INVALID_MESSAGE</CauseText><DebugInfo>Problems creating SAAJ object model</DebugInfo></ns3:XcbSoapFault></detail></soap:Fault></soap:Body></soap:Envelope>"");
    System.out.println(prettyPrintXMLAsString(x));
}


here is the output:

<soap:Envelope xmlns:soap=""http://schemas.xmlsoap.org/soap/envelope/"">
  <soap:Body>
    <soap:Fault>
        <faultcode>soap:Client</faultcode>
        <faultstring>INVALID_MESSAGE</faultstring>
        <detail>
            <ns3:XcbSoapFault xmlns="""" xmlns:ns3=""http://www.someapp.eu/xcb/types/xcb/v1"">
                <CauseCode>20007</CauseCode>
                <CauseText>INVALID_MESSAGE</CauseText>
                <DebugInfo>Problems creating SAAJ object model</DebugInfo>
            </ns3:XcbSoapFault>
        </detail>
    </soap:Fault>
  </soap:Body>
</soap:Envelope>

    I always use the below function:

public static String prettyPrintXml(String xmlStringToBeFormatted) {
    String formattedXmlString = null;
    try {
        DocumentBuilderFactory documentBuilderFactory = DocumentBuilderFactory.newInstance();
        documentBuilderFactory.setValidating(true);
        DocumentBuilder documentBuilder = documentBuilderFactory.newDocumentBuilder();
        InputSource inputSource = new InputSource(new StringReader(xmlStringToBeFormatted));
        Document document = documentBuilder.parse(inputSource);

        Transformer transformer = TransformerFactory.newInstance().newTransformer();
        transformer.setOutputProperty(OutputKeys.INDENT, ""yes"");
        transformer.setOutputProperty(""{http://xml.apache.org/xslt}indent-amount"", ""2"");

        StreamResult streamResult = new StreamResult(new StringWriter());
        DOMSource dOMSource = new DOMSource(document);
        transformer.transform(dOMSource, streamResult);
        formattedXmlString = streamResult.getWriter().toString().trim();
    } catch (Exception ex) {
        StringWriter sw = new StringWriter();
        ex.printStackTrace(new PrintWriter(sw));
        System.err.println(sw.toString());
    }
    return formattedXmlString;
}

    Regarding comment that ""you must first build a DOM tree"": No, you need not and should not do that.

Instead, create a StreamSource (new StreamSource(new StringReader(str)), and feed that to the identity transformer mentioned. That'll use SAX parser, and result will be much faster.
Building an intermediate tree is pure overhead for this case.
Otherwise the top-ranked answer is good.
    Since you are starting with a String, you need to covert to a DOM object (e.g. Node) before you can use the Transformer.   However, if you know your XML string is valid, and you don't want to incur the memory overhead of parsing a string into a DOM, then running a transform over the DOM to get a string back - you could just do some old fashioned character by character parsing.  Insert a newline and spaces after every </...> characters, keep and indent counter (to determine the number of spaces) that you increment for every <...> and decrement for every </...> you see.

Disclaimer - I did a cut/paste/text edit of the functions below, so they may not compile as is.

public static final Element createDOM(String strXML) 
    throws ParserConfigurationException, SAXException, IOException {

    DocumentBuilderFactory dbf = DocumentBuilderFactory.newInstance();
    dbf.setValidating(true);
    DocumentBuilder db = dbf.newDocumentBuilder();
    InputSource sourceXML = new InputSource(new StringReader(strXML));
    Document xmlDoc = db.parse(sourceXML);
    Element e = xmlDoc.getDocumentElement();
    e.normalize();
    return e;
}

public static final void prettyPrint(Node xml, OutputStream out)
    throws TransformerConfigurationException, TransformerFactoryConfigurationError, TransformerException {
    Transformer tf = TransformerFactory.newInstance().newTransformer();
    tf.setOutputProperty(OutputKeys.OMIT_XML_DECLARATION, ""yes"");
    tf.setOutputProperty(OutputKeys.ENCODING, ""UTF-8"");
    tf.setOutputProperty(OutputKeys.INDENT, ""yes"");
    tf.transform(new DOMSource(xml), new StreamResult(out));
}

    I mix all of them and writing one small program. It is reading from the xml file and printing out. Just Instead of xzy give your file path.

    public static void main(String[] args) throws Exception {
    DocumentBuilderFactory dbf = DocumentBuilderFactory.newInstance();
    dbf.setValidating(false);
    DocumentBuilder db = dbf.newDocumentBuilder();
    Document doc = db.parse(new FileInputStream(new File(""C:/Users/xyz.xml"")));
    prettyPrint(doc);

}

private static String prettyPrint(Document document)
        throws TransformerException {
    TransformerFactory transformerFactory = TransformerFactory
            .newInstance();
    Transformer transformer = transformerFactory.newTransformer();
    transformer.setOutputProperty(OutputKeys.INDENT, ""yes"");
    transformer.setOutputProperty(""{http://xml.apache.org/xslt}indent-amount"", ""2"");
    transformer.setOutputProperty(OutputKeys.ENCODING, ""UTF-8"");
    transformer.setOutputProperty(OutputKeys.OMIT_XML_DECLARATION, ""no"");
    DOMSource source = new DOMSource(document);
    StringWriter strWriter = new StringWriter();
    StreamResult result = new StreamResult(strWriter);transformer.transform(source, result);
    System.out.println(strWriter.getBuffer().toString());

    return strWriter.getBuffer().toString();

}

    All above solutions didn't work for me, then I found this http://myshittycode.com/2014/02/10/java-properly-indenting-xml-string/

The clue is remove whitespaces with XPath

    String xml = ""<root>"" +
             ""\n   "" +
             ""\n<name>Coco Puff</name>"" +
             ""\n        <total>10</total>    </root>"";

try {
    Document document = DocumentBuilderFactory.newInstance()
            .newDocumentBuilder()
            .parse(new InputSource(new ByteArrayInputStream(xml.getBytes(""utf-8""))));

    XPath xPath = XPathFactory.newInstance().newXPath();
    NodeList nodeList = (NodeList) xPath.evaluate(""//text()[normalize-space()='']"",
                                                  document,
                                                  XPathConstants.NODESET);

    for (int i = 0; i < nodeList.getLength(); ++i) {
        Node node = nodeList.item(i);
        node.getParentNode().removeChild(node);
    }

    Transformer transformer = TransformerFactory.newInstance().newTransformer();
    transformer.setOutputProperty(OutputKeys.ENCODING, ""UTF-8"");
    transformer.setOutputProperty(OutputKeys.OMIT_XML_DECLARATION, ""yes"");
    transformer.setOutputProperty(OutputKeys.INDENT, ""yes"");
    transformer.setOutputProperty(""{http://xml.apache.org/xslt}indent-amount"", ""4"");

    StringWriter stringWriter = new StringWriter();
    StreamResult streamResult = new StreamResult(stringWriter);

    transformer.transform(new DOMSource(document), streamResult);

    System.out.println(stringWriter.toString());
}
catch (Exception e) {
    e.printStackTrace();
}

    Just another solution which works for us

import java.io.StringWriter;
import org.dom4j.DocumentHelper;
import org.dom4j.io.OutputFormat;
import org.dom4j.io.XMLWriter;

**
 * Pretty Print XML String
 * 
 * @param inputXmlString
 * @return
 */
public static String prettyPrintXml(String xml) {

    final StringWriter sw;

    try {
        final OutputFormat format = OutputFormat.createPrettyPrint();
        final org.dom4j.Document document = DocumentHelper.parseText(xml);
        sw = new StringWriter();
        final XMLWriter writer = new XMLWriter(sw, format);
        writer.write(document);
    }
    catch (Exception e) {
        throw new RuntimeException(""Error pretty printing xml:\n"" + xml, e);
    }
    return sw.toString();
}

    I've pretty printed in the past using the org.dom4j.io.OutputFormat.createPrettyPrint() method

public String prettyPrint(final String xml){  

    if (StringUtils.isBlank(xml)) {
        throw new RuntimeException(""xml was null or blank in prettyPrint()"");
    }

    final StringWriter sw;

    try {
        final OutputFormat format = OutputFormat.createPrettyPrint();
        final org.dom4j.Document document = DocumentHelper.parseText(xml);
        sw = new StringWriter();
        final XMLWriter writer = new XMLWriter(sw, format);
        writer.write(document);
    }
    catch (Exception e) {
        throw new RuntimeException(""Error pretty printing xml:\n"" + xml, e);
    }
    return sw.toString();
}

    This code below working perfectly

import javax.xml.transform.OutputKeys;
import javax.xml.transform.Source;
import javax.xml.transform.Transformer;
import javax.xml.transform.TransformerFactory;
import javax.xml.transform.stream.StreamResult;
import javax.xml.transform.stream.StreamSource;

String formattedXml1 = prettyFormat(""<root><child>aaa</child><child/></root>"");

public static String prettyFormat(String input) {
    return prettyFormat(input, ""2"");
}

public static String prettyFormat(String input, String indent) {
    Source xmlInput = new StreamSource(new StringReader(input));
    StringWriter stringWriter = new StringWriter();
    try {
        TransformerFactory transformerFactory = TransformerFactory.newInstance();
        Transformer transformer = transformerFactory.newTransformer();
        transformer.setOutputProperty(OutputKeys.INDENT, ""yes"");
        transformer.setOutputProperty(""{http://xml.apache.org/xslt}indent-amount"", indent);
        transformer.transform(xmlInput, new StreamResult(stringWriter));

        String pretty = stringWriter.toString();
        pretty = pretty.replace(""\r\n"", ""\n"");
        return pretty;              
    } catch (Exception e) {
        throw new RuntimeException(e);
    }
}

    Just to note that top rated answer requires the use of xerces.

If you don't want to add this external dependency then you can simply use the standard jdk libraries (which actually are built using xerces internally).

N.B. There was a bug with jdk version 1.5 see http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6296446 but it is resolved now.,

(Note if an error occurs this will return the original text)

package com.test;

import java.io.ByteArrayInputStream;
import java.io.ByteArrayOutputStream;

import javax.xml.transform.OutputKeys;
import javax.xml.transform.Source;
import javax.xml.transform.Transformer;
import javax.xml.transform.sax.SAXSource;
import javax.xml.transform.sax.SAXTransformerFactory;
import javax.xml.transform.stream.StreamResult;

import org.xml.sax.InputSource;

public class XmlTest {
    public static void main(String[] args) {
        XmlTest t = new XmlTest();
        System.out.println(t.formatXml(""<a><b><c/><d>text D</d><e value='0'/></b></a>""));
    }

    public String formatXml(String xml){
        try{
            Transformer serializer= SAXTransformerFactory.newInstance().newTransformer();
            serializer.setOutputProperty(OutputKeys.INDENT, ""yes"");
            //serializer.setOutputProperty(OutputKeys.OMIT_XML_DECLARATION, ""yes"");
            serializer.setOutputProperty(""{http://xml.apache.org/xslt}indent-amount"", ""2"");
            //serializer.setOutputProperty(""{http://xml.customer.org/xslt}indent-amount"", ""2"");
            Source xmlSource=new SAXSource(new InputSource(new ByteArrayInputStream(xml.getBytes())));
            StreamResult res =  new StreamResult(new ByteArrayOutputStream());            
            serializer.transform(xmlSource, res);
            return new String(((ByteArrayOutputStream)res.getOutputStream()).toByteArray());
        }catch(Exception e){
            //TODO log error
            return xml;
        }
    }

}

    Here's a way of doing it using dom4j:

Imports:

import org.dom4j.Document;  
import org.dom4j.DocumentHelper;  
import org.dom4j.io.OutputFormat;  
import org.dom4j.io.XMLWriter;


Code: 

String xml = ""<your xml='here'/>"";  
Document doc = DocumentHelper.parseText(xml);  
StringWriter sw = new StringWriter();  
OutputFormat format = OutputFormat.createPrettyPrint();  
XMLWriter xw = new XMLWriter(sw, format);  
xw.write(doc);  
String result = sw.toString();

    slightly improved version from milosmns...

public static String getPrettyXml(String xml) {
    if (xml == null || xml.trim().length() == 0) return """";

    int stack = 0;
    StringBuilder pretty = new StringBuilder();
    String[] rows = xml.trim().replaceAll("">"", "">\n"").replaceAll(""<"", ""\n<"").split(""\n"");

    for (int i = 0; i < rows.length; i++) {
        if (rows[i] == null || rows[i].trim().length() == 0) continue;

        String row = rows[i].trim();
        if (row.startsWith(""<?"")) {
            pretty.append(row + ""\n"");
        } else if (row.startsWith(""</"")) {
            String indent = repeatString(--stack);
            pretty.append(indent + row + ""\n"");
        } else if (row.startsWith(""<"") && row.endsWith(""/>"") == false) {
            String indent = repeatString(stack++);
            pretty.append(indent + row + ""\n"");
            if (row.endsWith(""]]>"")) stack--;
        } else {
            String indent = repeatString(stack);
            pretty.append(indent + row + ""\n"");
        }
    }

    return pretty.toString().trim();
}

private static String repeatString(int stack) {
     StringBuilder indent = new StringBuilder();
     for (int i = 0; i < stack; i++) {
        indent.append("" "");
     }
     return indent.toString();
} 

    If you're sure that you have a valid XML, this one is simple, and avoids XML DOM trees. Maybe has some bugs, do comment if you see anything

public String prettyPrint(String xml) {
            if (xml == null || xml.trim().length() == 0) return """";

            int stack = 0;
            StringBuilder pretty = new StringBuilder();
            String[] rows = xml.trim().replaceAll("">"", "">\n"").replaceAll(""<"", ""\n<"").split(""\n"");

            for (int i = 0; i < rows.length; i++) {
                    if (rows[i] == null || rows[i].trim().length() == 0) continue;

                    String row = rows[i].trim();
                    if (row.startsWith(""<?"")) {
                            // xml version tag
                            pretty.append(row + ""\n"");
                    } else if (row.startsWith(""</"")) {
                            // closing tag
                            String indent = repeatString(""    "", --stack);
                            pretty.append(indent + row + ""\n"");
                    } else if (row.startsWith(""<"")) {
                            // starting tag
                            String indent = repeatString(""    "", stack++);
                            pretty.append(indent + row + ""\n"");
                    } else {
                            // tag data
                            String indent = repeatString(""    "", stack);
                            pretty.append(indent + row + ""\n"");
                    }
            }

            return pretty.toString().trim();
    }

    If using a 3rd party XML library is ok, you can get away with something significantly simpler than what the currently highest-voted answers suggest.  

It was stated that both input and output should be Strings, so here's a utility method that does just that, implemented with the XOM library:

import nu.xom.*;
import java.io.*;

[...]

public static String format(String xml) throws ParsingException, IOException {
    ByteArrayOutputStream out = new ByteArrayOutputStream();
    Serializer serializer = new Serializer(out);
    serializer.setIndent(4);  // or whatever you like
    serializer.write(new Builder().build(xml, """"));
    return out.toString(""UTF-8"");
}


I tested that it works, and the results do not depend on your JRE version or anything like that. To see how to customise the output format to your liking, take a look at the Serializer API.

This actually came out longer than I thought - some extra lines were needed because Serializer wants an OutputStream to write to. But note that there's very little code for actual XML twiddling here.

(This answer is part of my evaluation of XOM, which was suggested as one option in my question about the best Java XML library to replace dom4j. For the record, with dom4j you could achieve this with similar ease using XMLWriter and OutputFormat. Edit: ...as demonstrated in mlo55's answer.)
    Hmmm... faced something like this and it is a known bug ... 
just add this OutputProperty ..

transformer.setOutputProperty(OutputPropertiesFactory.S_KEY_INDENT_AMOUNT, ""8"");


Hope this helps ...
    Using scala:

import xml._
val xml = XML.loadString(""<tag><nested>hello</nested></tag>"")
val formatted = new PrettyPrinter(150, 2).format(xml)
println(formatted)


You can do this in Java too, if you depend on the scala-library.jar. It looks like this:

import scala.xml.*;

public class FormatXML {
    public static void main(String[] args) {
        String unformattedXml = ""<tag><nested>hello</nested></tag>"";
        PrettyPrinter pp = new PrettyPrinter(150, 3);
        String formatted = pp.format(XML.loadString(unformattedXml), TopScope$.MODULE$);
        System.out.println(formatted);
    }
}


The PrettyPrinter object is constructed with two ints, the first being max line length and the second being the indentation step.
    Just for future reference, here's a solution that worked for me (thanks to a comment that @George Hawkins posted in one of the answers):

DOMImplementationRegistry registry = DOMImplementationRegistry.newInstance();
DOMImplementationLS impl = (DOMImplementationLS) registry.getDOMImplementation(""LS"");
LSSerializer writer = impl.createLSSerializer();
writer.getDomConfig().setParameter(""format-pretty-print"", Boolean.TRUE);
LSOutput output = impl.createLSOutput();
ByteArrayOutputStream out = new ByteArrayOutputStream();
output.setByteStream(out);
writer.write(document, output);
String xmlStr = new String(out.toByteArray());

    As an alternative to the answers from max, codeskraps, David Easley and milosmns, have a look at my lightweight, high-performance pretty-printer library: xml-formatter

// construct lightweight, threadsafe, instance
PrettyPrinter prettyPrinter = PrettyPrinterBuilder.newPrettyPrinter().build();

StringBuilder buffer = new StringBuilder();
String xml = ..; // also works with char[] or Reader

if(prettyPrinter.process(xml, buffer)) {
     // valid XML, print buffer
} else {
     // invalid XML, print xml
}


Sometimes, like when running mocked SOAP services directly from file, it is good to have a pretty-printer which also handles already pretty-printed XML:

PrettyPrinter prettyPrinter = PrettyPrinterBuilder.newPrettyPrinter().ignoreWhitespace().build();


As some have commented, pretty-printing is just a way of presenting XML in a more human-readable form - whitespace strictly does not belong in your XML data. 

The library is intended for pretty-printing for logging purposes, and also includes functions for filtering (subtree removal / anonymization) and pretty-printing of XML in CDATA and Text nodes.
    I had the same problem and I'm having great success with JTidy (http://jtidy.sourceforge.net/index.html)

Example:

Tidy t = new Tidy();
t.setIndentContent(true);
Document d = t.parseDOM(
    new ByteArrayInputStream(""HTML goes here"", null);

OutputStream out = new ByteArrayOutputStream();
t.pprint(d, out);
String html = out.toString();

    I have found that in Java 1.6.0_32 the normal method to pretty print an XML string (using a Transformer with a null or identity xslt) does not behave as I would like if tags are merely separated by whitespace, as opposed to having no separating text. I tried using <xsl:strip-space elements=""*""/> in my template to no avail. The simplest solution I found was to strip the space the way I wanted using a SAXSource and XML filter. Since my solution was for logging  I also extended this to work with incomplete XML fragments. Note the normal method seems to work fine if you use a DOMSource but I did not want to use this because of the incompleteness and memory overhead. 

public static class WhitespaceIgnoreFilter extends XMLFilterImpl
{

    @Override
    public void ignorableWhitespace(char[] arg0,
                                    int arg1,
                                    int arg2) throws SAXException
    {
        //Ignore it then...
    }

    @Override
    public void characters( char[] ch,
                            int start,
                            int length) throws SAXException
    {
        if (!new String(ch, start, length).trim().equals("""")) 
               super.characters(ch, start, length); 
    }
}

public static String prettyXML(String logMsg, boolean allowBadlyFormedFragments) throws SAXException, IOException, TransformerException
    {
        TransformerFactory transFactory = TransformerFactory.newInstance();
        transFactory.setAttribute(""indent-number"", new Integer(2));
        Transformer transformer = transFactory.newTransformer();
        transformer.setOutputProperty(OutputKeys.INDENT, ""yes"");
        transformer.setOutputProperty(""{http://xml.apache.org/xslt}indent-amount"", ""4"");
        StringWriter out = new StringWriter();
        XMLReader masterParser = SAXHelper.getSAXParser(true);
        XMLFilter parser = new WhitespaceIgnoreFilter();
        parser.setParent(masterParser);

        if(allowBadlyFormedFragments)
        {
            transformer.setErrorListener(new ErrorListener()
            {
                @Override
                public void warning(TransformerException exception) throws TransformerException
                {
                }

                @Override
                public void fatalError(TransformerException exception) throws TransformerException
                {
                }

                @Override
                public void error(TransformerException exception) throws TransformerException
                {
                }
            });
        }

        try
        {
            transformer.transform(new SAXSource(parser, new InputSource(new StringReader(logMsg))), new StreamResult(out));
        }
        catch (TransformerException e)
        {
            if(e.getCause() != null && e.getCause() instanceof SAXParseException)
            {
                if(!allowBadlyFormedFragments || !""XML document structures must start and end within the same entity."".equals(e.getCause().getMessage()))
                {
                    throw e;
                }
            }
            else
            {
                throw e;
            }
        }
        out.flush();
        return out.toString();
    }

    The solutions I have found here for Java 1.6+ do not reformat the code if it is already formatted. The one that worked for me (and re-formatted already formatted code) was the following.

import org.apache.xml.security.c14n.CanonicalizationException;
import org.apache.xml.security.c14n.Canonicalizer;
import org.apache.xml.security.c14n.InvalidCanonicalizerException;
import org.w3c.dom.Element;
import org.w3c.dom.bootstrap.DOMImplementationRegistry;
import org.w3c.dom.ls.DOMImplementationLS;
import org.w3c.dom.ls.LSSerializer;
import org.xml.sax.InputSource;
import org.xml.sax.SAXException;

import javax.xml.parsers.DocumentBuilderFactory;
import javax.xml.parsers.ParserConfigurationException;
import javax.xml.transform.TransformerException;
import java.io.IOException;
import java.io.StringReader;

public class XmlUtils {
    public static String toCanonicalXml(String xml) throws InvalidCanonicalizerException, ParserConfigurationException, SAXException, CanonicalizationException, IOException {
        Canonicalizer canon = Canonicalizer.getInstance(Canonicalizer.ALGO_ID_C14N_OMIT_COMMENTS);
        byte canonXmlBytes[] = canon.canonicalize(xml.getBytes());
        return new String(canonXmlBytes);
    }

    public static String prettyFormat(String input) throws TransformerException, ParserConfigurationException, IOException, SAXException, InstantiationException, IllegalAccessException, ClassNotFoundException {
        InputSource src = new InputSource(new StringReader(input));
        Element document = DocumentBuilderFactory.newInstance().newDocumentBuilder().parse(src).getDocumentElement();
        Boolean keepDeclaration = input.startsWith(""<?xml"");
        DOMImplementationRegistry registry = DOMImplementationRegistry.newInstance();
        DOMImplementationLS impl = (DOMImplementationLS) registry.getDOMImplementation(""LS"");
        LSSerializer writer = impl.createLSSerializer();
        writer.getDomConfig().setParameter(""format-pretty-print"", Boolean.TRUE);
        writer.getDomConfig().setParameter(""xml-declaration"", keepDeclaration);
        return writer.writeToString(document);
    }
}


It is a good tool to use in your unit tests for full-string xml comparison. 

private void assertXMLEqual(String expected, String actual) throws ParserConfigurationException, IOException, SAXException, CanonicalizationException, InvalidCanonicalizerException, TransformerException, IllegalAccessException, ClassNotFoundException, InstantiationException {
    String canonicalExpected = prettyFormat(toCanonicalXml(expected));
    String canonicalActual = prettyFormat(toCanonicalXml(actual));
    assertEquals(canonicalExpected, canonicalActual);
}

    I saw one answer using Scala, so here is another one in Groovy, just in case someone finds it interesting. The default indentation is 2 steps, XmlNodePrinter constructor can be passed another value as well.

def xml = ""<tag><nested>hello</nested></tag>""
def stringWriter = new StringWriter()
def node = new XmlParser().parseText(xml);
new XmlNodePrinter(new PrintWriter(stringWriter)).print(node)
println stringWriter.toString()


Usage from Java if groovy jar is in classpath

  String xml = ""<tag><nested>hello</nested></tag>"";
  StringWriter stringWriter = new StringWriter();
  Node node = new XmlParser().parseText(xml);
  new XmlNodePrinter(new PrintWriter(stringWriter)).print(node);
  System.out.println(stringWriter.toString());

    In case you do not need indentation that much but a few line breaks, it could be sufficient to simply regex...

String leastPrettifiedXml = uglyXml.replaceAll(""><"", "">\n<"");


The code is nice, not the result because of missing indentation. 



(For solutions with indentation, see other answers.)
    There is a very nice command line XML utility called xmlstarlet(http://xmlstar.sourceforge.net/) that can do a lot of things which a lot of people use.
You could execute this program programmatically using Runtime.exec and then read in the formatted output file. It has more options and better error reporting than a few lines of Java code can provide.
download xmlstarlet : http://sourceforge.net/project/showfiles.php?group_id=66612&package_id=64589
    ","[485, 292, 139, 4, 138, 105, 15, 2, 2, 10, 17, 6, 6, 5, 33, 6, 54, 19, 9, 5, 12, 11, 9, 8, 3, 2, 1, 1, 1, 1, 1]",516441,154,2008-09-26T12:21:11,2022-02-06 00:09:43Z,java xml 
How can I use JavaScript source maps (.map files)?,"
                
Recently I have seen files with the .js.map extension shipped with some JavaScript libraries (like Angular), and that just raised a few questions in my head:

What is it for? Why do the guys at Angular care to deliver a .js.map file?
How can I (as a JavaScript developer) use the angular.min.js.map file?
Should I care about creating .js.map files for my JavaScript applications?
How does it get created? I took a look at angular.min.js.map and it was filled with strange-formatted strings, so I assume it's not created manually.

    The .map files are for JavaScript and CSS (and now TypeScript too) files that have been minified. They are called source maps. When you minify a file, like the angular.js file, it takes thousands of lines of pretty code and turns it into only a few lines of ugly code. Hopefully, when you are shipping your code to production, you are using the minified code instead of the full, unminified version. When your app is in production, and has an error, the source map will help take your ugly file, and will allow you to see the original version of the code. If you didn't have the source map, then any error would seem cryptic at best.
Same for CSS files. Once you take a Sass or Less file and compile it to CSS, it looks nothing like its original form. If you enable sourcemaps, then you can see the original state of the file, instead of the modified state.
So, to answer you questions in order:

What is it for? To de-reference uglified code
How can a developer use it? You use it for debugging a production app. In development mode you can use the full version of Angular. In production, you would use the minified version.
Should I care about creating a js.map file? If you care about being able to debug production code easier, then yes, you should do it.
How does it get created? It is created at build time. There are build tools that can build your .map file for you as it does other files. Sourcemaps fail if the output file is not located in the project root directory #71

I hope this makes sense.
    I just wanted to focus on the last part of the question; How are source map files created? by listing the build tools I know that can create source maps.

Grunt: using plugin grunt-contrib-uglify
Gulp: using plugin gulp-uglify
Google closure: using parameter --create_source_map

    How can a developer use it?

Don't link your js.map file in your index.html file (no need for that)

Minification tools (good ones) add a comment to your .min.js file:
//# sourceMappingURL=yourFileName.min.js.map

which will connect your .map file.
When the min.js and js.map files are ready...

Chrome: Open dev-tools, navigate to Sources tab. You will see the sources folder, where un-minified applications files are kept.


    The map file maps the unminified file to the minified file. If you make changes in the unminified file, the changes will be automatically reflected to the minified version of the file.
    Just to add to how to use map files: I use Google Chrome for Ubuntu and if I go to sources and click on a file, if there is a map file a message comes up telling me that I can view the original file and how to do it.
For the Angular files that I worked with today I click Ctrl + P and a list of original files comes up in a small window.
I can then browse through the list to view the file that I would like to inspect and check where the issue might be.
    ","[485, 728, 47, 55, 18, 4]",177178,109,2014-02-12T05:38:30,2021-09-14 15:01:07Z,javascript 
what are the .map files used for in Bootstrap 3.x?,"
                
There are two files included in the CSS folder with .map file extensions. They are:

bootstrap-theme.css.map
bootstrap.css.map


They appear to be minified files but I don't know what they are for.
    From Working with CSS preprocessors in Chrome DevTools:

Many developers generate CSS style sheets using a CSS preprocessor, such as Sass, Less, or Stylus. Because the CSS files are generated, editing the CSS files directly is not as helpful.
For preprocessors that support CSS source maps, DevTools lets you live-edit your preprocessor source files in the Sources panel, and view the results without having to leave DevTools or refresh the page. When you inspect an element whose styles are provided by a generated CSS file, the Elements panel displays a link to the original source file, not the generated .css file.

    If you just want to get rid of the error, you can also delete this line in bootstrap.css:

/*# sourceMappingURL=bootstrap.css.map */

    Map files (source maps) are there to de-reference minified code (css and javascript).
And they are mainly used to help developers debugging a production environment, because developers usually use minified files for production which makes it impossible to debug. Map files help them de-referencing the code to see how the original file looked like.
    For anyone who came here looking for these files (Like me), you can usually find them by adding .map to the end of the URL:

https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css.map

Be sure to replace the version with whatever version of Bootstrap you're using. 
    What is a CSS map file?

It is a JSON format file that links the CSS file to its source files, normally, files written in preprocessors (i.e., Less, Sass, Stylus, etc.), this is in order do a live debug to the source files from the web browser. 

What is CSS preprocessor? Examples: Sass, Less, Stylus

It is a CSS generator tool that uses programming power to generate CSS robustly and quickly.
    These are source maps.  Provide these alongside compressed source files; developer tools such as those in Firefox and Chrome will use them to allow debugging as if the code was not compressed.
    
  Have you ever found yourself wishing you could keep your client-side code readable and more importantly debuggable even after you've combined and minified it, without impacting performance? Well now you can through the magic of source maps.


This article explains Source Maps using a practical approach.
    The bootstrap css can be generated by Less. The main purpose of map file is used to link the css source code to less source code in the chrome dev tool.
As we used to do .If we inspect the element in the chrome dev tool. you can see the source code of css.
But if include the map file in the page with bootstrap css file. you can see the less code which apply to the element style you want to inspect. 
    ","[485, 490, 192, 8, 9, 11, 76, 8, 11]",329446,75,2014-02-01T22:40:21,2020-07-01 13:56:52Z,
Vim and Ctags tips and tricks [closed],"
                    
            
        
            
                    
                        
                    
                
                    
                        As it currently stands, this question is not a good fit for our Q&A format. We expect answers to be supported by facts, references,  or expertise, but this question will likely solicit debate, arguments, polling, or extended discussion. If you feel that this question  can be improved and possibly reopened, visit the help center for guidance.
                        
                    
                
            
                Closed 10 years ago.
        

            
        
            
                    
                        
                    
                
                    
                        Locked. This question and its answers are locked because the question is off-topic but has historical significance. It is not currently accepting new answers or interactions.
                        
                    
                
            
        

    

I have just installed Ctags (to help with C++ development) with my Vim (or rather gVim), and would like to find out your favorite commands, macros, shortcuts, tips that go along with it...

Share your best arsenal. What other Vim add-ons you would recommend for C++ on Vim development?

EDIT What other add-on you would use in conjunction with Ctags?

EDIT2 What version of gVim you use with tags? Does it make a difference? 

EDIT3 How do you enhance your programming experience for both big and small projects?
    Ctrl+] - go to definition
Ctrl+T - Jump back from the definition.
Ctrl+W Ctrl+] - Open the definition in a horizontal split  

Add these lines in vimrc
    map <C-\> :tab split<CR>:exec(""tag "".expand(""<cword>""))<CR>
    map <A-]> :vsp <CR>:exec(""tag "".expand(""<cword>""))<CR>  

Ctrl+\ - Open the definition in a new tab
Alt+] - Open the definition in a vertical split

After the tags are generated. You can use the following keys to tag into and tag out of functions:

Ctrl+Left MouseClick - Go to definition
Ctrl+Right MouseClick - Jump back from definition 
    One line that always goes in my .vimrc:

set tags=./tags;/


This will look in the current directory for ""tags"", and work up the tree towards root until one is found.  IOW, you can be anywhere in your source tree instead of just the root of it.
    Another useful plugin for C development is cscope
Just as Ctags lets you jump to definitions, Cscope jumps to the calling functions.

If you have cscope in your ~/bin/ directory, add the following to your .vimrc and use g^] to go to the calling function (see :help cscope).

if has(""cscope"")
    set csprg=~/bin/cscope
    set csto=0
    set cst
    set nocsverb
    "" add any database in current directory
    if filereadable(""cscope.out"")
        cs add cscope.out
        "" else add database pointed to by environment
    elseif $CSCOPE_DB != """"
        cs add $CSCOPE_DB
    endif
endif


Almost forgot... Just as ctags - you have to generate (and periodically update) the database. I use the following script

select_files > cscope.files
ctags -L cscope.files
ctags -e -L cscope.files
cscope -ub -i cscope.files


Where 'select_files' is another script that extracts the list of C and header files from the Makefile. This way I index only the files actually used by the project.
    You can add directories to your ctags lookup.  For example, I have a ctags index built for Qt4, and have this in my .vimrc:

set tags+=/usr/local/share/ctags/qt4

    All of the above and...

code_complete : function parameter complete, code snippets, and much more. 


http://www.vim.org/scripts/script.php?script_id=1764


taglist.vim : Source code browser (supports C/C++, java, perl, python, tcl, sql, php, etc) 


http://www.vim.org/scripts/script.php?script_id=273

    I use ALT-left and ALT-right to pop/push from/to the tag stack.

"" Alt-right/left to navigate forward/backward in the tags stack
map <M-Left> <C-T>
map <M-Right> <C-]>


If you use hjkl for movement you can map <M-h> and <M-l> instead.
    Several definitions of the same name

<C-w>g<C-]> open the definition in a split, but also do :tjump which either goes to the definition or, if there are several definitions, presents you with a list of definitions to choose from. 
    The command I am using most is C-] which jumps to the definition of the function under the cursor. You can use it more often to follow more calls. After that, C-o will bring you back one level, C-i goes deeper again.
    I've found the taglist plug-in a must-have. It lists all tags that it knows about (files that you have opened) in a seperate window and makes it very easy to navigate larger files.

I use it mostly for Python development, but it can only be better for C/C++.
    I've encapsulated tags manipulation in an experimental plugin of mine.

Regarding C++ development in vim, I've already answered there: I use my own suite, and a few other plugins.
    I've been adapting my vim plugins for two years to support big enough c++ project. You can take a look at them.

They use ctags and cscsope.

http://www.vim.org/scripts/script.php?script_id=1638
http://www.vim.org/scripts/script.php?script_id=2507
    I put the following in my .gvimrc file, which searches up the tree from any point for a tags file when gvim starts:

function SetTags()
    let curdir = getcwd()

    while !filereadable(""tags"") && getcwd() != ""/""
        cd ..
    endwhile

    if filereadable(""tags"")
        execute ""set tags="" . getcwd() . ""/tags""
    endif

    execute ""cd "" . curdir
endfunction

call SetTags()


I then periodically regenerate a tags file at the top of my source tree with a script that looks like:

#!/bin/bash

find . -regex "".*\.\(c\|h\|hpp\|cc\|cpp\)"" -print | ctags --totals --recurse --extra=""+qf"" --fields=""+i"" -L -

    I use vim in macos, and the original ctags doesn't work well, so I download newest and configure make make install it.
I install ctgas in /usr/local/bin/ctags(to keep original one)

""taglist
let Tlist_Ctags_Cmd = ""/usr/local/bin/ctags""
let Tlist_WinWidth = 50
map <leader>ta :TlistToggle<cr>
map <leader>bta :!/usr/local/bin/ctags -R .<CR>
set tags=tags;/
map <M-j> <C-]>
map <M-k> <C-T>

    I adapted the SetTags() search function above (which should be replaced by the equivalent set tags+=./tags;/) to work for cscope. Seems to work!

""cscope file-searching alternative
function SetCscope()
    let curdir = getcwd()

    while !filereadable(""cscope.out"") && getcwd() != ""/""
            cd ..
                endwhile

    if filereadable(""cscope.out"")
            execute ""cs add "" . getcwd() . ""/cscope.out""
                endif

    execute ""cd "" . curdir
    endfunction

call SetCscope()

    Another iteration on the SetCscope() function above. That sets cscope pre-path to get matches without being on the dir where ""cscope.out"" is:

function s:FindFile(file)
    let curdir = getcwd()
    let found = curdir
    while !filereadable(a:file) && found != ""/""
        cd ..
        let found = getcwd()
    endwhile
    execute ""cd "" . curdir
    return found
endfunction

if has('cscope')    
    let $CSCOPE_DIR=s:FindFile(""cscope.out"")
    let $CSCOPE_DB=$CSCOPE_DIR.""/cscope.out""
    if filereadable($CSCOPE_DB)
        cscope add $CSCOPE_DB $CSCOPE_DIR
    endif

    command -nargs=0 Cscope !cscope -ub -R &
endif

    ",,298269,702,2009-02-19T01:37:11,2016-02-02 12:53:56Z,
"Difference between ""@id/"" and ""@+id/"" in Android","
                

  What is the diffirence between the @id/ and @+id/?


In @+id/ the plus symbol + instructs to create a new resource name and add in to the R.java file but what about @id/? From the documentation of ID: when referencing an Android resource ID, you do not need the plus symbol, but must add the android package namespace, like so:

android:id=""@android:id/list""


But in the image below Eclipse doesn't suggest any kind of @android:id/.




  Are @id/ and @android:id/ the same? 

    In Short

android:id=""@+id/my_button""



  +id    Plus sign tells android to add or create a new id in Resources. 


while 

android:layout_below=""@id/my_button""



  it just help to refer the already generated id..

    Difference between @+id and @id is:


@+id is used to create an id for a view in R.java file.
@id is used to refer the id created for the view in R.java file.


We use @+id with android:id="""", but what if the id is not created and we are referring it before getting created(Forward Referencing).

In that case, we have use @+id to create id and while defining the view we have to refer it.

Please refer the below code:

<RelativeLayout>

     <TextView
        android:id=""@+id/dates""
        android:layout_width=""wrap_content""
        android:layout_height=""wrap_content""
        android:layout_alignParentLeft=""true""
        android:layout_toLeftOf=""@+id/spinner"" />

   <Spinner
     android:id=""@id/spinner""
     android:layout_width=""96dp""
     android:layout_height=""wrap_content""
     android:layout_below=""@id/dates""
     android:layout_alignParentRight=""true"" />

</RelativeLayout>


In the above code,id for Spinner @+id/spinner is created in other view and while defining the spinner we are referring the id created above.

So, we have to create the id if we are using the view before the view has been created.
    you refer to Android resources , which are already defined in Android system, with @android:id/.. while to access resources that you have defined/created in your project, you use @id/..

More Info

As per your clarifications in the chat, you said you have a problem like this :


  If we use android:id=""@id/layout_item_id"" it doesn't work.  Instead @+id/ works so what's the difference here?  And that was my original question.


Well, it depends on the context, when you're using the XML attribute of android:id, then you're specifying a new id, and are instructing the parser (or call it the builder) to create a new entry in R.java, thus you have to include a + sign.

While in the other case, like android:layout_below=""@id/myTextView"" , you're referring to an id that has already been created, so parser links this to the already created id in R.java.

More Info Again

As you said in your chat, note that android:layout_below=""@id/myTextView"" won't recognize an element with id myTextViewif it is written after the element you're using it in.
    the + sign is a short cut to add the id to your list of resource ids.  Otherwise you need to have them in a xml file like this

<?xml version=""1.0"" encoding=""utf-8""?>
<resources>
    <item name=""my_logo"" type=""id""/>
</resources>

    If the view item performs the same operation, you can use the @+id for each entry in any layout because during the compilation of multiple @+id/foo the R.java file only creates one enumeration.  So for example, if I have a save button on each page that performs the same operation, I use android:id=""@+id/button_save"" in each layout.  The R.java file only has one entry for the button_save.
    Its very simple:

""@+..."" - create new

""@..."" - link on existing

Source: https://developer.android.com/guide/topics/resources/layout-resource.html#idvalue
    From the Developer Guide:

android:id=""@+id/my_button""


The at-symbol (@) at the beginning of the string indicates that the XML parser should parse and expand the rest of the ID string and identify it as an ID resource. The plus-symbol (+) means that this is a new resource name that must be created and added to our resources (in the R.java file). There are a number of other ID resources that are offered by the Android framework. When referencing an Android resource ID, you do not need the plus-symbol, but must add the android package namespace, like so:

android:id=""@android:id/empty""
    
  The plus sign (+) before the resource type is needed only when you're defining a resource ID for the first time. When you compile the app, the SDK tools use the ID name to create a new resource ID in your project's R.java file that refers to the EditText element. With the resource ID declared once this way, other references to the ID do not need the plus sign. Using the plus sign is necessary only when specifying a new resource ID and not needed for concrete resources such as strings or layouts. See the sidebox for more information about resource objects.


From: https://developer.android.com/training/basics/firstapp/building-ui.html
    Android uses some files called resources where values are stored for the XML files.

Now when you use @id/ for an XML object, It is trying to refer to an id which is already registered in the values files. On the other hand, when you use @+id/ it registers a new id in the values files as implied by the '+' symbol.

Hope this helps :).
    Difference between “@+id/” and “@id/” in Android

The first one is used for to create the ID of the particular ui component and the another one is used for to refer the particular component
    There's a bug with Eclipse where sometimes if you just created a new @+id/.., it won't be added immediately to the R.java file, even after clean-building the project. The solution is to restart Eclipse.

This I think should be solved as soon as possible, because it may (and from experience, will) confuse some developers into thinking that there's something wrong with their syntax, and try to debug it even if there's really nothing to debug.
    @id/ and @android:id/ is not the same.

@id/ referencing ID in your application, @android:id/ referencing an item in Android platform.

Eclipse is wrong.
    ","[485, 47, 4, 368, 91, 2, 9, 6, 9, 4, 1, 4, 4]",236736,123,2011-02-17T06:52:31,2020-05-20 11:16:09Z,
MongoDB or CouchDB - fit for production? [closed],"
                    
            
        
            
                
                    
                        Closed. This question needs to be more focused. It is not currently accepting answers.
                        
                    
                
            
                Closed 7 years ago.
        

            
        
            
                    
                        
                    
                
                    
                        Locked. This question and its answers are locked because the question is off-topic but has historical significance. It is not currently accepting new answers or interactions.
                        
                    
                
            
        

    

I was wondering if anyone can tell me if MongoDB or CouchDB are ready for a production environment.  

I'm now looking at these storage solutions (I'm favouring MongoDB at the moment), however these projects are quite young and so I foresee that I'm going to have to work quite hard to convince my manager that we should adopt this new technology.

What I'd like to know is:


Who is using MongoDB or CouchDB today in a production environment?
How are you using MongoDB/CouchDB?
What problems (if any) did you come across when you adopted this new storage mechanism (and how did you overcome them)?
How did you deal with any migration issues that you had to deal with?
Do you have any good/bad experiences with either of these solutions that you'd like to share?

    I'm the CTO of 10gen (developers of MongoDB) so I'm a bit biased, but I also manage a few sites that are using MongoDB in production.

businessinsider has been using mongo in production for over a year now.  They are using it for everything from users and blog posts, to every image on the site.

shopwiki is using it for a few things including real time analytics and a caching layer. They are doing over 1000 writes per second to a fairly large database.

If you go to the mongodb Production Deployments page you'll see some people who are using mongo in production.

If you have any questions about the scale or scope of production deployments, post on our user list and we'll be more than happy to help.
    The BBC and meebo.com use CouchDB in production and so does one of my clients.
Here is a list of other people using Couch: CouchDB in the wild

The major challenge is to know how to organize your documents and stop thinking in terms of relational data.
    SourceForge uses MongoDB. See this presentation or read here.
    We are running CouchDB as a replacemant for MySQL for our shops (70.0000 items/shop, a total of 4 million attributes of all items, cross connections between items).

Our goals were:


Easy replication from a master-db to several clients with different documents.
Fast pre-calculated data like ""how many parts do I have with this attribute and that filter, fitting to those conditions""


facts: 


Our shops are now running much faster than with MySQL (and mysql-database needed additionaly  1-3 days of pre-calculating (so updating was twice a month), making the data ready for product counting and filtering, CouchDB needs 5 hours, so we could update product data every night)
Setting up (filtered) data distribution & backups to the shop nodes is fast and easy


but also:


Understanding map/reduce and the limits of not having joins is quite hard
No operation on data like ""delete where"" or ""update where"" without external programs 
Replication works well, unless there is a problem; then it's really hard to find out what was the reason (for beginners)
The installation of CouchDB without binaries (yes there are a some in the wild, but not for every OS/version) could be hard, if you are not a Linux geek. But the CouchDB Community is helpful (#couchdb), and luckily there are companies out there (cloudant, iriscouch) that offer services from free to big business.
CouchDB is moving forward, so there are a lot of changes (improvements) going on that might change they way you work. But basic things remain stable. 


As a result:
MySQL as a database for data creation and maintaining is reliable and easy to understand and handle. I think we will not change this. 
But I also don't want to miss the power of CouchDB views and the ease of replication setup.

Production couches sometimes caused trouble after months of work due to misconfiguration and forgotten logrotates (view building takes too long or hangs, replication stops), but never lost data, and always could be easily reset.
    I am using CouchDB in production. Currently it stores all those 'optional' fields that weren't in the original DB schema. And right now I am thinking about moving all data to CouchDB. 

It's quite a risky step, I admit. Firstly, because it's not v1.0 yet. And secondly, because it is drivespace-hungry. By my calculations, CouchDB file (with indexes) is ~30 times larger than MySQL database with the same rows. 
But I am pretty sure it will work out just fine.
    CouchDB 0.11 (released at the end of March) is a feature-freeze release for 1.0. This means we'll be maintaining compatibility with the current API for 1.0, so now is a good time to take another look at CouchDB if you haven't in a while.

The CouchDB 0.11 source code release is available here. There are binary installers and other goodies linked here.
    I don't know anything about MongoDB, but from the CouchDB FAQ:


  Is CouchDB Ready for Production?
  
  Yes, see InTheWild for a partial list of projects using CouchDB. Another good overview is CouchDB Case Studies


Also, some links:


Re: Current CouchDB state?
SimpleDB, CouchDB and Other ""NEW"" Data Stores - Feedback

    We use couchdb in production and have since just before the project went under the Apache umbrella.

We use it to store everything that we might otherwise use a dbms, plus all sorts of unstructured data.  Personally, I really like how you can just throw all sorts of data into it and use the views to cull what you don't need depending on the situation.

The hardest part was moving away from the dbms mindset.  We wrote our own migration utils when the storage format changed just to be safe, so that wasn't really a problem.

We haven't had any negative experiences yet, but then again we haven't had the setup under any kind of huge load.  I think things would work pretty well since we have two slave type servers that replicate from a single master server that gets all of the writes.  I'm pretty sure that we don't have to do it that way for replication to work correctly, but it's how we set it up in the beginning and it stuck.
    We use CouchDB to store mobile inbound and outbound messages and to report on this traffic via some custom views that I wrote.  The front-end is written in Python.  We did not have any real technical issues, and it has been running since the end of December.  The only hurdle I encountered was initially thinking in terms of MapReduce, but once I learned how to do that, everything else went smoothly.
    We are currently using MongoDB in production as the caching layer as well as storage engine for product importing and manipulating product data. We are an eCommerce company managing over two million products (100+ million attributes), spanning 10+ distributors and without MongoDB, this task would be nearing impossible.
    We are currently using mongodb as an file storage service for our collaboration over LAN.
Also, projects like trello are using mongodb as their backend datastore.
I have used couchdb earlier, but not in production capacity.
    We are using MongoDB in production in our mobile backend service namely Netmera. We are using it to store all user and content data.
    I have been using CouchDB in production for almost 2 years now. There's no migration work as the project started of directly with CouchDB implementation. It serves as a database that stores the data of a single electronic product from beginning till packaging.

Since we are selling sensor with a demand on high accuracy, we do a lot of test at different stage and all these will be stored into one document on CouchDB.

There's some learning curve that I learnt from my experience, which is to make full use of the views (or also known as permanent views). Views should be ""small filter"" of a fraction of the Database that will be called often.

My CouchDB databse is not as crazy as other gigantic company. But so far, I'm still doing fine. Currently I'm having 24000 documents at 700MB. 

Feature from CouchDB that I like is 'replication', 'store revisions of a document'.

I'd read a lot of good reviews on MongoDB and I will want to try it if there's a chance. 
    We are using mongodb in production for 

www.beachfront.io - close to 5k write request per sec
www.beachfrontbuilder.com - 500 read/write request per sec, maintain 10m users data & olap.

The only challenge faced around archiving of data, we overcome by implementing our custom component. 
    This question has already accepted answer but now a days one more NoSQL DB is in trend for many of its great features. It is Couchbase; which runs as CouchbaseLite on mobile platform and Couchbase Server on your server side.

Here is some of main features of Couchbase Lite.

Couchbase Lite is a lightweight, document-oriented (NoSQL), syncable database engine suitable for embedding into mobile apps.

Lightweight means:

Embedded—the database engine is a library linked into the app, not a separate server process.
Small code size—important for mobile apps, which are often downloaded over cell networks.
Quick startup time—important because mobile devices have relatively slow CPUs.
Low memory usage—typical mobile data sets are relatively small, but some documents might have large multimedia attachments.
Good performance—exact figures depend on your data and application, of course.

Document-oriented means:

Stores records in flexible JSON format instead of requiring predefined schemas or normalization.
Documents can have arbitrary-sized binary attachments, such as multimedia content.
Application data format can evolve over time without any need for explicit migrations.
MapReduce indexing provides fast lookups without needing to use special query languages.

Syncable means:

Any two copies of a database can be brought into sync via an efficient, reliable, proven replication algorithm.
Sync can be on-demand or continuous (with a latency of a few seconds).
Devices can sync with a subset of a large database on a remote server.
The sync engine supports intermittent and unreliable network connections.
Conflicts can be detected and resolved, with app logic in full control of merging.
Revision trees allow for complex replication topologies, including server-to-server (for multiple data centers) and peer-to-peer, without data loss or false conflicts.
Couchbase Lite provides native APIs for seamless iOS (Objective-C) and Android (Java) development. In addition, it includes the Couchbase Lite Plug-in for PhoneGap, which enables you to build iOS and Android apps that you develop by using familiar web-application programming techniques and the PhoneGap mobile development framework.

You can explore more on Couchbase Lite

and  Couchbase Server

This is going to the next big thing.
    Speaking production,  seamless failover/recovery  both require a baby sitter 
1- Couchbase, there is no seamless failover/recovery, manual intervention is required. rebalancing takes too much time, too much risk if more than one node get lost. 

2- Mongo with shards, data recovery from loosing a config server, is not an easy task
    Adobe is using MongoDB for their upcoming release of Adobe Experience Manager (formerly Day CQ) as the core DB engine.

Several client's at the agency I work at are using CouchDB on projects for large clients.

Both are great and viable DBs, in my opinion.  :)
    Here's a list of production deployed sites with mongoDB


The New Yorks Times: Using it in a form-building application for photo submissions. Mongo's lack of schema gives producers the ability to define any combination of custom form fields.
SourceForge: is used for back-end storage on the SourceForge front pages, project pages, and download pages for all projects.
Bit.ly
Etsy
IGN: powers IGN’s real-time traffic analytics and RESTful Content APIs.
Justin.tv: powers Justin.tv's internal analytics tools for virality, user retention, and general usage stats that out-of-the-box solutions can't provide.
Posterous
Intuit
Foursquare: Sharded Mongo databases are used for most data at foursquare.
Business Insider: Using it since the beginning of 2008. All of the site's data, including posts, comments, and even the images, are stored on MongoDB.
Github: is used for an internal reporting application.
Examiner: migrated their site from Cold Fusion and SQL Server to Drupal 7 and MongoDB.
Grooveshark: currently uses Mongo to manage over one million unique user sessions per day.
Buzzfeed
Discus
Evite: Used for analytics and quick reporting.
Squarespace
Shutterfly: is used for various persistent data storage requirements within Shutterfly. MongoDB helps Shutterfly build an unrivaled service that enables deeper, more personal relationships between customers and those who matter most in their lives.
Topsy
Sharethis
Mongohq: provides a hosting platform for MongoDB and also uses MongoDB as the back-end for its service. Our hosting centers page provides more information about MongoHQ and other MongoDB hosting options.


and more...

Extracted from:
http://lineofthought.com/tools/mongodb

You can check other databases or tools there too.
    MongoDB has some issues with licensing to businesses, I am not sure of the details but our legal department told us in no certain terms that we were not allowed to use MongoDB in any of our products. 
    ",,131485,203,2009-05-21T23:22:23,2014-08-05 06:41:08Z,
Google Chrome redirecting localhost to https,"
                
When I debug a Visual Studio project using Chrome the browser tries to redirect to the https equivalent of my web address. I do not have SSL enabled in the web project and the start URL is the http URL.  When I debug using FireFox or IE I do not have this problem.

I did re-install Chrome which fixed the problem for a day.  Without downloading any addons the problem happened again the next day.

What is making Chrome redirect localhost to https?

Network Inspect Shows:
Request URL:data:text/html,chromewebdata
Request Headers
Provisional headers are shown
User-Agent:Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1985.143 Safari/537.36

No preview and no response data in those tabs.
    I believe this is caused by HSTS - see http://en.wikipedia.org/wiki/HTTP_Strict_Transport_Security

If you have (developed) any other localhost sites which send a HSTS header...

eg. Strict-Transport-Security: max-age=31536000; includeSubDomains; preload

...then depending on the value of max-age, future requests to localhost will be required to be served over HTTPS.  

To get around this, I did the following. 


In the Chrome address bar type ""chrome://net-internals/#hsts""
At the very bottom of a page is QUERY domain textbox - verify that localhost is known to the browser. If it says ""Not found"" then this is not the answer you are looking for.
If it is, DELETE the localhost domain using the textbox above
Your site should now work using plain old HTTP


This is not a permanent solution, but will at least get it working between projects. If anyone knows how to permanently exclude localhost from the HSTS list please let me know :)

UPDATE - November 2017

Chrome has recently moved this setting to sit under Delete domain security policies



UPDATE - December 2017
If you are using .dev domain see other answers below as Chrome (and others) force HTTPS via preloaded HSTS.
    Go to
chrome://net-internals/#hsts 

Enter localhost under Delete domain security policies and press the Delete button.
Now go to
chrome://settings/clearBrowserData 

tick the box Cached images and files and press click the button Clear data.
    I experienced the same problem in Chrome and I tried unsuccessfully to use BigJump's solution. 

I fixed my problem by forcing a hard refresh, as shown in this blog (originally from this SuperUser answer).

Ensure your address bar is using the http scheme and then go through these steps, possibly a couple of times:


Open the Developer Tools panel (CTRL+SHIFT+I)   
Click and hold the reload icon / Right click the reload icon.       
A menu will open.       
Choose the 3rd option from this menu (""Empty Cache and Hard Reload"")

    NEW DEVELOPMENTS! (if you have Chrome 63+)
If your localhost domain is .dev then I don't think the previously accepted answer works. The reason why is because since Chrome 63, Chrome will force .dev domains to HTTPS via preloaded HSTS.
What this means is, .dev basically won't work at all anymore unless you have proper signed SSL certificate -- no more self signed certificates allowed! Learn more at this blog post.
So to fix this issue now and to avoid this happening again in the future .test is one recommended domain because it is reserved by IETF for testing / dev purposes. You should also be able to use .localhost for local dev.
    Open Chrome Developer Tools -> go to Network -> select Disable Cache -> reload 
    Piggybacking off Adiyat Mubarak

Could not hard refresh as it was just refreshing on https. Follows some of the same steps. 

1. Open chrome developer tools (ctrl + shift + i)
2. Network Tab at the top
3. Click Disable cache checkbox at the top (right under network tab for me).
4. Refresh page (while the developer tools is still open)

    A lazy and fast solution for lazy people like me (working in Chrome 67). 

Just launch another Chrome window in Stealth Mode, with the ""Incognito Window"" option (CTRL + SHIFT + N). No need to delete cache, no need to dive into deep Chrome settings, etc.
    I also have been struggling with this issue. Seems that HSTS is intended for only domain names. So if you are developing in local machine, it much easier to use IP address. So I switched from localhost to 127.0.0.1
    This can be caused by a cached https redirect, and can be fixed by clearing the cache manually as in Adiyat Mubarak's answer.

But if you are visiting localhost you likely are a developer, in which case you will find a cache clearing chrome extension such as ""classic cache killer"" (see e.g. https://chrome.google.com/webstore/search/classic%20cache%20killer?hl=en) useful in a variety of situations, and likely already have one installed.  

So the quick fix is: Install a cache killer (if you don't have one already), turn it on, and reload the page.  Done! 
    from https://galaxyinternet.us/google-chrome-redirects-localhost-to-https-fix/

None of the option fixes worked for me, for fixing https://localhost:3000, this did.

click and hold Reload Button and select Empty Cache and Hard Reload, this seems to only be an option on localhost
    How I solved this problem with chrome 79:

Just paste this url in you search input chrome://flags/#allow-insecure-localhost

It helped me by using experimental features.
    Unfortunately, none of the solution listed here helped me to resolve this issue.  I fixed this issue by using http://127.0.0.1 (ip address) instead of http://localhost.  A quick little hack to work with angular development with chrome browser.
    Tried everything mentioned (browser preferences, hsts, etc.) but nothing worked for me.
I solved it by adding a trailing .localhost to the host aliases.
Like this:
127.0.0.1    myproject.localhost
127.0.0.1    dev.project.localhost

    I never figured out the root of the problem however I was able to fix this problem.
I deleted the Google Chrome app cache folder which solved the problem.

C:\Users[users]\AppData\Local\Google\Chrome
    A simple solution to this is to edit your /etc/hosts file and establish one alias per project.

127.0.0.1   project1 project2 project3


These domainless names will never have the problem with HSTS unless you send the HSTS response mentioned by @bigjump and with the added benefit of maintaining your login session if you change back and forth between projects.
    I am facing the same problem but only in Chrome Canary and searching a solution I've found this post.


  one of the next versions of Chrome is going to force all domains ending on .dev (and .foo) to be redirected to HTTPs via a preloaded HTTP Strict Transport Security (HSTS) header.


{ ""name"": ""dev"", ""include_subdomains"": true, ""mode"": ""force-https"" },
{ ""name"": ""foo"", ""include_subdomains"": true, ""mode"": ""force-https"" },


So, change your domains.
    In my case, I had my project path set as /Users/me/dev/project_root/ and was running the nodeJS/express server from there.
Renaming my path to /Users/me/project_root (removing dev from the path to project) resolved the issue.

Most likely has to do with this new regulation:


  Chrome 63 (out since December 2017), will force all domains ending on .dev (and .foo) to be redirected to HTTPS via a preloaded HTTP Strict Transport Security (HSTS) header. 


You can find more information about this here.

Using:


Google Chrome Version 70.0.3538.110 (Official Build) (64-bit)
nodeJS v9.2.0

    Chrome 63 (out since December 2017), will force all domains ending on .dev (and .foo) to be redirected to HTTPS via a preloaded HTTP Strict Transport Security (HSTS) header. You can find more information about this here.
    None of these worked for me. It started happening after a chrome update (Version 63.0.3239.84, linux) with a local URL. Would always redirect to https no matter what. Lost some hours and a lot of patience on this

What did worked after all was just changing the domain. 

For what is worth, the domain was .app. Perhaps it got something to do? And just changed it to .test and chrome stopped redirecting it
    Go to settings in Chrome and then to Advanced settings, under privacy and security section click Clear browsing data and then clear all data. I followed these steps and it worked for me. Hope it helps some one.
    For someone who had the same problem I solved by pressing CTRL + SHIFT + DELETE to delete just the entire browser cache. Now I can access my localhost website on HTTP protocol.
    @Adiyat Mubarak answer did not work for me. When I attempted to clear the cache and hard-reload, the page still redirected to https. 

My solution: In the upper right-hand corner of the url bar (just to the left of the favorites star icon) there is an icon with an ""x"" through it.  Right-click on that, and it will say something about ""unsafe scripts"", then there is an option to load them anyway. Do that.
    Another option would be to use something like https://github.com/rchampourlier/tunnelss 

Sure it added another dependency / setup, but it also enables testing of https in dev, which could be nice.

I use RVM however to get tunnelss working I had to use sudo gem install tunnelss and sudo tunnelss
    That's the fastest solution today (17-3-2018):

Close all Chrome tabs / windows and run on your command line this: (or add it as a shortcode)

""C:\Program Files (x86)\Google\Chrome\Application\chrome.exe"" --ignore-certificate-errors

    Chrome 63 forces .dev domains automatic to HTTPS via preloaded HSTS. 
Quick fix: just change the .dev domains to .localhost. 
    This is not a solution, it's just a workaround.


Click on your visual studio project (top level) in the solution explorer and go to the properties window.
Change SSL Enabled to true. You will now see another port number as 'SSL URL' in the properties window.  
Now, when you run your application (or view in browser), you have to manually change the port number to the SSL port number in the address bar.


Now it works fine as a SSL link
    The issue could be replicated in VS 2019 also. This is caused due to ""Enable Javascript debugging from Visual Studio IDE"". The VS attaches to Chrome and it is a possibility that due to security or reasons known to Google and Microsoft, it sometimes fails to attach and you have this issue. I am able to run http and https with localhost from ASP net core 3.1 app. So while debugging in VS, go to the run with arrow -> IIS express, just below ""Web Browser(Chrome)"" select ""Script Debugging (Disabled)"".
See article: https://devblogs.microsoft.com/aspnet/client-side-debugging-of-asp-net-projects-in-google-chrome/
https://docs.microsoft.com/en-us/visualstudio/debugger/debugging-web-applications?view=vs-2019
Always fallback to Microsoft docs to get more clarity than googling an issue.
    For me, the following worked in Chrome 90. My app opened up a local webpack server on localhost:3000 which automatically redirected to HTTPS, and I got ERR_SSL_PROTOCOL_ERROR.
I clicked on the little info icon next to the URL, opened up the Site Settings from the menu dropdown. In the list, the Insecure content was set to Block (default).
I changed this to Allow, and just reloaded the http version and it loaded fine.
Hope this will help people out.
    I could not get any solution to work; but a redirect in my web.config allowed me to continue to work (localhost) until I find what is causing the issue.
This is essentially a rewrite rule that turns HTTPS to HTTP; it seems to have overwritten the previous rule that redirected HTTP to HTTPS.
It needs to be within your <system.webServer> </system.webServer> section in web.config
    <rewrite>
  <rules>
    <clear />
    <rule name=""Redirect to https"" stopProcessing=""true"">
      <match url="".*"" />
      <conditions>
        <add input=""{HTTP}"" pattern=""off"" ignoreCase=""true"" />
      </conditions>
      <action type=""Redirect"" url=""http://{HTTP_HOST}{REQUEST_URI}"" redirectType=""Permanent"" appendQueryString=""false"" />
    </rule>
  </rules>
</rewrite>

    In my case I was using browser-sync on a Mac and the browser kept redirecting http://localhost:3000 to https://localhost:3000.
I am using Valet to serve local sites, and I had run valet secure on the local *.test domain to give it a SSL cert. Because I was proxying this HTTPS domain in browser-sync, the browser was loading localhost:3000 with HTTPS.
To fix it I had to:

run valet unsecure to remove the SSL cert
run valet restart
restart browser-sync
open localhost:3000 in the browser (Vivaldi in my case which is a Chromium browser)
Open Developer Tools
Tick ""Disable Cache"" on the Network tab
Refresh the page

    ","[484, 821, 34, 372, 211, 19, 79, 12, 17, 7, 17, 9, 4, 2, 7, 3, 48, 1, 18, 5, 0, -1, -2, -2, -4, 0, 0, 0, 0, 0, 0]",307103,168,2014-08-13T03:14:44,2022-04-18 12:13:11Z,
How to convert a Bitmap to Drawable in android?,"
                
How can I convert a Bitmap image to Drawable ?
    Try this it converts a Bitmap type image to Drawable

Drawable d = new BitmapDrawable(getResources(), bitmap);

    1) bitmap to Drawable  :

Drawable mDrawable = new BitmapDrawable(getResources(), bitmap);
// mImageView.setDrawable(mDrawable);


2) drawable to Bitmap :

Bitmap mIcon = BitmapFactory.decodeResource(context.getResources(),R.drawable.icon_resource);
// mImageView.setImageBitmap(mIcon);

    Sounds like you want to use BitmapDrawable

From the documentation:


  A Drawable that wraps a bitmap and can
  be tiled, stretched, or aligned. You
  can create a BitmapDrawable from a
  file path, an input stream, through
  XML inflation, or from a Bitmap
  object.

    Having seen a large amount of issues with bitmaps incorrectly scaling when converted to a BitmapDrawable, the general way to convert should be:

Drawable d = new BitmapDrawable(getResources(), bitmap);


Without the Resources reference, the bitmap may not render properly, even when scaled correctly. There are numerous questions on here which would be solved simply by using this method rather than a straight call with only the bitmap argument.
    Offical Bitmapdrawable documentation

This is sample on how to convert bitmap to drawable

Bitmap bitmap;  
//Convert bitmap to drawable
Drawable drawable = new BitmapDrawable(getResources(), bitmap);
imageView.setImageDrawable(drawable);

    If you have a bitmap image and you want to use it in drawable, like

Bitmap contact_pic;    //a picture to show in drawable
drawable = new BitmapDrawable(contact_pic); 

    I used with context

//Convert bitmap to drawable
Drawable drawable = new BitmapDrawable(context.getResources(), bitmap);

    here's another one:

Drawable drawable = RoundedBitmapDrawableFactory.create(context.getResources(), bitmap);

    Just do this:

private void setImg(ImageView mImageView, Bitmap bitmap) {

    Drawable mDrawable = new BitmapDrawable(getResources(), bitmap);
    mImageView.setDrawable(mDrawable);
}

    And you can try this:
public static Bitmap mirrorBitmap(Bitmap bInput)
    {
        Bitmap  bOutput;
        Matrix matrix = new Matrix();
        matrix.preScale(-1.0f, 1.0f);
        bOutput = Bitmap.createBitmap(bInput, 0, 0, bInput.getWidth(), bInput.getHeight(), matrix, true);
        return bOutput;
    }

    covert bit map to drawable in sketchware app using code

    android.graphics.drawable.BitmapDrawable d = new android.graphics.drawable.BitmapDrawable(getResources(), bitmap);

    For Kotlin users:
Kotlin has a function for converting Bitmap to BitmapDrawable:
Bitmap.toDrawable(resources)
    ","[484, 875, 17, 280, 158, 36, 20, 32, 1, 11, -1, 0, 0]",377513,82,2010-03-10T09:09:06,2022-02-10 16:27:25Z,
What's the best way to detect a 'touch screen' device using JavaScript?,"
                
I've written a jQuery plug-in that's for use on both desktop and mobile devices. I wondered if there is a way with JavaScript to detect if the device has touch screen capability. I'm using jquery-mobile.js to detect the touch screen events and it works on iOS, Android etc., but I'd also like to write conditional statements based on whether the user's device has a touch screen.

Is that possible?
    UPDATE 2021
To see the old answers: check the history. I decided to start on a clean slate as it was getting out of hands when keeping the history in the post.
My original answer said that it could be a good idea to use the same function as Modernizr was using, but that is not valid anymore as they removed the ""touchevents"" tests on this PR: https://github.com/Modernizr/Modernizr/pull/2432 due to it being a confusing subject.
With that said this should be a fairly ok way of detecting if the browser has ""touch capabilities"":
function isTouchDevice() {
  return (('ontouchstart' in window) ||
     (navigator.maxTouchPoints > 0) ||
     (navigator.msMaxTouchPoints > 0));
}

But for more advanced use cases far more smarter persons than me have written about this subject, I would recommend reading those articles:

Stu Cox: You Can't Detect a Touchscreen
Detecting touch: it's the 'why', not the 'how'
Getting touchy presentation by Patrick H. Lauke

    Since the introduction of interaction media features you simply can do:

if(window.matchMedia(""(pointer: coarse)"").matches) {
    // touchscreen
}


https://www.w3.org/TR/mediaqueries-4/#descdef-media-any-pointer

Update (due to comments): The above solution is to detect if a ""coarse pointer"" - usually a touch screen - is the primary input device. In case you want to dectect if a device with e.g. a mouse also has a touch screen you may use any-pointer: coarse instead.

For more information have a look here: Detecting that the browser has no mouse and is touch-only
    I like this one:
function isTouchDevice(){
    return window.ontouchstart !== undefined;
}

alert(isTouchDevice());

    The biggest ""gotcha"" with trying to detect touch is on hybrid devices that support both touch and the trackpad/mouse. Even if you're able to correctly detect whether the user's device supports touch, what you really need to do is detect what input device the user is currently using. There's a detailed write up of this challenge and a possible solution here. 

Basically the approach to figuring out whether a user just touched the screen or used a mouse/ trackpad instead is to register both a touchstart and mouseover event on the page:

document.addEventListener('touchstart', functionref, false) // on user tap, ""touchstart"" fires first
document.addEventListener('mouseover', functionref, false) // followed by mouse event, ie: ""mouseover""


A touch action will trigger both of these events, though the former (touchstart) always first on most devices. So counting on this predictable sequence of events, you can create a mechanism that dynamically adds or removes a can-touch class to the document root to reflect the current input type of the user at this moment on the document:

;(function(){
    var isTouch = false //var to indicate current input type (is touch versus no touch) 
    var isTouchTimer 
    var curRootClass = '' //var indicating current document root class (""can-touch"" or """")
     
    function addtouchclass(e){
        clearTimeout(isTouchTimer)
        isTouch = true
        if (curRootClass != 'can-touch'){ //add ""can-touch' class if it's not already present
            curRootClass = 'can-touch'
            document.documentElement.classList.add(curRootClass)
        }
        isTouchTimer = setTimeout(function(){isTouch = false}, 500) //maintain ""istouch"" state for 500ms so removetouchclass doesn't get fired immediately following a touch event
    }
     
    function removetouchclass(e){
        if (!isTouch && curRootClass == 'can-touch'){ //remove 'can-touch' class if not triggered by a touch event and class is present
            isTouch = false
            curRootClass = ''
            document.documentElement.classList.remove('can-touch')
        }
    }
     
    document.addEventListener('touchstart', addtouchclass, false) //this event only gets called when input type is touch
    document.addEventListener('mouseover', removetouchclass, false) //this event gets called when input type is everything from touch to mouse/ trackpad
})();


More details here.
    There is something better than checking if they have a touchScreen, is to check if they are using it, plus that's easier to check.

if (window.addEventListener) {
    var once = false;
    window.addEventListener('touchstart', function(){
        if (!once) {
            once = true;
            // Do what you need for touch-screens only
        }
    });
}

    As Modernizr doesn't detect IE10 on Windows Phone 8/WinRT, a simple, cross-browser solution is:

var supportsTouch = 'ontouchstart' in window || navigator.msMaxTouchPoints;


You only ever need to check once as the device won't suddenly support or not support touch, so just store it in a variable so you can use it multiple times more efficiently.
    I think the best method is:
var isTouchDevice =
    (('ontouchstart' in window) ||
    (navigator.maxTouchPoints > 0) ||
    (navigator.msMaxTouchPoints > 0));
if(!isTouchDevice){
    /* Code for touch device /*
}else{
    /* Code for non touch device */
}

    Right so there is a huge debate over detecting touch/non-touch devices. The number of window tablets and the size of tablets is increasing creating another set of headaches for us web developers.
I have used and tested blmstr's answer for a menu. The menu works like this: when the page loads the script detects if this is a touch or non touch device. Based on that the menu would work on hover (non-touch) or on click/tap (touch).
In most of the cases blmstr's scripts seemed to work just fine (specifically the 2018 one). BUT there was still that one device that would be detected as touch when it is not or vice versa.
For this reason I did a bit of digging and thanks to this article I replaced a few lines from blmstr's 4th script into this:
function is_touch_device4() {
    if (""ontouchstart"" in window)
        return true;

    if (window.DocumentTouch && document instanceof DocumentTouch)
        return true;


    return window.matchMedia( ""(pointer: coarse)"" ).matches;
}

alert('Is touch device: '+is_touch_device4());
console.log('Is touch device: '+is_touch_device4());

Because of the lockdown have a limited supply of touch devices to test this one but so far the above works great.
I would appreceate if anyone with a desktop touch device (ex. surface tablet) can confirm if script works all right.
Now in terms of support the pointer: coarse media query seems to be supported. I kept the lines above since I had (for some reason) issues on mobile firefox but the lines above the media query do the trick.
Thanks
    Using all the comments above I've assembled the following code that is working for my needs:

var isTouch = (('ontouchstart' in window) || (navigator.msMaxTouchPoints > 0));


I have tested this on iPad, Android (Browser and Chrome), Blackberry Playbook, iPhone 4s, Windows Phone 8, IE 10, IE 8, IE 10 (Windows 8 with Touchscreen), Opera, Chrome and Firefox.

It currently fails on Windows Phone 7 and I haven't been able to find a solution for that browser yet.

Hope someone finds this useful.
    Actually, I researched this question and consider all situations. because it is a big issue on my project too. So I reach the below function, it works for all versions of all browsers on all devices:

const isTouchDevice = () => {
  const prefixes = ['', '-webkit-', '-moz-', '-o-', '-ms-', ''];
  const mq = query => window.matchMedia(query).matches;

  if (
    'ontouchstart' in window ||
    (window.DocumentTouch && document instanceof DocumentTouch)
  ) {
    return true;
  }
  return mq(['(', prefixes.join('touch-enabled),('), 'heartz', ')'].join(''));
};


Hint: Definitely, the isTouchDevice just returns boolean values.
    The problem
Due to hybrid devices which use a combination of touch and mouse input, you need to be able dynamically change the state / variable which controls whether a piece of code should run if the user is a touch user or not.
Touch devices also fire mousemove on tap.
Solution

Assume touch is false on load.
Wait until a touchstart event is fired, then set it to true.
If touchstart was fired, add a mousemove handler.
If the time between two mousemove events firing was less than 20ms, assume they are using a mouse as input. Remove the event as it's no longer needed and mousemove is an expensive event for mouse devices.
As soon as touchstart is fired again (user went back to using touch), the variable is set back to true. And repeat the process so it's determined in a dynamic fashion. If by some miracle mousemove gets fired twice on touch absurdly quickly (in my testing it's virtually impossible to do it within 20ms), the next touchstart will set it back to true.

Tested on Safari iOS and Chrome for Android.
Note: not 100% sure on the pointer-events for MS Surface, etc.
Codepen demo

const supportsTouch = 'ontouchstart' in window;
let isUsingTouch = false;

// `touchstart`, `pointerdown`
const touchHandler = () => {
  isUsingTouch = true;
  document.addEventListener('mousemove', mousemoveHandler);
};

// use a simple closure to store previous time as internal state
const mousemoveHandler = (() => {
  let time;
  
  return () => {
    const now = performance.now();

    if (now - time < 20) {
      isUsingTouch = false;
      document.removeEventListener('mousemove', mousemoveHandler);
    }

    time = now;
  }
})();

// add listeners
if (supportsTouch) {
  document.addEventListener('touchstart', touchHandler);
} else if (navigator.maxTouchPoints || navigator.msMaxTouchPoints) {
  document.addEventListener('pointerdown', touchHandler);
}

    Many of these work but either require jQuery, or javascript linters complain about the syntax. Considering your initial question asks for a ""JavaScript"" (not jQuery, not Modernizr) way of solving this, here's a simple function that works every time. It's also about as minimal as you can get.

function isTouchDevice() {
    return !!window.ontouchstart;
}

console.log(isTouchDevice());


One last benefit I'll mention is that this code is framework and device agnostic. Enjoy!
    All browser supported except Firefox for desktop always TRUE because of Firefox for desktop support responsive design for developer even you click Touch-Button or not!

I hope Mozilla will fix this in next version.

I'm using Firefox 28 desktop.

function isTouch()
{
    return !!(""ontouchstart"" in window) || !!(navigator.msMaxTouchPoints);
}

    jQuery v1.11.3

There is a lot of good information in the answers provided.  But, recently I spent a lot of time trying to actually tie everything together into a working solution for the accomplishing two things:


Detect that the device in use is a touch screen type device.
Detect that the device was tapped.


Besides this post and Detecting touch screen devices with Javascript, I found this post by Patrick Lauke extremely helpful: https://hacks.mozilla.org/2013/04/detecting-touch-its-the-why-not-the-how/

Here is the code...

$(document).ready(function() {
//The page is ""ready"" and the document can be manipulated.

    if (('ontouchstart' in window) || (navigator.maxTouchPoints > 0) || (navigator.msMaxTouchPoints > 0))
    {
      //If the device is a touch capable device, then...
      $(document).on(""touchstart"", ""a"", function() {

        //Do something on tap.

      });
    }
    else
    {
      null;
    }
});


Important!  The *.on( events [, selector ] [, data ], handler ) method needs to have a selector, usually an element, that can handle the ""touchstart"" event, or any other like event associated with touches.  In this case, it is the hyperlink element ""a"".

Now, you don't need to handle the regular mouse clicking in JavaScript, because you can use CSS to handle these events using selectors for the hyperlink ""a"" element like so:

/* unvisited link */
a:link 
{

}

/* visited link */
a:visited 
{

}

/* mouse over link */
a:hover 
{

}

/* selected link */
a:active 
{

}


Note:  There are other selectors as well...
    If you use Modernizr, it is very easy to use Modernizr.touch as mentioned earlier.

However, I prefer using a combination of Modernizr.touch and user agent testing, just to be safe.

var deviceAgent = navigator.userAgent.toLowerCase();

var isTouchDevice = Modernizr.touch || 
(deviceAgent.match(/(iphone|ipod|ipad)/) ||
deviceAgent.match(/(android)/)  || 
deviceAgent.match(/(iemobile)/) || 
deviceAgent.match(/iphone/i) || 
deviceAgent.match(/ipad/i) || 
deviceAgent.match(/ipod/i) || 
deviceAgent.match(/blackberry/i) || 
deviceAgent.match(/bada/i));

if (isTouchDevice) {
        //Do something touchy
    } else {
        //Can't touch this
    }


If you don't use Modernizr, you can simply replace the Modernizr.touch function above with ('ontouchstart' in document.documentElement)

Also note that testing the user agent iemobile will give you broader range of detected Microsoft mobile devices than Windows Phone.

Also see this SO question
    We tried the modernizr implementation, but detecting the touch events is not consistent anymore (IE 10 has touch events on windows desktop, IE 11 works, because the've dropped touch events and added pointer api). 

So we decided to optimize the website as a touch site as long as we don't know what input type the user has. This is more reliable than any other solution.

Our researches say, that most desktop users move with their mouse over the screen before they click, so we can detect them and change the behaviour before they are able to click or hover anything.

This is a simplified version of our code:

var isTouch = true;
window.addEventListener('mousemove', function mouseMoveDetector() {
    isTouch = false;
    window.removeEventListener('mousemove', mouseMoveDetector);
});

    This one works well even in Windows Surface tablets !!!  

function detectTouchSupport {
msGesture = window.navigator && window.navigator.msPointerEnabled && window.MSGesture,
touchSupport = (( ""ontouchstart"" in window ) || msGesture || window.DocumentTouch &&     document instanceof DocumentTouch);
if(touchSupport) {
    $(""html"").addClass(""ci_touch"");
}
else {
    $(""html"").addClass(""ci_no_touch"");
}
}

    I used pieces of the code above to detect whether touch, so my fancybox iframes would show up on desktop computers and not on touch. I noticed that Opera Mini for Android 4.0 was still registering as a non-touch device when using blmstr's code alone. (Does anyone know why?) 

I ended up using:

<script>
$(document).ready(function() {
    var ua = navigator.userAgent;
    function is_touch_device() { 
        try {  
            document.createEvent(""TouchEvent"");  
            return true;  
        } catch (e) {  
            return false;  
        }  
    }

    if ((is_touch_device()) || ua.match(/(iPhone|iPod|iPad)/) 
    || ua.match(/BlackBerry/) || ua.match(/Android/)) {
        // Touch browser
    } else {
        // Lightbox code
    }
});
</script>

    Check out this post, it gives a really nice code snippet for what to do when touch devices are detected or what to do if touchstart event is called:

$(function(){
  if(window.Touch) {
    touch_detect.auto_detected();
  } else {
    document.ontouchstart = touch_detect.surface;
  }
}); // End loaded jQuery
var touch_detect = {
  auto_detected: function(event){
    /* add everything you want to do onLoad here (eg. activating hover controls) */
    alert('this was auto detected');
    activateTouchArea();
  },
  surface: function(event){
    /* add everything you want to do ontouchstart here (eg. drag & drop) - you can fire this in both places */
    alert('this was detected by touching');
    activateTouchArea();
  }
}; // touch_detect
function activateTouchArea(){
  /* make sure our screen doesn't scroll when we move the ""touchable area"" */
  var element = document.getElementById('element_id');
  element.addEventListener(""touchstart"", touchStart, false);
}
function touchStart(event) {
  /* modularize preventing the default behavior so we can use it again */
  event.preventDefault();
}

    I would avoid using screen width to determine if a device is a touch device. There are touch screens much larger than 699px, think of Windows 8. Navigatior.userAgent may be nice to override false postives. 

I would recommend checking out this issue on Modernizr.

Are you wanting to test if the device supports touch events or is a touch device. Unfortunately, that's not the same thing.
    No, it's not possible. The excellent answers given are only ever partial, because any given method will produce false positives and false negatives. Even the browser doesn't always know if a touchscreen is present, due to OS APIs, and the fact can change during a browser session, particularly with KVM-type arrangements.

See further details in this excellent article:

http://www.stucox.com/blog/you-cant-detect-a-touchscreen/

The article suggests you reconsider the assumptions that make you want to detect touchscreens, they're probably wrong. (I checked my own for my app, and my assumptions were indeed wrong!)

The article concludes:


  For layouts, assume everyone has a touchscreen. Mouse users can use
  large UI controls much more easily than touch users can use small
  ones. The same goes for hover states.
  
  For events and interactions, assume anyone may have a touchscreen.
  Implement keyboard, mouse and touch interactions alongside each other,
  ensuring none block each other.

    It looks like Chrome 24 now support touch events, probably for Windows 8. So the code posted here no longer works. Instead of trying to detect if touch is supported by the browser, I'm now binding both touch and click events and making sure only one is called: 

myCustomBind = function(controlName, callback) {

  $(controlName).bind('touchend click', function(e) {
    e.stopPropagation();
    e.preventDefault();

    callback.call();
  });
};


And then calling it: 

myCustomBind('#mnuRealtime', function () { ... });


Hope this helps !
    I use:

if(jQuery.support.touch){
    alert('Touch enabled');
}


in jQuery mobile 1.0.1
    You can install modernizer and use a simple touch event. This is very effective and works on every device I have tested it on including windows surface!

I've created a jsFiddle    

function isTouchDevice(){
    if(Modernizr.hasEvent('touchstart') || navigator.userAgent.search(/Touch/i) != -1){
         alert(""is touch"");
            return true;
         }else{
            alert(""is not touch"");
            return false;
    }
}

    Update: Please read blmstr's answer below before pulling a whole feature detection library into your project. Detecting actual touch support is more complex, and Modernizr only covers a basic use case.

Modernizr is a great, lightweight way to do all kinds of feature detection on any site.

It simply adds classes to the html element for each feature.

You can then target those features easily in CSS and JS. For example:

html.touch div {
    width: 480px;
}

html.no-touch div {
    width: auto;
}


And Javascript (jQuery example):

$('html.touch #popup').hide();

    var isTouchScreen = 'createTouch' in document;


or 

var isTouchScreen = 'createTouch' in document || screen.width <= 699 || 
    ua.match(/(iPhone|iPod|iPad)/) || ua.match(/BlackBerry/) || 
    ua.match(/Android/);


would be a more thorough check I suppose.
    I also struggled a lot with different options on how to detect in Javascript whether the page is displayed on a touch screen device or not.
IMO, as of now, no real option exists to detect the option properly.
Browsers either report touch events on desktop machines (because the OS maybe touch-ready), or some solutions don't work on all mobile devices.

In the end, I realized that I was following the wrong approach from the start:
If my page was to look similar on touch and non-touch devices, I maybe shouldn't have to worry about detecting the property at all:
My scenario was to deactivate tooltips over buttons on touch devices as they lead to double-taps where I wanted a single tap to activate the button.

My solution was to refactor the view so that no tooltip was needed over a button, and in the end I didn't need to detect the touch device from Javascript with methods that all have their drawbacks.
    The practical answer seems to be one that considers the context:

1) Public site (no login)
  Code the UI to work with both options together.

2) Login site
Capture whether a mouse-move occurred on the login form, and save this into a hidden input. The value is passed with the login credentials and added to the user's session, so it can be used for the duration of the session.

Jquery to add to login page only:

$('#istouch').val(1); // <-- value will be submitted with login form

if (window.addEventListener) {
    window.addEventListener('mousemove', function mouseMoveListener(){
        // Update hidden input value to false, and stop listening
        $('#istouch').val(0); 
        window.removeEventListener('mousemove', mouseMoveListener);
    });
} 


(+1 to @Dave Burt and +1 to @Martin Lantzsch on their answers)
    Working Fiddle

I have achieved it like this;

function isTouchDevice(){
    return true == (""ontouchstart"" in window || window.DocumentTouch && document instanceof DocumentTouch);
}

if(isTouchDevice()===true) {
    alert('Touch Device'); //your logic for touch device
}
else {
    alert('Not a Touch Device'); //your logic for non touch device
}

    $.support.touch ? ""true"" : ""false"";

    ","[484, 804, 95, 25, 7, 12, 129, 4, 4, 41, 6, 4, 5, 4, 4, 19, 16, 8, 6, 5, 5, 5, 4, 3, 3, 144, 3, 2, 2, 9, 0]",595061,223,2011-01-27T13:39:43,2021-12-05 12:03:54Z,javascript 
Why do I need to override the equals and hashCode methods in Java?,"
                
Recently I read through this
 Developer Works Document. 

The document is all about defining hashCode() and equals() effectively and correctly, however I am not able to figure out why we need to override these two methods. 

How can I take the decision to implement these methods efficiently?
    Joshua Bloch says on Effective Java

You must override hashCode() in every class that overrides equals(). Failure to do so will result in a violation of the general contract for Object.hashCode(), which will prevent your class from functioning properly in conjunction with all hash-based collections, including HashMap, HashSet, and Hashtable.

Let's try to understand it with an example of what would happen if we override equals() without overriding hashCode() and attempt to use a Map.
Say we have a class like this and that two objects of MyClass are equal if their importantField is equal (with hashCode() and equals() generated by eclipse)
public class MyClass {
    private final String importantField;
    private final String anotherField;

    public MyClass(final String equalField, final String anotherField) {
        this.importantField = equalField;
        this.anotherField = anotherField;
    }

    @Override
    public int hashCode() {
        final int prime = 31;
        int result = 1;
        result = prime * result
                + ((importantField == null) ? 0 : importantField.hashCode());
        return result;
    }

    @Override
    public boolean equals(final Object obj) {
        if (this == obj)
            return true;
        if (obj == null)
            return false;
        if (getClass() != obj.getClass())
            return false;
        final MyClass other = (MyClass) obj;
        if (importantField == null) {
            if (other.importantField != null)
                return false;
        } else if (!importantField.equals(other.importantField))
            return false;
        return true;
    }
}


Imagine you have this
MyClass first = new MyClass(""a"",""first"");
MyClass second = new MyClass(""a"",""second"");

Override only equals
If only equals is overriden, then when you call myMap.put(first,someValue) first will hash to some bucket and when you call myMap.put(second,someOtherValue) it will hash to some other bucket (as they have a different hashCode). So, although they are equal, as they don't hash to the same bucket, the map can't realize it and both of them stay in the map.

Although it is not necessary to override equals() if we override hashCode(), let's see what would happen in this particular case where we know that two objects of MyClass are equal if their importantField is equal but we do not override equals().
Override only hashCode
If you only override hashCode then when you call myMap.put(first,someValue) it takes first, calculates its hashCode and stores it in a given bucket. Then when you call myMap.put(second,someOtherValue) it should replace first with second  as per the Map Documentation because they are equal (according to the business requirement).
But the problem is that equals was not redefined, so when the map hashes second and iterates through the bucket looking if there is an object k such that second.equals(k) is true it won't find any as second.equals(first) will be false.
Hope it was clear
    Collections such as HashMap and HashSet use a hashcode value of an object to determine how it should be stored inside a collection, and the hashcode is used again in order to locate the object
in its collection.

Hashing retrieval is a two-step process:


Find the right bucket (using hashCode())
Search the bucket for the right element (using equals() )


Here is a small example on why we should overrride equals() and hashcode().

Consider an Employee class which has two fields: age and name.

public class Employee {

    String name;
    int age;

    public Employee(String name, int age) {
        this.name = name;
        this.age = age;
    }

    public String getName() {
        return name;
    }

    public void setName(String name) {
        this.name = name;
    }

    public int getAge() {
        return age;
    }

    public void setAge(int age) {
        this.age = age;
    }

    @Override
    public boolean equals(Object obj) {
        if (obj == this)
            return true;
        if (!(obj instanceof Employee))
            return false;
        Employee employee = (Employee) obj;
        return employee.getAge() == this.getAge()
                && employee.getName() == this.getName();
    }

    // commented    
    /*  @Override
        public int hashCode() {
            int result=17;
            result=31*result+age;
            result=31*result+(name!=null ? name.hashCode():0);
            return result;
        }
     */
}


Now create a class, insert Employee object into a HashSet and test whether that object is present or not.

public class ClientTest {
    public static void main(String[] args) {
        Employee employee = new Employee(""rajeev"", 24);
        Employee employee1 = new Employee(""rajeev"", 25);
        Employee employee2 = new Employee(""rajeev"", 24);

        HashSet<Employee> employees = new HashSet<Employee>();
        employees.add(employee);
        System.out.println(employees.contains(employee2));
        System.out.println(""employee.hashCode():  "" + employee.hashCode()
        + ""  employee2.hashCode():"" + employee2.hashCode());
    }
}


It will print the following:

false
employee.hashCode():  321755204  employee2.hashCode():375890482


Now uncomment hashcode() method , execute the same and the output would be: 

true
employee.hashCode():  -938387308  employee2.hashCode():-938387308


Now can you see why if two objects are considered equal, their hashcodes must
also be equal? Otherwise, you'd never be able to find the object since the default
hashcode method in class Object virtually always comes up with a unique number
for each object, even if the equals() method is overridden in such a way that two
or more objects are considered equal. It doesn't matter how equal the objects are if
their hashcodes don't reflect that. So one more time: If two objects are equal, their
hashcodes must be equal as well.
    Why we override equals() method
In Java we can not overload how operators like ==, +=, -+ behave. They are behaving a certain way. So let's focus on the operator == for our case here.
How operator == works.
It checks if 2 references that we compare point to the same instance in memory. Operator == will resolve to true only if those 2 references represent the same instance in memory.
So now let's consider the following example
public class Person {

      private Integer age;
      private String name;
    
      ..getters, setters, constructors
      }

So let's say that in your program you have built 2 Person objects on different places and you wish to compare them.
Person person1 = new Person(""Mike"", 34);
Person person2 = new Person(""Mike"", 34);
System.out.println ( person1 == person2 );  --> will print false!

Those 2 objects from business perspective look the same right? For JVM they are not the same. Since they are both created with new keyword those instances are located in different segments in memory. Therefore the operator == will return false
But if we can not override the == operator how can we say to JVM that we want those 2 objects to be treated as same. There comes the .equals() method in play.
You can override equals() to check if some objects have same values for specific fields to be considered equal.
You can select which fields you want to be compared. If we say that 2 Person objects will be the same if and only if they have the same age and same name, then the IDE will create something like the following for automatic generation of equals()
@Override
    public boolean equals(Object o) {
        if (this == o) return true;
        if (o == null || getClass() != o.getClass()) return false;
        Person person = (Person) o;
        return age == person.age &&
                name.equals(person.name);
    }

Let's go back to our previous example
    Person person1 = new Person(""Mike"", 34);
    Person person2 = new Person(""Mike"", 34);
    System.out.println ( person1 == person2 );   --> will print false!
    System.out.println ( person1.equals(person2) );  --> will print true!

So we can not overload == operator to compare objects the way we want but Java gave us another way, the equals() method, which we can override as we want.
Keep in mind however, if we don't provide our custom version of .equals() (aka override) in our class then the predefined .equals() from Object class and == operator will behave exactly the same.
Default equals() method which is inherited from Object will check whether both compared instances are the same in memory!
Why we override hashCode() method
Some Data Structures in java like HashSet, HashMap store their elements based on a hash function which is applied on those elements. The hashing function is the hashCode()
If we have a choice of overriding .equals() method then we must also have a choice of overriding hashCode() method. There is a reason for that.
Default implementation of hashCode() which is inherited from Object considers all objects in memory unique!
Let's get back to those hash data structures. There is a rule for those data structures.
HashSet can not contain duplicate values and HashMap can not contain duplicate keys
HashSet is implemented with a HashMap behind the scenes where each value of a HashSet is stored as a key in a HashMap.
So we have to understand how a HashMap works.
In a simple way a HashMap is a native array that has some buckets. Each bucket has a linkedList. In that linkedList our keys are stored. HashMap locates the correct linkedList for each key by applying hashCode() method and after that it iterates through all elements of that linkedList and applies equals() method on each of these elements to check if that element is already contained there. No duplicate keys are allowed.

When we put something inside a HashMap, the key is stored in one of those linkedLists. In which linkedList that key will be stored is shown by the result of hashCode() method on that key. So if key1.hashCode() has as a result 4, then that key1 will be stored on the 4th bucket of the array, in the linkedList that exists there.
By default hashCode() method returns a different result for each different instance. If we have the default equals() which behaves like == which considers all instances in memory as different objects we don't have any problem.
But in our previous example we said we want Person instances to be considered equal if their ages and names match.
    Person person1 = new Person(""Mike"", 34);
    Person person2 = new Person(""Mike"", 34);
    System.out.println ( person1.equals(person2) );  --> will print true!

Now let's create a map to store those instances as keys with some string as pair value
Map<Person, String> map = new HashMap();
map.put(person1, ""1"");
map.put(person2, ""2"");

In Person class we have not overridden the hashCode method but we have overridden equals method. Since the default hashCode provides different results for different java instances person1.hashCode() and person2.hashCode() have big chances of having different results.
Our map might end with those persons in different linkedLists.

This is against the logic of a HashMap
A HashMap is not allowed to have multiple equal keys!
But ours now has and the reason is that the default hashCode() which was inherited from Object Class was not enough. Not after we have overridden the equals() method on Person Class.
That is the reason why we must override hashCode() method after we have overridden equals method.
Now let's fix that. Let's override our hashCode() method to consider the same fields that equals() considers, namely age, name
 public class Person {

      private Integer age;
      private String name;
    
      ..getters, setters, constructors

    @Override
    public boolean equals(Object o) {
        if (this == o) return true;
        if (o == null || getClass() != o.getClass()) return false;
        Person person = (Person) o;
        return age == person.age &&
                name.equals(person.name);
    }

    @Override
    public int hashCode() {
        return Objects.hash(name, age);
    }

      }

Now let's try again to save those keys in our HashMap
Map<Person, String> map = new HashMap();
map.put(person1, ""1"");
map.put(person2, ""2"");

person1.hashCode() and person2.hashCode() will definitely be the same. Let's say it is 0.
HashMap will go to bucket 0 and in that LinkedList will save the person1 as key with the value ""1"". For the second put HashMap is intelligent enough and when it goes again to bucket 0 to save person2 key with value ""2"" it will see that another equal key already exists there. So it will overwrite the previous key. So in the end only person2 key will exist in our HashMap.

Now we are aligned with the rule of Hash Map that says no multiple equal keys are allowed!
    Simply put, the equals-method in Object check for reference equality, where as two instances of your class could still be semantically equal when the properties are equal. This is for instance important when putting your objects into a container that utilizes equals and hashcode, like HashMap and Set. Let's say we have a class like:

public class Foo {
    String id;
    String whatevs;

    Foo(String id, String whatevs) {
        this.id = id;
        this.whatevs = whatevs;
    }
}


We create two instances with the same id:

Foo a = new Foo(""id"", ""something"");
Foo b = new Foo(""id"", ""something else"");


Without overriding equals we are getting:


a.equals(b) is false because they are two different instances
a.equals(a) is true since it's the same instance
b.equals(b) is true since it's the same instance


Correct? Well maybe, if this is what you want. But let's say we want objects with the same id to be the same object, regardless if it's two different instances. We override the equals (and hashcode):

public class Foo {
    String id;
    String whatevs;

    Foo(String id, String whatevs) {
        this.id = id;
        this.whatevs = whatevs;
    }

    @Override
    public boolean equals(Object other) {
        if (other instanceof Foo) {
            return ((Foo)other).id.equals(this.id);   
        }
    }

    @Override
    public int hashCode() {
        return this.id.hashCode();
    }
}


As for implementing equals and hashcode I can recommend using Guava's helper methods
    Let me explain the concept in very simple words.
Firstly from a broader perspective we have collections, and hashmap is one of the datastructure in the collections.
To understand why we have to override the both equals and hashcode method, if need to first understand what is hashmap and what is does.
A hashmap is a datastructure which stores key value pairs of data in array fashion. Lets say a[], where each element in 'a' is a key value pair.
Also each index in the above array can be linked list thereby having more than one values at one index.
Now why is a hashmap used?
If we have to search among  a large array then searching through each if them will not be efficient, so what hash technique tells us that lets pre process the array with some logic and group the elements based on that logic i.e. Hashing
EG: we have array 1,2,3,4,5,6,7,8,9,10,11 and we apply a hash function mod 10 so 1,11 will be grouped in together. So if we had to search for 11 in previous array then we would have to iterate the complete array but when we group it we limit our scope of iteration thereby improving speed. That datastructure used to store all the above information can be thought of as a 2d array for simplicity
Now apart from the above hashmap also tells that it wont add any Duplicates in it. And this is the main reason why we have to override the equals and hashcode
So when its said that explain the internal working of hashmap , we need to find what methods the hashmap has and how does it follow the above rules which i explained above
so the hashmap has method called as put(K,V) , and according to hashmap it should follow the above rules of efficiently distributing the array and not adding any duplicates
so what put does is that it will first generate the hashcode for the given key to decide which index the value should go in.if nothing is present at that index then the new value will be added over there, if something is already present over there then the new value should be added after the end of the linked list at that index. but remember no duplicates should be added as per the desired behavior of the hashmap. so lets say you have two Integer objects aa=11,bb=11.
As every object derived from the object class, the default implementation for comparing two objects is that it compares the reference and not values inside the object. So in the above case both though semantically equal will fail the equality test, and possibility that two objects which same hashcode and same values will exists thereby creating duplicates. If we override then we could avoid adding duplicates.
You could also refer to Detail working
import java.util.HashMap;


public class Employee {
    String name;
    String mobile;

    public Employee(String name,String mobile) {
        this.name = name;
        this.mobile = mobile;
    }
    
    @Override
    public int hashCode() {
        System.out.println(""calling hascode method of Employee"");
        String str = this.name;
        int sum = 0;
        for (int i = 0; i < str.length(); i++) {
            sum = sum + str.charAt(i);
        }
        return sum;
    }

    @Override
    public boolean equals(Object obj) {
        // TODO Auto-generated method stub
        System.out.println(""calling equals method of Employee"");
        Employee emp = (Employee) obj;
        if (this.mobile.equalsIgnoreCase(emp.mobile)) {
            System.out.println(""returning true"");
            return true;
        } else {
            System.out.println(""returning false"");
            return false;
        }
    }

    public static void main(String[] args) {
        // TODO Auto-generated method stub

        Employee emp = new Employee(""abc"", ""hhh"");
        Employee emp2 = new Employee(""abc"", ""hhh"");
        HashMap<Employee, Employee> h = new HashMap<>();
        //for (int i = 0; i < 5; i++) {
            h.put(emp, emp);
            h.put(emp2, emp2);
        //}
        
        System.out.println(""----------------"");
        System.out.println(""size of hashmap: ""+h.size());
    }
}

    Identity is not equality.


equals operator == test identity.
equals(Object obj) method compares equality test(i.e. we need to tell equality by overriding the method)



  Why do I need to override the equals and hashCode methods in Java?   


First we have to understand the use of equals method.

In order to identity differences between two objects we need to override equals method.   

For example:

Customer customer1=new Customer(""peter"");
Customer customer2=customer1;
customer1.equals(customer2); // returns true by JVM. i.e. both are refering same Object
------------------------------
Customer customer1=new Customer(""peter"");
Customer customer2=new Customer(""peter"");
customer1.equals(customer2); //return false by JVM i.e. we have two different peter customers.

------------------------------
Now I have overriden Customer class equals method as follows:
 @Override
    public boolean equals(Object obj) {
        if (this == obj)   // it checks references
            return true;
        if (obj == null) // checks null
            return false;
        if (getClass() != obj.getClass()) // both object are instances of same class or not
            return false;
        Customer other = (Customer) obj;
        if (name == null) {
            if (other.name != null)
                return false;
        } else if (!name.equals(other.name)) // it again using bulit in String object equals to identify the difference 
            return false;
        return true; 
    }
Customer customer1=new Customer(""peter"");
Customer customer2=new Customer(""peter"");
Insteady identify the Object equality by JVM, we can do it by overring equals method.
customer1.equals(customer2);  // returns true by our own logic


Now hashCode method can understand easily.

hashCode produces integer in order to store object in data structures like HashMap, HashSet.

Assume we have override equals method of Customer as above, 

customer1.equals(customer2);  // returns true by our own logic


While working with data structure when we store object in buckets(bucket is a fancy name for folder). If we use built-in hash technique, for above two customers it generates two different hashcode. So we are storing the same identical object in two different places. To avoid this kind of issues we should override the hashCode method also based on the following principles.  


un-equal instances may have same hashcode.
equal instances should return same hashcode.

    Java puts a rule that 


  ""If two objects are equal using Object class equals method, then the hashcode method should give the same value for these two objects.""


So, if in our class we override equals() we should override hashcode() method also to follow this rule.
Both methods, equals() and hashcode(), are used in Hashtable, for example, to store values as key-value pairs. If we override one and not the other, there is a possibility that the Hashtable may not work as we want, if we use such object as a key.
    
You must override hashCode() in every
class that overrides equals(). Failure
to do so will result in a violation of
the general contract for
Object.hashCode(), which will prevent
your class from functioning properly
in conjunction with all hash-based
collections, including HashMap,
HashSet, and Hashtable.
    from Effective Java, by Joshua Bloch

By defining equals() and hashCode() consistently, you can improve the usability of your classes as keys in hash-based collections. As the API doc for hashCode explains: ""This method is supported for the benefit of hashtables such as those provided by java.util.Hashtable.""
The best answer to your question about how to implement these methods efficiently is suggesting you to read Chapter 3 of Effective Java.
    hashCode() :
If you only override the hash-code method nothing happens, because it always returns a new hashCode for each object as an Object class.
equals() :
If you only override the equals method, if a.equals(b) is true it means the hashCode of a and b must be the same but that does not happen since you did not override the hashCode method.
Note :  hashCode() method of Object class always returns a new hashCode for each object.
So when you need to use your object in the hashing based collection, you must override both equals() and hashCode().
    1) The common mistake is shown in the example below.

public class Car {

    private String color;

    public Car(String color) {
        this.color = color;
    }

    public boolean equals(Object obj) {
        if(obj==null) return false;
        if (!(obj instanceof Car))
            return false;   
        if (obj == this)
            return true;
        return this.color.equals(((Car) obj).color);
    }

    public static void main(String[] args) {
        Car a1 = new Car(""green"");
        Car a2 = new Car(""red"");

        //hashMap stores Car type and its quantity
        HashMap<Car, Integer> m = new HashMap<Car, Integer>();
        m.put(a1, 10);
        m.put(a2, 20);
        System.out.println(m.get(new Car(""green"")));
    }
}


the green Car is not found

2. Problem caused by hashCode()

The problem is caused by the un-overridden method hashCode(). The contract between equals() and hashCode() is:


If two objects are equal, then they must have the same hash code.
If two objects have the same hash code, they may or may not be equal.

public int hashCode(){  
  return this.color.hashCode(); 
}


    If you override equals() and not hashcode(), you will not find any problem unless you or someone else uses that class type in a hashed collection like HashSet.
People before me have clearly explained the documented theory multiple times, I am just here to provide a very simple example.

Consider a class whose equals() need to mean something customized :-

    public class Rishav {

        private String rshv;

        public Rishav(String rshv) {
            this.rshv = rshv;
        }

        /**
        * @return the rshv
        */
        public String getRshv() {
            return rshv;
        }

        /**
        * @param rshv the rshv to set
        */
        public void setRshv(String rshv) {
            this.rshv = rshv;
        }

        @Override
        public boolean equals(Object obj) {
            if (obj instanceof Rishav) {
                obj = (Rishav) obj;
                if (this.rshv.equals(((Rishav) obj).getRshv())) {
                    return true;
                } else {
                    return false;
                }
            } else {
                return false;
            }
        }

        @Override
        public int hashCode() {
            return rshv.hashCode();
        }

    }


Now consider this main class :-

    import java.util.HashSet;
    import java.util.Set;

    public class TestRishav {

        public static void main(String[] args) {
            Rishav rA = new Rishav(""rishav"");
            Rishav rB = new Rishav(""rishav"");
            System.out.println(rA.equals(rB));
            System.out.println(""-----------------------------------"");

            Set<Rishav> hashed = new HashSet<>();
            hashed.add(rA);
            System.out.println(hashed.contains(rB));
            System.out.println(""-----------------------------------"");

            hashed.add(rB);
            System.out.println(hashed.size());
        }

    }


This will yield the following output :-

    true
    -----------------------------------
    true
    -----------------------------------
    1


I am happy with the results. But if I have not overridden hashCode(), it will cause nightmare as objects of Rishav with same member content will no longer be treated as unique as the hashCode will be different, as generated by default behavior, here's the would be output :-

    true
    -----------------------------------
    false
    -----------------------------------
    2

    Because if you do not override them you will be use the default implentation in Object.

Given that instance equality and hascode values generally require knowledge of what makes up an object they generally will need to be redefined in your class to have any tangible meaning.
    Assume you have class (A) that aggregates two other (B) (C), and you need to store instances of (A) inside hashtable. Default implementation only allows distinguishing of instances, but not by (B) and (C). So two instances of A could be equal, but default wouldn't allow you to compare them in correct way.  
    It is useful when using Value Objects. The following is an excerpt from the Portland Pattern Repository:


  Examples of value objects are things
  like numbers, dates, monies and
  strings. Usually, they are small
  objects which are used quite widely.
  Their identity is based on their state
  rather than on their object identity.
  This way, you can have multiple copies
  of the same conceptual value object.
  
  So I can have multiple copies of an
  object that represents the date 16 Jan
  1998. Any of these copies will be equal to each other. For a small
  object such as this, it is often
  easier to create new ones and move
  them around rather than rely on a
  single object to represent the date.
  
  A value object should always override
  .equals() in Java (or = in Smalltalk).
  (Remember to override .hashCode() as
  well.)

    hashCode() method is used to get a unique integer for given object. This integer is used for determining the bucket location, when this object needs to be stored in some HashTable, HashMap like data structure. By default, Object’s hashCode() method returns and integer representation of memory address where object is stored.

The hashCode() method of objects is used when we insert them into a HashTable, HashMap or HashSet. More about HashTables on Wikipedia.org for reference.

To insert any entry in map data structure, we need both key and value. If both key and values are user define data types, the hashCode() of the key will be determine where to store the object internally. When require to lookup the object from the map also, the hash code of the key will be determine where to search for the object.

The hash code only points to a certain ""area"" (or list, bucket etc) internally. Since different key objects could potentially have the same hash code, the hash code itself is no guarantee that the right key is found. The HashTable then iterates this area (all keys with the same hash code) and uses the key's equals() method to find the right key. Once the right key is found, the object stored for that key is returned.

So, as we can see, a combination of the hashCode() and equals() methods are used when storing and when looking up objects in a HashTable.

NOTES:


Always use same attributes of an object to generate hashCode() and equals() both. As in our case, we have used employee id.
equals() must be consistent (if the objects are not modified, then it must keep returning the same value).
Whenever a.equals(b), then a.hashCode() must be same as b.hashCode().
If you override one, then you should override the other.


http://parameshk.blogspot.in/2014/10/examples-of-comparable-comporator.html
    When you want to store and retrieve your custom object as a key in Map, then you should always override equals and hashCode in your custom Object .
Eg:

Person p1 = new Person(""A"",23);
Person p2 = new Person(""A"",23);
HashMap map = new HashMap();
map.put(p1,""value 1"");
map.put(p2,""value 2"");


Here p1 & p2 will consider as only one object and map size will be only 1 because they are equal.
    public class Employee {

    private int empId;
    private String empName;

    public Employee(int empId, String empName) {
        super();
        this.empId = empId;
        this.empName = empName;
    }

    public int getEmpId() {
        return empId;
    }

    public void setEmpId(int empId) {
        this.empId = empId;
    }

    public String getEmpName() {
        return empName;
    }

    public void setEmpName(String empName) {
        this.empName = empName;
    }

    @Override
    public String toString() {
        return ""Employee [empId="" + empId + "", empName="" + empName + ""]"";
    }

    @Override
    public int hashCode() {
        return empId + empName.hashCode();
    }

    @Override
    public boolean equals(Object obj) {

        if (this == obj) {
            return true;
        }
        if (!(this instanceof Employee)) {
            return false;
        }
        Employee emp = (Employee) obj;
        return this.getEmpId() == emp.getEmpId() && this.getEmpName().equals(emp.getEmpName());
    }

}


Test Class 

public class Test {

    public static void main(String[] args) {
        Employee emp1 = new Employee(101,""Manash"");
        Employee emp2 = new Employee(101,""Manash"");
        Employee emp3 = new Employee(103,""Ranjan"");
        System.out.println(emp1.hashCode());
        System.out.println(emp2.hashCode());
        System.out.println(emp1.equals(emp2));
        System.out.println(emp1.equals(emp3));
    }

}


In Object Class equals(Object obj) is used to compare address comparesion thats why when in Test class if you compare two objects then equals method giving false but when we override hashcode() the it can compare content and give proper result.
    Both the methods are defined in Object class. And both are in its simplest implementation. So when you need you want add some more implementation to these methods then you have override in  your class. 

For Ex: equals() method in object only checks its equality on the reference. So if you need compare its state as well then you can override that as it is done in String class.
    Bah - ""You must override hashCode() in every class that overrides equals().""

[from Effective Java, by Joshua Bloch?]

Isn't this the wrong way round?  Overriding hashCode likely implies you're writing a hash-key class, but overriding equals certainly does not. There are many classes that are not used as hash-keys, but do want a logical-equality-testing method for some other reason. If you choose ""equals"" for it, you may then be mandated to write a hashCode implementation by overzealous application of this rule. All that achieves is adding untested code in the codebase, an evil waiting to trip someone up in the future. Also writing code you don't need is anti-agile. It's just wrong (and an ide generated one will probably be incompatible with your hand-crafted equals). 

Surely they should have mandated an Interface on objects written to be used as keys? Regardless, Object should never have provided default hashCode() and equals() imho. It's probably encouraged many broken hash collections.

But anyway, I think the ""rule"" is written back to front. In the meantime, I'll keep avoiding using ""equals"" for equality testing methods :-(
    Adding to @Lombo 's answer

When will you need to override equals() ?

The default implementation of Object's equals() is

public boolean equals(Object obj) {
        return (this == obj);
}


which means two objects will be considered equal only if they have the same memory address which will be true only if you are
comparing an object with itself.

But you might want to consider two objects the same if they have the same value for one
or more of their properties (Refer the example given in @Lombo 's answer). 

So you will override equals() in these situations and you would give your own conditions for equality.

I have successfully implemented equals() and it is working great.So why are they asking to override hashCode() as well?

Well.As long as you don't use ""Hash"" based Collections on your user-defined class,it is fine.
But some time in the future you might want to use HashMap or HashSet and if you don't override and ""correctly implement"" hashCode(), these Hash based collection won't work as intended.

Override only equals (Addition to @Lombo 's answer)

myMap.put(first,someValue)
myMap.contains(second); --> But it should be the same since the key are the same.But returns false!!! How?


First of all,HashMap checks if the hashCode of second is the same as first.
Only if the values are the same,it will proceed to check the equality in the same bucket.

But here the hashCode is different for these 2 objects (because they have different memory address-from default implementation).
Hence it will not even care to check for equality.

If you have a breakpoint inside your overridden equals() method,it wouldn't step in if they have different hashCodes.
contains() checks hashCode() and only if they are the same it would call your equals() method.

Why can't we make the HashMap check for equality in all the buckets? So there is no necessity for me to override hashCode() !!

Then you are missing the point of Hash based Collections.
Consider the following :

Your hashCode() implementation : intObject%9.


The following are the keys stored in the form of buckets.

Bucket 1 : 1,10,19,... (in thousands)
Bucket 2 : 2,20,29...
Bucket 3 : 3,21,30,...
...


Say,you want to know if the map contains the key 10.
Would you want to search all the buckets? or Would you want to search only one bucket?

Based on the hashCode,you would identify that if 10 is present,it must be present in Bucket 1.
So only Bucket 1 will be searched !!
    class A {
    int i;
    // Hashing Algorithm
    if even number return 0 else return 1
    // Equals Algorithm,
    if i = this.i return true else false
}



put('key','value') will calculate the hash value using hashCode() to determine the
bucket and uses equals() method to find whether the value is already
present in the Bucket. If not it will added else it will be replaced with current value
get('key') will use hashCode() to find the Entry (bucket) first and
equals() to find the value in Entry


if Both are overridden,

Map<A> 

Map.Entry 1 --> 1,3,5,...
Map.Entry 2 --> 2,4,6,...


if equals is not overridden

Map<A> 

Map.Entry 1 --> 1,3,5,...,1,3,5,... // Duplicate values as equals not overridden
Map.Entry 2 --> 2,4,6,...,2,4,..


If hashCode is not overridden

Map<A> 

Map.Entry 1 --> 1
Map.Entry 2 --> 2
Map.Entry 3 --> 3
Map.Entry 4 --> 1
Map.Entry 5 --> 2
Map.Entry 6 --> 3 // Same values are Stored in different hasCodes violates Contract 1
So on...


HashCode Equal Contract


Two keys equal according to equal method should generate same hashCode
Two Keys generating same hashCode need not be equal (In above example all even numbers generate same hash Code)

    In order to use our own class objects as keys in collections like HashMap, Hashtable etc.. , we should override both methods ( hashCode() and equals() ) by having an awareness on internal working of collection. Otherwise, it leads to wrong results which we are not expected.
    To help you check for duplicate Objects, we need a custom equals and hashCode.

Since hashcode always returns a number its always fast to retrieve an object using a number rather than an alphabetic key. How will it do? Assume we created a new object by passing some value which is already available in some other object. Now the new object will return the same hash value as of another object because the value passed is same. Once the same hash value is returned, JVM will go to the same memory address every time and if in case there are more than one objects present for the same hash value it will use equals() method to identify the correct object.
    The methods equals and hashcode are defined in the object class. By default if the equals method returns true, then the system will go further and check the value of the hash code. If the hash code of the 2 objects is also same only then the objects will be considered as same. So if you override only equals method, then even though the overridden equals method indicates 2 objects to be equal , the system defined hashcode may not indicate that the 2 objects are equal. So we need to override hash code as well.
    String class and wrapper classes have different implementation of equals() and hashCode() methods than Object class. equals() method of Object class compares the references of the objects, not the contents. hashCode() method of Object class returns distinct hashcode for every single object whether the contents are same.

It leads problem when you use Map collection and the key is of Persistent type, StringBuffer/builder type. Since they don't override equals() and hashCode() unlike String class, equals() will return false when you compare two different objects even though both have same contents. It will make the hashMap storing same content keys. Storing same content keys means it is violating the rule of Map because Map doesnt allow duplicate keys at all.
Therefore you override equals() as well as hashCode() methods in your class and provide the implementation(IDE can generate these methods) so that they work same as String's equals() and hashCode() and prevent same content keys. 

You have to override hashCode() method along with equals() because equals() work according hashcode. 

Moreover overriding hashCode() method along with equals() helps to intact the equals()-hashCode() contract: ""If two objects are equal, then they must have the same hash code.""

When do you need to write custom implementation for hashCode()?

As we know that internal working of HashMap is on principle of Hashing. There are certain buckets where entrysets get stored. You customize the hashCode() implementation according your requirement so that same category objects can be stored into same index. 
when you store the values into Map collection using put(k,v)method, the internal implementation of put() is:

put(k, v){
hash(k);
index=hash & (n-1);
}


Means, it generates index and the index is generated based on the hashcode of particular key object. So make this method generate hashcode according your requirement because same hashcode entrysets will be stored into same bucket or index. 

That's it!
    Consider collection of balls in a bucket all in black color. Your Job is to color those balls as follows and use it for appropriate game,

For Tennis - Yellow, Red.
For Cricket - White

Now bucket has balls in three colors Yellow, Red and White. And that now you did the coloring Only you know which color is for which game.

Coloring the balls - Hashing.
Choosing the ball for game - Equals.

If you did the coloring and some one chooses the ball for either cricket or tennis they wont mind the color!!!
    I was looking into the explanation "" If you only override hashCode then when you call myMap.put(first,someValue) it takes first, calculates its hashCode and stores it in a given bucket. Then when you call myMap.put(first,someOtherValue) it should replace first with second as per the Map Documentation because they are equal (according to our definition)."" :

I think 2nd time when we are adding in myMap then it should be the 'second' object like myMap.put(second,someOtherValue)
    Equals and Hashcode methods in Java

They are methods of java.lang.Object class which is the super class of all the classes (custom classes as well and others defined in java API).

Implementation:


  public boolean equals(Object obj)
  
  public int hashCode()




public boolean equals(Object obj)

This method simply checks if two object references x and y refer to the same object. i.e. It checks if x == y.

It is reflexive: for any reference value x, x.equals(x) should return true.

It is symmetric: for any reference values x and y, x.equals(y) should return true if and only if y.equals(x) returns true.

It is transitive: for any reference values x, y, and z, if x.equals(y) returns true and y.equals(z) returns true, then x.equals(z) should return true.

It is consistent: for any reference values x and y, multiple invocations of x.equals(y) consistently return true or consistently return false, provided no information used in equals comparisons on the object is modified.


  For any non-null reference value x, x.equals(null) should return
  false.


public int hashCode()

This method returns the hash code value for the object on which this method is invoked. This method returns the hash code value as an integer and is supported for the benefit of hashing based collection classes such as Hashtable, HashMap, HashSet etc. This method must be overridden in every class that overrides the equals method.

The general contract of hashCode is:

Whenever it is invoked on the same object more than once during an execution of a Java application, the hashCode method must consistently return the same integer, provided no information used in equals comparisons on the object is modified. 

This integer need not remain consistent from one execution of an application to another execution of the same application.

If two objects are equal according to the equals(Object) method, then calling the hashCode method on each of the two objects must produce the same integer result.

It is not required that if two objects are unequal according to the equals(java.lang.Object) method, then calling the hashCode method on each of the two objects must produce distinct integer results. However, the programmer should be aware that producing distinct integer results for unequal objects may improve the performance of hashtables.


  Equal objects must produce the same hash code as long as they are
  equal, however unequal objects need not produce distinct hash codes.


Resources: 

JavaRanch

Picture
    In the example below, if you comment out the override for equals or hashcode in the Person class, this code will fail to look up Tom's order. Using the default implementation of hashcode can cause failures in hashtable lookups.

What I have below is a simplified code that pulls up people's order by Person. Person is being used as a key in the hashtable.

public class Person {
    String name;
    int age;
    String socialSecurityNumber;

    public Person(String name, int age, String socialSecurityNumber) {
        this.name = name;
        this.age = age;
        this.socialSecurityNumber = socialSecurityNumber;
    }

    @Override
    public boolean equals(Object p) {
        //Person is same if social security number is same

        if ((p instanceof Person) && this.socialSecurityNumber.equals(((Person) p).socialSecurityNumber)) {
            return true;
        } else {
            return false;
        }

    }

    @Override
    public int hashCode() {        //I am using a hashing function in String.java instead of writing my own.
        return socialSecurityNumber.hashCode();
    }
}


public class Order {
    String[]  items;

    public void insertOrder(String[]  items)
    {
        this.items=items;
    }

}



import java.util.Hashtable;

public class Main {

    public static void main(String[] args) {

       Person p1=new Person(""Tom"",32,""548-56-4412"");
        Person p2=new Person(""Jerry"",60,""456-74-4125"");
        Person p3=new Person(""Sherry"",38,""418-55-1235"");

        Order order1=new Order();
        order1.insertOrder(new String[]{""mouse"",""car charger""});

        Order order2=new Order();
        order2.insertOrder(new String[]{""Multi vitamin""});

        Order order3=new Order();
        order3.insertOrder(new String[]{""handbag"", ""iPod""});

        Hashtable<Person,Order> hashtable=new Hashtable<Person,Order>();
        hashtable.put(p1,order1);
        hashtable.put(p2,order2);
        hashtable.put(p3,order3);

       //The line below will fail if Person class does not override hashCode()
       Order tomOrder= hashtable.get(new Person(""Tom"", 32, ""548-56-4412""));
        for(String item:tomOrder.items)
        {
            System.out.println(item);
        }
    }
}

    IMHO, it's as per the rule says - If two objects are equal then they should have same hash, i.e., equal objects should produce equal hash values.

Given above, default equals() in Object is == which does comparison on the address, hashCode() returns the address in integer(hash on actual address) which is again distinct for distinct Object.

If you need to use the custom Objects in the Hash based collections, you need to override both equals() and hashCode(), example If I want to maintain the HashSet of the Employee Objects, if I don't use stronger hashCode and equals I may endup overriding the two different Employee Objects, this happen when I use the age as the hashCode(), however I should be using the unique value which can be the Employee ID.
    ","[484, 647, 348, 27, 26, 16, 36, 12, 54, 13, 5, 3, 7, 4, 5, 2, 1, 1, 0, -3, 6, 5, 6, 1, 3, 2, 4, 4, 3, 2, 1]",555087,351,2010-02-15T11:17:59,2021-10-15 07:40:52Z,java 
Fixed page header overlaps in-page anchors,"
                
If I have a non-scrolling header in an HTML page, fixed to the top, having a defined height:
Is there a way to use the URL anchor (the #fragment part) to have the browser scroll to a certain point in the page, but still respect the height of the fixed element without the help of JavaScript?
http://example.com/#bar


WRONG (but the common behavior):         CORRECT:
+---------------------------------+      +---------------------------------+
| BAR///////////////////// header |      | //////////////////////// header |
+---------------------------------+      +---------------------------------+
| Here is the rest of the Text    |      | BAR                             |
| ...                             |      |                                 |
| ...                             |      | Here is the rest of the Text    |
| ...                             |      | ...                             |
+---------------------------------+      +---------------------------------+

    html {
  scroll-padding-top: 70px; /* height of sticky header */
}


from: https://css-tricks.com/fixed-headers-on-page-links-and-overlapping-content-oh-my/
    If you can’t or don’t want to set a new class, add a fixed-height ::before pseudo-element to the :target pseudo-class in CSS:

:target::before {
  content: """";
  display: block;
  height: 60px; /* fixed header height*/
  margin: -60px 0 0; /* negative fixed header height */
}


Or scroll the page relative to :target with jQuery:

var offset = $(':target').offset();
var scrollto = offset.top - 60; // minus fixed header height
$('html, body').animate({scrollTop:scrollto}, 0);

    From 4/2021 there is single non-hacky and fully cross-browser solution:
h1 {
  scroll-margin-top: 50px
}

It is part of CSS Scroll Snap spec. Runs on all modern browsers.
    I solve my issue with scroll-margin-top property for the anchor element
scroll-margin-top: 100px;

https://developer.mozilla.org/en-US/docs/Web/CSS/scroll-margin-top
    I had the same problem.
I solved it by adding a class to the anchor element with the topbar height as the padding-top value.
<h1><a class=""anchor"" name=""barlink"">Bar</a></h1>

I used this CSS:
.anchor { padding-top: 90px; }

    I didn't see the option to simply use :target listed as an option. I've found that
:target { margin-top: -100px; padding-top: 100px; }
appears to work in the provided scenario. :target is also compatible with all modern browsers. https://caniuse.com/?search=%3Atarget
    While some of the proposed solutions work for fragment links (= hash links) within the same page (like a menu link that scrolls down), I found that none of them worked in current Chrome when you want to use fragment links coming in from other pages. 

So calling www.mydomain.com/page.html#foo from scratch will NOT offset your target in current Chrome with any of the given CSS solutions or JS solutions.

There is also a jQuery bug report describing some details of the problem.

SOLUTION

The only option I found so far that really works in Chrome is JavaScript that is not called onDomReady but with a delay.

// set timeout onDomReady
$(function() {
    setTimeout(delayedFragmentTargetOffset, 500);
});

// add scroll offset to fragment target (if there is one)
function delayedFragmentTargetOffset(){
    var offset = $(':target').offset();
    if(offset){
        var scrollto = offset.top - 95; // minus fixed header height
        $('html, body').animate({scrollTop:scrollto}, 0);
    }
}


SUMMARY 

Without a JS delay solutions will probably work in Firefox, IE, Safari, but not in Chrome.
    You can now use scroll-margin-top, which is pretty widely adopted.

Simply add the following CSS to the element you want to scroll to:

.element {
  scroll-margin-top: 2em;
}

    I've got it working easily with CSS and HTML, using the ""anchor:before"" method mentioned above. I think it works the best, because it doesn't create massive padding between your divs.

.anchor:before {
  content:"""";
  display:block;
  height:60px; /* fixed header height*/
  margin:-60px 0 0; /* negative fixed header height */
}


It doesn't seem to work for the first div on the page, but you can counter that by adding padding to that first div.

#anchor-one{padding-top: 60px;}


Here's a working fiddle: http://jsfiddle.net/FRpHE/24/
    It feels somewhat hacky to my purist mind but as a css-only solution you can add padding to the active anchored element using the :target selector:

html, body {height:100%; min-height:100%; margin:0;}
body {min-height:200%;}
header {display:inline-block; position:fixed; font-size:1.5em; height:100px; top:0; left:0; right:0; line-height:100px; background:black; text-align:center;}
header a {color:#fff;}
section {padding:30px; margin:20px;}
section:first-of-type, section:target {padding-top:130px;}<header><a href=""#one"">#One</a> <a href=""#two"">#two</a> <a href=""#three"">#three</a></header>
<section id=""one""><h1>One</h1>Aenean lacinia bibendum nulla sed consectetur. Nullam id dolor id nibh ultricies vehicula ut id elit. Integer posuere erat a ante venenatis dapibus posuere velit aliquet.</section>
<section id=""two""><h1>Two</h1>Aenean lacinia bibendum nulla sed consectetur. Nullam id dolor id nibh ultricies vehicula ut id elit. Integer posuere erat a ante venenatis dapibus posuere velit aliquet.</section>
<section id=""three""><h1>Three</h1>Aenean lacinia bibendum nulla sed consectetur. Nullam id dolor id nibh ultricies vehicula ut id elit. Integer posuere erat a ante venenatis dapibus posuere velit aliquet.</section>

    The best way that I found to handle this issue is (replace 65px with your fixed element height):

div:target {
  padding-top: 65px; 
  margin-top: -65px;
}


If you do not like to use the target selector you can also do it in this way:

.my-target {
    padding-top: 65px;
    margin-top: -65px;
}


Note: this example will not work if the target element have a backgound color that differant from his parent.
for example:

<div style=""background-color:red;height:100px;""></div>
<div class=""my-target"" style=""background-color:green;height:100px;""></div>


in this case the green color of my-target element will overwrite his parent red element in 65px.
I did not find any pure CSS solution to handle this issue but if you do not have another background color this solution is the best.
    I wasn't having any luck with the answer listed above and ended up using this solution which worked perfectly...

Create a blank span where you want to set your anchor. 

<span class=""anchor"" id=""section1""></span>
<div class=""section""></div>


And apply the following class:

.anchor {
  display: block;
  height: 115px;       /* same height as header */
  margin-top: -115px;  /* same height as header */
  visibility: hidden;
}


This solution will work even if the sections have different colored backgrounds! I found the solution at this link.
    You could try this:

<style>
h1:target { padding-top: 50px; }
</style>

<a href=""#bar"">Go to bar</a>

<h1 id=""bar"">Bar</h1>


Set the top padding value to the actual height of your header. This will introduce a slight extra gap at the top of your header, but it will only be visible when the user jumps to the anchor and then scrolls up. I've made up that solution for my site right now, but it only shows a small fixed bar at the top of the page, nothing too high.
    Just discovered another pure CSS solution that worked like a charme for me!

html {
  scroll-padding-top: 80px; /* height of your sticky header */
}


Found on this site!
    I had a lot of trouble with many of the answers here and elsewhere as my bookmarked anchors were section headers in an FAQ page, so offsetting the header didn't help as the rest of the content would just stay where it was. So I thought I'd post.

What I ended up doing was a composite of a few solutions:


The CSS:

.bookmark {
    margin-top:-120px;
    padding-bottom:120px; 
    display:block;
}



Where ""120px"" is your fixed header height (maybe plus some margin).


The bookmark link HTML:

<a href=""#01"">What is your FAQ question again?</a>

The bookmarked content HTML:

<span class=""bookmark"" id=""01""></span>
<h3>What is your FAQ question again?</h3>
<p>Some FAQ text, followed by ...</p>
<p>... some more FAQ text, etc ...</p>



The good thing about this solution is that the span element is not only hidden, it is essentially collapsed and doesn't pad out your content.

I can't take much credit for this solution as it comes from a swag of different resources, but it worked best for me in my situation.

You can see the actual result here.
    I think this approach is more useful:

<h2 id=""bar"" title=""Bar"">Bar</h2>

[id]:target {
    display: block;
    position: relative;
    top: -120px;
    visibility: hidden;
}

[id]:target::before {
    content: attr(title);
    top: 120px;
    position: relative;
    visibility: visible;
}

    Used this script 

$(document).on('click', 'a[href^=""#""]', function (event) {
    event.preventDefault();

    $('html, body').animate({
        scrollTop: $($.attr(this, 'href')).offset().top -140
    }, 1000);
});

    I needed something that works for inbound links, links on page, AND that can be targeted by JS so the page can respond to changes in the header height

HTML

<ul>
  <li><a href=""#ft_who"">Who?</a></li>
  <li><a href=""#ft_what"">What?</a></li>
  <li><a href=""#ft_when"">When?</a></li>
</ul>
...
<h2 id=""ft_who"" class=""fragment-target"">Who?</h2> 
...
<a href=""#"">Can I be clicked?</a>
<h2 id=""ft_what"" class=""fragment-target"">What?</h2>
...
<h2 id=""ft_when"" class=""fragment-target"">When?</h2> 


CSS

.fragment-target {
    display: block;
    margin-top: -HEADER_HEIGHTpx;
    padding-top: HEADER_HEIGHTpx;
    z-index: -1;
}


The z-index: -1 allows links in the 'padding area' above a fragment-target to still be clickable, as commented by @MuttenXd on his answer

I haven't found an issue yet in IE 11, Edge 15+, Chrome 38+, FF 52+, or Safari 9.1+
    I created a div with a few line breaks and gave that the id, I then put the code I wanted to show underneath. The link would then take you to the space above the image and the header would no longer be in the way:

<a href=""#image"">Image</a>
<div id=""image""><br><br></div>
<img src=""Image.png"">


Of course, you can change the number of line breaks to suit your needs.
This worked perfectly for me, not sure if there are any problems though, I am still learning HTML.
    I found I had to use both MutttenXd's and Badabam's CSS solutions together, as the first did not work in Chrome and the second did not work in Firefox:

a.anchor { 
  padding-top: 90px;
}

a.anchor:before { 
  display: block;
  content: """";
  height: 90px;
  margin-top: -90px;
}

<a class=""anchor"" name=""shipping""></a><h2>Shipping (United States)</h2>
...

    CSS trick will be a workaround. A proper solution which will work in all scenario can be implemented using jQuery.

Refer to https://codepen.io/pikeshmn/pen/mMxEdZ

Approach: We get the height of fixed nav using document.getElementById('header').offsetHeight
And offset the scroll to this value.

var jump=function(e){  

e.preventDefault();                        //prevent ""hard"" jump
  var target = $(this).attr(""href"");       //get the target

      //perform animated scrolling
      $('html,body').animate(
        {
          scrollTop: $(target).offset().top - document.getElementById('header').offsetHeight - 5  //get top-position of target-element and set it as scroll target
        },1000,function()                  //scrolldelay: 1 seconds
        {
          location.hash = target;          //attach the hash (#jumptarget) to the pageurl
        });
      }

  $(document).ready(function()
  {
    $('a[href*=""#""]').bind(""click"", jump); //get all hrefs
    return false;
  });


P.S: 


It includes a nice 5 pixels difference between header and target
Scroll effect is not hard, rather smooth; Smooth Scrolling

    The way that I find being the cleanest is the following one :

  #bar::before {
    display: block;
    content: "" "";
    margin-top: -150px;
    height: 150px;
    visibility: hidden;
    pointer-events: none;
  }

    A minimally intrusive approach using jQuery:

Link:

<a href=""#my-anchor-1"" class=""anchor-link"">Go To Anchor 1</a>


Content:

<h3 id=""my-anchor-1"">Here is Anchor 1</a>


Script:

$("".anchor-link"").click(function() {
    var headerHeight = 120;
    $('html, body').stop(true, true).animate({
        scrollTop: $(this.hash).offset().top - headerHeight
    }, 750);
    return false;
});


By assigning the anchor-link class to the links, the behaviour of other links (like accordion or tab controls) are not affected.

The question doesn't want javascript but the other more popular question is closed because of this one and I couldn't answer there.
    It works for me:

HTML LINK to Anchor:

<a href=""#security"">SECURITY</a>


HTML Anchor:

<a name=""security"" class=""anchor""></a>


CSS :

.anchor::before {
    content: """";
    display: block;
    margin-top: -50px;
    position: absolute;
}

    For Chrome/Safari/Firefox you could add a display: block and use a negative margin to compensate the offset, like:

a[name] {
    display: block;
    padding-top: 90px;
    margin-top: -90px;
}


See example http://codepen.io/swed/pen/RrZBJo
    This is how I got it to finally go to the proper place when you click on the navigation. I added an event handler for the navigation clicks. Then you can just use ""scrollBy"" to move up on the offset.

var offset = 90;

 $('.navbar li a').click(function(event) {
    event.preventDefault();
    $($(this).attr('href'))[0].scrollIntoView();
    scrollBy(0, -offset);
 });

    I'm using @Jpsy's answer, but for performance reasons I'm only setting the timer if the hash is present in the URL.

$(function() {
      // Only set the timer if you have a hash
      if(window.location.hash) {
        setTimeout(delayedFragmentTargetOffset, 500);
      }
  });

function delayedFragmentTargetOffset(){
      var offset = $(':target').offset();
      if(offset){
          var scrollto = offset.top - 80; // minus fixed header height
          $('html, body').animate({scrollTop:scrollto}, 0);
          $(':target').highlight();
      }
  };

    The top answer here created a 60px-high  tag that was masking other links that stopped working as a result. I found this solution working without side-effects.
<a class=""anchor"" id=""top""></a>

a.anchor {
    display: block;
    position: relative;
    top: -60px;
    visibility: hidden;
}

    I use this approach:

/* add class=""jumptarget"" to all targets. */

.jumptarget::before {
  content:"""";
  display:block;
  height:50px; /* fixed header height*/
  margin:-50px 0 0; /* negative fixed header height */
}


It adds an invisible element before each target. It works IE8+.

Here are more solutions:
http://nicolasgallagher.com/jump-links-and-viewport-positioning/
    Official Bootstrap Adopted Answer:

*[id]:before { 
  display: block; 
  content: "" ""; 
  margin-top: -75px; // Set the Appropriate Height
  height: 75px; // Set the Appropriate Height
  visibility: hidden; 
}


Credits

Merge
    ","[484, 189, 345, 68, 5, 176, 5, 19, 15, 7, 4, 35, 6, 6, 8, 5, 1, 1, 2, 1, 3, 0, 3, 2, 5, 8, 1, 4, -1, 130, 51]",239049,154,2010-11-03T10:31:11,2021-12-17 18:29:30Z,html 
How can I delete a service in Windows?,"
                
I have a couple old services that I want to completely uninstall. How can I do this?
    Use the SC command, like this (you need to be on a command prompt to execute the commands in this post):

SC STOP shortservicename
SC DELETE shortservicename




Note: You need to run the command prompt as an administrator, not just logged in as the administrator, but also with administrative rights. If you get errors above about not having the necessary access rights to stop and/or delete the service, run the command prompt as an administrator. You can do this by searching for the command prompt on your start menu and then right-clicking and selecting ""Run as administrator"". Note to PowerShell users: sc is aliased to set-content. So sc delete service will actually create a file called delete with the content service. To do this in Powershell, use sc.exe delete service instead



If you need to find the short service name of a service, use the following command to generate a text file containing a list of services and their statuses:

SC QUERY state= all >""C:\Service List.txt""


For a more concise list, execute this command:

SC QUERY state= all | FIND ""_NAME""


The short service name will be listed just above the display name, like this:

SERVICE_NAME: MyService
DISPLAY_NAME: My Special Service


And thus to delete that service:

SC STOP MyService
SC DELETE MyService

    Click Start | Run and type regedit in the Open: line. Click OK.

Navigate to HKEY_LOCAL_MACHINE\SYSTEM\CurrentControlSet\Services

Scroll down the left pane, locate the service name, right click it and select Delete.

Reboot the system.
    As described above I executed:

sc delete ServiceName


However this didn't work as I was executing it from PowerShell.

When using PowerShell you must specify the full path to sc.exe because PowerShell has a default alias for sc assigning it to Set-Content. Since it's a valid command it doesn't actually show an error message.

To resolve this I executed it as follows:

C:\Windows\System32\sc.exe delete ServiceName

    Use services.msc or (Start > Control Panel > Administrative Tools > Services) to find the service in question. Double-click to see the service name and the path to the executable.

Check the exe version information for a clue as to the owner of the service, and use Add/Remove programs to do a clean uninstall if possible.

Failing that, from the command prompt:

sc stop servicexyz
sc delete servicexyz


No restart should be required.
    SC DELETE ""service name""


Run the command on cmd as Administrator otherwise you will get this error :- 


  openservice failed 5 access is denied

    If you have Windows Vista or above please run this from a command prompt as Administrator:

sc delete [your service name as shown in service.msc e.g moneytransfer]


For example: sc delete moneytransfer

Delete the folder C:\Program Files\BBRTL\moneytransfer\

Find moneytransfer registry keys and delete them:

 HKEY_CLASSES_ROOT\Installer\Products\
 HKEY_LOCAL_MACHINE\Software\Microsoft\Windows\CurrentVersion\Uninstall\
 HKEY_LOCAL_MACHINE\System\CurrentControlSet\Services\EventLog\
 HKEY_LOCAL_MACHINE\System\CurrentControlSet002\Services\
 HKEY_LOCAL_MACHINE\System\CurrentControlSet002\Services\EventLog\
 HKEY_LOCAL_MACHINE\Software\Classes\Installer\Assemblies\ [remove .exe references]
 HKEY_LOCAL_MACHINE\Software\Microsoft\Windows\CurrentVersion\Installer\Folders


These steps have been tested on Windows XP, Windows 7, Windows Vista, Windows Server 2003, and Windows Server 2008.
    This did the job for me on Windows 10:

start the cmd.exe as admin
run SC DELETE ""com.docker.service""
reinstall docker

    Before removing the service you should review the dependencies.

You can check it:

Open services.msc and find the service name, switch to the ""Dependencies"" tab.

Source: http://www.sysadmit.com/2016/03/windows-eliminar-un-servicio.html
    We can do it in two different ways
Remove Windows Service via Registry
Its very easy to remove a service from registry if you know the right path. Here is how I did that:

Run Regedit or Regedt32

Go to the registry entry ""HKEY_LOCAL_MACHINE/SYSTEM/CurrentControlSet/Services""

Look for the service that you want delete and delete it. You can look at the keys to know what files the service was using and delete them as well (if necessary).


Delete Windows Service via Command Window
Alternatively, you can also use command prompt and delete a service using following command:
sc delete 
You can also create service by using following command
sc create ""MorganTechService"" binpath= ""C:\Program Files\MorganTechSPace\myservice.exe""
Note: You may have to reboot the system to get the list updated in service manager.
    If they are .NET created services you can use the installutil.exe with the /u switch
its in the .net framework folder like
C:\Windows\Microsoft.NET\Framework64\v2.0.50727
    sc delete name
    Here is a vbs script that was passed down to me:

Set servicelist = GetObject(""winmgmts:"").InstancesOf (""Win32_Service"")

for each service in servicelist
    sname = lcase(service.name)
    If sname = ""NameOfMyService"" Then 
        msgbox(sname)
        service.delete ' the internal name of your service
    end if
next

    For me my service that I created had to be uninstalled in Control Panel > Programs and Features
    You can use my small service list editor utility Service Manager



You can choose any service > Modify > Delete. Method works immediately, no reboot required.

Executable file: [Download]

Source code: [Download]

Blog post: [BlogLink]

Service editor class: WinServiceUtils.cs
    ","[484, 901, 61, 14, 25, 19, 9, 1, 1, 9, 6, 1, 2, 0, 0]",673526,129,2008-09-16T19:36:41,2021-08-13 11:50:34Z,
Maven Modules + Building a Single Specific Module,"
                
I have a multi-module Maven project with a parent project P and three sub-modules A, B, and C.  Both B and C are war projects and both depend on A.  

I can type mvn compile in P and have all of the sub-modules properly compiled. The problem comes when I want to do operations for specific modules.

I'd like to be able to package a war for project B, but when I run the package command from B's directory, it complains that it can't find the dependencies for A.  

I understand from this question: Maven and dependent modules that perhaps Maven isn't really designed for this type of dependency resolution, but that begs the question of how do I package B?  


Do I have to run mvn package for the entire project hierarchy when I really just want B?  
Do I have to install snapshots of A into my local repository every time I want to package B?  


This second scenario isn't much fun when A is still under active development.

Any best practices here?
    
Any best practices here?

Use the Maven advanced reactor options, more specifically:
-pl, --projects
        Build specified reactor projects instead of all projects
-am, --also-make
        If project list is specified, also build projects required by the list

So just cd into the parent P directory and run:
mvn install -pl B -am

And this will build B and the modules required by B.
Note that you need to use a colon if you are referencing an artifactId which differs from the directory name:
mvn install -pl :B -am

As described here:

Define modules list which shall be build in Maven multiproject build

    Say Parent pom.xml contains 6 modules and you want to run A, B and F.

<modules>
        <module>A</module>
        <module>B</module>
        <module>C</module>
        <module>D</module>
        <module>E</module>
        <module>F</module>
  </modules>


1- cd into parent project

 mvn --projects A,B,F --also-make clean install


OR

mvn -pl A,B,F -am clean install


OR

mvn -pl A,B,F -amd clean install


Note: When you specify a project with the -am option, Maven will build all of the projects that the specified project depends upon (either directly or indirectly). Maven will examine the list of projects and walk down the dependency tree, finding all of the projects that it needs to build.

While the -am command makes all of the projects required by a particular project in a multi-module build, the -amd or --also-make-dependents option configures Maven to build a project and any project that depends on that project. When using --also-make-dependents, Maven will examine all of the projects in our reactor to find projects that depend on a particular project. It will automatically build those projects and nothing else.
    Maven absolutely was designed for this type of dependency.

mvn package won't install anything in your local repository it just packages the project and leaves it in the target folder.

Do mvn install in parent project (A), with this all the sub-modules will be installed in your computer's Maven repository, if there are no changes you just need to compile/package the sub-module (B) and Maven will take the already packaged and installed dependencies just right.

You just need to a mvn install in the parent project if you updated some portion of the code.
    You say you ""really just want B"", but this is false.  You want B, but you also want an updated A if there have been any changes to it (""active development"").

So, sometimes you want to work with A, B, and C.  For this case you have aggregator project P.  For the case where you want to work with A and B (but do not want C), you should create aggregator project Q.

Edit 2016: The above information was perhaps relevant in 2009. As of 2016, I highly recommend ignoring this in most cases, and simply using the -am or -pl command-line flags as described in the accepted answer. If you're using a version of maven from before v2.1, change that first :)
    If you have previously run mvn install on project B it will have been installed to your local repository, so when you build package A Maven can resolve the dependency. So as long as you install project B each time you change it your builds for project A will be up to date.

You can define a multi-module project with an aggregator pom to build a set of projects. 

It's also worthwhile mentioning m2eclipse, it integrates Maven into Eclipse and allows you to (optionally) resolve dependencies from the workspace. So if you are hacking away on multiple projects, the workspace content will be used for compilation. Once you are happy with your changes, run mvn install (on each project in turn, or using an aggregator) to put them in your local repository.
    Take a look at my answer Maven and dependent modules.  

The Maven Reactor plugin is designed to deal with building part of a project.

The particular goal you'll want to use it reactor:make.
    ","[484, 847, 57, 12, 5, 10, 5]",317453,179,2009-07-11T16:12:05,2021-08-05 17:02:21Z,java 
Can you set a border opacity in CSS?,"
                
Is there a straight forward CSS way to make the border of an element semi-transparent with something like this?

border-opacity: 0.7;


If not, does anyone have an idea how I could do so without using images?
    Unfortunately the opacity property makes the whole element (including any text) semi-transparent. The best way to make the border semi-transparent is with the rgba color format. For example, this would give a red border with 50% opacity:
div {
    border: 1px solid rgba(255, 0, 0, .5);
    -webkit-background-clip: padding-box; /* for Safari */
    background-clip: padding-box; /* for IE9+, Firefox 4+, Opera, Chrome */
}

For extremely old browsers that don't support rgba (IE8 and older), the solution is to provide two border declarations. The first with a fake opacity, and the second with the actual. If a browser is capable, it will use the second, if not, it will use the first.
div {
    border: 1px solid rgb(127, 0, 0);
    border: 1px solid rgba(255, 0, 0, .5);
    -webkit-background-clip: padding-box; /* for Safari */
    background-clip: padding-box; /* for IE9+, Firefox 4+, Opera, Chrome */
}

The first border declaration will be the equivalent color to a 50% opaque red border over a white background (although any graphics under the border will not bleed through).
I've added background-clip: padding-box; to the examples above to ensure the border remains transparent even if a solid background color is applied.
    It's easy, use a solid shadow with 0 offset:

#foo {
  border-radius: 1px;
  box-shadow: 0px 0px 0px 8px rgba(0,0,0,0.3);       
}


Also, if you set a border-radius to the element, it gives you pretty rounded borders

jsFiddle Demo


    As others have mentioned, CSS3 supports the rgba(...) syntax to specify a border color with an opacity (alpha) value.
Here's a quick JSFiddle demo if you'd like to check it.

It works in Safari and Chrome (probably works in all webkit browsers).

It works in Firefox

I doubt that it works at all in IE, but I suspect that there is some filter or behavior that will make it work.


There's also CSS RGBA border / background alpha double, which suggests some other issues—namely, that the border renders on-top-of any background color (or background image) that you've specified; thus limiting the usefulness of border alpha in many cases.
    If you check your CSS coding with W3C validator, you will see if your CSS code is acceptable, even if it worked in the major browsers.

Creating a transparent border via CSS, as written above, 

border: 1px solid rgba(255, 0, 0, .5);


is not accepted by W3C standards, not even for CSS3. I used the direct input validator with the following CSS code, 

.test { border: 1px solid rgba(255, 0, 0, .5); }


The results were, 


  Value Error : border Too many values or values are not recognized :
  1px solid rgba(255,0,0,0.5 )


Unfortunate that the alpha value (the letter ""a"" at the end of ""rgb"") is not accepted by W3C as part of the border color values as yet. I do wonder why it is not standardized, since it works in all browsers. The only hitch is whether you want to stick to W3C standards or step aside from it to create something in CSS.

To use W3C online CSS validator / Direct Input.

Always a good idea to use a validator to check your work, it really helps finding small or even large errors in coding when your going cross-eyed after hours of coding work.
    One may also consider other border styles (dashed, dotted) to make the border partly fully transparent:

http://jsfiddle.net/c1rvp3ga
body {
    background: url('http://i.imgur.com/pr86mh.jpg');
}

#foo {
  border: 5px dashed #b00;
  background: #ddd;
  background-clip: padding-box;
  padding: 8px;
  width: 100px;
  margin: 30px;
}<p id=foo>some content</p>

    try this:

<h2>Snippet for making borders transparent</h2>
<div>
  <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Integer nec odio. Praesent libero. Sed cursus ante dapibus diam. Sed nisi. Nulla quis sem at nibh elementum imperdiet. Duis sagittis ipsum. Praesent mauris. Fusce nec tellus sed augue semper porta.
    Mauris massa. Vestibulum lacinia arcu eget nulla. <b>Lorem ipsum dolor sit amet, consectetur adipiscing elit</b>. Class aptent taciti sociosqu ad litora torquent per conubia nostra, per inceptos himenaeos. Curabitur sodales ligula in libero. Sed dignissim
    lacinia nunc. <i>Lorem ipsum dolor sit amet, consectetur adipiscing elit</i>. Curabitur tortor. Pellentesque nibh. Aenean quam. In scelerisque sem at dolor. Maecenas mattis. Sed convallis tristique sem. Proin ut ligula vel nunc egestas porttitor.
    <i>Lorem ipsum dolor sit amet, consectetur adipiscing elit</i>. Morbi lectus risus, iaculis vel, suscipit quis, luctus non, massa. Fusce ac turpis quis ligula lacinia aliquet. Mauris ipsum. Nulla metus metus, ullamcorper vel, tincidunt sed, euismod
    in, nibh. Quisque volutpat condimentum velit. Class aptent taciti sociosqu ad litora torquent per conubia nostra, per inceptos himenaeos. Nam nec ante. Sed lacinia, urna non tincidunt mattis, tortor neque adipiscing diam, a cursus ipsum ante quis
    turpis. Nulla facilisi. Ut fringilla. Suspendisse potenti. Nunc feugiat mi a tellus consequat imperdiet. Vestibulum sapien. Proin quam. Etiam ultrices. <b>Nam nec ante</b>. Suspendisse in justo eu magna luctus suscipit. Sed lectus. <i>Sed convallis tristique sem</i>.
    Integer euismod lacus luctus magna. <b>Class aptent taciti sociosqu ad litora torquent per conubia nostra, per inceptos himenaeos</b>. Quisque cursus, metus vitae pharetra auctor, sem massa mattis sem, at interdum magna augue eget diam. Vestibulum
    ante ipsum primis in faucibus orci luctus et ultrices posuere cubilia Curae; Morbi lacinia molestie dui. Praesent blandit dolor. Sed non quam. In vel mi sit amet augue congue elementum. Morbi in ipsum sit amet pede facilisis laoreet. Donec lacus nunc,
    viverra nec, blandit vel, egestas et, augue. Vestibulum tincidunt malesuada tellus. Ut ultrices ultrices enim. <b>Suspendisse in justo eu magna luctus suscipit</b>. Curabitur sit amet mauris. Morbi in dui quis est pulvinar ullamcorper. </p>
</div>
<div id=""transparentBorder"">
  This &lt;div&gt; has transparent borders.
</div>


And here comes our magical CSS..

* {
  padding: 10pt;
  font: 13px/1.5 Helvetica Neue, Arial, Helvetica, 'Liberation Sans', FreeSans, sans-serif;
}

b {
  font-weight: bold;
}

i {
  font-style: oblique;
}

H2 {
  font-size: 2em;
}

div[id='transparentBorder'] {
  height: 100px;
  width: 200px;
  padding: 10px;
  position: absolute;
  top: 40%;
  left: 30%;
  text-align: center;
  background: Black;
  border-radius: 4px;
  border: 10pt solid rgba(0, 0, 0, 0.5);
  -moz-background-clip: border;
  /* Firefox 3.6 */
  -webkit-background-clip: border;
  /* Safari 4? Chrome 6? */
  background-clip: border-box;
  /* Firefox 4, Safari 5, Opera 10, IE 9 */
  -moz-background-clip: padding;
  /* Firefox 3.6 */
  -webkit-background-clip: padding;
  /* Safari 4? Chrome 6? */
  background-clip: padding-box;
  /* Firefox 4, Safari 5, Opera 10, IE 9 */
  text-align: center;
  margin: 0;
  color: #fff;
  cursor: pointer;
}


Check out the Demo here.
    *Not as far as i know there isn't what i do normally in this kind of circumstances is create a block beneath with a bigger size((bordersize*2)+originalsize) and make it transparent using

filter:alpha(opacity=50);
-moz-opacity:0.5;
-khtml-opacity: 0.5;
opacity: 0.5;


here is an example

#main{
    width:400px;
    overflow:hidden;
    position:relative;
}
.border{
    width:100%;
    position:absolute;
    height:100%;
    background-color:#F00;
    filter:alpha(opacity=50);
    -moz-opacity:0.5;
    -khtml-opacity: 0.5;
    opacity: 0.5;
}
.content{
    margin:15px;/*size of border*/
    background-color:black;
}
<div id=""main"">
    <div class=""border"">
    </div>
    <div class=""content"">
        testing
    </div>
</div>


Update:

This answer is outdated, since after all this question is more than 8 years old. Today all up to date browsers support rgba, box shadows and so on. But this is a decent example how it was 8+ years ago.
    As an alternate solution that may work in some cases: change the border-style to dotted.

Having alternating groups of pixels between the foreground color and the background color isn't the same as a continuous line of partially transparent pixels. On the other hand, this requires significantly less CSS and it is much more compatible across every browser without any browser-specific directives.
    Since this answer is top of Google results, decided to post an updated (2021) answer for the rookies like me.
You can set a border opacity buy using an rgba color.
border:2px solid rgba(232, 69, 69,.5); /* notice the .5 */

See example fiddle here - http://jsfiddle.net/joshdane/74pybasm/33/
You can use it, and enjoy it.
There is some discussion that older browsers don't support rgba, but most people are not using older browsers anymore. If you are just learning, don't worry about supporting older browsers.

    Other answers deal with the technical aspect of the border-opacity issue, while I'd like to present a hack(pure CSS and HTML only). Basically create a container div, having a border div and then the content div.

<div class=""container"">
  <div class=""border-box""></div>
  <div class=""content-box""></div>
</div>


And then the CSS:(set content border to none, take care of positioning such that border thickness is accounted for)

.container {
  width: 20vw;
  height: 20vw;
  position: relative;
}
.border-box {
  width: 100%;
  height: 100%;
  border: 5px solid black;
  position: absolute;
  opacity: 0.5;
}
.content-box {
  width: 100%;
  height: 100%;
  border: none;
  background: green;
  top: 5px;
  left: 5px;
  position: absolute;
}

    Thinking outside the box a bit here: if you are working with SVG basic shapes, you can use a combination of stroke, stroke-width (browser support > 97%), and stroke-opacity (browser support > 99%) to do essentially the same thing the OP is asking.
For example, this declaration:
circle {
    stroke: blue;
    stroke-width: 5px;
    stroke-opacity: 0.4
}

will add a translucent blue halo around the perimeter of a <circle> with #000 fill.
This JSFiddle provides a demo for several SVG basic shapes. The fiddle uses a red fill and blue stroke to highlight a major difference here between stroke and border - half the stroke-width is inside the perimeter of the basic shape.
This gives a ""double border"" appearance (from outside towards the center for each basic shape: blue->(blue + red = purple)->red) that would be impossible to achieve with CSS border alone (but border + outline could - see the above JSFiddle for an example using a <div>), and difficult to achieve (in the case of radial basic shapes) with a radial-gradient().
    ","[484, 733, 149, 17, 8, 0, -1, 5, 1, -2, 0, 0]",783276,100,2010-10-31T05:48:53,2022-03-01 02:13:09Z,css 
What is the reason for having '//' in Python? [duplicate],"
                    
            
        
            
                
                    
                        This question already has answers here:
                        
                    
                
            
                    
                        What is the difference between '/' and '//' when used for division?
                            
                                (16 answers)
                            
                    
                Closed 6 years ago.
        

    

I saw this in someone's code:
y = img_index // num_images

where img_index is a running index and num_images is 3.
When I mess around with // in IPython, it seems to act just like a division sign (i.e. one forward slash). I was just wondering if there is any reason for having double forward slashes?
    In Python 3, they made the / operator do a floating-point division, and added the // operator to do integer division (i.e., quotient without remainder); whereas in Python 2, the / operator was simply integer division, unless one of the operands was already a floating point number.
In Python 2.X:
>>> 10/3
3
>>> # To get a floating point number from integer division:
>>> 10.0/3
3.3333333333333335
>>> float(10)/3
3.3333333333333335

In Python 3:
>>> 10/3
3.3333333333333335
>>> 10//3
3

For further reference, see PEP238.
    // is unconditionally ""flooring division"", e.g:
>>> 4.0//1.5
2.0

As you see, even though both operands are floats, // still floors -- so you always know securely what it's going to do.
Single / may or may not floor depending on Python release, future imports, and even flags on which Python's run, e.g.:
$ python2.6 -Qold -c 'print 2/3'
0
$ python2.6 -Qnew -c 'print 2/3'
0.666666666667

As you see, single / may floor, or it may return a float, based on completely non-local issues, up to and including the value of the -Q flag...;-).
So, if and when you know you want flooring, always use //, which guarantees it. If and when you know you don't want flooring, slap a float() around other operand and use /. Any other combination, and you're at the mercy of version, imports, and flags!-)
    To complement these other answers, the // operator also offers significant (3x) performance benefits over /, presuming you want integer division.
$ python -m timeit '20.5 // 2'
100,000,000 loops, best of 3: 14.9 nsec per loop

$ python -m timeit '20.5 / 2'
 10,000,000 loops, best of 3: 48.4 nsec per loop

$ python -m timeit '20 / 2'
 10,000,000 loops, best of 3: 43.0 nsec per loop

$ python -m timeit '20 // 2'
100,000,000 loops, best of 3: 14.4 nsec per loop

    To complement Alex's response, I would add that starting from Python 2.2.0a2, from __future__ import division is a convenient alternative to using lots of float(…)/….  All divisions  perform float divisions, except those with //.  This works with all versions from 2.2.0a2 on.
    // can be considered an alias to math.floor() for divisions with return value of type float. It operates as no-op for divisions with return value of type int.

import math
# let's examine `float` returns
# -------------------------------------
# divide
>>> 1.0 / 2
0.5
# divide and round down
>>> math.floor(1.0/2)
0.0
# divide and round down
>>> 1.0 // 2
0.0

# now let's examine `integer` returns
# -------------------------------------
>>> 1/2
0
>>> 1//2
0

    ","[484, 617, 216, 27, 24, 11]",362617,90,2009-10-08T04:15:37,2020-12-01 10:04:39Z,python 
What is an NP-complete in computer science?,"
                
What is an NP-complete problem? Why is it such an important topic in computer science?
    What is NP?
NP is the set of all decision problems (questions with a yes-or-no answer) for which the 'yes'-answers can be verified in polynomial time (O(nk) where n is the problem size, and k is a constant) by a deterministic Turing machine. Polynomial time is sometimes used as the definition of fast or quickly.
What is P?
P is the set of all decision problems which can be solved in polynomial time by a deterministic Turing machine. Since they can be solved in polynomial time, they can also be verified in polynomial time. Therefore P is a subset of NP.
What is NP-Complete?
A problem x that is in NP is also in NP-Complete if and only if every other problem in NP can be quickly (ie. in polynomial time) transformed into x.
In other words:

x is in NP, and
Every problem in NP is reducible to x

So, what makes NP-Complete so interesting is that if any one of the NP-Complete problems was to be solved quickly, then all NP problems can be solved quickly.
See also the post What's ""P=NP?"", and why is it such a famous question?
What is NP-Hard?
NP-Hard are problems that are at least as hard as the hardest problems in NP. Note that NP-Complete problems are also NP-hard. However not all NP-hard problems are NP (or even a decision problem), despite having NP as a prefix. That is the NP in NP-hard does not mean non-deterministic polynomial time. Yes, this is confusing, but its usage is entrenched and unlikely to change.
    NP stands for Non-deterministic Polynomial time.

This means that the problem can be solved in Polynomial time using a Non-deterministic Turing machine (like a regular Turing machine but also including a non-deterministic ""choice"" function). Basically, a solution has to be testable in poly time. If that's the case, and a known NP problem can be solved using the given problem with modified input (an NP problem can be reduced to the given problem) then the problem is NP complete.

The main thing to take away from an NP-complete problem is that it cannot be solved in polynomial time in any known way. NP-Hard/NP-Complete is a way of showing that certain classes of problems are not solvable in realistic time.

Edit: As others have noted, there are often approximate solutions for NP-Complete problems. In this case, the approximate solution usually gives an approximation bound using special notation which tells us how close the approximation is.
    NP-Complete is a class of problems. 

The class P consists of those problems that are solvable in polynomial time. For example, they could be solved in O(nk) for some constant k, where n is the size of the input. Simply put, you can write a program that will run in reasonable time.

The class NP consists of those problems that are verifiable in polynomial time. That is, if we are given a potential solution, then we could check if the given solution is correct in polynomial time.

Some examples are the Boolean Satisfiability (or SAT) problem, or the Hamiltonian-cycle problem. There are many problems that are known to be in the class NP. 

NP-Complete means the problem is at least as hard as any problem in NP.

It is important to computer science because it has been proven that any problem in NP can be transformed into another problem in NP-complete. That means that a solution to any one NP-complete problem is a solution to all NP problems.

Many algorithms in security depends on the fact that no known solutions exist for NP hard problems. It would definitely have a significant impact on computing if a solution were found.
    As far as I understand
P is the set of problems which could be solved in polynomial time with a deterministic TM.
NP is the set of problems which requires a non-deterministic TM to be solved in polynomial time.
This means that we can check all different combinations of variables in parallel with each instance taking polynomial time. If the problem is solvable then at least one of those parallel instances of TM would halt with ""yes"".
This also means that if you could make a correct guess about the variables/solution then you just need to check it's validity in polynomial time.
NP-Hard is the set where problems are harder than NP. This means NP-Hard problem are more difficult than any problem in NP set. These problems are exponential even when using non-determinism of Turing machines. So parallel computation does not helps while solving these problems.
NP-Complete is the intersection set of NP and NP-Hard. According to what I understood,

problems in NP-Complete are at least as hard as the hardest problem in the NP set.
The class of all NP-Complete problems are equivalent to each other, i.e, a problem in NP-Complete set can be reduced to any other NP-Complete problem. That means if any of the NP-Complete problem would have an efficient solution then all of the NP-Complete problems could be solved with same solution.

If any problem in NP-Complete set is deterministically solvable in polynomial time, then the entire NP-Complete set is deterministically solvable in polynomial time. Also since NP-Complete problems are at least as hard as the hardest problem in the NP set, all problems in the NP set (which are equal or easier than the problems in NP-Complete set) will be bounded above by deterministically polynomial running time, expanding the P set over the NP set, resulting in P=NP.
Please let me know if I made any mistake.
    It's a class of problems where we must simulate every possibility to be sure we have the optimal solution. 

There are a lot of good heuristics for some NP-Complete problems, but they are only an educated guess at best.
    NP-Complete means something very specific and you have to be careful or you will get the definition wrong.  First, an NP problem is a yes/no problem such that


There is polynomial-time proof for every instance of the problem with a ""yes"" answer that the answer is ""yes"", or (equivalently)
There exists a polynomial-time algorithm (possibly using random variables) that has a non-zero probability of answering ""yes"" if the answer to an instance of the problem is ""yes"" and will say ""no"" 100% of the time if the answer is ""no."" In other words, the algorithm must have a false-negative rate less than 100% and no false positives.


A problem X is NP-Complete if


X is in NP, and
For any problem Y in NP, there is a ""reduction"" from Y to X: a polynomial-time algorithm that transforms any instance of Y into an instance of X such that the answer to the Y-instance is ""yes"" if and only if the answer X-instance is ""yes"".


If X is NP-complete and a deterministic, polynomial-time algorithm exists that can solve all instances of X correctly (0% false-positives, 0% false-negatives), then any problem in NP can be solved in deterministic-polynomial-time (by reduction to X).

So far, nobody has come up with such a deterministic polynomial-time algorithm, but nobody has proven one doesn't exist (there's a million bucks for anyone who can do either: the is the P = NP problem).  That doesn't mean that you can't solve a particular instance of an NP-Complete (or NP-Hard) problem.  It just means you can't have something that will work reliably on all instances of a problem the same way you could reliably sort a list of integers.  You might very well be able to come up with an algorithm that will work very well on all practical instances of a NP-Hard problem.
    The definitions for NP complete problems above is correct, but I thought I might wax lyrical about their philosophical importance as nobody has addressed that issue yet.

Almost all complex problems you'll come up against will be NP Complete. There's something very fundamental about this class, and which just seems to be computationally different from easily solvable problems. They sort of have their own flavour, and it's not so hard to recognise them. This basically means that any moderately complex algorithm is impossible for you to solve exactly -- scheduling, optimising, packing, covering etc.

But not all is lost if a problem you'll encounter is NP Complete. There is a vast and very technical field where people study approximation algorithms, which will give you guarantees for being close to the solution of an NP complete problem. Some of these are incredibly strong guarantees -- for example, for 3sat, you can get a 7/8 guarantee through a really obvious algorithm. Even better, in reality, there are some very strong heuristics, which excel at giving great answers (but no guarantees!) for these problems.

Note that two very famous problems -- graph isomorphism and factoring -- are not known to be P or NP. 
    If you're looking for an example of an NP-complete problem then I suggest you take a look at 3-SAT.

The basic premise is you have an expression in conjunctive normal form, which is a way of saying you have a series of expressions joined by ORs that all must be true:

(a or b) and (b or !c) and (d or !e or f) ...


The 3-SAT problem is to find a solution that will satisfy the expression where each of the OR-expressions has exactly 3 booleans to match:

(a or !b or !c) and (!a or b or !d) and (b or !c or d) ...


A solution to this one might be (a=T, b=T, c=F, d=F). However, no algorithm has been discovered that will solve this problem in the general case in polynomial time. What this means is that the best way to solve this problem is to do essentially a brute force guess-and-check and try different combinations until you find one that works.

What's special about the 3-SAT problem is that ANY NP-complete problem can be reduced to a 3-SAT problem. This means that if you can find a polynomial-time algorithm to solve this problem then you get $1,000,000, not to mention the respect and admiration of computer scientists and mathematicians around the world.
    Basically this world's problems can be categorized as

         1) Unsolvable Problem
         2) Intractable Problem
         3) NP-Problem
         4) P-Problem



         1)The first one is no solution to the problem.
         2)The second is the need exponential time (that is O (2 ^ n) above).
         3)The third is called the NP.
         4)The fourth is easy problem.



P: refers to a solution of the problem of Polynomial Time.

NP: refers Polynomial Time yet to find a solution. We are not sure there is no Polynomial Time solution, but once you provide a solution, this solution can be verified in Polynomial Time.

NP Complete: refers in Polynomial Time we still yet to find a solution, but it can be verified in Polynomial Time . The problem NPC in NP is the more difficult problem, so if we can prove that we have P solution to NPC problem then NP problems that can be found in P solution.

NP Hard: refers Polynomial Time is yet to find a solution, but it sure is not able to be verified in Polynomial Time . NP Hard problem surpasses NPC difficulty.
    I have heard an explanation, that is:""
NP-Completeness is probably one of the more enigmatic ideas in the study of algorithms. ""NP"" stands for ""nondeterministic polynomial time,"" and is the name for what is called a complexity class to which problems can belong. The important thing about the NP complexity class is that problems within that class can be verified by a polynomial time algorithm.
As an example, consider the problem of counting stuff. Suppose there are a bunch of apples on a table. The problem is ""How many apples are there?"" You are provided with a possible answer, 8. You can verify this answer in polynomial time by using the algorithm of, duh, counting the apples. Counting the apples happens in O(n) (that's Big-oh notation) time, because it takes one step to count each apple. For n apples, you need n steps. This problem is in the NP complexity class.

A problem is classified as NP-complete if it can be shown that it is both NP-Hard and verifiable in polynomial time. Without going too deeply into the discussion of NP-Hard, suffice it to say that there are certain problems to which polynomial time solutions have not been found. That is, it takes something like n! (n factorial) steps to solve them. However, if you're given a solution to an NP-Complete problem, you can verify it in polynomial time.

A classic example of an NP-Complete problem is The Traveling Salesman Problem.""

The author: ApoxyButt
From: http://www.everything2.com/title/NP-complete
    We need to separate algorithms and problems. We write algorithms to solve problems, and they scale in a certain way. Although this is a simplification, let's label an algorithm with a 'P' if the scaling is good enough, and 'NP' if it isn't.

It's helpful to know things about the problems we're trying to solve, rather than the algorithms we use to solve them. So we'll say that all the problems which have a well-scaling algorithm are ""in P"". And the ones which have a poor-scaling algorithm are ""in NP"".

That means that lots of simple problems are ""in NP"" too, because we can write bad algorithms to solve easy problems. It would be good to know which problems in NP are the really tricky ones, but we don't just want to say ""it's the ones we haven't found a good algorithm for"". After all, I could come up with a problem (call it X) that I think needs a super-amazing algorithm. I tell the world that the best algorithm I could come up with to solve X scales badly, and so I think that X is a really tough problem. But tomorrow, maybe somebody cleverer than me invents an algorithm which solves X and is in P. So this isn't a very good definition of hard problems.

All the same, there are lots of problems in NP that nobody knows a good algorithm for. So if I could prove that X is a certain sort of problem: one where a good algorithm to solve X could also be used, in some roundabout way, to give a good algorithm for every other problem in NP. Well now people might be a bit more convinced that X is a genuinely tricky problem. And in this case we call X NP-Complete.
    NP Problem :-

NP problem are such problem that can be solved in non-deterministic polynomial time.
Non deterministic algorithm operate in two stage.
Non deterministic guessing stage && Non deterministic verification stage.

Type of Np Problem

NP complete
NP Hard

NP Complete problem :-
1 Decision Problem A is called NP complete if it has following two properties:-

It belong to class NP.
Every other problem in NP can be transformed to P in polynomial time.

Some Ex :-

Knapsack problem
sub set sum problem
Vertex covering problem

    Honestly, Wikipedia might be the best place to look for an answer to this.

If NP = P, then we can solve very hard problems much faster than we thought we could before.  If we solve only one NP-Complete problem in P (polynomial) time, then it can be applied to all other problems in the NP-Complete category.
    NP-complete problems are a set of problems to each of which any
other NP-problem can be reduced in polynomial time, and whose solution
may still be verified in polynomial time. That is, any NP problem can be
transformed into any of the NP-complete problems.
– Informally, an NP-complete problem is an NP problem that is at least as ""tough""
as any other problem in NP.
    ","[484, 471, 230, 33, 5, 22, 36, 6, 19, 33, 8, 11, 3, 14, 1]",294559,244,2008-10-17T01:25:36,2021-07-01 14:38:42Z,
Map vs Object in JavaScript,"
                
I just discovered this feature:

Map: Map objects are simple key/value maps.

That confused me. Regular JavaScript objects are dictionaries, so how is a Map different from a dictionary? Conceptually, they're identical (according to another question on Stack Overflow)
The documentation doesn't help either:

Map objects are collections of key/value pairs where both the keys and values may be arbitrary ECMAScript language values. A distinct key value may only occur in one key/value pair within the Map’s collection. Distinct key values as discriminated using the a comparision algorithm that is selected when the Map is created.


A Map object can iterate its elements in insertion order. Map object must be implemented using either hash tables or other mechanisms that, on average, provide access times that are sublinear on the number of elements in the collection. The data structures used in this Map objects specification is only intended to describe the required observable semantics of Map objects. It is not intended to be a viable implementation model.

…still sounds like an object to me, so clearly I've missed something.
Why is JavaScript gaining a (well-supported) Map object? What does it do?
    According to MDN:

A Map object can iterate its elements in insertion order - a for..of loop will return an array of [key, value] for each iteration.

and

Objects are similar to Maps in that both let you set keys to values,
retrieve those values, delete keys, and detect whether something is
stored at a key. Because of this, Objects have been used as Maps
historically; however, there are important differences between Objects
and Maps that make using a Map better.
An Object has a prototype, so there are default keys in the map.
However, this can be bypassed using map = Object.create(null). The
keys of an Object are Strings, where they can be any value for a Map.
You can get the size of a Map easily while you have to manually keep
track of size for an Object.

Map
The iterability-in-order is a feature that has long been wanted by developers, in part because it ensures the same performance in all browsers. So to me that's a big one.
The myMap.has(key) method will be especially handy, and also the myMap.size property.
    The key difference is that Objects only support string and Symbol keys where as Maps support more or less any key type.
If I do obj[123] = true and then Object.keys(obj) then I will get [""123""] rather than [123]. A Map would preserve the type of the key and return [123] which is great. Maps also allow you to use Objects as keys. Traditionally to do this you would have to give objects some kind of unique identifier to hash them (I don't think I've ever seen anything like getObjectId in JavaScript as part of the standard). Maps also guarantee preservation of order so are all round better for preservation and can sometimes save you needing to do a few sorts.
Between maps and objects in practice there are several pros and cons. Objects gain both advantages and disadvantages being very tightly integrated into the core of JavaScript which sets them apart from significantly Map beyond the difference in key support.
An immediate advantage is that you have syntactical support for Objects making it easy to access elements. You also have direct support for it with JSON. When used as a hash it's annoying to get an object without any properties at all. By default if you want to use Objects as a hash table they will be polluted and you will often have to call hasOwnProperty on them when accessing properties. You can see here how by default Objects are polluted and how to create hopefully unpolluted objects for use as hashes:
({}).toString
    toString() { [native code] }
JSON.parse('{}').toString
    toString() { [native code] }
(Object.create(null)).toString
    undefined
JSON.parse('{}', (k,v) => (typeof v === 'object' && Object.setPrototypeOf(v, null) ,v)).toString
    undefined

Pollution on objects is not only something that makes code more annoying, slower, etc., but can also have potential consequences for security.
Objects are not pure hash tables, but they are trying to do more. You have headaches like hasOwnProperty, not being able to get the length easily (Object.keys(obj).length) and so on. Objects are not meant to purely be used as hash maps, but as dynamic extensible Objects as well and so when you use them as pure hash tables problems arise.
Comparison/List of various common operations:
Object:
   var o = {};
   var o = Object.create(null);
   o.key = 1;
   o.key += 10;
   for(let k in o) o[k]++;
   var sum = 0;
   for(let v of Object.values(m)) sum += v;
   if('key' in o);
   if(o.hasOwnProperty('key'));
   delete(o.key);
   Object.keys(o).length
Map:
   var m = new Map();
   m.set('key', 1);
   m.set('key', m.get('key') + 10);
   m.foreach((k, v) => m.set(k, m.get(k) + 1));
   for(let k of m.keys()) m.set(k, m.get(k) + 1);
   var sum = 0;
   for(let v of m.values()) sum += v;
   if(m.has('key'));
   m.delete('key');
   m.size();

There are a few other options, approaches, methodologies, etc. with varying ups and downs (performance, terse, portable, extendable, etc.). Objects are a bit strange being core to the language so you have a lot of static methods for working with them.
Besides the advantage of Maps preserving key types as well as being able to support things like objects as keys they are isolated from the side effects that objects much have. A Map is a pure hash, there's no confusion about trying to be an object at the same time. Maps can also be easily extended with proxy functions. Object's currently have a Proxy class however performance and memory usage is grim, in fact creating your own proxy that looks like Map for Objects currently performs better than Proxy.
A substantial disadvantage for Maps is that they are not supported with JSON directly. Parsing is possible, but it has several hangups:
JSON.parse(str, (k,v) => {
    if(typeof v !== 'object') return v;
    let m = new Map();
    for(k in v) m.set(k, v[k]);
    return m;
});

The above will introduce a serious performance hit and will also not support any string keys. JSON encoding is even more difficult and problematic (this is one of many approaches):
// An alternative to this it to use a replacer in JSON.stringify.
Map.prototype.toJSON = function() {
    return JSON.stringify({
        keys: Array.from(this.keys()),
        values: Array.from(this.values())
    });
};

This is not so bad if you're purely using Maps, but it will have problems when you are mixing types or using non-scalar values as keys (not that JSON is perfect with that kind of issue as it is, IE circular object reference). I haven't tested it, but chances are that it will severely hurt performance compared to stringify.
Other scripting languages often don't have such problems as they have explicit non-scalar types for Map, Object and Array. Web development is often a pain with non-scalar types where you have to deal with things like PHP merges Array/Map with Object using A/M for properties and JavaScript merges Map/Object with Array extending M/O. Merging complex types is the devil's bane of high level scripting languages.
So far these are largely issues around implementation, but performance for basic operations is important as well. Performance is also complex because it depends on engine and usage. Take my tests with a grain of salt as I cannot rule out any mistake (I have to rush this). You should also run your own tests to confirm as mine examine only very specific simple scenarios to give a rough indication only. According to tests in Chrome for very large objects/maps the performance for objects is worse because of delete which is apparently somehow proportionate to the number of keys rather than O(1):
Object Set Took: 146
Object Update Took: 7
Object Get Took: 4
Object Delete Took: 8239
Map Set Took: 80
Map Update Took: 51
Map Get Took: 40
Map Delete Took: 2

Chrome clearly has a strong advantage with getting and updating, but the delete performance is horrific. Maps use a tiny amount more memory in this case (overhead), but with only one Object/Map being tested with millions of keys the impact of overhead for maps is not expressed well. With memory management objects also do seem to free earlier if I am reading the profile correctly which might be one benefit in favor of objects.
In Firefox for this particular benchmark it is a different story:
Object Set Took: 435
Object Update Took: 126
Object Get Took: 50
Object Delete Took: 2
Map Set Took: 63
Map Update Took: 59
Map Get Took: 33
Map Delete Took: 1

I should immediately point out that in this particular benchmark deleting from objects in Firefox is not causing any problems, however in other benchmarks it has caused problems especially when there are many keys just as in Chrome. Maps are clearly superior in Firefox for large collections.
However this is not the end of the story, what about many small objects or maps? I have done a quick benchmark of this, but not an exhaustive one (setting/getting) of which performs best with a small number of keys in the above operations. This test is more about memory and initialization.
Map Create: 69    // new Map
Object Create: 34 // {}

Again these figures vary, but basically Object has a good lead. In some cases the lead for Objects over maps is extreme (~10 times better), but on average it was around 2-3 times better. It seems extreme performance spikes can work both ways. I only tested this in Chrome and creation to profile memory usage and overhead. I was quite surprised to see that in Chrome it appears that Maps with one key use around 30 times more memory than Objects with one key.
For testing many small objects with all the above operations (4 keys):
Chrome Object Took: 61
Chrome Map Took: 67
Firefox Object Took: 54
Firefox Map Took: 139

In terms of memory allocation these behaved the same in terms of freeing/GC, but Map used five times more memory. This test used four keys where as in the last test I only set one key so this would explain the reduction in memory overhead. I ran this test a few times and Map/Object are more or less neck and neck overall for Chrome in terms of overall speed. In Firefox for small Objects there is a definite performance advantage over maps overall.
This of course doesn't include the individual options which could vary wildly. I would not advice micro-optimizing with these figures. What you can get out of this is that as a rule of thumb, consider Maps more strongly for very large key value stores and objects for small key value stores.
Beyond that the best strategy with these two it to implement it and just make it work first. When profiling it is important to keep in mind that sometimes things that you wouldn't think would be slow when looking at them can be incredibly slow because of engine quirks as seen with the object key deletion case.
    An object behaves like a dictionary because JavaScript is dynamically typed, allowing you to add or remove properties at any time.
But Map() is much better because it:

Provides get, set, has, and delete methods.
Accepts any type for the keys instead of just strings.
Provides an iterator for easy for-of usage and maintains the order of results.
Doesn't have edge cases with prototypes and other properties showing up during iteration or copying.
Supports millions of items.
Is very fast.

If you need a dictionary then use a Map().
However, if you're only using string-based keys and need maximum read performance, then objects might be a better choice. This is because JavaScript engines compile objects down to C++ classes in the background, and the access path for properties is much faster than a function call for Map().get().
These classes are also cached, so creating a new object with the same exact properties means the engine will reuse an existing background class. Adding or removing a property causes the shape of the class to change and the backing class to be re-compiled, which is why using an object as a dictionary with lots of additions and deletions is very slow, but reads of existing keys without changing the object are very fast.
So if you have a write-once read-heavy workload with string keys then you can use an object as a high-performance dictionary, but for everything else use a Map().
    Summary:

Object: A data structure in which data is stored as key value pairs. In an object the key has to be a number, string, or symbol. The value can be anything so also other objects, functions, etc. An object is a nonordered data structure, i.e. the sequence of insertion of key value pairs is not remembered
ES6 Map: A data structure in which data is stored as key value pairs. In which a unique key maps to a value. Both the key and the value can be in any data type. A map is an iterable data structure. This means that the sequence of insertion is remembered and that we can access the elements in e.g. a for..of loop.

Key differences:

A Map is ordered and iterable, whereas a objects is not ordered and not iterable

We can put any type of data as a Map key, whereas objects can only have a number, string, or symbol as a key.

A Map inherits from Map.prototype. This offers all sorts of utility functions and properties which makes working with Map objects a lot easier.


Example:
object:
let obj = {};

// adding properties to a object
obj.prop1 = 1;
obj[2]    =  2;

// getting nr of properties of the object
console.log(Object.keys(obj).length)

// deleting a property
delete obj[2]

console.log(obj)

Map:
const myMap = new Map();

const keyString = 'a string',
    keyObj = {},
    keyFunc = function() {};

// setting the values
myMap.set(keyString, ""value associated with 'a string'"");
myMap.set(keyObj, 'value associated with keyObj');
myMap.set(keyFunc, 'value associated with keyFunc');

console.log(myMap.size); // 3

// getting the values
console.log(myMap.get(keyString));    // ""value associated with 'a string'""
console.log(myMap.get(keyObj));       // ""value associated with keyObj""
console.log(myMap.get(keyFunc));      // ""value associated with keyFunc""

console.log(myMap.get('a string'));   // ""value associated with 'a string'""
                         // because keyString === 'a string'
console.log(myMap.get({}));           // undefined, because keyObj !== {}
console.log(myMap.get(function() {})) // undefined, because keyFunc !== function () {}

Source: MDN
    I don't think the following points have been mentioned in the answers so far, and I thought they'd be worth mentioning.

Maps can be bigger
In Chrome I can get 16.7 million key/value pairs with Map vs. 11.1 million with a regular object. Almost exactly 50% more pairs with a Map. They both take up about 2 GB of memory before they crash, and so I think may be to do with memory limiting by chrome (Yep, try filling 2 Maps and you only get to 8.3 million pairs each before it crashes). You can test it yourself with this code (run them separately and not at the same time, obviously):
var m = new Map();
var i = 0;
while(1) {
    m.set(((10**30)*Math.random()).toString(36), ((10**30)*Math.random()).toString(36));
    i++;
    if(i%1000 === 0) { console.log(i/1000,""thousand"") }
}
// versus:
var m = {};
var i = 0;
while(1) {
    m[((10**30)*Math.random()).toString(36)] = ((10**30)*Math.random()).toString(36);
    i++;
    if(i%1000 === 0) { console.log(i/1000,""thousand"") }
}

Objects have some properties/keys already
This one has tripped me up before. Regular objects have toString, constructor, valueOf, hasOwnProperty, isPrototypeOf and a bunch of other pre-existing properties. This may not be a big problem for most use cases, but it has caused problems for me before.
Maps can be slower:
Due to the .get function call overhead and lack of internal optimisation, Map can be considerably slower than a plain old JavaScript object for some tasks.
    Additionally to being iterable in a well-defined order, and the ability to use arbitrary values as keys (except -0), maps can be useful because of the following reasons:


The spec enforces map operations to be sublinear on average.

Any non-stupid implementation of object will use a hash table or similar, so property lookups will probably be constant on average. Then objects could be even faster than maps. But that is not required by the spec.
Objects can have nasty unexpected behaviors.

For example, let's say you didn't set any foo property to a newly created object obj, so you expect obj.foo to return undefined. But foo could be built-in property inherited from Object.prototype. Or you attempt to create obj.foo by using an assignment, but some setter in Object.prototype runs instead of storing your value.

Maps prevent these kind of things. Well, unless some script messes up with Map.prototype. And Object.create(null) would work too, but then you lose the simple object initializer syntax.

    This is a short way for me to remember it: KOI

Keys. Object key is strings or symbols. Map keys can also be numbers (1 and ""1"" are different), objects, NaN, etc. It uses === to distinguish between keys, with one exception NaN !== NaN but you can use NaN as a key.
Order. The insertion order is remembered. So [...map] or [...map.keys()] has a particular order.
Interface. Object: obj[key] or obj.a (in some language, [] and []= are really part of the interface). Map has get(), set(), has(), delete() etc. Note that you can use map[123], but that is using it as a plain JavaScript object.

    According to Mozilla
Object vs. Map in JavaScript in a short way with examples.
Object- follows the same concept as that of map i.e. using key-value pair for storing data. But there are slight differences which makes map a better performer in certain situations.
Map- is a data structure which helps in storing the data in the form of pairs. The pair consists of a unique key and a value mapped to the key. It helps prevent duplicity.
Key differences

The Map is an instance of an object but the vice-versa is not true.

var map = new Map();
var obj = new Object();
console.log(obj instanceof Map);   // false
console.log(map instanceof Object);  // true


In Object, the data-type of the key-field is restricted to integer, strings, and symbols. Whereas in Map, the key-field can be of any data-type (integer, an array, an object)

var map = new Map();//Empty
map.set(1,'1');
map.set('one', 1);
map.set('{}', {name:'Hello, World!'});
map.set(12.3, 12.3)
map.set([12],[12345])

for(let [key,value] of map.entries())
  console.log(key+'---'+value)


In the Map, the original order of elements is preserved. This is not true in case of objects.

let obj ={
  1:'1',
  'one':1,
  '{}': {name:'Hello world'},
  12.3:12.3,
  [12]:[100]
}
console.log(obj)

    When to use maps instead of plain JavaScript objects
The plain JavaScript Object { key: 'value' } holds structured data. But a plain JavaScript object has its limitations:

Only strings and symbols can be used as keys of Objects. If we use any other things, say, numbers as keys of an object then during accessing those keys we will see those keys will be converted into strings implicitly causing us to lose consistency of types. const names= {1: 'one', 2: 'two'};  Object.keys(names);   // ['1', '2']

There are chances of accidentally overwriting inherited properties from prototypes by writing JavaScript identifiers as key names of an object (e.g., toString, constructor, etc.)

Another object cannot be used as key of an object, so no extra information can be written for an object by writing that object as key of another object and value of that another object will contain the extra information

Objects are not iterators

The size of an object cannot be determined directly


These limitations of Objects are solved by Maps but we must consider Maps as complement for Objects instead of replacement. Basically Map is just array of arrays but we must pass that array of arrays to the Map object as argument with new keyword otherwise only for array of arrays the useful properties and methods of Map aren't available. And remember key-value pairs inside the array of arrays or the Map must be separated by commas only, no colons like in plain objects.
Three tips to decide whether to use a Map or an Object

Use maps over objects when keys are unknown until run time because keys formed by user input or unknowingly can break the code which uses the object if those keys overwrite the inherited properties of the object, so map is safer in those cases. Also use maps when all keys are the same type and all maps are the same type.

Use maps if there is a need to store primitive values as keys.

Use objects if we need to operate on individual elements.


Benefits of using Maps
1. Map accepts any key type and preserves the type of key:
We know that if the object's key is not a string or symbol then JavaScript implicitly transforms it into a string. On the contrary, Map accepts any type of keys : string, number, boolean, symbol. etc. and Map preserves the original key type. Here we will use number as key inside a Map and it will remain a number:
const numbersMap= new Map();

numbersMap.set(1, 'one');

numbersMap.set(2, 'two');

const keysOfMap= [...numbersMap.keys()];

console.log(keysOfMap);                        // [1, 2]

Inside a Map we can even use an entire object as a key. There may be times when we want to store some object related data, without attaching this data inside the object itself so that we can work with lean objects but want to store some information about the object. In those cases we need to use Map so that we can make Object as key and related data of the object as value.
const foo= {name: foo};

const bar= {name: bar};

const kindOfMap= [[foo, 'Foo related data'], [bar, 'Bar related data']];

But the downside of this approach is the complexity of accessing the value by key, as we have to loop through the entire array to get the desired value.
function getBy Key(kindOfMap, key) {
    for (const [k, v]  of kindOfMap) {
        if(key === k) {
            return v;
        }
    }
    return undefined;
}

getByKey(kindOfMap, foo);            // 'Foo related data'

We can solve this problem of not getting direct access to the value by using a proper Map.
const foo= {name: 'foo'};

const bar= {name: 'bar'};

const myMap= new Map();

myMap.set(foo, 'Foo related data');
myMap.set(bar, 'Bar related data');

console.log(myMap.get(foo));            // 'Foo related data'

We could have done this using WeakMap, just have to write, const myMap= new WeakMap(). The differences between Map and WeakMap are that WeakMap allows for garbage collection of keys (here objects) so it prevents memory leaks, WeakMap accepts only objects as keys, and WeakMap has reduced set of methods.
2. Map has no restriction over key names:
For plain JavaScript objects we can accidentally overwrite property inherited from the prototype and it can be dangerous. Here we will overwrite the toString( ) property of the actor object:
const actor= {
    name: 'Harrison Ford',
    toString: 'Actor: Harrison Ford'
};

Now let's define a function, isPlainObject(), to determine if the supplied argument is a plain object and this function uses toString() method to check it:
function isPlainObject(value) {
    return value.toString() === '[object Object]';
}

isPlainObject(actor);        // TypeError : value.toString is not a function

// this is because inside actor object toString property is a string instead of inherited method from prototype

The Map does not have any restrictions on the key names. We can use key names like toString, constructor, etc. here although actorMap object has a property named toString, but the method toString( ) inherited from prototype of actorMap object works perfectly.
const actorMap= new Map();

actorMap.set('name', 'Harrison Ford');

actorMap.set('toString', 'Actor: Harrison Ford');

function isMap(value) {
  return value.toString() === '[object Map]';
}

console.log(isMap(actorMap));     // true

If we have a situation where user input creates keys then we must take those keys inside a Map instead of a plain object. This is because user may choose a custom field name like, toString, constructor, etc. then such key names in a plain object can potentially break the code that later uses this object. So the right solution is to bind the user interface state to a map, there is no way to break the Map:
const userCustomFieldsMap= new Map([['color', 'blue'], ['size', 'medium'], ['toString', 'A blue box']]);

3. Map is iterable:
To iterate a plain object's properties we need Object.entries( ) or Object.keys(). The Object.entries(plainObject) returns an array of key value pairs extracted from the object, we can then destructure those keys and values and can get normal keys and values output.
const colorHex= {
  'white': '#FFFFFF',
  'black': '#000000'
}

for(const [color, hex] of Object.entries(colorHex)) {
  console.log(color, hex);
}
//
'white' '#FFFFFF'
'black' '#000000'

As Maps are iterable that's why we do not need entries() methods to iterate over a Map and destructuring of key, value array can be done directly on the Map as inside a Map each element lives as an array of key value pairs separated by commas.
const colorHexMap = new Map();
colorHexMap.set('white', '#FFFFFF');
colorHexMap.set('black', '#000000');


for(const [color, hex] of colorHexMap) {
  console.log(color, hex);
}
//'white' '#FFFFFF'   'black' '#000000'

Also map.keys() returns an iterator over keys and map.values() returns an iterator over values.
4. We can easily know the size of a Map
We cannot directly determine the number of properties in a plain object. We need a helper function like, Object.keys() which returns an array with keys of the object then using length property we can get the number of keys or the size of the plain object.
const exams= {'John Rambo': '80%', 'James Bond': '60%'};

const sizeOfObj= Object.keys(exams).length;

console.log(sizeOfObj);       // 2

But in the case of Maps we can have direct access to the size of the Map using the map.size property.
const examsMap = new Map([['John Rambo', '80%'], ['James Bond', '60%']]);

console.log(examsMap.size);

    In addition to the other answers, I've found that Maps are more unwieldy and verbose to operate with than objects.

obj[key] += x
// vs.
map.set(map.get(key) + x)


This is important, because shorter code is faster to read, more directly expressive, and better kept in the programmer's head.

Another aspect: because set() returns the map, not the value, it's impossible to chain assignments.

foo = obj[key] = x;  // Does what you expect
foo = map.set(key, x)  // foo !== x; foo === map


Debugging maps is also more painful. Below, you can't actually see what keys are in the map. You'd have to write code to do that.



Objects can be evaluated by any IDE:


    One aspect of the Map that is not given much press here is lookup. According to the specification:

A Map object must be implemented using either hash tables or other
mechanisms that, on average, provide access times that are sublinear
on the number of elements in the collection. The data structures used
in this Map objects specification is only intended to describe the
required observable semantics of Map objects. It is not intended to be
a viable implementation model.

For collections that have a huge number of items and require item lookups, this is a huge performance boost.
TL;DR - Object lookup is not specified, so it can be on the order of the number of elements in the object, i.e., O(n). Map lookup must use a hash table or similar, so Map lookup is the same regardless of Map size, i.e. O(1).
    These two tips can help you to decide whether to use a Map or an Object:

Use maps over objects when keys are unknown until run time, and when
all keys are the same type and all values are the same type.

Use maps in case if there is a need to store primitive values as keys
because object treats each key as a string either its a number value,
Boolean value or any other primitive value.

Use objects when there is logic that operates on individual elements.


Source: Keyed collections
    I came across this post by Minko Gechev which clearly explains the major differences.

    ","[484, 429, 174, 63, 37, 40, 5, 6, 8, 14, 19, 2, 0, 5]",227792,109,2013-08-30T21:47:42,2022-01-03 20:49:48Z,javascript 
